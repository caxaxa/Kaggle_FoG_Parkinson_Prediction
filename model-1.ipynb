{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Credit to 此般浅薄 for the initial inspiration","metadata":{}},{"cell_type":"code","source":"# Install tsflex and seglearn\n!pip install tsflex --no-index --find-links=file:///kaggle/input/time-series-tools\n!pip install seglearn --no-index --find-links=file:///kaggle/input/time-series-tools","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":26.425736,"end_time":"2023-04-16T22:41:22.382325","exception":false,"start_time":"2023-04-16T22:40:55.956589","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-30T15:55:35.190340Z","iopub.execute_input":"2023-05-30T15:55:35.190803Z","iopub.status.idle":"2023-05-30T15:56:06.673394Z","shell.execute_reply.started":"2023-05-30T15:55:35.190760Z","shell.execute_reply":"2023-05-30T15:56:06.671908Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Looking in links: file:///kaggle/input/time-series-tools\nProcessing /kaggle/input/time-series-tools/tsflex-0.3.0-py3-none-any.whl\nRequirement already satisfied: tqdm<5.0.0,>=4.62.3 in /opt/conda/lib/python3.7/site-packages (from tsflex) (4.64.1)\nRequirement already satisfied: multiprocess<0.71.0,>=0.70.12 in /opt/conda/lib/python3.7/site-packages (from tsflex) (0.70.14)\nRequirement already satisfied: numpy<2.0.0,>=1.21.5 in /opt/conda/lib/python3.7/site-packages (from tsflex) (1.21.6)\nRequirement already satisfied: dill<0.4.0,>=0.3.4 in /opt/conda/lib/python3.7/site-packages (from tsflex) (0.3.6)\nRequirement already satisfied: pandas<2.0.0,>=1.3.5 in /opt/conda/lib/python3.7/site-packages (from tsflex) (1.3.5)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas<2.0.0,>=1.3.5->tsflex) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas<2.0.0,>=1.3.5->tsflex) (2022.7.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas<2.0.0,>=1.3.5->tsflex) (1.16.0)\nInstalling collected packages: tsflex\nSuccessfully installed tsflex-0.3.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mLooking in links: file:///kaggle/input/time-series-tools\nProcessing /kaggle/input/time-series-tools/seglearn-1.2.5-py3-none-any.whl\nRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.7/site-packages (from seglearn) (1.0.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from seglearn) (1.21.6)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from seglearn) (1.7.3)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seglearn) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seglearn) (3.1.0)\nInstalling collected packages: seglearn\nSuccessfully installed seglearn-1.2.5\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn import *\nimport glob\nfrom tqdm.auto import tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom os import path\nfrom pathlib import Path\nfrom seglearn.feature_functions import base_features, emg_features\nfrom tsflex.features import FeatureCollection, MultipleFeatureDescriptors\nfrom tsflex.features.integrations import seglearn_feature_dict_wrapper\nfrom sklearn.model_selection import GroupKFold\nimport lightgbm as lgb\nfrom sklearn.multioutput import MultiOutputRegressor\nfrom sklearn.base import clone\nfrom sklearn.metrics import average_precision_score","metadata":{"papermill":{"duration":2.755431,"end_time":"2023-04-16T22:41:25.148066","exception":false,"start_time":"2023-04-16T22:41:22.392635","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-30T15:56:06.677161Z","iopub.execute_input":"2023-05-30T15:56:06.677751Z","iopub.status.idle":"2023-05-30T15:56:10.149638Z","shell.execute_reply.started":"2023-05-30T15:56:06.677687Z","shell.execute_reply":"2023-05-30T15:56:10.148109Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .time    { background: #40CC40; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tbody td { text-align: left; }\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .sp {  opacity: 0.25;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"# Grab important files\n\n## Open Files","metadata":{"papermill":{"duration":0.009576,"end_time":"2023-04-16T22:41:25.16752","exception":false,"start_time":"2023-04-16T22:41:25.157944","status":"completed"},"tags":[]}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root = '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/'\n\ntrain = glob.glob(path.join(root, 'train/**/**')) # Lists all files in the train directory recursively.\ntest = glob.glob(path.join(root, 'test/**/**')) # Lists all files in the test directory recursively.\n\n# Reads CSV files into pandas DataFrames.\nsubjects = pd.read_csv(path.join(root, 'subjects.csv')) \ntasks = pd.read_csv(path.join(root, 'tasks.csv'))\nevents = pd.read_csv(path.join(root, 'events.csv'))\ntdcsfog_metadata = pd.read_csv(path.join(root, 'tdcsfog_metadata.csv'))\ndefog_metadata = pd.read_csv(path.join(root, 'defog_metadata.csv')) \n\n# Adds a new column to each metadata dataframe to distinguish between them.\ntdcsfog_metadata['Module'] = 'tdcsfog'\ndefog_metadata['Module'] = 'defog'\n\n# Concatenates the two metadata dataframes into one.\nfull_metadata = pd.concat([tdcsfog_metadata, defog_metadata])\n","metadata":{"papermill":{"duration":0.170669,"end_time":"2023-04-16T22:41:25.347896","exception":false,"start_time":"2023-04-16T22:41:25.177227","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-30T15:56:10.151162Z","iopub.execute_input":"2023-05-30T15:56:10.152173Z","iopub.status.idle":"2023-05-30T15:56:10.302144Z","shell.execute_reply.started":"2023-05-30T15:56:10.152130Z","shell.execute_reply":"2023-05-30T15:56:10.300593Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"seed = 42\ncluster_size = 8","metadata":{"papermill":{"duration":0.02392,"end_time":"2023-04-16T22:41:25.577077","exception":false,"start_time":"2023-04-16T22:41:25.553157","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-30T15:56:10.305826Z","iopub.execute_input":"2023-05-30T15:56:10.306262Z","iopub.status.idle":"2023-05-30T15:56:10.311844Z","shell.execute_reply.started":"2023-05-30T15:56:10.306217Z","shell.execute_reply":"2023-05-30T15:56:10.310336Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"subjects","metadata":{"execution":{"iopub.status.busy":"2023-05-30T15:56:10.314033Z","iopub.execute_input":"2023-05-30T15:56:10.314880Z","iopub.status.idle":"2023-05-30T15:56:10.359464Z","shell.execute_reply.started":"2023-05-30T15:56:10.314818Z","shell.execute_reply":"2023-05-30T15:56:10.358104Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"    Subject  Visit  Age Sex  YearsSinceDx  UPDRSIII_On  UPDRSIII_Off  NFOGQ\n0    00f674    2.0   63   M          27.0         43.0          49.0     24\n1    00f674    1.0   63   M          27.0         31.0          30.0     26\n2    02bc69    NaN   69   M           4.0         21.0           NaN     22\n3    040587    2.0   75   M          26.0         52.0          69.0     21\n4    040587    1.0   75   M          26.0         47.0          75.0     24\n..      ...    ...  ...  ..           ...          ...           ...    ...\n168  f80507    1.0   57   M           2.0         12.0           NaN      0\n169  fa8764    NaN   60   F           7.0         30.0           NaN     19\n170  fba3a3    1.0   65   F           8.0         28.0           NaN      0\n171  fcb9f5    1.0   69   M           3.5         27.0          49.0     23\n172  fcb9f5    2.0   69   M           3.5         28.0          34.0     21\n\n[173 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Subject</th>\n      <th>Visit</th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>YearsSinceDx</th>\n      <th>UPDRSIII_On</th>\n      <th>UPDRSIII_Off</th>\n      <th>NFOGQ</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00f674</td>\n      <td>2.0</td>\n      <td>63</td>\n      <td>M</td>\n      <td>27.0</td>\n      <td>43.0</td>\n      <td>49.0</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00f674</td>\n      <td>1.0</td>\n      <td>63</td>\n      <td>M</td>\n      <td>27.0</td>\n      <td>31.0</td>\n      <td>30.0</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>02bc69</td>\n      <td>NaN</td>\n      <td>69</td>\n      <td>M</td>\n      <td>4.0</td>\n      <td>21.0</td>\n      <td>NaN</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>040587</td>\n      <td>2.0</td>\n      <td>75</td>\n      <td>M</td>\n      <td>26.0</td>\n      <td>52.0</td>\n      <td>69.0</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>040587</td>\n      <td>1.0</td>\n      <td>75</td>\n      <td>M</td>\n      <td>26.0</td>\n      <td>47.0</td>\n      <td>75.0</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>168</th>\n      <td>f80507</td>\n      <td>1.0</td>\n      <td>57</td>\n      <td>M</td>\n      <td>2.0</td>\n      <td>12.0</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>169</th>\n      <td>fa8764</td>\n      <td>NaN</td>\n      <td>60</td>\n      <td>F</td>\n      <td>7.0</td>\n      <td>30.0</td>\n      <td>NaN</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>170</th>\n      <td>fba3a3</td>\n      <td>1.0</td>\n      <td>65</td>\n      <td>F</td>\n      <td>8.0</td>\n      <td>28.0</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>171</th>\n      <td>fcb9f5</td>\n      <td>1.0</td>\n      <td>69</td>\n      <td>M</td>\n      <td>3.5</td>\n      <td>27.0</td>\n      <td>49.0</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>172</th>\n      <td>fcb9f5</td>\n      <td>2.0</td>\n      <td>69</td>\n      <td>M</td>\n      <td>3.5</td>\n      <td>28.0</td>\n      <td>34.0</td>\n      <td>21</td>\n    </tr>\n  </tbody>\n</table>\n<p>173 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Clean the Data","metadata":{}},{"cell_type":"code","source":"# Imputes missing data for subject 'fe5d84', setting its sex as 'F'.\nsubjects.loc[subjects['Subject'] == 'fe5d84', 'Sex'] = 'F'\n\n# Transforms categorical variable 'Sex' into integers.\nsubjects['Sex'] = subjects['Sex'].factorize()[0]\n\n# Fills any remaining missing values with 0 and takes the median value for each subject.\nsubjects = subjects.fillna(0).groupby('Subject').median()\n\n# Clusters the subjects into a predetermined number of clusters and stores the cluster labels in a new column.\nsubjects['s_group'] = cluster.KMeans(n_clusters = cluster_size, random_state = seed).fit_predict(subjects[subjects.columns[1:]])\n\n# Renames columns in the subjects dataframe.\nnew_names = {'Visit':'s_visit','Age':'s_age','YearsSinceDx':'s_years','UPDRSIII_On':'s_on','UPDRSIII_Off':'s_off','NFOGQ':'s_NFOGQ', 'Sex': 's_sex'}\nsubjects = subjects.rename(columns = new_names)\n","metadata":{"papermill":{"duration":0.110973,"end_time":"2023-04-16T22:41:25.698532","exception":false,"start_time":"2023-04-16T22:41:25.587559","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-30T15:56:10.361087Z","iopub.execute_input":"2023-05-30T15:56:10.361496Z","iopub.status.idle":"2023-05-30T15:56:10.431029Z","shell.execute_reply.started":"2023-05-30T15:56:10.361458Z","shell.execute_reply":"2023-05-30T15:56:10.429875Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Process Tasks","metadata":{}},{"cell_type":"code","source":"# Creates a new feature, 'Duration', which is the difference between 'End' and 'Begin'.\ntasks['Duration'] = tasks['End'] - tasks['Begin']\n\n# Transforms the tasks dataframe from long to wide format, filling missing values with 0.\ntasks = pd.pivot_table(tasks, values=['Duration'], index=['Id'], columns=['Task'], aggfunc='sum', fill_value=0)\ntasks.columns = [c[1] for c in tasks.columns] # Renames the columns.\ntasks = tasks.reset_index()\n\n# Clusters the tasks into a predetermined number of clusters and stores the cluster labels in a new column.\ntasks['t_group'] = cluster.KMeans(n_clusters = cluster_size, random_state = seed).fit_predict(tasks[tasks.columns[1:]])\n","metadata":{"papermill":{"duration":0.108699,"end_time":"2023-04-16T22:41:25.903139","exception":false,"start_time":"2023-04-16T22:41:25.79444","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-30T15:56:10.432870Z","iopub.execute_input":"2023-05-30T15:56:10.433754Z","iopub.status.idle":"2023-05-30T15:56:10.561170Z","shell.execute_reply.started":"2023-05-30T15:56:10.433704Z","shell.execute_reply":"2023-05-30T15:56:10.555302Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Merge metadata and process","metadata":{}},{"cell_type":"code","source":"# Merges the full_metadata dataframe with the subjects dataframe.\nmetadata_w_subjects = full_metadata.merge(subjects, how='left', on='Subject').copy()\nfeatures = metadata_w_subjects.columns # Stores the names of the columns.\n\n# Transforms categorical variable 'Medication' into integers.\nmetadata_w_subjects['Medication'] = metadata_w_subjects['Medication'].factorize()[0]\n","metadata":{"papermill":{"duration":0.060364,"end_time":"2023-04-16T22:41:26.141472","exception":false,"start_time":"2023-04-16T22:41:26.081108","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-30T15:56:10.563485Z","iopub.execute_input":"2023-05-30T15:56:10.564382Z","iopub.status.idle":"2023-05-30T15:56:10.581347Z","shell.execute_reply.started":"2023-05-30T15:56:10.564327Z","shell.execute_reply":"2023-05-30T15:56:10.579603Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Using Kaggle User Model LGBM to regress baseline\n\nfrom tsflex.features import FeatureCollection, MultipleFeatureDescriptors\nfrom tsflex.features.integrations import seglearn_feature_dict_wrapper from the time series data itself","metadata":{"papermill":{"duration":0.021931,"end_time":"2023-04-16T22:41:26.370019","exception":false,"start_time":"2023-04-16T22:41:26.348088","status":"completed"},"tags":[]}},{"cell_type":"code","source":"basic_feats = MultipleFeatureDescriptors(\n    functions=seglearn_feature_dict_wrapper(base_features()),\n    series_names=['AccV', 'AccML', 'AccAP'],\n    windows=[5000],\n    strides=[5000],\n)\n\nemg_feats = emg_features()\ndel emg_feats['simple square integral'] # is same as abs_energy (which is in base_features)\n\nemg_feats = MultipleFeatureDescriptors(\n    functions=seglearn_feature_dict_wrapper(emg_feats),\n    series_names=['AccV', 'AccML', 'AccAP'],\n    windows=[5000],\n    strides=[5000],\n)\n\nfc = FeatureCollection([basic_feats, emg_feats])","metadata":{"papermill":{"duration":0.032203,"end_time":"2023-04-16T22:41:26.517639","exception":false,"start_time":"2023-04-16T22:41:26.485436","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-30T15:56:10.585224Z","iopub.execute_input":"2023-05-30T15:56:10.585710Z","iopub.status.idle":"2023-05-30T15:56:10.597793Z","shell.execute_reply.started":"2023-05-30T15:56:10.585658Z","shell.execute_reply":"2023-05-30T15:56:10.596639Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Here I optimized the original code to be less memory intensive\n","metadata":{}},{"cell_type":"code","source":"import gc","metadata":{"execution":{"iopub.status.busy":"2023-05-30T15:56:10.602035Z","iopub.execute_input":"2023-05-30T15:56:10.602546Z","iopub.status.idle":"2023-05-30T15:56:10.613965Z","shell.execute_reply.started":"2023-05-30T15:56:10.602497Z","shell.execute_reply":"2023-05-30T15:56:10.612768Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"metadata_w_subjects","metadata":{"execution":{"iopub.status.busy":"2023-05-30T15:56:44.487719Z","iopub.execute_input":"2023-05-30T15:56:44.488602Z","iopub.status.idle":"2023-05-30T15:56:44.528505Z","shell.execute_reply.started":"2023-05-30T15:56:44.488550Z","shell.execute_reply":"2023-05-30T15:56:44.527332Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"             Id Subject  Visit  Test  Medication   Module  s_visit  s_age  \\\n0    003f117e14  4dc2f8      3   2.0           0  tdcsfog      0.0   68.0   \n1    009ee11563  f62eec      4   2.0           0  tdcsfog      0.0   71.0   \n2    011322847a  231c3b      2   2.0           0  tdcsfog      0.0   67.0   \n3    01d0fe7266  231c3b      2   1.0           1  tdcsfog      0.0   67.0   \n4    024418ba39  fa8764     19   3.0           0  tdcsfog      0.0   60.0   \n..          ...     ...    ...   ...         ...      ...      ...    ...   \n965  f3a921edee  1a778d      1   NaN           1    defog      1.5   65.0   \n966  f40e8c6ebe  575c60      1   NaN           1    defog      1.0   28.0   \n967  f8ddbdd98d  107712      1   NaN           0    defog      1.0   82.0   \n968  f9efef91fb  5d9cae      2   NaN           1    defog      1.5   72.0   \n969  f9fc61ce85  040587      1   NaN           0    defog      1.5   75.0   \n\n     s_sex  s_years  s_on  s_off  s_NFOGQ  s_group  \n0      1.0      9.0  17.0   15.0     15.0        3  \n1      0.0     10.0  42.0    0.0     24.0        0  \n2      0.0     12.0  27.0   28.0     19.0        3  \n3      0.0     12.0  27.0   28.0     19.0        3  \n4      1.0      7.0  30.0    0.0     19.0        2  \n..     ...      ...   ...    ...      ...      ...  \n965    0.0      7.0  50.0   59.5     24.5        1  \n966    0.0      4.0  54.0   50.0     25.0        1  \n967    1.0     11.0  38.0   42.0     21.0        6  \n968    0.5     14.0  22.5   39.0     16.0        7  \n969    0.0     26.0  49.5   72.0     22.5        5  \n\n[970 rows x 14 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Subject</th>\n      <th>Visit</th>\n      <th>Test</th>\n      <th>Medication</th>\n      <th>Module</th>\n      <th>s_visit</th>\n      <th>s_age</th>\n      <th>s_sex</th>\n      <th>s_years</th>\n      <th>s_on</th>\n      <th>s_off</th>\n      <th>s_NFOGQ</th>\n      <th>s_group</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>003f117e14</td>\n      <td>4dc2f8</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>tdcsfog</td>\n      <td>0.0</td>\n      <td>68.0</td>\n      <td>1.0</td>\n      <td>9.0</td>\n      <td>17.0</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>009ee11563</td>\n      <td>f62eec</td>\n      <td>4</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>tdcsfog</td>\n      <td>0.0</td>\n      <td>71.0</td>\n      <td>0.0</td>\n      <td>10.0</td>\n      <td>42.0</td>\n      <td>0.0</td>\n      <td>24.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>011322847a</td>\n      <td>231c3b</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>tdcsfog</td>\n      <td>0.0</td>\n      <td>67.0</td>\n      <td>0.0</td>\n      <td>12.0</td>\n      <td>27.0</td>\n      <td>28.0</td>\n      <td>19.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01d0fe7266</td>\n      <td>231c3b</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>tdcsfog</td>\n      <td>0.0</td>\n      <td>67.0</td>\n      <td>0.0</td>\n      <td>12.0</td>\n      <td>27.0</td>\n      <td>28.0</td>\n      <td>19.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>024418ba39</td>\n      <td>fa8764</td>\n      <td>19</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>tdcsfog</td>\n      <td>0.0</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>30.0</td>\n      <td>0.0</td>\n      <td>19.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>965</th>\n      <td>f3a921edee</td>\n      <td>1a778d</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>defog</td>\n      <td>1.5</td>\n      <td>65.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>50.0</td>\n      <td>59.5</td>\n      <td>24.5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>966</th>\n      <td>f40e8c6ebe</td>\n      <td>575c60</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>defog</td>\n      <td>1.0</td>\n      <td>28.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>54.0</td>\n      <td>50.0</td>\n      <td>25.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>967</th>\n      <td>f8ddbdd98d</td>\n      <td>107712</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>defog</td>\n      <td>1.0</td>\n      <td>82.0</td>\n      <td>1.0</td>\n      <td>11.0</td>\n      <td>38.0</td>\n      <td>42.0</td>\n      <td>21.0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>968</th>\n      <td>f9efef91fb</td>\n      <td>5d9cae</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>defog</td>\n      <td>1.5</td>\n      <td>72.0</td>\n      <td>0.5</td>\n      <td>14.0</td>\n      <td>22.5</td>\n      <td>39.0</td>\n      <td>16.0</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>969</th>\n      <td>f9fc61ce85</td>\n      <td>040587</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>defog</td>\n      <td>1.5</td>\n      <td>75.0</td>\n      <td>0.0</td>\n      <td>26.0</td>\n      <td>49.5</td>\n      <td>72.0</td>\n      <td>22.5</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>970 rows × 14 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def reader(file):\n    try:\n        df = pd.read_csv(file, index_col='Time')\n        path_split = file.split('/')\n        df['Id'] = path_split[-1].split('.')[0]\n        dataset = Path(file).parts[-2]\n        df['Module'] = dataset\n        df['Time_frac']=(df.index/df.index.max()).values\n        # Check if optional columns exist in df, if not create them with default values\n        for col in ['StartHesitation', 'Turn', 'Walking']:\n            if col not in df.columns:\n                df[col] = 0 # or any other default value\n        chunksize = 100000 # adjust this value depending on your system memory\n        chunks = []\n        for chunk in pd.read_csv(file, index_col='Time', chunksize=chunksize,\n                                 usecols=['Time', 'AccV', 'AccML', 'AccAP', 'StartHesitation', 'Turn' , 'Walking']):\n\n            path_split = file.split('/')\n            chunk['Id'] = path_split[-1].split('.')[0]\n            dataset = Path(file).parts[-2]\n            chunk['Module'] = dataset\n\n            chunk['Time_frac']=(chunk.index/chunk.index.max()).values\n\n            chunk = pd.merge(chunk, tasks[['Id','t_group']], how='left', on='Id').fillna(-1)\n            chunk = pd.merge(chunk, metadata_w_subjects[['Id','Subject', 'Visit','Test','Medication','s_group']], how='left', on='Id').fillna(-1)\n\n            chunk_feats = fc.calculate(chunk, return_df=True, include_final_window=True, approve_sparsity=True, window_idx=\"begin\").astype(np.float32)\n            chunk = chunk.merge(chunk_feats, how=\"left\", left_index=True, right_index=True)\n            \n            chunk.fillna(method=\"ffill\", inplace=True)\n\n            chunks.append(chunk)\n\n        df = pd.concat(chunks)\n        \n        # Clear the memory from chunks list\n        del chunks\n        gc.collect()\n        \n        return df\n    except Exception as e:\n        print(f\"Error processing file {file}: {e}\")\n        return pd.DataFrame()\n\ntrain = pd.concat([reader(f) for f in tqdm(train)]).fillna(0); print(train.shape)\n","metadata":{"papermill":{"duration":533.977331,"end_time":"2023-04-16T22:50:20.513889","exception":false,"start_time":"2023-04-16T22:41:26.536558","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-30T16:01:34.533707Z","iopub.execute_input":"2023-05-30T16:01:34.534187Z","iopub.status.idle":"2023-05-30T16:01:45.394134Z","shell.execute_reply.started":"2023-05-30T16:01:34.534146Z","shell.execute_reply":"2023-05-30T16:01:45.392237Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/970 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcc97c3f844a440095bd19b8736b2a6f"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/1550375572.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_27/1550375572.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_27/1550375572.py\u001b[0m in \u001b[0;36mreader\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# Clear the memory from chunks list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"train = reader('/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/defog/be9d33541d.csv')","metadata":{"execution":{"iopub.status.busy":"2023-05-30T16:03:37.364731Z","iopub.execute_input":"2023-05-30T16:03:37.365452Z","iopub.status.idle":"2023-05-30T16:03:38.907153Z","shell.execute_reply.started":"2023-05-30T16:03:37.365392Z","shell.execute_reply":"2023-05-30T16:03:38.905725Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"\ncols = [c for c in train.columns if c not in ['Id','Subject','Module', 'Time', 'StartHesitation', 'Turn' , 'Walking', 'Valid', 'Task','Event']]\npcols = ['StartHesitation', 'Turn' , 'Walking']\nscols = ['Id', 'StartHesitation', 'Turn' , 'Walking']\n","metadata":{"execution":{"iopub.status.busy":"2023-05-30T16:03:39.251229Z","iopub.execute_input":"2023-05-30T16:03:39.251746Z","iopub.status.idle":"2023-05-30T16:03:39.260094Z","shell.execute_reply.started":"2023-05-30T16:03:39.251703Z","shell.execute_reply":"2023-05-30T16:03:39.258654Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.048438,"end_time":"2023-04-16T22:50:20.575881","exception":false,"start_time":"2023-04-16T22:50:20.527443","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_params_ = { \n    'gpu_platform_id': 0,\n    'gpu_device_id': 0,\n    'num_leaves': 31,  # consider adjusting this based on max_depth\n    'max_depth': 30,  # decrease from 50 to 30\n    'min_child_weight': 20,  # you can try larger values to avoid overfitting\n    'subsample': 0.8,  # slightly decrease from 0.996 to control overfitting\n    'colsample_bytree': 0.8,  # slightly decrease from 0.9 to control overfitting\n    'n_estimators': 500,  # increase from 291 if computational cost is not a problem\n    'learning_rate': 0.05,  # increase from 0.01 to make learning faster, but you may want to decrease it if the model isn't accurate enough\n}\ndef custom_average_precision(y_true, y_pred):\n    score = average_precision_score(y_true, y_pred)\n    return 'average_precision', score, True\n\nclass LGBMMultiOutputRegressor(MultiOutputRegressor):\n    def fit(self, X, y, eval_set=None, **fit_params):\n        self.estimators_ = [clone(self.estimator) for _ in range(y.shape[1])]\n        \n        for i, estimator in enumerate(self.estimators_):\n            if eval_set:\n                fit_params['eval_set'] = [(eval_set[0], eval_set[1][:, i])]\n            estimator.fit(X, y[:, i], **fit_params)\n        \n        return self","metadata":{"papermill":{"duration":0.031497,"end_time":"2023-04-16T22:50:29.071479","exception":false,"start_time":"2023-04-16T22:50:29.039982","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-29T22:12:54.509893Z","iopub.execute_input":"2023-05-29T22:12:54.511370Z","iopub.status.idle":"2023-05-29T22:12:54.524498Z","shell.execute_reply.started":"2023-05-29T22:12:54.511304Z","shell.execute_reply":"2023-05-29T22:12:54.523187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kfold = GroupKFold(5)\ngroups=kfold.split(train, groups=train.Subject)\n\nregs = []\ncvs = []\n\nfor _, (tr_idx, te_idx) in enumerate(tqdm(groups, total=5, desc=\"Folds\")):\n    \n    tr_idx = pd.Series(tr_idx).sample(n=2000000,random_state=42).values\n\n    multioutput_regressor = LGBMMultiOutputRegressor(lgb.LGBMRegressor(**best_params_))\n\n    x_train = train.loc[tr_idx, cols].to_numpy()\n    y_train = train.loc[tr_idx, pcols].to_numpy()\n    \n    x_test = train.loc[te_idx, cols].to_numpy()\n    y_test = train.loc[te_idx, pcols].to_numpy()\n\n    multioutput_regressor.fit(\n        x_train, y_train,\n        eval_set=(x_test, y_test),\n        eval_metric=custom_average_precision,\n        early_stopping_rounds=15,\n        verbose = 0,\n    )\n    \n    regs.append(multioutput_regressor)\n    \n    cv = metrics.average_precision_score(y_test, multioutput_regressor.predict(x_test).clip(0.0,1.0))\n    \n    cvs.append(cv)\n    \nprint(cvs)\nprint(np.mean(cvs))","metadata":{"papermill":{"duration":943.279901,"end_time":"2023-04-16T23:06:12.366865","exception":false,"start_time":"2023-04-16T22:50:29.086964","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-29T22:12:54.526207Z","iopub.execute_input":"2023-05-29T22:12:54.526714Z","iopub.status.idle":"2023-05-29T22:30:01.918409Z","shell.execute_reply.started":"2023-05-29T22:12:54.526660Z","shell.execute_reply":"2023-05-29T22:30:01.916942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\n\n# Save the model\nwith open('model.pkl', 'wb') as f:\n    pickle.dump(regs, f)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-29T22:47:16.653982Z","iopub.execute_input":"2023-05-29T22:47:16.654532Z","iopub.status.idle":"2023-05-29T22:47:16.698515Z","shell.execute_reply.started":"2023-05-29T22:47:16.654468Z","shell.execute_reply":"2023-05-29T22:47:16.697193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sub = pd.read_csv(path.join(root, 'sample_submission.csv'))\n# submission = []\n\n# # Load the saved model\n# with open('model.pkl', 'rb') as f:\n#     loaded_model = pickle.load(f)\n\n# for f in test:\n#     df = pd.read_csv(f)\n#     df.set_index('Time', drop=True, inplace=True)\n\n#     df['Id'] = f.split('/')[-1].split('.')[0]\n\n#     dataset = Path(f).parts[-2]\n        \n# #     if dataset == 'tdcsfog':\n# #         df.AccV = df.AccV / 9.80665\n# #         df.AccML = df.AccML / 9.80665\n# #         df.AccAP = df.AccAP / 9.80665\n            \n#     df['Time_frac']=(df.index/df.index.max()).values\n#     df = pd.merge(df, tasks[['Id','t_group']], how='left', on='Id').fillna(-1)\n\n#     df = pd.merge(df, metadata_w_subjects[['Id','Subject', 'Visit','Test','Medication','s_group']], how='left', on='Id').fillna(-1)\n#     df_feats = fc.calculate(df, return_df=True, include_final_window=True, approve_sparsity=True, window_idx=\"begin\")\n#     df = df.merge(df_feats, how=\"left\", left_index=True, right_index=True)\n#     df.fillna(method=\"ffill\", inplace=True)\n\n# #     # stride\n# #     df[\"Stride\"] = df[\"AccV\"] + df[\"AccML\"] + df[\"AccAP\"]\n\n# #     # step\n# #     df[\"Step\"] = np.sqrt(abs(df[\"Stride\"]))\n        \n#     res_vals = []\n    \n#     for i_fold in range(5):\n        \n#         pred = loaded_model[i_fold].predict(df[cols]).clip(0.0,1.0)\n#         res_vals.append(np.expand_dims(np.round(pred, 3), axis = 2))\n        \n#     res_vals = np.mean(np.concatenate(res_vals, axis = 2), axis = 2)\n#     res = pd.DataFrame(res_vals, columns=pcols)\n    \n#     df = pd.concat([df,res], axis=1)\n#     df['Id'] = df['Id'].astype(str) + '_' + df.index.astype(str)\n#     submission.append(df[scols])\n    \n# submission = pd.concat(submission)\n# submission = pd.merge(sub[['Id']], submission, how='left', on='Id').fillna(0.0)\n# submission[scols].to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-29T22:47:58.062343Z","iopub.execute_input":"2023-05-29T22:47:58.063038Z","iopub.status.idle":"2023-05-29T22:48:08.951378Z","shell.execute_reply.started":"2023-05-29T22:47:58.062984Z","shell.execute_reply":"2023-05-29T22:48:08.949764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission","metadata":{"execution":{"iopub.status.busy":"2023-05-29T22:48:20.489332Z","iopub.execute_input":"2023-05-29T22:48:20.489859Z","iopub.status.idle":"2023-05-29T22:48:20.512883Z","shell.execute_reply.started":"2023-05-29T22:48:20.489807Z","shell.execute_reply":"2023-05-29T22:48:20.511175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-05-29T22:44:51.409641Z","iopub.execute_input":"2023-05-29T22:44:51.410196Z","iopub.status.idle":"2023-05-29T22:44:51.423645Z","shell.execute_reply.started":"2023-05-29T22:44:51.410122Z","shell.execute_reply":"2023-05-29T22:44:51.422460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"execution":{"iopub.status.busy":"2023-05-29T22:44:54.930928Z","iopub.execute_input":"2023-05-29T22:44:54.931425Z","iopub.status.idle":"2023-05-29T22:44:54.951573Z","shell.execute_reply.started":"2023-05-29T22:44:54.931380Z","shell.execute_reply":"2023-05-29T22:44:54.949911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}