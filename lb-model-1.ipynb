{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13565f4e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-06T17:06:46.439530Z",
     "iopub.status.busy": "2024-05-06T17:06:46.438572Z",
     "iopub.status.idle": "2024-05-06T17:06:47.225003Z",
     "shell.execute_reply": "2024-05-06T17:06:47.223814Z"
    },
    "papermill": {
     "duration": 0.805953,
     "end_time": "2024-05-06T17:06:47.227299",
     "exception": false,
     "start_time": "2024-05-06T17:06:46.421346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/leash-BELKA/sample_submission.csv\n",
      "/kaggle/input/leash-BELKA/train.parquet\n",
      "/kaggle/input/leash-BELKA/test.parquet\n",
      "/kaggle/input/leash-BELKA/train.csv\n",
      "/kaggle/input/leash-BELKA/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under theinput directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3144fe45",
   "metadata": {
    "papermill": {
     "duration": 0.012748,
     "end_time": "2024-05-06T17:06:47.253752",
     "exception": false,
     "start_time": "2024-05-06T17:06:47.241004",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LB Competition:\n",
    "\n",
    "## 1. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0124a10f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T17:06:47.284821Z",
     "iopub.status.busy": "2024-05-06T17:06:47.284009Z",
     "iopub.status.idle": "2024-05-06T17:06:47.288398Z",
     "shell.execute_reply": "2024-05-06T17:06:47.287406Z"
    },
    "papermill": {
     "duration": 0.023585,
     "end_time": "2024-05-06T17:06:47.290735",
     "exception": false,
     "start_time": "2024-05-06T17:06:47.267150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## Loading The Data\n",
    "\n",
    "# # Change to full Dataseet  for Massive Training and for testing\n",
    "# df_train = pd.read_csv('/kaggle/input/leash-BELKA/train.csv', nrows=1000)\n",
    "# df_test = pd.read_csv('/kaggle/input/leash-BELKA/test.csv', nrows=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d82f9342",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T17:06:47.320416Z",
     "iopub.status.busy": "2024-05-06T17:06:47.319617Z",
     "iopub.status.idle": "2024-05-06T17:06:47.323830Z",
     "shell.execute_reply": "2024-05-06T17:06:47.322957Z"
    },
    "papermill": {
     "duration": 0.021643,
     "end_time": "2024-05-06T17:06:47.325915",
     "exception": false,
     "start_time": "2024-05-06T17:06:47.304272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "248b8720",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T17:06:47.354305Z",
     "iopub.status.busy": "2024-05-06T17:06:47.353981Z",
     "iopub.status.idle": "2024-05-06T17:06:47.357973Z",
     "shell.execute_reply": "2024-05-06T17:06:47.357094Z"
    },
    "papermill": {
     "duration": 0.020636,
     "end_time": "2024-05-06T17:06:47.360160",
     "exception": false,
     "start_time": "2024-05-06T17:06:47.339524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install rdkit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0826a60",
   "metadata": {
    "papermill": {
     "duration": 0.012962,
     "end_time": "2024-05-06T17:06:47.386622",
     "exception": false,
     "start_time": "2024-05-06T17:06:47.373660",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Plotting 2d Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5937db5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T17:06:47.414699Z",
     "iopub.status.busy": "2024-05-06T17:06:47.414304Z",
     "iopub.status.idle": "2024-05-06T17:06:47.418983Z",
     "shell.execute_reply": "2024-05-06T17:06:47.418039Z"
    },
    "papermill": {
     "duration": 0.021389,
     "end_time": "2024-05-06T17:06:47.421327",
     "exception": false,
     "start_time": "2024-05-06T17:06:47.399938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from rdkit import Chem\n",
    "# from rdkit.Chem import Draw\n",
    "\n",
    "# def plot_2d_molecule(df, molecule_id):\n",
    "#     # Filter the DataFrame for the given id\n",
    "#     row = df[df['id'] == molecule_id]\n",
    "#     # Get the SMILES string for the molecule\n",
    "#     smiles_string = row['molecule_smiles'].values[0]\n",
    "#     # Generate an RDKit molecule object\n",
    "#     mol = Chem.MolFromSmiles(smiles_string)\n",
    "#     # Use RDKit to draw the molecule\n",
    "#     img = Draw.MolToImage(mol)\n",
    "#     # Display the image\n",
    "#     return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18fde20d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T17:06:47.452237Z",
     "iopub.status.busy": "2024-05-06T17:06:47.451413Z",
     "iopub.status.idle": "2024-05-06T17:06:47.455885Z",
     "shell.execute_reply": "2024-05-06T17:06:47.454821Z"
    },
    "papermill": {
     "duration": 0.021545,
     "end_time": "2024-05-06T17:06:47.457964",
     "exception": false,
     "start_time": "2024-05-06T17:06:47.436419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #Example usage:\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mpimg\n",
    "\n",
    "# img = plot_2d_molecule(df_train, 1)\n",
    "# plt.imshow(img)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6167a8",
   "metadata": {
    "papermill": {
     "duration": 0.013361,
     "end_time": "2024-05-06T17:06:47.485399",
     "exception": false,
     "start_time": "2024-05-06T17:06:47.472038",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Plotting 3d Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0ab0830",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T17:06:47.515753Z",
     "iopub.status.busy": "2024-05-06T17:06:47.515045Z",
     "iopub.status.idle": "2024-05-06T17:06:47.519235Z",
     "shell.execute_reply": "2024-05-06T17:06:47.518244Z"
    },
    "papermill": {
     "duration": 0.021708,
     "end_time": "2024-05-06T17:06:47.521397",
     "exception": false,
     "start_time": "2024-05-06T17:06:47.499689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install py3Dmol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d9191e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T17:06:47.550744Z",
     "iopub.status.busy": "2024-05-06T17:06:47.550381Z",
     "iopub.status.idle": "2024-05-06T17:06:47.555872Z",
     "shell.execute_reply": "2024-05-06T17:06:47.554919Z"
    },
    "papermill": {
     "duration": 0.022519,
     "end_time": "2024-05-06T17:06:47.558008",
     "exception": false,
     "start_time": "2024-05-06T17:06:47.535489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# from rdkit.Chem import AllChem\n",
    "# import py3Dmol\n",
    "\n",
    "# def plot_3d_molecule_by_id(df, molecule_id):\n",
    "#     # Filter the DataFrame for the given id\n",
    "#     row = df[df['id'] == molecule_id]\n",
    "#     if row.empty:\n",
    "#         return \"No entry with the given ID.\"\n",
    "\n",
    "#     # Get the SMILES string for the molecule\n",
    "#     smiles_string = row['molecule_smiles'].values[0]\n",
    "#     if not smiles_string:\n",
    "#         return \"No SMILES string found for the given ID.\"\n",
    "    \n",
    "#     # Create a molecule from a SMILES string\n",
    "#     mol = Chem.MolFromSmiles(smiles_string)\n",
    "#     if mol is None:\n",
    "#         return \"Invalid SMILES string.\"\n",
    "    \n",
    "#     # Generate 3D coordinates\n",
    "#     mol = Chem.AddHs(mol)  # Add hydrogens\n",
    "#     AllChem.EmbedMolecule(mol, AllChem.ETKDG())  # Embed molecule in 3D space using ETKDG methodology\n",
    "#     AllChem.UFFOptimizeMolecule(mol)  # Optimize the geometry\n",
    "\n",
    "#     # Use py3Dmol for visualization\n",
    "#     mb = Chem.MolToMolBlock(mol)\n",
    "#     viewer = py3Dmol.view(width=800, height=400)\n",
    "#     viewer.addModel(mb, \"mol\")\n",
    "#     viewer.setStyle({'stick': {}})\n",
    "#     viewer.zoomTo()\n",
    "#     return viewer.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "287f95b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T17:06:47.587290Z",
     "iopub.status.busy": "2024-05-06T17:06:47.586635Z",
     "iopub.status.idle": "2024-05-06T17:06:47.590797Z",
     "shell.execute_reply": "2024-05-06T17:06:47.589950Z"
    },
    "papermill": {
     "duration": 0.020963,
     "end_time": "2024-05-06T17:06:47.592744",
     "exception": false,
     "start_time": "2024-05-06T17:06:47.571781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Example usage:\n",
    "# plot_3d_molecule_by_id(df_train, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1c8a4cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T17:06:47.622172Z",
     "iopub.status.busy": "2024-05-06T17:06:47.621369Z",
     "iopub.status.idle": "2024-05-06T17:06:47.625633Z",
     "shell.execute_reply": "2024-05-06T17:06:47.624663Z"
    },
    "papermill": {
     "duration": 0.021853,
     "end_time": "2024-05-06T17:06:47.628048",
     "exception": false,
     "start_time": "2024-05-06T17:06:47.606195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install rdkit-pypi networkx matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98ebd05a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T17:06:47.658718Z",
     "iopub.status.busy": "2024-05-06T17:06:47.658351Z",
     "iopub.status.idle": "2024-05-06T17:06:47.663947Z",
     "shell.execute_reply": "2024-05-06T17:06:47.662946Z"
    },
    "papermill": {
     "duration": 0.02332,
     "end_time": "2024-05-06T17:06:47.666172",
     "exception": false,
     "start_time": "2024-05-06T17:06:47.642852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# import pandas as pd\n",
    "# import networkx as nx\n",
    "# import matplotlib.pyplot as plt\n",
    "# from rdkit import Chem\n",
    "# from rdkit.Chem import Draw\n",
    "# from rdkit.Chem.rdmolops import GetAdjacencyMatrix\n",
    "\n",
    "# def plot_molecule_graph(df, molecule_id):\n",
    "#     # Find the molecule by ID\n",
    "#     row = df[df['id'] == molecule_id]\n",
    "#     if row.empty:\n",
    "#         print(\"No entry with the given ID.\")\n",
    "#         return\n",
    "\n",
    "#     # Extract the SMILES string\n",
    "#     smiles = row['molecule_smiles'].values[0]\n",
    "#     mol = Chem.MolFromSmiles(smiles)\n",
    "#     if mol is None:\n",
    "#         print(\"Invalid SMILES string.\")\n",
    "#         return\n",
    "\n",
    "#     # Create a graph from the molecule\n",
    "#     G = nx.Graph(Chem.rdmolops.GetAdjacencyMatrix(mol))\n",
    "#     labels = {}\n",
    "#     for idx, atom in enumerate(mol.GetAtoms()):\n",
    "#         G.nodes[idx]['label'] = atom.GetSymbol()\n",
    "#         labels[idx] = atom.GetSymbol()\n",
    "\n",
    "#     # Draw the graph\n",
    "#     pos = nx.spring_layout(G)  # positions for all nodes\n",
    "#     nx.draw(G, pos, with_labels=True, labels=labels, node_size=700, node_color='skyblue', font_size=16, font_weight='bold', edge_color='gray')\n",
    "#     plt.title(f'Molecular graph of ID {molecule_id}')\n",
    "#     plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc6c7726",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T17:06:47.697075Z",
     "iopub.status.busy": "2024-05-06T17:06:47.696411Z",
     "iopub.status.idle": "2024-05-06T17:06:47.700729Z",
     "shell.execute_reply": "2024-05-06T17:06:47.699778Z"
    },
    "papermill": {
     "duration": 0.022043,
     "end_time": "2024-05-06T17:06:47.702826",
     "exception": false,
     "start_time": "2024-05-06T17:06:47.680783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Example usage:\n",
    "# plot_molecule_graph(df_train, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54840e80",
   "metadata": {
    "papermill": {
     "duration": 0.013658,
     "end_time": "2024-05-06T17:06:47.730930",
     "exception": false,
     "start_time": "2024-05-06T17:06:47.717272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c2de181",
   "metadata": {
    "papermill": {
     "duration": 0.013905,
     "end_time": "2024-05-06T17:06:47.758649",
     "exception": false,
     "start_time": "2024-05-06T17:06:47.744744",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model 1 - SMILESBerth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b7bee43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T17:06:47.788054Z",
     "iopub.status.busy": "2024-05-06T17:06:47.787287Z",
     "iopub.status.idle": "2024-05-06T17:06:55.561736Z",
     "shell.execute_reply": "2024-05-06T17:06:55.560645Z"
    },
    "papermill": {
     "duration": 7.791952,
     "end_time": "2024-05-06T17:06:55.564392",
     "exception": false,
     "start_time": "2024-05-06T17:06:47.772440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Path to the Parquet file\n",
    "# Change to full Dataseet  for Massive Training and for testing\n",
    "df = pd.read_csv('/kaggle/input/leash-BELKA/train.csv', nrows=2000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07b49d75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T17:06:55.594433Z",
     "iopub.status.busy": "2024-05-06T17:06:55.593673Z",
     "iopub.status.idle": "2024-05-06T17:06:57.771217Z",
     "shell.execute_reply": "2024-05-06T17:06:57.770015Z"
    },
    "papermill": {
     "duration": 2.195386,
     "end_time": "2024-05-06T17:06:57.773971",
     "exception": false,
     "start_time": "2024-05-06T17:06:55.578585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split df_train to create a new training set and an evaluation set\n",
    "df_train, df_eval = train_test_split(df, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "609a31d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T17:06:57.802898Z",
     "iopub.status.busy": "2024-05-06T17:06:57.802537Z",
     "iopub.status.idle": "2024-05-06T17:06:57.811217Z",
     "shell.execute_reply": "2024-05-06T17:06:57.810281Z"
    },
    "papermill": {
     "duration": 0.025971,
     "end_time": "2024-05-06T17:06:57.813673",
     "exception": false,
     "start_time": "2024-05-06T17:06:57.787702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'buildingblock1_smiles', 'buildingblock2_smiles',\n",
       "       'buildingblock3_smiles', 'molecule_smiles', 'protein_name', 'binds'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5316869",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T17:06:57.841850Z",
     "iopub.status.busy": "2024-05-06T17:06:57.841508Z",
     "iopub.status.idle": "2024-05-06T17:06:57.857278Z",
     "shell.execute_reply": "2024-05-06T17:06:57.856323Z"
    },
    "papermill": {
     "duration": 0.032937,
     "end_time": "2024-05-06T17:06:57.859717",
     "exception": false,
     "start_time": "2024-05-06T17:06:57.826780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>buildingblock1_smiles</th>\n",
       "      <th>buildingblock2_smiles</th>\n",
       "      <th>buildingblock3_smiles</th>\n",
       "      <th>molecule_smiles</th>\n",
       "      <th>protein_name</th>\n",
       "      <th>binds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1828401</th>\n",
       "      <td>1828401</td>\n",
       "      <td>C#CC[C@@H](NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O</td>\n",
       "      <td>NCC1(Cc2ccccc2)CC1</td>\n",
       "      <td>Nc1nc(Br)cn2ccnc12</td>\n",
       "      <td>C#CC[C@@H](Nc1nc(NCC2(Cc3ccccc3)CC2)nc(Nc2nc(B...</td>\n",
       "      <td>BRD4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200071</th>\n",
       "      <td>1200071</td>\n",
       "      <td>C#CC[C@@H](NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O</td>\n",
       "      <td>CCOC(=O)c1cnc(SC)nc1N</td>\n",
       "      <td>Cl.NCc1cccc2cc[nH]c12</td>\n",
       "      <td>C#CC[C@@H](Nc1nc(NCc2cccc3cc[nH]c23)nc(Nc2nc(S...</td>\n",
       "      <td>sEH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194849</th>\n",
       "      <td>194849</td>\n",
       "      <td>C#CC[C@@H](CC(=O)O)NC(=O)OCC1c2ccccc2-c2ccccc21</td>\n",
       "      <td>COC(=O)c1cnc(N)cn1</td>\n",
       "      <td>NCc1cc(F)cc(F)c1</td>\n",
       "      <td>C#CC[C@@H](CC(=O)N[Dy])Nc1nc(NCc2cc(F)cc(F)c2)...</td>\n",
       "      <td>sEH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629054</th>\n",
       "      <td>1629054</td>\n",
       "      <td>C#CC[C@@H](NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O</td>\n",
       "      <td>Cl.N#Cc1ccc(CN)nc1</td>\n",
       "      <td>Cl.Cl.NCC#Cc1cccnc1</td>\n",
       "      <td>C#CC[C@@H](Nc1nc(NCC#Cc2cccnc2)nc(NCc2ccc(C#N)...</td>\n",
       "      <td>BRD4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191144</th>\n",
       "      <td>191144</td>\n",
       "      <td>C#CC[C@@H](CC(=O)O)NC(=O)OCC1c2ccccc2-c2ccccc21</td>\n",
       "      <td>COC(=O)c1cccc(N)n1</td>\n",
       "      <td>Cl.Cl.NCc1cn2cc(Br)ccc2n1</td>\n",
       "      <td>C#CC[C@@H](CC(=O)N[Dy])Nc1nc(NCc2cn3cc(Br)ccc3...</td>\n",
       "      <td>sEH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                            buildingblock1_smiles  \\\n",
       "1828401  1828401   C#CC[C@@H](NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O   \n",
       "1200071  1200071   C#CC[C@@H](NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O   \n",
       "194849    194849  C#CC[C@@H](CC(=O)O)NC(=O)OCC1c2ccccc2-c2ccccc21   \n",
       "1629054  1629054   C#CC[C@@H](NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O   \n",
       "191144    191144  C#CC[C@@H](CC(=O)O)NC(=O)OCC1c2ccccc2-c2ccccc21   \n",
       "\n",
       "         buildingblock2_smiles      buildingblock3_smiles  \\\n",
       "1828401     NCC1(Cc2ccccc2)CC1         Nc1nc(Br)cn2ccnc12   \n",
       "1200071  CCOC(=O)c1cnc(SC)nc1N      Cl.NCc1cccc2cc[nH]c12   \n",
       "194849      COC(=O)c1cnc(N)cn1           NCc1cc(F)cc(F)c1   \n",
       "1629054     Cl.N#Cc1ccc(CN)nc1        Cl.Cl.NCC#Cc1cccnc1   \n",
       "191144      COC(=O)c1cccc(N)n1  Cl.Cl.NCc1cn2cc(Br)ccc2n1   \n",
       "\n",
       "                                           molecule_smiles protein_name  binds  \n",
       "1828401  C#CC[C@@H](Nc1nc(NCC2(Cc3ccccc3)CC2)nc(Nc2nc(B...         BRD4      0  \n",
       "1200071  C#CC[C@@H](Nc1nc(NCc2cccc3cc[nH]c23)nc(Nc2nc(S...          sEH      0  \n",
       "194849   C#CC[C@@H](CC(=O)N[Dy])Nc1nc(NCc2cc(F)cc(F)c2)...          sEH      0  \n",
       "1629054  C#CC[C@@H](Nc1nc(NCC#Cc2cccnc2)nc(NCc2ccc(C#N)...         BRD4      0  \n",
       "191144   C#CC[C@@H](CC(=O)N[Dy])Nc1nc(NCc2cn3cc(Br)ccc3...          sEH      0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b25c5abd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T17:06:57.890636Z",
     "iopub.status.busy": "2024-05-06T17:06:57.889870Z",
     "iopub.status.idle": "2024-05-06T17:07:12.861845Z",
     "shell.execute_reply": "2024-05-06T17:07:12.860633Z"
    },
    "papermill": {
     "duration": 14.989517,
     "end_time": "2024-05-06T17:07:12.864580",
     "exception": false,
     "start_time": "2024-05-06T17:06:57.875063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.2.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4037efe1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T17:07:12.951590Z",
     "iopub.status.busy": "2024-05-06T17:07:12.951143Z",
     "iopub.status.idle": "2024-05-06T17:07:20.206437Z",
     "shell.execute_reply": "2024-05-06T17:07:20.205381Z"
    },
    "papermill": {
     "duration": 7.275417,
     "end_time": "2024-05-06T17:07:20.208947",
     "exception": false,
     "start_time": "2024-05-06T17:07:12.933530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1cce9c92079452691eae126d5ac5f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/62.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88920c04f4184c2cb142b0b1ca326a7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/515 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd80d165abd24086881cc1d70ea598f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/165k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f5322c70d4342ff92d7e0d7d06000e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/101k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1eb0ad4d24249efb0222efe59ba2729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_name = \"seyonec/PubChem10M_SMILES_BPE_450k\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfd00bb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T17:07:20.242017Z",
     "iopub.status.busy": "2024-05-06T17:07:20.241456Z",
     "iopub.status.idle": "2024-05-06T17:10:23.469214Z",
     "shell.execute_reply": "2024-05-06T17:10:23.468188Z"
    },
    "papermill": {
     "duration": 183.246897,
     "end_time": "2024-05-06T17:10:23.471967",
     "exception": false,
     "start_time": "2024-05-06T17:07:20.225070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 17:07:23.149727: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-06 17:07:23.149844: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-06 17:07:23.273730: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "# Tokenizing the SMILES strings\n",
    "\n",
    "train_encodings = tokenizer(df_train['molecule_smiles'].tolist(), truncation=True, padding=True, max_length=512)\n",
    "eval_encodings = tokenizer(df_eval['molecule_smiles'].tolist(), truncation=True, padding=True, max_length=512)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69cd1c33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T17:10:23.507877Z",
     "iopub.status.busy": "2024-05-06T17:10:23.506308Z",
     "iopub.status.idle": "2024-05-06T17:10:24.395176Z",
     "shell.execute_reply": "2024-05-06T17:10:24.394139Z"
    },
    "papermill": {
     "duration": 0.909375,
     "end_time": "2024-05-06T17:10:24.397849",
     "exception": false,
     "start_time": "2024-05-06T17:10:23.488474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Encode protein names\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "train_proteins = encoder.fit_transform(df_train['protein_name'].values.reshape(-1, 1))\n",
    "eval_proteins = encoder.transform(df_eval['protein_name'].values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbac4350",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T17:10:24.432119Z",
     "iopub.status.busy": "2024-05-06T17:10:24.431757Z",
     "iopub.status.idle": "2024-05-06T17:10:24.439684Z",
     "shell.execute_reply": "2024-05-06T17:10:24.438650Z"
    },
    "papermill": {
     "duration": 0.027646,
     "end_time": "2024-05-06T17:10:24.441988",
     "exception": false,
     "start_time": "2024-05-06T17:10:24.414342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Creating a Dataset object for Hugging Face\n",
    "import torch\n",
    "\n",
    "class SMILESDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels, protein_encodings):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.protein_encodings = protein_encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        item['protein_encodings'] = torch.tensor(self.protein_encodings[idx], dtype=torch.float32)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90b4c0b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T17:10:24.476261Z",
     "iopub.status.busy": "2024-05-06T17:10:24.475387Z",
     "iopub.status.idle": "2024-05-06T17:10:24.484247Z",
     "shell.execute_reply": "2024-05-06T17:10:24.483280Z"
    },
    "papermill": {
     "duration": 0.02824,
     "end_time": "2024-05-06T17:10:24.486581",
     "exception": false,
     "start_time": "2024-05-06T17:10:24.458341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ProteinBindingModel(nn.Module):\n",
    "    def __init__(self, transformer_model, num_protein_features):\n",
    "        super(ProteinBindingModel, self).__init__()\n",
    "        self.transformer = transformer_model\n",
    "        self.protein_features = nn.Linear(num_protein_features, 256)\n",
    "        self.classifier = nn.Linear(768 + 256, 2)  # Adjust sizes accordingly if using a different model\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, protein_features):\n",
    "        # Obtain the outputs from the transformer model\n",
    "        outputs = self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Use the last hidden state\n",
    "        last_hidden_state = outputs.last_hidden_state  # This is generally [batch size, sequence length, hidden size]\n",
    "        pooled_output = last_hidden_state[:, 0, :]  # Take the first token's embeddings across all batches\n",
    "        \n",
    "        # Process protein features\n",
    "        protein_features = self.protein_features(protein_features)\n",
    "        \n",
    "        # Concatenate pooled output and protein features\n",
    "        combined_features = torch.cat((pooled_output, protein_features), dim=1)\n",
    "        output = self.classifier(combined_features)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8562fda9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T17:10:24.521134Z",
     "iopub.status.busy": "2024-05-06T17:10:24.520782Z",
     "iopub.status.idle": "2024-05-06T17:10:24.577750Z",
     "shell.execute_reply": "2024-05-06T17:10:24.576813Z"
    },
    "papermill": {
     "duration": 0.077088,
     "end_time": "2024-05-06T17:10:24.580013",
     "exception": false,
     "start_time": "2024-05-06T17:10:24.502925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create Dataset\n",
    "train_dataset = SMILESDataset(train_encodings, df_train['binds'].tolist(), train_proteins)\n",
    "eval_dataset = SMILESDataset(eval_encodings, df_eval['binds'].tolist(), eval_proteins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5b014b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T17:10:24.614800Z",
     "iopub.status.busy": "2024-05-06T17:10:24.614018Z",
     "iopub.status.idle": "2024-05-06T17:10:30.922881Z",
     "shell.execute_reply": "2024-05-06T17:10:30.921526Z"
    },
    "papermill": {
     "duration": 6.329738,
     "end_time": "2024-05-06T17:10:30.926332",
     "exception": false,
     "start_time": "2024-05-06T17:10:24.596594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e953e9d3150e48ed9399d000276ec073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/336M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at seyonec/PubChem10M_SMILES_BPE_450k and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the base transformer model without the classification head\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2).base_model\n",
    "model = ProteinBindingModel(base_model, train_proteins.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12d1ee6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T17:10:30.985372Z",
     "iopub.status.busy": "2024-05-06T17:10:30.983865Z",
     "iopub.status.idle": "2024-05-06T17:10:31.167767Z",
     "shell.execute_reply": "2024-05-06T17:10:31.166838Z"
    },
    "papermill": {
     "duration": 0.214516,
     "end_time": "2024-05-06T17:10:31.170367",
     "exception": false,
     "start_time": "2024-05-06T17:10:30.955851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='/kaggle/working/',           # output directory\n",
    "    num_train_epochs=3,                      # number of training epochs\n",
    "    per_device_train_batch_size=16,          # batch size for training\n",
    "    per_device_eval_batch_size=64,           # batch size for evaluation\n",
    "    warmup_steps=500,                        # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,                       # strength of weight decay\n",
    "    logging_dir='/kaggle/working/logs',      # directory for storing logs\n",
    "    logging_steps=1000,\n",
    "    report_to=\"none\",                        # suppress logging to WANDB\n",
    "    save_steps=10000,                        # save model every 10000 steps\n",
    "    evaluation_strategy='steps',             # evaluate each `eval_steps`\n",
    "    eval_steps=5000,                         # evaluation every 5000 steps\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a520673c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T17:10:31.205925Z",
     "iopub.status.busy": "2024-05-06T17:10:31.205549Z",
     "iopub.status.idle": "2024-05-06T17:10:35.496344Z",
     "shell.execute_reply": "2024-05-06T17:10:35.495317Z"
    },
    "papermill": {
     "duration": 4.311041,
     "end_time": "2024-05-06T17:10:35.498635",
     "exception": false,
     "start_time": "2024-05-06T17:10:31.187594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff17472b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T17:10:35.533381Z",
     "iopub.status.busy": "2024-05-06T17:10:35.533014Z",
     "iopub.status.idle": "2024-05-06T17:10:35.540891Z",
     "shell.execute_reply": "2024-05-06T17:10:35.539852Z"
    },
    "papermill": {
     "duration": 0.027328,
     "end_time": "2024-05-06T17:10:35.543125",
     "exception": false,
     "start_time": "2024-05-06T17:10:35.515797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ProteinBindingTrainer(Trainer):\n",
    "    def _prepare_inputs(self, inputs):\n",
    "        # Instead of modifying inputs, just pass them through.\n",
    "        return inputs\n",
    "\n",
    "    def training_step(self, model, batch):\n",
    "        # Move batch to device\n",
    "        batch = {k: v.to(self.args.device) for k, v in batch.items() if hasattr(v, 'to')}\n",
    "\n",
    "        # Extract inputs from batch\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        protein_features = batch['protein_encodings']\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, protein_features=protein_features)\n",
    "        logits = outputs.logits if hasattr(outputs, 'logits') else outputs[0]\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = self.compute_loss(logits, labels)\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e41fe357",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T17:10:35.577865Z",
     "iopub.status.busy": "2024-05-06T17:10:35.577519Z",
     "iopub.status.idle": "2024-05-06T17:10:35.838861Z",
     "shell.execute_reply": "2024-05-06T17:10:35.837893Z"
    },
    "papermill": {
     "duration": 0.281513,
     "end_time": "2024-05-06T17:10:35.841218",
     "exception": false,
     "start_time": "2024-05-06T17:10:35.559705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels', 'protein_encodings'])\n"
     ]
    }
   ],
   "source": [
    "test_loader = torch.utils.data.DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "test_batch = next(iter(test_loader))\n",
    "print(test_batch.keys())  # This should include 'labels' and 'protein_encodings'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8add1fa0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T17:10:35.875164Z",
     "iopub.status.busy": "2024-05-06T17:10:35.874778Z",
     "iopub.status.idle": "2024-05-06T17:10:35.879725Z",
     "shell.execute_reply": "2024-05-06T17:10:35.878636Z"
    },
    "papermill": {
     "duration": 0.024318,
     "end_time": "2024-05-06T17:10:35.881976",
     "exception": false,
     "start_time": "2024-05-06T17:10:35.857658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Ensure the model is on the correct device\n",
    "# model.to(device)\n",
    "\n",
    "#THIS TRAINER IS NOT WORKING... SOMEHOW THE FUNCTION IS NOT GETTNG THE KEYS PROPERLY\n",
    "\n",
    "# # Initialize the trainer with all settings\n",
    "# trainer = ProteinBindingTrainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_dataset,  # Ensure this is your dataset, not DataLoader\n",
    "#     eval_dataset=eval_dataset     # Ensure this is your dataset, not DataLoader\n",
    "# )\n",
    "\n",
    "# # Start training\n",
    "# trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "549c81b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T17:10:35.916114Z",
     "iopub.status.busy": "2024-05-06T17:10:35.915732Z",
     "iopub.status.idle": "2024-05-06T17:10:35.921479Z",
     "shell.execute_reply": "2024-05-06T17:10:35.920435Z"
    },
    "papermill": {
     "duration": 0.025806,
     "end_time": "2024-05-06T17:10:35.923775",
     "exception": false,
     "start_time": "2024-05-06T17:10:35.897969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set the device to GPU if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b202ec7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T17:10:35.958309Z",
     "iopub.status.busy": "2024-05-06T17:10:35.957421Z",
     "iopub.status.idle": "2024-05-07T01:24:59.881021Z",
     "shell.execute_reply": "2024-05-07T01:24:59.879687Z"
    },
    "papermill": {
     "duration": 29663.94427,
     "end_time": "2024-05-07T01:24:59.884032",
     "exception": false,
     "start_time": "2024-05-06T17:10:35.939762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch 50, Loss: 0.0003614469605963677\n",
      "Epoch 0, Batch 100, Loss: 0.0029486739076673985\n",
      "Epoch 0, Batch 150, Loss: 0.0002984902821481228\n",
      "Epoch 0, Batch 200, Loss: 0.0005729823606088758\n",
      "Epoch 0, Batch 250, Loss: 0.0017560385167598724\n",
      "Epoch 0, Batch 300, Loss: 0.007374221924692392\n",
      "Epoch 0, Batch 350, Loss: 0.000599383725784719\n",
      "Epoch 0, Batch 400, Loss: 0.00019215265638194978\n",
      "Epoch 0, Batch 450, Loss: 0.0013185401912778616\n",
      "Epoch 0, Batch 500, Loss: 0.0014266889775171876\n",
      "Epoch 0, Batch 550, Loss: 0.0014793782029300928\n",
      "Epoch 0, Batch 600, Loss: 0.0014758659526705742\n",
      "Epoch 0, Batch 650, Loss: 0.0016343713505193591\n",
      "Epoch 0, Batch 700, Loss: 0.0025703124701976776\n",
      "Epoch 0, Batch 750, Loss: 0.0009630720014683902\n",
      "Epoch 0, Batch 800, Loss: 0.0013702663127332926\n",
      "Epoch 0, Batch 850, Loss: 0.0013361740857362747\n",
      "Epoch 0, Batch 900, Loss: 0.0009236173937097192\n",
      "Epoch 0, Batch 950, Loss: 0.006925922352820635\n",
      "Epoch 0, Batch 1000, Loss: 0.00032512241159565747\n",
      "Epoch 0, Batch 1050, Loss: 0.0006730055902153254\n",
      "Epoch 0, Batch 1100, Loss: 0.0008284641662612557\n",
      "Epoch 0, Batch 1150, Loss: 0.0012880789581686258\n",
      "Epoch 0, Batch 1200, Loss: 0.001956341555342078\n",
      "Epoch 0, Batch 1250, Loss: 0.00018975335115101188\n",
      "Epoch 0, Batch 1300, Loss: 0.0018144124187529087\n",
      "Epoch 0, Batch 1350, Loss: 0.00032349606044590473\n",
      "Epoch 0, Batch 1400, Loss: 0.0006369948387145996\n",
      "Epoch 0, Batch 1450, Loss: 0.0023833259474486113\n",
      "Epoch 0, Batch 1500, Loss: 0.00023710940149612725\n",
      "Epoch 0, Batch 1550, Loss: 0.0028787909541279078\n",
      "Epoch 0, Batch 1600, Loss: 0.0017769874539226294\n",
      "Epoch 0, Batch 1650, Loss: 0.37080880999565125\n",
      "Epoch 0, Batch 1700, Loss: 0.00037819615681655705\n",
      "Epoch 0, Batch 1750, Loss: 0.0009502001339569688\n",
      "Epoch 0, Batch 1800, Loss: 0.0032495902851223946\n",
      "Epoch 0, Batch 1850, Loss: 0.0006076105637475848\n",
      "Epoch 0, Batch 1900, Loss: 0.0008365333778783679\n",
      "Epoch 0, Batch 1950, Loss: 0.007309009321033955\n",
      "Epoch 0, Batch 2000, Loss: 0.001330602914094925\n",
      "Epoch 0, Batch 2050, Loss: 0.0002227963850600645\n",
      "Epoch 0, Batch 2100, Loss: 0.002859386382624507\n",
      "Epoch 0, Batch 2150, Loss: 0.0017113802023231983\n",
      "Epoch 0, Batch 2200, Loss: 0.0006187840481288731\n",
      "Epoch 0, Batch 2250, Loss: 0.0031870920211076736\n",
      "Epoch 0, Batch 2300, Loss: 0.0007082512602210045\n",
      "Epoch 0, Batch 2350, Loss: 0.001862632343545556\n",
      "Epoch 0, Batch 2400, Loss: 0.0016345316544175148\n",
      "Epoch 0, Batch 2450, Loss: 0.0007464702357538044\n",
      "Epoch 0, Batch 2500, Loss: 0.0007997328648343682\n",
      "Epoch 0, Batch 2550, Loss: 0.3077430725097656\n",
      "Epoch 0, Batch 2600, Loss: 0.0012592163402587175\n",
      "Epoch 0, Batch 2650, Loss: 0.004927237052470446\n",
      "Epoch 0, Batch 2700, Loss: 0.0004216534725856036\n",
      "Epoch 0, Batch 2750, Loss: 0.0017713475972414017\n",
      "Epoch 0, Batch 2800, Loss: 0.0003754558856599033\n",
      "Epoch 0, Batch 2850, Loss: 0.0002028602611972019\n",
      "Epoch 0, Batch 2900, Loss: 0.33192363381385803\n",
      "Epoch 0, Batch 2950, Loss: 0.0013166357530280948\n",
      "Epoch 0, Batch 3000, Loss: 0.0032927091233432293\n",
      "Epoch 0, Batch 3050, Loss: 0.0026446962729096413\n",
      "Epoch 0, Batch 3100, Loss: 0.0009355823276564479\n",
      "Epoch 0, Batch 3150, Loss: 0.0030306302942335606\n",
      "Epoch 0, Batch 3200, Loss: 0.0017133874353021383\n",
      "Epoch 0, Batch 3250, Loss: 0.0007896567112766206\n",
      "Epoch 0, Batch 3300, Loss: 0.0010758568532764912\n",
      "Epoch 0, Batch 3350, Loss: 0.006142954342067242\n",
      "Epoch 0, Batch 3400, Loss: 0.0037271585315465927\n",
      "Epoch 0, Batch 3450, Loss: 0.0005966068711131811\n",
      "Epoch 0, Batch 3500, Loss: 0.0017725365469232202\n",
      "Epoch 0, Batch 3550, Loss: 0.0013769185170531273\n",
      "Epoch 0, Batch 3600, Loss: 0.0010294419480487704\n",
      "Epoch 0, Batch 3650, Loss: 0.000864948146045208\n",
      "Epoch 0, Batch 3700, Loss: 0.0004108423599973321\n",
      "Epoch 0, Batch 3750, Loss: 0.0006678208010271192\n",
      "Epoch 0, Batch 3800, Loss: 0.0008341819047927856\n",
      "Epoch 0, Batch 3850, Loss: 0.0005047374870628119\n",
      "Epoch 0, Batch 3900, Loss: 0.004703651648014784\n",
      "Epoch 0, Batch 3950, Loss: 0.0030741700902581215\n",
      "Epoch 0, Batch 4000, Loss: 0.0008890014723874629\n",
      "Epoch 0, Batch 4050, Loss: 0.0004038441402371973\n",
      "Epoch 0, Batch 4100, Loss: 0.0013369142543524504\n",
      "Epoch 0, Batch 4150, Loss: 0.001332999556325376\n",
      "Epoch 0, Batch 4200, Loss: 0.0019576626364141703\n",
      "Epoch 0, Batch 4250, Loss: 0.0016257123788818717\n",
      "Epoch 0, Batch 4300, Loss: 0.0025081424973905087\n",
      "Epoch 0, Batch 4350, Loss: 0.005031682085245848\n",
      "Epoch 0, Batch 4400, Loss: 0.0015975929563865066\n",
      "Epoch 0, Batch 4450, Loss: 0.0014676861464977264\n",
      "Epoch 0, Batch 4500, Loss: 0.000495081883855164\n",
      "Epoch 0, Batch 4550, Loss: 0.4350516200065613\n",
      "Epoch 0, Batch 4600, Loss: 0.001306409714743495\n",
      "Epoch 0, Batch 4650, Loss: 0.0019661213736981153\n",
      "Epoch 0, Batch 4700, Loss: 0.002557652536779642\n",
      "Epoch 0, Batch 4750, Loss: 0.001326733734458685\n",
      "Epoch 0, Batch 4800, Loss: 0.00275388453155756\n",
      "Epoch 0, Batch 4850, Loss: 0.002793308347463608\n",
      "Epoch 0, Batch 4900, Loss: 0.0012716026976704597\n",
      "Epoch 0, Batch 4950, Loss: 0.003921284340322018\n",
      "Epoch 0, Batch 5000, Loss: 0.0010557909263297915\n",
      "Epoch 0, Batch 5050, Loss: 0.0010910478886216879\n",
      "Epoch 0, Batch 5100, Loss: 0.0017679155571386218\n",
      "Epoch 0, Batch 5150, Loss: 0.0016048616962507367\n",
      "Epoch 0, Batch 5200, Loss: 0.0014669944066554308\n",
      "Epoch 0, Batch 5250, Loss: 0.002378145232796669\n",
      "Epoch 0, Batch 5300, Loss: 0.362518846988678\n",
      "Epoch 0, Batch 5350, Loss: 0.0022178057115525007\n",
      "Epoch 0, Batch 5400, Loss: 0.00211141025647521\n",
      "Epoch 0, Batch 5450, Loss: 0.0037483361084014177\n",
      "Epoch 0, Batch 5500, Loss: 0.0013592243194580078\n",
      "Epoch 0, Batch 5550, Loss: 0.004494020715355873\n",
      "Epoch 0, Batch 5600, Loss: 0.0022699630353599787\n",
      "Epoch 0, Batch 5650, Loss: 0.004238372202962637\n",
      "Epoch 0, Batch 5700, Loss: 0.0016047373646870255\n",
      "Epoch 0, Batch 5750, Loss: 0.0018565612845122814\n",
      "Epoch 0, Batch 5800, Loss: 0.0010349864605814219\n",
      "Epoch 0, Batch 5850, Loss: 0.0017391910078004003\n",
      "Epoch 0, Batch 5900, Loss: 0.0008062331471592188\n",
      "Epoch 0, Batch 5950, Loss: 0.0009110326645895839\n",
      "Epoch 0, Batch 6000, Loss: 6.354013021336868e-05\n",
      "Epoch 0, Batch 6050, Loss: 1.8209049812867306e-05\n",
      "Epoch 0, Batch 6100, Loss: 0.00860458891838789\n",
      "Epoch 0, Batch 6150, Loss: 0.0010518931085243821\n",
      "Epoch 0, Batch 6200, Loss: 0.003879643976688385\n",
      "Epoch 0, Batch 6250, Loss: 0.0036363694816827774\n",
      "Epoch 0, Batch 6300, Loss: 0.0010805197525769472\n",
      "Epoch 0, Batch 6350, Loss: 0.006554577499628067\n",
      "Epoch 0, Batch 6400, Loss: 0.43495696783065796\n",
      "Epoch 0, Batch 6450, Loss: 0.005544386804103851\n",
      "Epoch 0, Batch 6500, Loss: 0.41748860478401184\n",
      "Epoch 0, Batch 6550, Loss: 0.004909506533294916\n",
      "Epoch 0, Batch 6600, Loss: 0.001733082695864141\n",
      "Epoch 0, Batch 6650, Loss: 0.0015608620597049594\n",
      "Epoch 0, Batch 6700, Loss: 0.0013281176798045635\n",
      "Epoch 0, Batch 6750, Loss: 0.0029472573660314083\n",
      "Epoch 0, Batch 6800, Loss: 0.005379049573093653\n",
      "Epoch 0, Batch 6850, Loss: 0.000926180393435061\n",
      "Epoch 0, Batch 6900, Loss: 0.002084244042634964\n",
      "Epoch 0, Batch 6950, Loss: 0.0025251752231270075\n",
      "Epoch 0, Batch 7000, Loss: 0.0007822914631105959\n",
      "Epoch 0, Batch 7050, Loss: 0.0017459149239584804\n",
      "Epoch 0, Batch 7100, Loss: 0.0006722400430589914\n",
      "Epoch 0, Batch 7150, Loss: 0.0011078448733314872\n",
      "Epoch 0, Batch 7200, Loss: 0.0007526579429395497\n",
      "Epoch 0, Batch 7250, Loss: 0.002975898329168558\n",
      "Epoch 0, Batch 7300, Loss: 0.0015260765794664621\n",
      "Epoch 0, Batch 7350, Loss: 0.0005684131756424904\n",
      "Epoch 0, Batch 7400, Loss: 0.00030619182507507503\n",
      "Epoch 0, Batch 7450, Loss: 0.0010345586342737079\n",
      "Epoch 0, Batch 7500, Loss: 0.010548019781708717\n",
      "Epoch 0, Batch 7550, Loss: 0.002878450555726886\n",
      "Epoch 0, Batch 7600, Loss: 0.0011856294004246593\n",
      "Epoch 0, Batch 7650, Loss: 0.0035326769575476646\n",
      "Epoch 0, Batch 7700, Loss: 0.0018037292174994946\n",
      "Epoch 0, Batch 7750, Loss: 0.0014653197722509503\n",
      "Epoch 0, Batch 7800, Loss: 0.0019754429813474417\n",
      "Epoch 0, Batch 7850, Loss: 0.004627262707799673\n",
      "Epoch 0, Batch 7900, Loss: 0.0029753707349300385\n",
      "Epoch 0, Batch 7950, Loss: 0.0010868193348869681\n",
      "Epoch 0, Batch 8000, Loss: 0.0026260146405547857\n",
      "Epoch 0, Batch 8050, Loss: 0.002987729851156473\n",
      "Epoch 0, Batch 8100, Loss: 0.0017452859319746494\n",
      "Epoch 0, Batch 8150, Loss: 0.0022927492391318083\n",
      "Epoch 0, Batch 8200, Loss: 0.0035586797166615725\n",
      "Epoch 0, Batch 8250, Loss: 0.004342484287917614\n",
      "Epoch 0, Batch 8300, Loss: 0.0014716816367581487\n",
      "Epoch 0, Batch 8350, Loss: 0.371087908744812\n",
      "Epoch 0, Batch 8400, Loss: 0.0027619265019893646\n",
      "Epoch 0, Batch 8450, Loss: 0.0010898024775087833\n",
      "Epoch 0, Batch 8500, Loss: 0.0017988819163292646\n",
      "Epoch 0, Batch 8550, Loss: 0.0011017359793186188\n",
      "Epoch 0, Batch 8600, Loss: 0.0014157413970679045\n",
      "Epoch 0, Batch 8650, Loss: 0.0007746715564280748\n",
      "Epoch 0, Batch 8700, Loss: 0.0009586388478055596\n",
      "Epoch 0, Batch 8750, Loss: 0.0011014887131750584\n",
      "Epoch 0, Batch 8800, Loss: 0.005262600723654032\n",
      "Epoch 0, Batch 8850, Loss: 0.0019230026518926024\n",
      "Epoch 0, Batch 8900, Loss: 0.001317682210355997\n",
      "Epoch 0, Batch 8950, Loss: 0.0021263170056045055\n",
      "Epoch 0, Batch 9000, Loss: 0.000857184175401926\n",
      "Epoch 0, Batch 9050, Loss: 0.00129037001170218\n",
      "Epoch 0, Batch 9100, Loss: 0.005388317164033651\n",
      "Epoch 0, Batch 9150, Loss: 0.0024230647832155228\n",
      "Epoch 0, Batch 9200, Loss: 0.0027811089530587196\n",
      "Epoch 0, Batch 9250, Loss: 0.003100084140896797\n",
      "Epoch 0, Batch 9300, Loss: 0.001798475394025445\n",
      "Epoch 0, Batch 9350, Loss: 0.0010427884990349412\n",
      "Epoch 0, Batch 9400, Loss: 0.002371653215959668\n",
      "Epoch 0, Batch 9450, Loss: 0.0018028210615739226\n",
      "Epoch 0, Batch 9500, Loss: 0.0015003553126007318\n",
      "Epoch 0, Batch 9550, Loss: 0.0017931017791852355\n",
      "Epoch 0, Batch 9600, Loss: 0.0016189704183489084\n",
      "Epoch 0, Batch 9650, Loss: 0.003669097786769271\n",
      "Epoch 0, Batch 9700, Loss: 0.0031155834440141916\n",
      "Epoch 0, Batch 9750, Loss: 2.1166863007238135e-05\n",
      "Epoch 0, Batch 9800, Loss: 1.3723869415116496e-05\n",
      "Epoch 0, Batch 9850, Loss: 0.00034652798785828054\n",
      "Epoch 0, Batch 9900, Loss: 0.0010277307592332363\n",
      "Epoch 0, Batch 9950, Loss: 0.003449223702773452\n",
      "Epoch 0, Batch 10000, Loss: 0.0019162800163030624\n",
      "Epoch 0, Batch 10050, Loss: 0.0016771381488069892\n",
      "Epoch 0, Batch 10100, Loss: 0.0018530698725953698\n",
      "Epoch 0, Batch 10150, Loss: 0.003473069053143263\n",
      "Epoch 0, Batch 10200, Loss: 0.0019216821528971195\n",
      "Epoch 0, Batch 10250, Loss: 0.002200946444645524\n",
      "Epoch 0, Batch 10300, Loss: 0.0019372296519577503\n",
      "Epoch 0, Batch 10350, Loss: 0.0016771572409197688\n",
      "Epoch 0, Batch 10400, Loss: 0.0025774468667805195\n",
      "Epoch 0, Batch 10450, Loss: 0.001964513910934329\n",
      "Epoch 0, Batch 10500, Loss: 0.0015621139900758862\n",
      "Epoch 0, Batch 10550, Loss: 0.00198884098790586\n",
      "Epoch 0, Batch 10600, Loss: 0.0008682137122377753\n",
      "Epoch 0, Batch 10650, Loss: 0.0006285193958319724\n",
      "Epoch 0, Batch 10700, Loss: 0.0007670517079532146\n",
      "Epoch 0, Batch 10750, Loss: 0.0028005074709653854\n",
      "Epoch 0, Batch 10800, Loss: 0.008405541069805622\n",
      "Epoch 0, Batch 10850, Loss: 0.002874440746381879\n",
      "Epoch 0, Batch 10900, Loss: 0.0026818078476935625\n",
      "Epoch 0, Batch 10950, Loss: 0.0014430383453145623\n",
      "Epoch 0, Batch 11000, Loss: 0.005511037539690733\n",
      "Epoch 0, Batch 11050, Loss: 0.0026648337952792645\n",
      "Epoch 0, Batch 11100, Loss: 0.005963098257780075\n",
      "Epoch 0, Batch 11150, Loss: 0.004497173707932234\n",
      "Epoch 0, Batch 11200, Loss: 0.0016122957458719611\n",
      "Epoch 0, Batch 11250, Loss: 0.0024681882932782173\n",
      "Epoch 0, Batch 11300, Loss: 0.003383415751159191\n",
      "Epoch 0, Batch 11350, Loss: 0.0017624481115490198\n",
      "Epoch 0, Batch 11400, Loss: 0.0013433247804641724\n",
      "Epoch 0, Batch 11450, Loss: 0.0015247459523379803\n",
      "Epoch 0, Batch 11500, Loss: 0.0012803884455934167\n",
      "Epoch 0, Batch 11550, Loss: 0.42995646595954895\n",
      "Epoch 0, Batch 11600, Loss: 0.0012046663323417306\n",
      "Epoch 0, Batch 11650, Loss: 0.0008067612070590258\n",
      "Epoch 0, Batch 11700, Loss: 0.0010502167278900743\n",
      "Epoch 0, Batch 11750, Loss: 0.0013322860468178988\n",
      "Epoch 0, Batch 11800, Loss: 0.003919163718819618\n",
      "Epoch 0, Batch 11850, Loss: 0.00407822709530592\n",
      "Epoch 0, Batch 11900, Loss: 0.0031089186668395996\n",
      "Epoch 0, Batch 11950, Loss: 0.00132778100669384\n",
      "Epoch 0, Batch 12000, Loss: 0.0016704293666407466\n",
      "Epoch 0, Batch 12050, Loss: 0.0014448188012465835\n",
      "Epoch 0, Batch 12100, Loss: 0.0009434821549803019\n",
      "Epoch 0, Batch 12150, Loss: 0.002100227866321802\n",
      "Epoch 0, Batch 12200, Loss: 0.0017760222544893622\n",
      "Epoch 0, Batch 12250, Loss: 0.0017846579430624843\n",
      "Epoch 0, Batch 12300, Loss: 0.0017403955571353436\n",
      "Epoch 0, Batch 12350, Loss: 0.0028849791269749403\n",
      "Epoch 0, Batch 12400, Loss: 0.002869766904041171\n",
      "Epoch 0, Batch 12450, Loss: 0.002545823808759451\n",
      "Epoch 0, Batch 12500, Loss: 0.0017902797553688288\n",
      "Epoch 0, Batch 12550, Loss: 0.3730121850967407\n",
      "Epoch 0, Batch 12600, Loss: 0.0036631810944527388\n",
      "Epoch 0, Batch 12650, Loss: 0.0047981515526771545\n",
      "Epoch 0, Batch 12700, Loss: 0.002401353558525443\n",
      "Epoch 0, Batch 12750, Loss: 0.0027584463823586702\n",
      "Epoch 0, Batch 12800, Loss: 0.001761827734299004\n",
      "Epoch 0, Batch 12850, Loss: 0.0015526764327660203\n",
      "Epoch 0, Batch 12900, Loss: 0.0023580046836286783\n",
      "Epoch 0, Batch 12950, Loss: 0.007032419554889202\n",
      "Epoch 0, Batch 13000, Loss: 0.0025177698116749525\n",
      "Epoch 0, Batch 13050, Loss: 0.0011728601530194283\n",
      "Epoch 0, Batch 13100, Loss: 0.0007135213236324489\n",
      "Epoch 0, Batch 13150, Loss: 0.0014727639500051737\n",
      "Epoch 0, Batch 13200, Loss: 0.0013662803685292602\n",
      "Epoch 0, Batch 13250, Loss: 0.0008536507957614958\n",
      "Epoch 0, Batch 13300, Loss: 0.001612153835594654\n",
      "Epoch 0, Batch 13350, Loss: 0.001280760276131332\n",
      "Epoch 0, Batch 13400, Loss: 0.0013661764096468687\n",
      "Epoch 0, Batch 13450, Loss: 0.0006448946660384536\n",
      "Epoch 0, Batch 13500, Loss: 0.0008860942325554788\n",
      "Epoch 0, Batch 13550, Loss: 0.001367728691548109\n",
      "Epoch 0, Batch 13600, Loss: 0.00117909733671695\n",
      "Epoch 0, Batch 13650, Loss: 0.001315841916948557\n",
      "Epoch 0, Batch 13700, Loss: 0.0016912489663809538\n",
      "Epoch 0, Batch 13750, Loss: 0.0029933881014585495\n",
      "Epoch 0, Batch 13800, Loss: 0.002450730185955763\n",
      "Epoch 0, Batch 13850, Loss: 0.0017900653183460236\n",
      "Epoch 0, Batch 13900, Loss: 0.39814746379852295\n",
      "Epoch 0, Batch 13950, Loss: 0.0015841725980862975\n",
      "Epoch 0, Batch 14000, Loss: 0.0019177915528416634\n",
      "Epoch 0, Batch 14050, Loss: 0.0011500325053930283\n",
      "Epoch 0, Batch 14100, Loss: 0.0012345087016001344\n",
      "Epoch 0, Batch 14150, Loss: 0.0020146300084888935\n",
      "Epoch 0, Batch 14200, Loss: 0.0015526966890320182\n",
      "Epoch 0, Batch 14250, Loss: 0.00280980602838099\n",
      "Epoch 0, Batch 14300, Loss: 0.003776779631152749\n",
      "Epoch 0, Batch 14350, Loss: 0.0024583102203905582\n",
      "Epoch 0, Batch 14400, Loss: 0.0011883241822943091\n",
      "Epoch 0, Batch 14450, Loss: 0.0006768600433133543\n",
      "Epoch 0, Batch 14500, Loss: 0.0005159066058695316\n",
      "Epoch 0, Batch 14550, Loss: 0.46045276522636414\n",
      "Epoch 0, Batch 14600, Loss: 0.004069807939231396\n",
      "Epoch 0, Batch 14650, Loss: 0.001806237269192934\n",
      "Epoch 0, Batch 14700, Loss: 0.4404384195804596\n",
      "Epoch 0, Batch 14750, Loss: 0.002349094720557332\n",
      "Epoch 0, Batch 14800, Loss: 0.0016051818383857608\n",
      "Epoch 0, Batch 14850, Loss: 0.0018665478564798832\n",
      "Epoch 0, Batch 14900, Loss: 0.0021002651192247868\n",
      "Epoch 0, Batch 14950, Loss: 0.004584306851029396\n",
      "Epoch 0, Batch 15000, Loss: 0.0027828754391521215\n",
      "Epoch 0, Batch 15050, Loss: 0.003156497376039624\n",
      "Epoch 0, Batch 15100, Loss: 0.0023044494446367025\n",
      "Epoch 0, Batch 15150, Loss: 0.0015760866226628423\n",
      "Epoch 0, Batch 15200, Loss: 0.0018919830908998847\n",
      "Epoch 0, Batch 15250, Loss: 0.0013652814086526632\n",
      "Epoch 0, Batch 15300, Loss: 0.0026742347981780767\n",
      "Epoch 0, Batch 15350, Loss: 0.001250118250027299\n",
      "Epoch 0, Batch 15400, Loss: 0.0018832002533599734\n",
      "Epoch 0, Batch 15450, Loss: 0.36831167340278625\n",
      "Epoch 0, Batch 15500, Loss: 0.002247897442430258\n",
      "Epoch 0, Batch 15550, Loss: 0.0024023635778576136\n",
      "Epoch 0, Batch 15600, Loss: 0.002949606394395232\n",
      "Epoch 0, Batch 15650, Loss: 0.002542308298870921\n",
      "Epoch 0, Batch 15700, Loss: 0.00212245830334723\n",
      "Epoch 0, Batch 15750, Loss: 0.0017114179208874702\n",
      "Epoch 0, Batch 15800, Loss: 0.0009593966533429921\n",
      "Epoch 0, Batch 15850, Loss: 0.0011849808506667614\n",
      "Epoch 0, Batch 15900, Loss: 0.0016202973201870918\n",
      "Epoch 0, Batch 15950, Loss: 0.0020767187234014273\n",
      "Epoch 0, Batch 16000, Loss: 0.004314097110182047\n",
      "Epoch 0, Batch 16050, Loss: 0.001582847093231976\n",
      "Epoch 0, Batch 16100, Loss: 0.0022299932315945625\n",
      "Epoch 0, Batch 16150, Loss: 0.002123370999470353\n",
      "Epoch 0, Batch 16200, Loss: 0.0016660981345921755\n",
      "Epoch 0, Batch 16250, Loss: 0.0011592493392527103\n",
      "Epoch 0, Batch 16300, Loss: 0.0011710241669788957\n",
      "Epoch 0, Batch 16350, Loss: 0.001835579751059413\n",
      "Epoch 0, Batch 16400, Loss: 0.002616319339722395\n",
      "Epoch 0, Batch 16450, Loss: 0.002711591077968478\n",
      "Epoch 0, Batch 16500, Loss: 0.0016499180346727371\n",
      "Epoch 0, Batch 16550, Loss: 0.4342222511768341\n",
      "Epoch 0, Batch 16600, Loss: 0.0030367281287908554\n",
      "Epoch 0, Batch 16650, Loss: 0.3414437770843506\n",
      "Epoch 0, Batch 16700, Loss: 0.002587738446891308\n",
      "Epoch 0, Batch 16750, Loss: 0.0021522673778235912\n",
      "Epoch 0, Batch 16800, Loss: 0.005474235862493515\n",
      "Epoch 0, Batch 16850, Loss: 0.0053503005765378475\n",
      "Epoch 0, Batch 16900, Loss: 0.0024251947179436684\n",
      "Epoch 0, Batch 16950, Loss: 0.002309550065547228\n",
      "Epoch 0, Batch 17000, Loss: 0.003523091319948435\n",
      "Epoch 0, Batch 17050, Loss: 0.002041839063167572\n",
      "Epoch 0, Batch 17100, Loss: 0.0020660203881561756\n",
      "Epoch 0, Batch 17150, Loss: 0.0032324318308383226\n",
      "Epoch 0, Batch 17200, Loss: 0.4061262011528015\n",
      "Epoch 0, Batch 17250, Loss: 0.002842059824615717\n",
      "Epoch 0, Batch 17300, Loss: 0.002141820965334773\n",
      "Epoch 0, Batch 17350, Loss: 0.00164092518389225\n",
      "Epoch 0, Batch 17400, Loss: 0.0014849939616397023\n",
      "Epoch 0, Batch 17450, Loss: 0.0016813231632113457\n",
      "Epoch 0, Batch 17500, Loss: 0.0022977832704782486\n",
      "Epoch 0, Batch 17550, Loss: 0.00133998051751405\n",
      "Epoch 0, Batch 17600, Loss: 0.42168909311294556\n",
      "Epoch 0, Batch 17650, Loss: 0.001170310191810131\n",
      "Epoch 0, Batch 17700, Loss: 0.0026837079785764217\n",
      "Epoch 0, Batch 17750, Loss: 0.0019311154028400779\n",
      "Epoch 0, Batch 17800, Loss: 0.002108439803123474\n",
      "Epoch 0, Batch 17850, Loss: 0.001773085561580956\n",
      "Epoch 0, Batch 17900, Loss: 0.0014798727352172136\n",
      "Epoch 0, Batch 17950, Loss: 0.0015003170119598508\n",
      "Epoch 0, Batch 18000, Loss: 0.0019091966096311808\n",
      "Epoch 0, Batch 18050, Loss: 0.0041630081832408905\n",
      "Epoch 0, Batch 18100, Loss: 0.003801495535299182\n",
      "Epoch 0, Batch 18150, Loss: 0.0024186919908970594\n",
      "Epoch 0, Batch 18200, Loss: 0.001464475761167705\n",
      "Epoch 0, Batch 18250, Loss: 0.0016875193687155843\n",
      "Epoch 0, Batch 18300, Loss: 0.36614394187927246\n",
      "Epoch 0, Batch 18350, Loss: 0.003618258750066161\n",
      "Epoch 0, Batch 18400, Loss: 0.0025083094369620085\n",
      "Epoch 0, Batch 18450, Loss: 0.0026922840625047684\n",
      "Epoch 0, Batch 18500, Loss: 0.003871913766488433\n",
      "Epoch 0, Batch 18550, Loss: 0.002894790144637227\n",
      "Epoch 0, Batch 18600, Loss: 0.0015042159939184785\n",
      "Epoch 0, Batch 18650, Loss: 0.0022742729634046555\n",
      "Epoch 0, Batch 18700, Loss: 0.0013303847517818213\n",
      "Epoch 0, Batch 18750, Loss: 0.0013545871479436755\n",
      "Epoch 0, Batch 18800, Loss: 0.0007867659442126751\n",
      "Epoch 0, Batch 18850, Loss: 0.0013647559098899364\n",
      "Epoch 0, Batch 18900, Loss: 0.0033357187639921904\n",
      "Epoch 0, Batch 18950, Loss: 0.0020396418403834105\n",
      "Epoch 0, Batch 19000, Loss: 0.0035691075026988983\n",
      "Epoch 0, Batch 19050, Loss: 0.3821224570274353\n",
      "Epoch 0, Batch 19100, Loss: 0.0017048484878614545\n",
      "Epoch 0, Batch 19150, Loss: 0.0016178140649572015\n",
      "Epoch 0, Batch 19200, Loss: 0.0017394836759194732\n",
      "Epoch 0, Batch 19250, Loss: 0.0022804043255746365\n",
      "Epoch 0, Batch 19300, Loss: 0.001270148903131485\n",
      "Epoch 0, Batch 19350, Loss: 0.0008575264946557581\n",
      "Epoch 0, Batch 19400, Loss: 0.0008268171804957092\n",
      "Epoch 0, Batch 19450, Loss: 0.000666996231302619\n",
      "Epoch 0, Batch 19500, Loss: 0.0012884410098195076\n",
      "Epoch 0, Batch 19550, Loss: 0.0022969639394432306\n",
      "Epoch 0, Batch 19600, Loss: 0.0014315604930743575\n",
      "Epoch 0, Batch 19650, Loss: 0.001189334667287767\n",
      "Epoch 0, Batch 19700, Loss: 0.39597031474113464\n",
      "Epoch 0, Batch 19750, Loss: 0.0033660654444247484\n",
      "Epoch 0, Batch 19800, Loss: 0.001983296824619174\n",
      "Epoch 0, Batch 19850, Loss: 0.0012163425562903285\n",
      "Epoch 0, Batch 19900, Loss: 0.0016761181177571416\n",
      "Epoch 0, Batch 19950, Loss: 0.0015742909163236618\n",
      "Epoch 0, Batch 20000, Loss: 0.4543841481208801\n",
      "Epoch 0, Batch 20050, Loss: 0.0009816671954467893\n",
      "Epoch 0, Batch 20100, Loss: 0.0015079682925716043\n",
      "Epoch 0, Batch 20150, Loss: 0.002074677962809801\n",
      "Epoch 0, Batch 20200, Loss: 0.0025023159105330706\n",
      "Epoch 0, Batch 20250, Loss: 0.002946467837318778\n",
      "Epoch 0, Batch 20300, Loss: 0.0022399986628443003\n",
      "Epoch 0, Batch 20350, Loss: 0.0034920554608106613\n",
      "Epoch 0, Batch 20400, Loss: 0.0016108484705910087\n",
      "Epoch 0, Batch 20450, Loss: 0.0010380239691585302\n",
      "Epoch 0, Batch 20500, Loss: 0.001960220979526639\n",
      "Epoch 0, Batch 20550, Loss: 0.0016880332259461284\n",
      "Epoch 0, Batch 20600, Loss: 0.0013460178161039948\n",
      "Epoch 0, Batch 20650, Loss: 0.0010049333795905113\n",
      "Epoch 0, Batch 20700, Loss: 0.001939538517035544\n",
      "Epoch 0, Batch 20750, Loss: 0.005355609115213156\n",
      "Epoch 0, Batch 20800, Loss: 0.004571305122226477\n",
      "Epoch 0, Batch 20850, Loss: 0.0023624070454388857\n",
      "Epoch 0, Batch 20900, Loss: 0.0023386627435684204\n",
      "Epoch 0, Batch 20950, Loss: 0.0018033155938610435\n",
      "Epoch 0, Batch 21000, Loss: 0.001481342944316566\n",
      "Epoch 0, Batch 21050, Loss: 0.0016723767621442676\n",
      "Epoch 0, Batch 21100, Loss: 0.001435798592865467\n",
      "Epoch 0, Batch 21150, Loss: 0.0021665256936103106\n",
      "Epoch 0, Batch 21200, Loss: 0.0015953854890540242\n",
      "Epoch 0, Batch 21250, Loss: 0.0018302659736946225\n",
      "Epoch 0, Batch 21300, Loss: 0.0017790477722883224\n",
      "Epoch 0, Batch 21350, Loss: 0.0022067795507609844\n",
      "Epoch 0, Batch 21400, Loss: 0.0017701252363622189\n",
      "Epoch 0, Batch 21450, Loss: 0.0022715656086802483\n",
      "Epoch 0, Batch 21500, Loss: 0.004083279985934496\n",
      "Epoch 0, Batch 21550, Loss: 0.002885086927562952\n",
      "Epoch 0, Batch 21600, Loss: 0.0036093846429139376\n",
      "Epoch 0, Batch 21650, Loss: 0.005970058962702751\n",
      "Epoch 0, Batch 21700, Loss: 0.002961807418614626\n",
      "Epoch 0, Batch 21750, Loss: 0.41677555441856384\n",
      "Epoch 0, Batch 21800, Loss: 0.0013927747495472431\n",
      "Epoch 0, Batch 21850, Loss: 0.0017174441600218415\n",
      "Epoch 0, Batch 21900, Loss: 0.0016984184039756656\n",
      "Epoch 0, Batch 21950, Loss: 0.003574901493266225\n",
      "Epoch 0, Batch 22000, Loss: 0.003042355878278613\n",
      "Epoch 0, Batch 22050, Loss: 0.0020317949820309877\n",
      "Epoch 0, Batch 22100, Loss: 0.002356642624363303\n",
      "Epoch 0, Batch 22150, Loss: 0.0014212169917300344\n",
      "Epoch 0, Batch 22200, Loss: 0.0016485541127622128\n",
      "Epoch 0, Batch 22250, Loss: 0.0013399121817201376\n",
      "Epoch 0, Batch 22300, Loss: 0.0011940387776121497\n",
      "Epoch 0, Batch 22350, Loss: 0.002271217992529273\n",
      "Epoch 0, Batch 22400, Loss: 0.0028717974200844765\n",
      "Epoch 0, Batch 22450, Loss: 0.0023569350596517324\n",
      "Epoch 0, Batch 22500, Loss: 0.0017657297430559993\n",
      "Epoch 0, Batch 22550, Loss: 0.002696275245398283\n",
      "Epoch 0, Batch 22600, Loss: 0.0023391449358314276\n",
      "Epoch 0, Batch 22650, Loss: 0.00296231871470809\n",
      "Epoch 0, Batch 22700, Loss: 0.003224929329007864\n",
      "Epoch 0, Batch 22750, Loss: 0.0034266237635165453\n",
      "Epoch 0, Batch 22800, Loss: 0.003099821973592043\n",
      "Epoch 0, Batch 22850, Loss: 0.002175169065594673\n",
      "Epoch 0, Batch 22900, Loss: 0.002068465808406472\n",
      "Epoch 0, Batch 22950, Loss: 0.0013195143546909094\n",
      "Epoch 0, Batch 23000, Loss: 0.0008656115969642997\n",
      "Epoch 0, Batch 23050, Loss: 0.0010221714619547129\n",
      "Epoch 0, Batch 23100, Loss: 0.0010831851977854967\n",
      "Epoch 0, Batch 23150, Loss: 0.0019764783792197704\n",
      "Epoch 0, Batch 23200, Loss: 0.0018156508449465036\n",
      "Epoch 0, Batch 23250, Loss: 0.0011248678201809525\n",
      "Epoch 0, Batch 23300, Loss: 0.0021457774564623833\n",
      "Epoch 0, Batch 23350, Loss: 0.0022085413802415133\n",
      "Epoch 0, Batch 23400, Loss: 0.0012537463335320354\n",
      "Epoch 0, Batch 23450, Loss: 0.0024374083150178194\n",
      "Epoch 0, Batch 23500, Loss: 0.0034983817022293806\n",
      "Epoch 0, Batch 23550, Loss: 0.0018407652387395501\n",
      "Epoch 0, Batch 23600, Loss: 0.003346884623169899\n",
      "Epoch 0, Batch 23650, Loss: 0.0030095463152974844\n",
      "Epoch 0, Batch 23700, Loss: 0.0020673945546150208\n",
      "Epoch 0, Batch 23750, Loss: 0.002612883225083351\n",
      "Epoch 0, Batch 23800, Loss: 0.0032813537400215864\n",
      "Epoch 0, Batch 23850, Loss: 0.002711998065933585\n",
      "Epoch 0, Batch 23900, Loss: 0.0025424198247492313\n",
      "Epoch 0, Batch 23950, Loss: 0.0019705926533788443\n",
      "Epoch 0, Batch 24000, Loss: 0.0017892176983878016\n",
      "Epoch 0, Batch 24050, Loss: 0.00110963499173522\n",
      "Epoch 0, Batch 24100, Loss: 0.0013660421827808022\n",
      "Epoch 0, Batch 24150, Loss: 0.001567705301567912\n",
      "Epoch 0, Batch 24200, Loss: 0.002796160290017724\n",
      "Epoch 0, Batch 24250, Loss: 0.0025276662781834602\n",
      "Epoch 0, Batch 24300, Loss: 0.001841015531681478\n",
      "Epoch 0, Batch 24350, Loss: 0.0012742537073791027\n",
      "Epoch 0, Batch 24400, Loss: 0.001241438090801239\n",
      "Epoch 0, Batch 24450, Loss: 0.001099277171306312\n",
      "Epoch 0, Batch 24500, Loss: 0.0023182944860309362\n",
      "Epoch 0, Batch 24550, Loss: 0.0017801806097850204\n",
      "Epoch 0, Batch 24600, Loss: 0.0015571347903460264\n",
      "Epoch 0, Batch 24650, Loss: 0.0018732069293037057\n",
      "Epoch 0, Batch 24700, Loss: 0.0014888148289173841\n",
      "Epoch 0, Batch 24750, Loss: 0.0010294381063431501\n",
      "Epoch 0, Batch 24800, Loss: 0.002037642290815711\n",
      "Epoch 0, Batch 24850, Loss: 0.0020677163265645504\n",
      "Epoch 0, Batch 24900, Loss: 0.0020762255880981684\n",
      "Epoch 0, Batch 24950, Loss: 0.002301945351064205\n",
      "Epoch 0, Batch 25000, Loss: 0.0026773884892463684\n",
      "Epoch 0, Batch 25050, Loss: 0.0022065017838031054\n",
      "Epoch 0, Batch 25100, Loss: 0.0016934340819716454\n",
      "Epoch 0, Batch 25150, Loss: 0.001197469886392355\n",
      "Epoch 0, Batch 25200, Loss: 0.0008033209014683962\n",
      "Epoch 0, Batch 25250, Loss: 0.0007997810607776046\n",
      "Epoch 0, Batch 25300, Loss: 0.0015542454784736037\n",
      "Epoch 0, Batch 25350, Loss: 0.0012348599266260862\n",
      "Epoch 0, Batch 25400, Loss: 0.001094623701646924\n",
      "Epoch 0, Batch 25450, Loss: 0.0023200528230518103\n",
      "Epoch 0, Batch 25500, Loss: 0.002262470778077841\n",
      "Epoch 0, Batch 25550, Loss: 0.0012027729535475373\n",
      "Epoch 0, Batch 25600, Loss: 0.4315176010131836\n",
      "Epoch 0, Batch 25650, Loss: 0.0020440425723791122\n",
      "Epoch 0, Batch 25700, Loss: 0.0020169091876596212\n",
      "Epoch 0, Batch 25750, Loss: 0.0037386263720691204\n",
      "Epoch 0, Batch 25800, Loss: 0.0030731833539903164\n",
      "Epoch 0, Batch 25850, Loss: 0.00451027462258935\n",
      "Epoch 0, Batch 25900, Loss: 0.002209566067904234\n",
      "Epoch 0, Batch 25950, Loss: 0.00300980219617486\n",
      "Epoch 0, Batch 26000, Loss: 0.003731475444510579\n",
      "Epoch 0, Batch 26050, Loss: 0.0021296225022524595\n",
      "Epoch 0, Batch 26100, Loss: 0.002064075320959091\n",
      "Epoch 0, Batch 26150, Loss: 0.0021866997703909874\n",
      "Epoch 0, Batch 26200, Loss: 0.00316104618832469\n",
      "Epoch 0, Batch 26250, Loss: 0.002943259198218584\n",
      "Epoch 0, Batch 26300, Loss: 0.003217555582523346\n",
      "Epoch 0, Batch 26350, Loss: 0.0017611018847674131\n",
      "Epoch 0, Batch 26400, Loss: 0.0012189727276563644\n",
      "Epoch 0, Batch 26450, Loss: 0.0008341775392182171\n",
      "Epoch 0, Batch 26500, Loss: 0.001164872432127595\n",
      "Epoch 0, Batch 26550, Loss: 0.0013814314734190702\n",
      "Epoch 0, Batch 26600, Loss: 0.0015077170683071017\n",
      "Epoch 0, Batch 26650, Loss: 0.001328387763351202\n",
      "Epoch 0, Batch 26700, Loss: 0.0009489096119068563\n",
      "Epoch 0, Batch 26750, Loss: 0.0011289975373074412\n",
      "Epoch 0, Batch 26800, Loss: 0.4406205415725708\n",
      "Epoch 0, Batch 26850, Loss: 0.0012984280474483967\n",
      "Epoch 0, Batch 26900, Loss: 0.0014892154140397906\n",
      "Epoch 0, Batch 26950, Loss: 0.0014401120133697987\n",
      "Epoch 0, Batch 27000, Loss: 0.0025668414309620857\n",
      "Epoch 0, Batch 27050, Loss: 0.004364056047052145\n",
      "Epoch 0, Batch 27100, Loss: 0.0040527875535190105\n",
      "Epoch 0, Batch 27150, Loss: 0.003372784471139312\n",
      "Epoch 0, Batch 27200, Loss: 0.0027111682575196028\n",
      "Epoch 0, Batch 27250, Loss: 0.002405002247542143\n",
      "Epoch 0, Batch 27300, Loss: 0.0018572132103145123\n",
      "Epoch 0, Batch 27350, Loss: 0.0020180067513138056\n",
      "Epoch 0, Batch 27400, Loss: 0.0034977784380316734\n",
      "Epoch 0, Batch 27450, Loss: 0.0025647187139838934\n",
      "Epoch 0, Batch 27500, Loss: 0.004208363592624664\n",
      "Epoch 0, Batch 27550, Loss: 0.003872275585308671\n",
      "Epoch 0, Batch 27600, Loss: 0.0018812349298968911\n",
      "Epoch 0, Batch 27650, Loss: 0.0016622645780444145\n",
      "Epoch 0, Batch 27700, Loss: 0.001124371774494648\n",
      "Epoch 0, Batch 27750, Loss: 0.0019386883359402418\n",
      "Epoch 0, Batch 27800, Loss: 0.005140484776347876\n",
      "Epoch 0, Batch 27850, Loss: 0.0025392433162778616\n",
      "Epoch 0, Batch 27900, Loss: 0.0024038441479206085\n",
      "Epoch 0, Batch 27950, Loss: 0.0030916444957256317\n",
      "Epoch 0, Batch 28000, Loss: 0.003337489441037178\n",
      "Epoch 0, Batch 28050, Loss: 0.003680863883346319\n",
      "Epoch 0, Batch 28100, Loss: 0.002369790803641081\n",
      "Epoch 0, Batch 28150, Loss: 0.0023600447457283735\n",
      "Epoch 0, Batch 28200, Loss: 0.0028428747318685055\n",
      "Epoch 0, Batch 28250, Loss: 0.0020770009141415358\n",
      "Epoch 0, Batch 28300, Loss: 0.002216015476733446\n",
      "Epoch 0, Batch 28350, Loss: 0.0041379788890480995\n",
      "Epoch 0, Batch 28400, Loss: 0.35169538855552673\n",
      "Epoch 0, Batch 28450, Loss: 0.00313482410274446\n",
      "Epoch 0, Batch 28500, Loss: 0.0019814413972198963\n",
      "Epoch 0, Batch 28550, Loss: 0.0015470440266653895\n",
      "Epoch 0, Batch 28600, Loss: 0.001988079398870468\n",
      "Epoch 0, Batch 28650, Loss: 0.0022433213889598846\n",
      "Epoch 0, Batch 28700, Loss: 0.0030504062306135893\n",
      "Epoch 0, Batch 28750, Loss: 0.0019099427154287696\n",
      "Epoch 0, Batch 28800, Loss: 0.0012320877285674214\n",
      "Epoch 0, Batch 28850, Loss: 0.0023771426640450954\n",
      "Epoch 0, Batch 28900, Loss: 0.0030383788980543613\n",
      "Epoch 0, Batch 28950, Loss: 0.0024325221311300993\n",
      "Epoch 0, Batch 29000, Loss: 0.002989659085869789\n",
      "Epoch 0, Batch 29050, Loss: 0.002541256370022893\n",
      "Epoch 0, Batch 29100, Loss: 0.002606702037155628\n",
      "Epoch 0, Batch 29150, Loss: 0.004060742910951376\n",
      "Epoch 0, Batch 29200, Loss: 0.003142604371532798\n",
      "Epoch 0, Batch 29250, Loss: 0.002543356968089938\n",
      "Epoch 0, Batch 29300, Loss: 0.002123607089743018\n",
      "Epoch 0, Batch 29350, Loss: 0.0022879207972437143\n",
      "Epoch 0, Batch 29400, Loss: 0.3811648190021515\n",
      "Epoch 0, Batch 29450, Loss: 0.002095997566357255\n",
      "Epoch 0, Batch 29500, Loss: 0.0015283460961654782\n",
      "Epoch 0, Batch 29550, Loss: 0.0009927161736413836\n",
      "Epoch 0, Batch 29600, Loss: 0.0014725414803251624\n",
      "Epoch 0, Batch 29650, Loss: 0.0018194690346717834\n",
      "Epoch 0, Batch 29700, Loss: 0.0027221799828112125\n",
      "Epoch 0, Batch 29750, Loss: 0.003233127063140273\n",
      "Epoch 0, Batch 29800, Loss: 0.0027468751650303602\n",
      "Epoch 0, Batch 29850, Loss: 0.4162416458129883\n",
      "Epoch 0, Batch 29900, Loss: 0.00323783652856946\n",
      "Epoch 0, Batch 29950, Loss: 0.0020635691471397877\n",
      "Epoch 0, Batch 30000, Loss: 0.43008577823638916\n",
      "Epoch 0, Batch 30050, Loss: 0.0018490648362785578\n",
      "Epoch 0, Batch 30100, Loss: 0.0012218509800732136\n",
      "Epoch 0, Batch 30150, Loss: 0.0009704735712148249\n",
      "Epoch 0, Batch 30200, Loss: 0.0008342455257661641\n",
      "Epoch 0, Batch 30250, Loss: 0.0007839460158720613\n",
      "Epoch 0, Batch 30300, Loss: 0.0012411788338795304\n",
      "Epoch 0, Batch 30350, Loss: 0.0016521014040336013\n",
      "Epoch 0, Batch 30400, Loss: 0.0020157156977802515\n",
      "Epoch 0, Batch 30450, Loss: 0.0025147125124931335\n",
      "Epoch 0, Batch 30500, Loss: 0.0017060477985069156\n",
      "Epoch 0, Batch 30550, Loss: 0.3290613889694214\n",
      "Epoch 0, Batch 30600, Loss: 0.0038734611589461565\n",
      "Epoch 0, Batch 30650, Loss: 0.0022499551996588707\n",
      "Epoch 0, Batch 30700, Loss: 0.002120023360475898\n",
      "Epoch 0, Batch 30750, Loss: 0.0026632905937731266\n",
      "Epoch 0, Batch 30800, Loss: 0.0029428675770759583\n",
      "Epoch 0, Batch 30850, Loss: 0.3817567229270935\n",
      "Epoch 0, Batch 30900, Loss: 0.0019951588474214077\n",
      "Epoch 0, Batch 30950, Loss: 0.002454011235386133\n",
      "Epoch 0, Batch 31000, Loss: 0.002454499015584588\n",
      "Epoch 0, Batch 31050, Loss: 0.001980039058253169\n",
      "Epoch 0, Batch 31100, Loss: 0.0018176794983446598\n",
      "Epoch 0, Batch 31150, Loss: 0.0014153252122923732\n",
      "Epoch 0, Batch 31200, Loss: 0.00180243665818125\n",
      "Epoch 0, Batch 31250, Loss: 0.0025851509999483824\n",
      "Epoch 0, Batch 31300, Loss: 0.0022714685183018446\n",
      "Epoch 0, Batch 31350, Loss: 0.3726644515991211\n",
      "Epoch 0, Batch 31400, Loss: 0.4128732979297638\n",
      "Epoch 0, Batch 31450, Loss: 0.0021870972122997046\n",
      "Epoch 0, Batch 31500, Loss: 0.001557565527036786\n",
      "Epoch 0, Batch 31550, Loss: 0.0012188724940642715\n",
      "Epoch 0, Batch 31600, Loss: 0.0016550356522202492\n",
      "Epoch 0, Batch 31650, Loss: 0.0017045782878994942\n",
      "Epoch 0, Batch 31700, Loss: 0.0022191344760358334\n",
      "Epoch 0, Batch 31750, Loss: 0.0025663163978606462\n",
      "Epoch 0, Batch 31800, Loss: 0.002308651339262724\n",
      "Epoch 0, Batch 31850, Loss: 0.0025259596295654774\n",
      "Epoch 0, Batch 31900, Loss: 0.00219285418279469\n",
      "Epoch 0, Batch 31950, Loss: 0.0038862156216055155\n",
      "Epoch 0, Batch 32000, Loss: 0.33728766441345215\n",
      "Epoch 0, Batch 32050, Loss: 0.00292384997010231\n",
      "Epoch 0, Batch 32100, Loss: 0.0023417286574840546\n",
      "Epoch 0, Batch 32150, Loss: 0.0032349522225558758\n",
      "Epoch 0, Batch 32200, Loss: 0.0027996874414384365\n",
      "Epoch 0, Batch 32250, Loss: 0.0027358531951904297\n",
      "Epoch 0, Batch 32300, Loss: 0.001943457406014204\n",
      "Epoch 0, Batch 32350, Loss: 0.0024591253604739904\n",
      "Epoch 0, Batch 32400, Loss: 0.0029533389024436474\n",
      "Epoch 0, Batch 32450, Loss: 0.002922661602497101\n",
      "Epoch 0, Batch 32500, Loss: 0.0016275198431685567\n",
      "Epoch 0, Batch 32550, Loss: 0.0024107217323035\n",
      "Epoch 0, Batch 32600, Loss: 0.0025339117273688316\n",
      "Epoch 0, Batch 32650, Loss: 0.0028330660425126553\n",
      "Epoch 0, Batch 32700, Loss: 0.002501879585906863\n",
      "Epoch 0, Batch 32750, Loss: 0.0016121332300826907\n",
      "Epoch 0, Batch 32800, Loss: 0.0017066414002329111\n",
      "Epoch 0, Batch 32850, Loss: 0.0016398943262174726\n",
      "Epoch 0, Batch 32900, Loss: 0.001421742606908083\n",
      "Epoch 0, Batch 32950, Loss: 0.0017532503698021173\n",
      "Epoch 0, Batch 33000, Loss: 0.001782881561666727\n",
      "Epoch 0, Batch 33050, Loss: 0.00169679697137326\n",
      "Epoch 0, Batch 33100, Loss: 0.0023853641469031572\n",
      "Epoch 0, Batch 33150, Loss: 0.002887770999222994\n",
      "Epoch 0, Batch 33200, Loss: 0.0016799516743049026\n",
      "Epoch 0, Batch 33250, Loss: 0.001466266461648047\n",
      "Epoch 0, Batch 33300, Loss: 0.0014689834788441658\n",
      "Epoch 0, Batch 33350, Loss: 0.0015396049711853266\n",
      "Epoch 0, Batch 33400, Loss: 0.0032663997262716293\n",
      "Epoch 0, Batch 33450, Loss: 0.38078492879867554\n",
      "Epoch 0, Batch 33500, Loss: 0.0022990687284618616\n",
      "Epoch 0, Batch 33550, Loss: 0.00213515548966825\n",
      "Epoch 0, Batch 33600, Loss: 0.0017022003885358572\n",
      "Epoch 0, Batch 33650, Loss: 0.00254258094355464\n",
      "Epoch 0, Batch 33700, Loss: 0.0021678770426660776\n",
      "Epoch 0, Batch 33750, Loss: 0.0028114793822169304\n",
      "Epoch 0, Batch 33800, Loss: 0.0026507999282330275\n",
      "Epoch 0, Batch 33850, Loss: 0.002168123610317707\n",
      "Epoch 0, Batch 33900, Loss: 0.0016193549381569028\n",
      "Epoch 0, Batch 33950, Loss: 0.004771796986460686\n",
      "Epoch 0, Batch 34000, Loss: 0.006457462441176176\n",
      "Epoch 0, Batch 34050, Loss: 0.00336934020742774\n",
      "Epoch 0, Batch 34100, Loss: 0.0025888863019645214\n",
      "Epoch 0, Batch 34150, Loss: 0.0024490300565958023\n",
      "Epoch 0, Batch 34200, Loss: 0.001653051469475031\n",
      "Epoch 0, Batch 34250, Loss: 0.0014206668129190803\n",
      "Epoch 0, Batch 34300, Loss: 0.0023423810489475727\n",
      "Epoch 0, Batch 34350, Loss: 0.004501741845160723\n",
      "Epoch 0, Batch 34400, Loss: 0.0027687372639775276\n",
      "Epoch 0, Batch 34450, Loss: 0.001766715431585908\n",
      "Epoch 0, Batch 34500, Loss: 0.002813861006870866\n",
      "Epoch 0, Batch 34550, Loss: 0.0027625940274447203\n",
      "Epoch 0, Batch 34600, Loss: 0.0021141893230378628\n",
      "Epoch 0, Batch 34650, Loss: 0.0022182846441864967\n",
      "Epoch 0, Batch 34700, Loss: 0.0017573564546182752\n",
      "Epoch 0, Batch 34750, Loss: 0.0013404109049588442\n",
      "Epoch 0, Batch 34800, Loss: 0.001572232460603118\n",
      "Epoch 0, Batch 34850, Loss: 0.0013875418808311224\n",
      "Epoch 0, Batch 34900, Loss: 0.0013243851717561483\n",
      "Epoch 0, Batch 34950, Loss: 0.002761273179203272\n",
      "Epoch 0, Batch 35000, Loss: 0.001771896961145103\n",
      "Epoch 0, Batch 35050, Loss: 0.0013017893070355058\n",
      "Epoch 0, Batch 35100, Loss: 0.0017218802822753787\n",
      "Epoch 0, Batch 35150, Loss: 0.001283835619688034\n",
      "Epoch 0, Batch 35200, Loss: 0.0010626952862367034\n",
      "Epoch 0, Batch 35250, Loss: 0.0014954395592212677\n",
      "Epoch 0, Batch 35300, Loss: 0.0032176440581679344\n",
      "Epoch 0, Batch 35350, Loss: 0.002289555035531521\n",
      "Epoch 0, Batch 35400, Loss: 0.003336509456858039\n",
      "Epoch 0, Batch 35450, Loss: 0.002207917394116521\n",
      "Epoch 0, Batch 35500, Loss: 0.0018097470747306943\n",
      "Epoch 0, Batch 35550, Loss: 0.0022146275732666254\n",
      "Epoch 0, Batch 35600, Loss: 0.0051271854899823666\n",
      "Epoch 0, Batch 35650, Loss: 0.0036959503777325153\n",
      "Epoch 0, Batch 35700, Loss: 0.003739952575415373\n",
      "Epoch 0, Batch 35750, Loss: 0.0025779379066079855\n",
      "Epoch 0, Batch 35800, Loss: 0.002725499914959073\n",
      "Epoch 0, Batch 35850, Loss: 0.0018295575864613056\n",
      "Epoch 0, Batch 35900, Loss: 0.0014717666199430823\n",
      "Epoch 0, Batch 35950, Loss: 0.0013477853499352932\n",
      "Epoch 0, Batch 36000, Loss: 0.001419658656232059\n",
      "Epoch 0, Batch 36050, Loss: 0.001707941060885787\n",
      "Epoch 0, Batch 36100, Loss: 0.0021853952202945948\n",
      "Epoch 0, Batch 36150, Loss: 0.0016909168334677815\n",
      "Epoch 0, Batch 36200, Loss: 0.002827726537361741\n",
      "Epoch 0, Batch 36250, Loss: 0.0021532573737204075\n",
      "Epoch 0, Batch 36300, Loss: 0.003004206344485283\n",
      "Epoch 0, Batch 36350, Loss: 0.003810510039329529\n",
      "Epoch 0, Batch 36400, Loss: 0.002492284867912531\n",
      "Epoch 0, Batch 36450, Loss: 0.0027558058500289917\n",
      "Epoch 0, Batch 36500, Loss: 0.004587050527334213\n",
      "Epoch 0, Batch 36550, Loss: 0.005280445329844952\n",
      "Epoch 0, Batch 36600, Loss: 0.0039035652298480272\n",
      "Epoch 0, Batch 36650, Loss: 0.0026345476508140564\n",
      "Epoch 0, Batch 36700, Loss: 0.003659278154373169\n",
      "Epoch 0, Batch 36750, Loss: 0.0020377894397825003\n",
      "Epoch 0, Batch 36800, Loss: 0.0020537618547677994\n",
      "Epoch 0, Batch 36850, Loss: 0.41966283321380615\n",
      "Epoch 0, Batch 36900, Loss: 0.002374590840190649\n",
      "Epoch 0, Batch 36950, Loss: 0.0025441832840442657\n",
      "Epoch 0, Batch 37000, Loss: 0.002466069534420967\n",
      "Epoch 0, Batch 37050, Loss: 0.0035605141893029213\n",
      "Epoch 0, Batch 37100, Loss: 0.0020562601275742054\n",
      "Epoch 0, Batch 37150, Loss: 0.0023134795483201742\n",
      "Epoch 0, Batch 37200, Loss: 0.0021821055561304092\n",
      "Epoch 0, Batch 37250, Loss: 0.0023580710403621197\n",
      "Epoch 0, Batch 37300, Loss: 0.0028548790141940117\n",
      "Epoch 0, Batch 37350, Loss: 0.0018631460843607783\n",
      "Epoch 0, Batch 37400, Loss: 0.0023648040369153023\n",
      "Epoch 0, Batch 37450, Loss: 0.0018413853831589222\n",
      "Epoch 0, Batch 37500, Loss: 0.003847645130008459\n",
      "Epoch 0, Batch 37550, Loss: 0.003392113372683525\n",
      "Epoch 0, Batch 37600, Loss: 0.0022833067923784256\n",
      "Epoch 0, Batch 37650, Loss: 0.37995877861976624\n",
      "Epoch 0, Batch 37700, Loss: 0.002558111445978284\n",
      "Epoch 0, Batch 37750, Loss: 0.00196888973005116\n",
      "Epoch 0, Batch 37800, Loss: 0.001783087383955717\n",
      "Epoch 0, Batch 37850, Loss: 0.002076513133943081\n",
      "Epoch 0, Batch 37900, Loss: 0.0014190289657562971\n",
      "Epoch 0, Batch 37950, Loss: 0.0015489663928747177\n",
      "Epoch 0, Batch 38000, Loss: 0.0017034080810844898\n",
      "Epoch 0, Batch 38050, Loss: 0.0012818695977330208\n",
      "Epoch 0, Batch 38100, Loss: 0.0014423945685848594\n",
      "Epoch 0, Batch 38150, Loss: 0.0010156624484807253\n",
      "Epoch 0, Batch 38200, Loss: 0.0014500065008178353\n",
      "Epoch 0, Batch 38250, Loss: 0.0032392919529229403\n",
      "Epoch 0, Batch 38300, Loss: 0.0032070884481072426\n",
      "Epoch 0, Batch 38350, Loss: 0.0031530950218439102\n",
      "Epoch 0, Batch 38400, Loss: 0.002156349364668131\n",
      "Epoch 0, Batch 38450, Loss: 0.0020328997634351254\n",
      "Epoch 0, Batch 38500, Loss: 0.001842521596699953\n",
      "Epoch 0, Batch 38550, Loss: 0.0011845673434436321\n",
      "Epoch 0, Batch 38600, Loss: 0.0016020238399505615\n",
      "Epoch 0, Batch 38650, Loss: 0.0029429513961076736\n",
      "Epoch 0, Batch 38700, Loss: 0.0016162833198904991\n",
      "Epoch 0, Batch 38750, Loss: 0.3923889696598053\n",
      "Epoch 0, Batch 38800, Loss: 0.0013751756632700562\n",
      "Epoch 0, Batch 38850, Loss: 0.001826888183131814\n",
      "Epoch 0, Batch 38900, Loss: 0.0013982021482661366\n",
      "Epoch 0, Batch 38950, Loss: 0.001282055163756013\n",
      "Epoch 0, Batch 39000, Loss: 0.0013862057821825147\n",
      "Epoch 0, Batch 39050, Loss: 0.001628758735023439\n",
      "Epoch 0, Batch 39100, Loss: 0.003117903135716915\n",
      "Epoch 0, Batch 39150, Loss: 0.002619838807731867\n",
      "Epoch 0, Batch 39200, Loss: 0.0028310767374932766\n",
      "Epoch 0, Batch 39250, Loss: 0.0021168093662708998\n",
      "Epoch 0, Batch 39300, Loss: 0.0016441525658592582\n",
      "Epoch 0, Batch 39350, Loss: 0.0011878485092893243\n",
      "Epoch 0, Batch 39400, Loss: 0.002014639787375927\n",
      "Epoch 0, Batch 39450, Loss: 0.002278298605233431\n",
      "Epoch 0, Batch 39500, Loss: 0.001989619806408882\n",
      "Epoch 0, Batch 39550, Loss: 0.0035643342416733503\n",
      "Epoch 0, Batch 39600, Loss: 0.002250857185572386\n",
      "Epoch 0, Batch 39650, Loss: 0.0017609605565667152\n",
      "Epoch 0, Batch 39700, Loss: 0.002212029416114092\n",
      "Epoch 0, Batch 39750, Loss: 0.002017853083088994\n",
      "Epoch 0, Batch 39800, Loss: 0.002487001707777381\n",
      "Epoch 0, Batch 39850, Loss: 0.0017650120425969362\n",
      "Epoch 0, Batch 39900, Loss: 0.0013595185009762645\n",
      "Epoch 0, Batch 39950, Loss: 0.0012011855142191052\n",
      "Epoch 0, Batch 40000, Loss: 0.0026103288400918245\n",
      "Epoch 0, Batch 40050, Loss: 0.0027361568063497543\n",
      "Epoch 0, Batch 40100, Loss: 0.003350399900227785\n",
      "Epoch 0, Batch 40150, Loss: 0.003194639924913645\n",
      "Epoch 0, Batch 40200, Loss: 0.0024302254896610975\n",
      "Epoch 0, Batch 40250, Loss: 0.00212052371352911\n",
      "Epoch 0, Batch 40300, Loss: 0.0014917418593540788\n",
      "Epoch 0, Batch 40350, Loss: 0.41939830780029297\n",
      "Epoch 0, Batch 40400, Loss: 0.0024477008264511824\n",
      "Epoch 0, Batch 40450, Loss: 0.002118039643391967\n",
      "Epoch 0, Batch 40500, Loss: 0.0031665945425629616\n",
      "Epoch 0, Batch 40550, Loss: 0.0025150636211037636\n",
      "Epoch 0, Batch 40600, Loss: 0.002396370517089963\n",
      "Epoch 0, Batch 40650, Loss: 0.0019437946612015367\n",
      "Epoch 0, Batch 40700, Loss: 0.001405153307132423\n",
      "Epoch 0, Batch 40750, Loss: 0.0013924839440733194\n",
      "Epoch 0, Batch 40800, Loss: 0.0024941302835941315\n",
      "Epoch 0, Batch 40850, Loss: 0.0019428996602073312\n",
      "Epoch 0, Batch 40900, Loss: 0.0026703085750341415\n",
      "Epoch 0, Batch 40950, Loss: 0.0034642985556274652\n",
      "Epoch 0, Batch 41000, Loss: 0.0019907618407160044\n",
      "Epoch 0, Batch 41050, Loss: 0.001600061310455203\n",
      "Epoch 0, Batch 41100, Loss: 0.0011792754521593451\n",
      "Epoch 0, Batch 41150, Loss: 0.0009331946494057775\n",
      "Epoch 0, Batch 41200, Loss: 0.0008178859134204686\n",
      "Epoch 0, Batch 41250, Loss: 0.0016548411222174764\n",
      "Epoch 0, Batch 41300, Loss: 0.0020064804702997208\n",
      "Epoch 0, Batch 41350, Loss: 0.0017812465084716678\n",
      "Epoch 0, Batch 41400, Loss: 0.0050774235278368\n",
      "Epoch 0, Batch 41450, Loss: 0.004023237619549036\n",
      "Epoch 0, Batch 41500, Loss: 0.0029137833043932915\n",
      "Epoch 0, Batch 41550, Loss: 0.0016767075285315514\n",
      "Epoch 0, Batch 41600, Loss: 0.0015093997353687882\n",
      "Epoch 0, Batch 41650, Loss: 0.0010811989195644855\n",
      "Epoch 0, Batch 41700, Loss: 0.0009390002815052867\n",
      "Epoch 0, Batch 41750, Loss: 0.0008188057108782232\n",
      "Epoch 0, Batch 41800, Loss: 0.0012466281186789274\n",
      "Epoch 0, Batch 41850, Loss: 0.0016343856696039438\n",
      "Epoch 0, Batch 41900, Loss: 0.0019184923730790615\n",
      "Epoch 0, Batch 41950, Loss: 0.0028949417173862457\n",
      "Epoch 0, Batch 42000, Loss: 0.002163482829928398\n",
      "Epoch 0, Batch 42050, Loss: 0.0024516726844012737\n",
      "Epoch 0, Batch 42100, Loss: 0.0024451641365885735\n",
      "Epoch 0, Batch 42150, Loss: 0.001393595477566123\n",
      "Epoch 0, Batch 42200, Loss: 0.0018792299088090658\n",
      "Epoch 0, Batch 42250, Loss: 0.003035925328731537\n",
      "Epoch 0, Batch 42300, Loss: 0.0028028362430632114\n",
      "Epoch 0, Batch 42350, Loss: 0.002581915585324168\n",
      "Epoch 0, Batch 42400, Loss: 0.002350838389247656\n",
      "Epoch 0, Batch 42450, Loss: 0.0016878327587619424\n",
      "Epoch 0, Batch 42500, Loss: 0.0026894179172813892\n",
      "Epoch 0, Batch 42550, Loss: 0.0035419624764472246\n",
      "Epoch 0, Batch 42600, Loss: 0.0025070791598409414\n",
      "Epoch 0, Batch 42650, Loss: 0.002764457603916526\n",
      "Epoch 0, Batch 42700, Loss: 0.002585591981187463\n",
      "Epoch 0, Batch 42750, Loss: 0.003013049717992544\n",
      "Epoch 0, Batch 42800, Loss: 0.0038084385450929403\n",
      "Epoch 0, Batch 42850, Loss: 0.0028846198692917824\n",
      "Epoch 0, Batch 42900, Loss: 0.002947767497971654\n",
      "Epoch 0, Batch 42950, Loss: 0.002880517626181245\n",
      "Epoch 0, Batch 43000, Loss: 0.002793333726003766\n",
      "Epoch 0, Batch 43050, Loss: 0.0029259859584271908\n",
      "Epoch 0, Batch 43100, Loss: 0.0033068328630179167\n",
      "Epoch 0, Batch 43150, Loss: 0.0025384523905813694\n",
      "Epoch 0, Batch 43200, Loss: 0.0026808588299900293\n",
      "Epoch 0, Batch 43250, Loss: 0.0016738177509978414\n",
      "Epoch 0, Batch 43300, Loss: 0.00241269962862134\n",
      "Epoch 0, Batch 43350, Loss: 0.0025143560487776995\n",
      "Epoch 0, Batch 43400, Loss: 0.0033898053225129843\n",
      "Epoch 0, Batch 43450, Loss: 0.0027026080060750246\n",
      "Epoch 0, Batch 43500, Loss: 0.0024958783760666847\n",
      "Epoch 0, Batch 43550, Loss: 0.002359001198783517\n",
      "Epoch 0, Batch 43600, Loss: 0.004146090243011713\n",
      "Epoch 0, Batch 43650, Loss: 0.003948545549064875\n",
      "Epoch 0, Batch 43700, Loss: 0.003886655904352665\n",
      "Epoch 0, Batch 43750, Loss: 0.002440391108393669\n",
      "Epoch 0, Batch 43800, Loss: 0.003295839997008443\n",
      "Epoch 0, Batch 43850, Loss: 0.00208645430393517\n",
      "Epoch 0, Batch 43900, Loss: 0.0019514656160026789\n",
      "Epoch 0, Batch 43950, Loss: 0.003139038337394595\n",
      "Epoch 0, Batch 44000, Loss: 0.0060684895142912865\n",
      "Epoch 0, Batch 44050, Loss: 0.004166815895587206\n",
      "Epoch 0, Batch 44100, Loss: 0.35327327251434326\n",
      "Epoch 0, Batch 44150, Loss: 0.002505714073777199\n",
      "Epoch 0, Batch 44200, Loss: 0.0026923217810690403\n",
      "Epoch 0, Batch 44250, Loss: 0.0029816243331879377\n",
      "Epoch 0, Batch 44300, Loss: 0.0027364783454686403\n",
      "Epoch 0, Batch 44350, Loss: 0.0018407006282359362\n",
      "Epoch 0, Batch 44400, Loss: 0.0014587679179385304\n",
      "Epoch 0, Batch 44450, Loss: 0.001203911262564361\n",
      "Epoch 0, Batch 44500, Loss: 0.0010672413045540452\n",
      "Epoch 0, Batch 44550, Loss: 0.001071468461304903\n",
      "Epoch 0, Batch 44600, Loss: 0.0020844661630690098\n",
      "Epoch 0, Batch 44650, Loss: 0.002189797116443515\n",
      "Epoch 0, Batch 44700, Loss: 0.004148638807237148\n",
      "Epoch 0, Batch 44750, Loss: 0.003299521282315254\n",
      "Epoch 0, Batch 44800, Loss: 0.004091472364962101\n",
      "Epoch 0, Batch 44850, Loss: 0.0035831506829708815\n",
      "Epoch 0, Batch 44900, Loss: 0.0033210162073373795\n",
      "Epoch 0, Batch 44950, Loss: 0.002174732740968466\n",
      "Epoch 0, Batch 45000, Loss: 0.0016712658107280731\n",
      "Epoch 0, Batch 45050, Loss: 0.0013524267124012113\n",
      "Epoch 0, Batch 45100, Loss: 0.00152629055082798\n",
      "Epoch 0, Batch 45150, Loss: 0.0012733860639855266\n",
      "Epoch 0, Batch 45200, Loss: 0.0017172382213175297\n",
      "Epoch 0, Batch 45250, Loss: 0.002121364464983344\n",
      "Epoch 0, Batch 45300, Loss: 0.002224856521934271\n",
      "Epoch 0, Batch 45350, Loss: 0.0023313509300351143\n",
      "Epoch 0, Batch 45400, Loss: 0.001781283994205296\n",
      "Epoch 0, Batch 45450, Loss: 0.0018312057945877314\n",
      "Epoch 0, Batch 45500, Loss: 0.0024886364117264748\n",
      "Epoch 0, Batch 45550, Loss: 0.002095663221552968\n",
      "Epoch 0, Batch 45600, Loss: 0.002780669368803501\n",
      "Epoch 0, Batch 45650, Loss: 0.3656021058559418\n",
      "Epoch 0, Batch 45700, Loss: 0.0020069831516593695\n",
      "Epoch 0, Batch 45750, Loss: 0.002417330862954259\n",
      "Epoch 0, Batch 45800, Loss: 0.0021626718807965517\n",
      "Epoch 0, Batch 45850, Loss: 0.0013960701180621982\n",
      "Epoch 0, Batch 45900, Loss: 0.0017315500881522894\n",
      "Epoch 0, Batch 45950, Loss: 0.0011853612959384918\n",
      "Epoch 0, Batch 46000, Loss: 0.001526892650872469\n",
      "Epoch 0, Batch 46050, Loss: 0.001794619602151215\n",
      "Epoch 0, Batch 46100, Loss: 0.0014699229504913092\n",
      "Epoch 0, Batch 46150, Loss: 0.0014842306263744831\n",
      "Epoch 0, Batch 46200, Loss: 0.0014352264115586877\n",
      "Epoch 0, Batch 46250, Loss: 0.002026902511715889\n",
      "Epoch 0, Batch 46300, Loss: 0.0014191714581102133\n",
      "Epoch 0, Batch 46350, Loss: 0.0020399282220751047\n",
      "Epoch 0, Batch 46400, Loss: 0.0018438426777720451\n",
      "Epoch 0, Batch 46450, Loss: 0.0016536052571609616\n",
      "Epoch 0, Batch 46500, Loss: 0.0015405945014208555\n",
      "Epoch 0, Batch 46550, Loss: 0.0010847396915778518\n",
      "Epoch 0, Batch 46600, Loss: 0.001545999781228602\n",
      "Epoch 0, Batch 46650, Loss: 0.0016566443955525756\n",
      "Epoch 0, Batch 46700, Loss: 0.0020967996679246426\n",
      "Epoch 0, Batch 46750, Loss: 0.0032948791049420834\n",
      "Epoch 0, Batch 46800, Loss: 0.0018529720837250352\n",
      "Epoch 0, Batch 46850, Loss: 0.0017725973157212138\n",
      "Epoch 0, Batch 46900, Loss: 0.0020487243309617043\n",
      "Epoch 0, Batch 46950, Loss: 0.001819388009607792\n",
      "Epoch 0, Batch 47000, Loss: 0.0020625856705009937\n",
      "Epoch 0, Batch 47050, Loss: 0.004696852993220091\n",
      "Epoch 0, Batch 47100, Loss: 0.004539670888334513\n",
      "Epoch 0, Batch 47150, Loss: 0.002786932745948434\n",
      "Epoch 0, Batch 47200, Loss: 0.0021458908449858427\n",
      "Epoch 0, Batch 47250, Loss: 0.0016030773986130953\n",
      "Epoch 0, Batch 47300, Loss: 0.001405359711498022\n",
      "Epoch 0, Batch 47350, Loss: 0.0015161375049501657\n",
      "Epoch 0, Batch 47400, Loss: 0.0015062994789332151\n",
      "Epoch 0, Batch 47450, Loss: 0.0011200818698853254\n",
      "Epoch 0, Batch 47500, Loss: 0.0016592465108260512\n",
      "Epoch 0, Batch 47550, Loss: 0.38324347138404846\n",
      "Epoch 0, Batch 47600, Loss: 0.0027037595864385366\n",
      "Epoch 0, Batch 47650, Loss: 0.0026177489198744297\n",
      "Epoch 0, Batch 47700, Loss: 0.002164106350392103\n",
      "Epoch 0, Batch 47750, Loss: 0.00190460286103189\n",
      "Epoch 0, Batch 47800, Loss: 0.002301381900906563\n",
      "Epoch 0, Batch 47850, Loss: 0.002499203896149993\n",
      "Epoch 0, Batch 47900, Loss: 0.0020330045372247696\n",
      "Epoch 0, Batch 47950, Loss: 0.001741829444654286\n",
      "Epoch 0, Batch 48000, Loss: 0.0014964982401579618\n",
      "Epoch 0, Batch 48050, Loss: 0.0015255461912602186\n",
      "Epoch 0, Batch 48100, Loss: 0.0013017724268138409\n",
      "Epoch 0, Batch 48150, Loss: 0.001569286105223\n",
      "Epoch 0, Batch 48200, Loss: 0.003221375634893775\n",
      "Epoch 0, Batch 48250, Loss: 0.002479501534253359\n",
      "Epoch 0, Batch 48300, Loss: 0.0024655149318277836\n",
      "Epoch 0, Batch 48350, Loss: 0.0018374192295596004\n",
      "Epoch 0, Batch 48400, Loss: 0.0013951151631772518\n",
      "Epoch 0, Batch 48450, Loss: 0.0016950989374890924\n",
      "Epoch 0, Batch 48500, Loss: 0.0012391877826303244\n",
      "Epoch 0, Batch 48550, Loss: 0.0010271440260112286\n",
      "Epoch 0, Batch 48600, Loss: 0.0010135523043572903\n",
      "Epoch 0, Batch 48650, Loss: 0.0013659141259267926\n",
      "Epoch 0, Batch 48700, Loss: 0.0014597346307709813\n",
      "Epoch 0, Batch 48750, Loss: 0.0016835056012496352\n",
      "Epoch 0, Batch 48800, Loss: 0.002460339106619358\n",
      "Epoch 0, Batch 48850, Loss: 0.0021929896902292967\n",
      "Epoch 0, Batch 48900, Loss: 0.0020183261949568987\n",
      "Epoch 0, Batch 48950, Loss: 0.0014823530800640583\n",
      "Epoch 0, Batch 49000, Loss: 0.0020952350459992886\n",
      "Epoch 0, Batch 49050, Loss: 0.00408116914331913\n",
      "Epoch 0, Batch 49100, Loss: 0.37563052773475647\n",
      "Epoch 0, Batch 49150, Loss: 0.002534301020205021\n",
      "Epoch 0, Batch 49200, Loss: 0.002666671061888337\n",
      "Epoch 0, Batch 49250, Loss: 0.002525519812479615\n",
      "Epoch 0, Batch 49300, Loss: 0.0034207620192319155\n",
      "Epoch 0, Batch 49350, Loss: 0.002430348889902234\n",
      "Epoch 0, Batch 49400, Loss: 0.002937103621661663\n",
      "Epoch 0, Batch 49450, Loss: 0.003945391625165939\n",
      "Epoch 0, Batch 49500, Loss: 0.003023469354957342\n",
      "Epoch 0, Batch 49550, Loss: 0.0022965422831475735\n",
      "Epoch 0, Batch 49600, Loss: 0.0017560007981956005\n",
      "Epoch 0, Batch 49650, Loss: 0.0013993600150570273\n",
      "Epoch 0, Batch 49700, Loss: 0.0026757572777569294\n",
      "Epoch 0, Batch 49750, Loss: 0.001827799715101719\n",
      "Epoch 0, Batch 49800, Loss: 0.0021106735803186893\n",
      "Epoch 0, Batch 49850, Loss: 0.0016693475190550089\n",
      "Epoch 0, Batch 49900, Loss: 0.0015156627632677555\n",
      "Epoch 0, Batch 49950, Loss: 0.0021394253708422184\n",
      "Epoch 0, Batch 50000, Loss: 0.002620471641421318\n",
      "Epoch 0, Batch 50050, Loss: 0.002549008233472705\n",
      "Epoch 0, Batch 50100, Loss: 0.0028778170235455036\n",
      "Epoch 0, Batch 50150, Loss: 0.002953514689579606\n",
      "Epoch 0, Batch 50200, Loss: 0.00163848209194839\n",
      "Epoch 0, Batch 50250, Loss: 0.0018106414936482906\n",
      "Epoch 0, Batch 50300, Loss: 0.0016386444913223386\n",
      "Epoch 0, Batch 50350, Loss: 0.0018726458074524999\n",
      "Epoch 0, Batch 50400, Loss: 0.0019805142655968666\n",
      "Epoch 0, Batch 50450, Loss: 0.002082839608192444\n",
      "Epoch 0, Batch 50500, Loss: 0.00399031862616539\n",
      "Epoch 0, Batch 50550, Loss: 0.002975230338051915\n",
      "Epoch 0, Batch 50600, Loss: 0.0019745135214179754\n",
      "Epoch 0, Batch 50650, Loss: 0.0021024008747190237\n",
      "Epoch 0, Batch 50700, Loss: 0.002761924173682928\n",
      "Epoch 0, Batch 50750, Loss: 0.0018496005795896053\n",
      "Epoch 0, Batch 50800, Loss: 0.0012492986861616373\n",
      "Epoch 0, Batch 50850, Loss: 0.0011978124966844916\n",
      "Epoch 0, Batch 50900, Loss: 0.0009957232978194952\n",
      "Epoch 0, Batch 50950, Loss: 0.0007513784803450108\n",
      "Epoch 0, Batch 51000, Loss: 0.0017512984341010451\n",
      "Epoch 0, Batch 51050, Loss: 0.0024162926711142063\n",
      "Epoch 0, Batch 51100, Loss: 0.002451938344165683\n",
      "Epoch 0, Batch 51150, Loss: 0.0017378717893734574\n",
      "Epoch 0, Batch 51200, Loss: 0.0017919407691806555\n",
      "Epoch 0, Batch 51250, Loss: 0.002405596897006035\n",
      "Epoch 0, Batch 51300, Loss: 0.0025728221517056227\n",
      "Epoch 0, Batch 51350, Loss: 0.002719445154070854\n",
      "Epoch 0, Batch 51400, Loss: 0.0029529472813010216\n",
      "Epoch 0, Batch 51450, Loss: 0.002976713003590703\n",
      "Epoch 0, Batch 51500, Loss: 0.002253466285765171\n",
      "Epoch 0, Batch 51550, Loss: 0.0031007430516183376\n",
      "Epoch 0, Batch 51600, Loss: 0.0030649201944470406\n",
      "Epoch 0, Batch 51650, Loss: 0.0019093564478680491\n",
      "Epoch 0, Batch 51700, Loss: 0.0017025155248120427\n",
      "Epoch 0, Batch 51750, Loss: 0.0016203428385779262\n",
      "Epoch 0, Batch 51800, Loss: 0.3736024796962738\n",
      "Epoch 0, Batch 51850, Loss: 0.0017779916524887085\n",
      "Epoch 0, Batch 51900, Loss: 0.001408151350915432\n",
      "Epoch 0, Batch 51950, Loss: 0.0013223789865151048\n",
      "Epoch 0, Batch 52000, Loss: 0.0012136501027271152\n",
      "Epoch 0, Batch 52050, Loss: 0.0014723759377375245\n",
      "Epoch 0, Batch 52100, Loss: 0.0017450767336413264\n",
      "Epoch 0, Batch 52150, Loss: 0.0015129601815715432\n",
      "Epoch 0, Batch 52200, Loss: 0.002540546702221036\n",
      "Epoch 0, Batch 52250, Loss: 0.0024544934276491404\n",
      "Epoch 0, Batch 52300, Loss: 0.00277059362269938\n",
      "Epoch 0, Batch 52350, Loss: 0.002180347917601466\n",
      "Epoch 0, Batch 52400, Loss: 0.0018708512652665377\n",
      "Epoch 0, Batch 52450, Loss: 0.0013619113015010953\n",
      "Epoch 0, Batch 52500, Loss: 0.0027870098128914833\n",
      "Epoch 0, Batch 52550, Loss: 0.0028333235532045364\n",
      "Epoch 0, Batch 52600, Loss: 0.0023481145035475492\n",
      "Epoch 0, Batch 52650, Loss: 0.0014463600236922503\n",
      "Epoch 0, Batch 52700, Loss: 0.00166029529646039\n",
      "Epoch 0, Batch 52750, Loss: 0.0021243845112621784\n",
      "Epoch 0, Batch 52800, Loss: 0.001599394017830491\n",
      "Epoch 0, Batch 52850, Loss: 0.0014468185836449265\n",
      "Epoch 0, Batch 52900, Loss: 0.003019411116838455\n",
      "Epoch 0, Batch 52950, Loss: 0.0018764189444482327\n",
      "Epoch 0, Batch 53000, Loss: 0.002110158558934927\n",
      "Epoch 0, Batch 53050, Loss: 0.002870691241696477\n",
      "Epoch 0, Batch 53100, Loss: 0.0021579444874078035\n",
      "Epoch 0, Batch 53150, Loss: 0.001995514612644911\n",
      "Epoch 0, Batch 53200, Loss: 0.0015672126319259405\n",
      "Epoch 0, Batch 53250, Loss: 0.0012262845411896706\n",
      "Epoch 0, Batch 53300, Loss: 0.0015276900958269835\n",
      "Epoch 0, Batch 53350, Loss: 0.0014414985198527575\n",
      "Epoch 0, Batch 53400, Loss: 0.0013973666355013847\n",
      "Epoch 0, Batch 53450, Loss: 0.0010966778500005603\n",
      "Epoch 0, Batch 53500, Loss: 0.0009961831383407116\n",
      "Epoch 0, Batch 53550, Loss: 0.0010992229217663407\n",
      "Epoch 0, Batch 53600, Loss: 0.000881195766851306\n",
      "Epoch 0, Batch 53650, Loss: 0.0007496863254345953\n",
      "Epoch 0, Batch 53700, Loss: 0.0008027123403735459\n",
      "Epoch 0, Batch 53750, Loss: 0.0014672080287709832\n",
      "Epoch 0, Batch 53800, Loss: 0.002773866057395935\n",
      "Epoch 0, Batch 53850, Loss: 0.0023591474164277315\n",
      "Epoch 0, Batch 53900, Loss: 0.0019294541561976075\n",
      "Epoch 0, Batch 53950, Loss: 0.0015256396727636456\n",
      "Epoch 0, Batch 54000, Loss: 0.0020056646317243576\n",
      "Epoch 0, Batch 54050, Loss: 0.0013581879902631044\n",
      "Epoch 0, Batch 54100, Loss: 0.0015345398569479585\n",
      "Epoch 0, Batch 54150, Loss: 0.0017039026133716106\n",
      "Epoch 0, Batch 54200, Loss: 0.0029419907368719578\n",
      "Epoch 0, Batch 54250, Loss: 0.002304684603586793\n",
      "Epoch 0, Batch 54300, Loss: 0.002827515359967947\n",
      "Epoch 0, Batch 54350, Loss: 0.0020234521944075823\n",
      "Epoch 0, Batch 54400, Loss: 0.002850097371265292\n",
      "Epoch 0, Batch 54450, Loss: 0.0022675269283354282\n",
      "Epoch 0, Batch 54500, Loss: 0.0012924582697451115\n",
      "Epoch 0, Batch 54550, Loss: 0.0009682729141786695\n",
      "Epoch 0, Batch 54600, Loss: 0.0010257652029395103\n",
      "Epoch 0, Batch 54650, Loss: 0.0015671263681724668\n",
      "Epoch 0, Batch 54700, Loss: 0.002225087257102132\n",
      "Epoch 0, Batch 54750, Loss: 0.0019268348114565015\n",
      "Epoch 0, Batch 54800, Loss: 0.001794404466636479\n",
      "Epoch 0, Batch 54850, Loss: 0.0012283908436074853\n",
      "Epoch 0, Batch 54900, Loss: 0.0010319111170247197\n",
      "Epoch 0, Batch 54950, Loss: 0.0012583265779539943\n",
      "Epoch 0, Batch 55000, Loss: 0.0009872769005596638\n",
      "Epoch 0, Batch 55050, Loss: 0.0015729686710983515\n",
      "Epoch 0, Batch 55100, Loss: 0.003876646514981985\n",
      "Epoch 0, Batch 55150, Loss: 0.003108550328761339\n",
      "Epoch 0, Batch 55200, Loss: 0.0025052656419575214\n",
      "Epoch 0, Batch 55250, Loss: 0.002083399798721075\n",
      "Epoch 0, Batch 55300, Loss: 0.0018540602177381516\n",
      "Epoch 0, Batch 55350, Loss: 0.0018820995464920998\n",
      "Epoch 0, Batch 55400, Loss: 0.394069641828537\n",
      "Epoch 0, Batch 55450, Loss: 0.002540062880143523\n",
      "Epoch 0, Batch 55500, Loss: 0.003171152900904417\n",
      "Epoch 0, Batch 55550, Loss: 0.001939487410709262\n",
      "Epoch 0, Batch 55600, Loss: 0.0012992681004106998\n",
      "Epoch 0, Batch 55650, Loss: 0.0016357129206880927\n",
      "Epoch 0, Batch 55700, Loss: 0.0013654788490384817\n",
      "Epoch 0, Batch 55750, Loss: 0.001421801745891571\n",
      "Epoch 0, Batch 55800, Loss: 0.001018231618218124\n",
      "Epoch 0, Batch 55850, Loss: 0.0010956099722534418\n",
      "Epoch 0, Batch 55900, Loss: 0.0010361979948356748\n",
      "Epoch 0, Batch 55950, Loss: 0.001273683039471507\n",
      "Epoch 0, Batch 56000, Loss: 0.001218242570757866\n",
      "Epoch 0, Batch 56050, Loss: 0.0014704903587698936\n",
      "Epoch 0, Batch 56100, Loss: 0.0018537462456151843\n",
      "Epoch 0, Batch 56150, Loss: 0.0019488895777612925\n",
      "Epoch 0, Batch 56200, Loss: 0.0017878739163279533\n",
      "Epoch 0, Batch 56250, Loss: 0.0010703573934733868\n",
      "Epoch 0, Batch 56300, Loss: 0.0013406547950580716\n",
      "Epoch 0, Batch 56350, Loss: 0.00239893002435565\n",
      "Epoch 0, Batch 56400, Loss: 0.0019841939210891724\n",
      "Epoch 0, Batch 56450, Loss: 0.0013949052663519979\n",
      "Epoch 0, Batch 56500, Loss: 0.002664114348590374\n",
      "Epoch 0, Batch 56550, Loss: 0.0019528890261426568\n",
      "Epoch 0, Batch 56600, Loss: 0.0017633880488574505\n",
      "Epoch 0, Batch 56650, Loss: 0.001270580687560141\n",
      "Epoch 0, Batch 56700, Loss: 0.0012792774941772223\n",
      "Epoch 0, Batch 56750, Loss: 0.42643430829048157\n",
      "Epoch 0, Batch 56800, Loss: 0.004045629408210516\n",
      "Epoch 0, Batch 56850, Loss: 0.0030776613857597113\n",
      "Epoch 0, Batch 56900, Loss: 0.0021600371692329645\n",
      "Epoch 0, Batch 56950, Loss: 0.002151617780327797\n",
      "Epoch 0, Batch 57000, Loss: 0.0021229549311101437\n",
      "Epoch 0, Batch 57050, Loss: 0.003208788577467203\n",
      "Epoch 0, Batch 57100, Loss: 0.0024823714047670364\n",
      "Epoch 0, Batch 57150, Loss: 0.0020667100325226784\n",
      "Epoch 0, Batch 57200, Loss: 0.001702413777820766\n",
      "Epoch 0, Batch 57250, Loss: 0.0034935029689222574\n",
      "Epoch 0, Batch 57300, Loss: 0.002208068035542965\n",
      "Epoch 0, Batch 57350, Loss: 0.0013052362482994795\n",
      "Epoch 0, Batch 57400, Loss: 0.0013113843742758036\n",
      "Epoch 0, Batch 57450, Loss: 0.0018772970652207732\n",
      "Epoch 0, Batch 57500, Loss: 0.0026816760655492544\n",
      "Epoch 0, Batch 57550, Loss: 0.004877007100731134\n",
      "Epoch 0, Batch 57600, Loss: 0.0026347714010626078\n",
      "Epoch 0, Batch 57650, Loss: 0.0027491434011608362\n",
      "Epoch 0, Batch 57700, Loss: 0.001702150795608759\n",
      "Epoch 0, Batch 57750, Loss: 0.0019241226837038994\n",
      "Epoch 0, Batch 57800, Loss: 0.003430001437664032\n",
      "Epoch 0, Batch 57850, Loss: 0.002565409056842327\n",
      "Epoch 0, Batch 57900, Loss: 0.002098449505865574\n",
      "Epoch 0, Batch 57950, Loss: 0.0017457781359553337\n",
      "Epoch 0, Batch 58000, Loss: 0.0019408469088375568\n",
      "Epoch 0, Batch 58050, Loss: 0.002505374839529395\n",
      "Epoch 0, Batch 58100, Loss: 0.0019414855632930994\n",
      "Epoch 0, Batch 58150, Loss: 0.002745052333921194\n",
      "Epoch 0, Batch 58200, Loss: 0.0020372201688587666\n",
      "Epoch 0, Batch 58250, Loss: 0.0018813938368111849\n",
      "Epoch 0, Batch 58300, Loss: 0.001729646697640419\n",
      "Epoch 0, Batch 58350, Loss: 0.001698749023489654\n",
      "Epoch 0, Batch 58400, Loss: 0.0014265233185142279\n",
      "Epoch 0, Batch 58450, Loss: 0.0017157557886093855\n",
      "Epoch 0, Batch 58500, Loss: 0.0033519654534757137\n",
      "Epoch 0, Batch 58550, Loss: 0.0028521823696792126\n",
      "Epoch 0, Batch 58600, Loss: 0.3422035276889801\n",
      "Epoch 0, Batch 58650, Loss: 0.0022779779974371195\n",
      "Epoch 0, Batch 58700, Loss: 0.002967566018924117\n",
      "Epoch 0, Batch 58750, Loss: 0.002604460809379816\n",
      "Epoch 0, Batch 58800, Loss: 0.0028936099261045456\n",
      "Epoch 0, Batch 58850, Loss: 0.0024461569264531136\n",
      "Epoch 0, Batch 58900, Loss: 0.0022573242895305157\n",
      "Epoch 0, Batch 58950, Loss: 0.0020530957262963057\n",
      "Epoch 0, Batch 59000, Loss: 0.0014365570386871696\n",
      "Epoch 0, Batch 59050, Loss: 0.0022674573119729757\n",
      "Epoch 0, Batch 59100, Loss: 0.002327172551304102\n",
      "Epoch 0, Batch 59150, Loss: 0.0023762588389217854\n",
      "Epoch 0, Batch 59200, Loss: 0.0021477823611348867\n",
      "Epoch 0, Batch 59250, Loss: 0.0013230035547167063\n",
      "Epoch 0, Batch 59300, Loss: 0.0016338771674782038\n",
      "Epoch 0, Batch 59350, Loss: 0.0012273893225938082\n",
      "Epoch 0, Batch 59400, Loss: 0.0018299977527931333\n",
      "Epoch 0, Batch 59450, Loss: 0.0021404202561825514\n",
      "Epoch 0, Batch 59500, Loss: 0.001892050844617188\n",
      "Epoch 0, Batch 59550, Loss: 0.0022293718066066504\n",
      "Epoch 0, Batch 59600, Loss: 0.002620078856125474\n",
      "Epoch 0, Batch 59650, Loss: 0.0020957819651812315\n",
      "Epoch 0, Batch 59700, Loss: 0.0017758083995431662\n",
      "Epoch 0, Batch 59750, Loss: 0.001895513734780252\n",
      "Epoch 0, Batch 59800, Loss: 0.001417901599779725\n",
      "Epoch 0, Batch 59850, Loss: 0.0021466019097715616\n",
      "Epoch 0, Batch 59900, Loss: 0.002232053317129612\n",
      "Epoch 0, Batch 59950, Loss: 0.0020250724628567696\n",
      "Epoch 0, Batch 60000, Loss: 0.0029540809337049723\n",
      "Epoch 0, Batch 60050, Loss: 0.0018601183546707034\n",
      "Epoch 0, Batch 60100, Loss: 0.002110539237037301\n",
      "Epoch 0, Batch 60150, Loss: 0.001511397073045373\n",
      "Epoch 0, Batch 60200, Loss: 0.0011340933851897717\n",
      "Epoch 0, Batch 60250, Loss: 0.0011051282053813338\n",
      "Epoch 0, Batch 60300, Loss: 0.001250899862498045\n",
      "Epoch 0, Batch 60350, Loss: 0.0009292030590586364\n",
      "Epoch 0, Batch 60400, Loss: 0.0012469303328543901\n",
      "Epoch 0, Batch 60450, Loss: 0.0030889466870576143\n",
      "Epoch 0, Batch 60500, Loss: 0.0018007528269663453\n",
      "Epoch 0, Batch 60550, Loss: 0.0020750185940414667\n",
      "Epoch 0, Batch 60600, Loss: 0.0017709594685584307\n",
      "Epoch 0, Batch 60650, Loss: 0.0026905317790806293\n",
      "Epoch 0, Batch 60700, Loss: 0.001880346448160708\n",
      "Epoch 0, Batch 60750, Loss: 0.0016673781210556626\n",
      "Epoch 0, Batch 60800, Loss: 0.0012906017946079373\n",
      "Epoch 0, Batch 60850, Loss: 0.000929939211346209\n",
      "Epoch 0, Batch 60900, Loss: 0.001249440829269588\n",
      "Epoch 0, Batch 60950, Loss: 0.0015828340547159314\n",
      "Epoch 0, Batch 61000, Loss: 0.002797353081405163\n",
      "Epoch 0, Batch 61050, Loss: 0.002754330402240157\n",
      "Epoch 0, Batch 61100, Loss: 0.00217291247099638\n",
      "Epoch 0, Batch 61150, Loss: 0.001871789339929819\n",
      "Epoch 0, Batch 61200, Loss: 0.0013096581678837538\n",
      "Epoch 0, Batch 61250, Loss: 0.001430480508133769\n",
      "Epoch 0, Batch 61300, Loss: 0.00158601941075176\n",
      "Epoch 0, Batch 61350, Loss: 0.001810445450246334\n",
      "Epoch 0, Batch 61400, Loss: 0.00204944284632802\n",
      "Epoch 0, Batch 61450, Loss: 0.3424782454967499\n",
      "Epoch 0, Batch 61500, Loss: 0.0029132559429854155\n",
      "Epoch 0, Batch 61550, Loss: 0.0030698839109390974\n",
      "Epoch 0, Batch 61600, Loss: 0.002719660522416234\n",
      "Epoch 0, Batch 61650, Loss: 0.001477047917433083\n",
      "Epoch 0, Batch 61700, Loss: 0.0017183905001729727\n",
      "Epoch 0, Batch 61750, Loss: 0.0014927753945812583\n",
      "Epoch 0, Batch 61800, Loss: 0.0014734389260411263\n",
      "Epoch 0, Batch 61850, Loss: 0.40433216094970703\n",
      "Epoch 0, Batch 61900, Loss: 0.001440613646991551\n",
      "Epoch 0, Batch 61950, Loss: 0.0024356674402952194\n",
      "Epoch 0, Batch 62000, Loss: 0.0018944938201457262\n",
      "Epoch 0, Batch 62050, Loss: 0.001741767511703074\n",
      "Epoch 0, Batch 62100, Loss: 0.002215319313108921\n",
      "Epoch 0, Batch 62150, Loss: 0.002274480415508151\n",
      "Epoch 0, Batch 62200, Loss: 0.0016625465359538794\n",
      "Epoch 0, Batch 62250, Loss: 0.001590314437635243\n",
      "Epoch 0, Batch 62300, Loss: 0.0015868352493271232\n",
      "Epoch 0, Batch 62350, Loss: 0.001317594083957374\n",
      "Epoch 0, Batch 62400, Loss: 0.0020671961829066277\n",
      "Epoch 0, Batch 62450, Loss: 0.0021111397072672844\n",
      "Epoch 0, Batch 62500, Loss: 0.002431403612717986\n",
      "Epoch 0, Batch 62550, Loss: 0.0028644558042287827\n",
      "Epoch 0, Batch 62600, Loss: 0.004067250061780214\n",
      "Epoch 0, Batch 62650, Loss: 0.002433217829093337\n",
      "Epoch 0, Batch 62700, Loss: 0.002321626292541623\n",
      "Epoch 0, Batch 62750, Loss: 0.0031196046620607376\n",
      "Epoch 0, Batch 62800, Loss: 0.0031449482776224613\n",
      "Epoch 0, Batch 62850, Loss: 0.004276471212506294\n",
      "Epoch 0, Batch 62900, Loss: 0.004171861335635185\n",
      "Epoch 0, Batch 62950, Loss: 0.0026283671613782644\n",
      "Epoch 0, Batch 63000, Loss: 0.0027808614540845156\n",
      "Epoch 0, Batch 63050, Loss: 0.0021396372467279434\n",
      "Epoch 0, Batch 63100, Loss: 0.0014604615280404687\n",
      "Epoch 0, Batch 63150, Loss: 0.0020895039197057486\n",
      "Epoch 0, Batch 63200, Loss: 0.002957326825708151\n",
      "Epoch 0, Batch 63250, Loss: 0.0033006707672029734\n",
      "Epoch 0, Batch 63300, Loss: 0.0019252784550189972\n",
      "Epoch 0, Batch 63350, Loss: 0.0028156908228993416\n",
      "Epoch 0, Batch 63400, Loss: 0.0027457717806100845\n",
      "Epoch 0, Batch 63450, Loss: 0.0020785299129784107\n",
      "Epoch 0, Batch 63500, Loss: 0.0016309802886098623\n",
      "Epoch 0, Batch 63550, Loss: 0.0015024073654785752\n",
      "Epoch 0, Batch 63600, Loss: 0.001429141266271472\n",
      "Epoch 0, Batch 63650, Loss: 0.0015796389197930694\n",
      "Epoch 0, Batch 63700, Loss: 0.0020224626641720533\n",
      "Epoch 0, Batch 63750, Loss: 0.0023039616644382477\n",
      "Epoch 0, Batch 63800, Loss: 0.0023786493111401796\n",
      "Epoch 0, Batch 63850, Loss: 0.0027743394020944834\n",
      "Epoch 0, Batch 63900, Loss: 0.002019341569393873\n",
      "Epoch 0, Batch 63950, Loss: 0.0016666654264554381\n",
      "Epoch 0, Batch 64000, Loss: 0.0014748139074072242\n",
      "Epoch 0, Batch 64050, Loss: 0.001673616119660437\n",
      "Epoch 0, Batch 64100, Loss: 0.0013385075144469738\n",
      "Epoch 0, Batch 64150, Loss: 0.0018828173633664846\n",
      "Epoch 0, Batch 64200, Loss: 0.0012418600963428617\n",
      "Epoch 0, Batch 64250, Loss: 0.0012608451070263982\n",
      "Epoch 0, Batch 64300, Loss: 0.001516937743872404\n",
      "Epoch 0, Batch 64350, Loss: 0.0015363735146820545\n",
      "Epoch 0, Batch 64400, Loss: 0.001825591898523271\n",
      "Epoch 0, Batch 64450, Loss: 0.002695248695090413\n",
      "Epoch 0, Batch 64500, Loss: 0.0021885656751692295\n",
      "Epoch 0, Batch 64550, Loss: 0.002010444877669215\n",
      "Epoch 0, Batch 64600, Loss: 0.0016415865393355489\n",
      "Epoch 0, Batch 64650, Loss: 0.0015162588097155094\n",
      "Epoch 0, Batch 64700, Loss: 0.0018479384016245604\n",
      "Epoch 0, Batch 64750, Loss: 0.0015290697338059545\n",
      "Epoch 0, Batch 64800, Loss: 0.0014956799568608403\n",
      "Epoch 0, Batch 64850, Loss: 0.0021214766893535852\n",
      "Epoch 0, Batch 64900, Loss: 0.002830752171576023\n",
      "Epoch 0, Batch 64950, Loss: 0.0021894637029618025\n",
      "Epoch 0, Batch 65000, Loss: 0.0023861192166805267\n",
      "Epoch 0, Batch 65050, Loss: 0.002132719848304987\n",
      "Epoch 0, Batch 65100, Loss: 0.0014382916269823909\n",
      "Epoch 0, Batch 65150, Loss: 0.0014526211889460683\n",
      "Epoch 0, Batch 65200, Loss: 0.0011670812964439392\n",
      "Epoch 0, Batch 65250, Loss: 0.0011283878702670336\n",
      "Epoch 0, Batch 65300, Loss: 0.0014511379413306713\n",
      "Epoch 0, Batch 65350, Loss: 0.001613144762814045\n",
      "Epoch 0, Batch 65400, Loss: 0.0013067044783383608\n",
      "Epoch 0, Batch 65450, Loss: 0.0009411998325958848\n",
      "Epoch 0, Batch 65500, Loss: 0.0015682870289310813\n",
      "Epoch 0, Batch 65550, Loss: 0.0038140288088470697\n",
      "Epoch 0, Batch 65600, Loss: 0.002413042588159442\n",
      "Epoch 0, Batch 65650, Loss: 0.002523308154195547\n",
      "Epoch 0, Batch 65700, Loss: 0.003158315783366561\n",
      "Epoch 0, Batch 65750, Loss: 0.002208598190918565\n",
      "Epoch 0, Batch 65800, Loss: 0.0022480166517198086\n",
      "Epoch 0, Batch 65850, Loss: 0.002913964679464698\n",
      "Epoch 0, Batch 65900, Loss: 0.002179168164730072\n",
      "Epoch 0, Batch 65950, Loss: 0.0019022237975150347\n",
      "Epoch 0, Batch 66000, Loss: 0.0016218113014474511\n",
      "Epoch 0, Batch 66050, Loss: 0.001902478514239192\n",
      "Epoch 0, Batch 66100, Loss: 0.0025010048411786556\n",
      "Epoch 0, Batch 66150, Loss: 0.0022409027442336082\n",
      "Epoch 0, Batch 66200, Loss: 0.0039382935501635075\n",
      "Epoch 0, Batch 66250, Loss: 0.003691445104777813\n",
      "Epoch 0, Batch 66300, Loss: 0.003068289253860712\n",
      "Epoch 0, Batch 66350, Loss: 0.002194975735619664\n",
      "Epoch 0, Batch 66400, Loss: 0.0017652158858254552\n",
      "Epoch 0, Batch 66450, Loss: 0.0019723623991012573\n",
      "Epoch 0, Batch 66500, Loss: 0.001822818536311388\n",
      "Epoch 0, Batch 66550, Loss: 0.0022266970481723547\n",
      "Epoch 0, Batch 66600, Loss: 0.0030801533721387386\n",
      "Epoch 0, Batch 66650, Loss: 0.0021905330941081047\n",
      "Epoch 0, Batch 66700, Loss: 0.002606453839689493\n",
      "Epoch 0, Batch 66750, Loss: 0.0030529664363712072\n",
      "Epoch 0, Batch 66800, Loss: 0.002497702604159713\n",
      "Epoch 0, Batch 66850, Loss: 0.0019134115427732468\n",
      "Epoch 0, Batch 66900, Loss: 0.0033587550278753042\n",
      "Epoch 0, Batch 66950, Loss: 0.0024748360738158226\n",
      "Epoch 0, Batch 67000, Loss: 0.0017629293724894524\n",
      "Epoch 0, Batch 67050, Loss: 0.0012658977648243308\n",
      "Epoch 0, Batch 67100, Loss: 0.0011107512982562184\n",
      "Epoch 0, Batch 67150, Loss: 0.001480838400311768\n",
      "Epoch 0, Batch 67200, Loss: 0.0022711812052875757\n",
      "Epoch 0, Batch 67250, Loss: 0.0017497625667601824\n",
      "Epoch 0, Batch 67300, Loss: 0.0013267926406115294\n",
      "Epoch 0, Batch 67350, Loss: 0.0016753623494878411\n",
      "Epoch 0, Batch 67400, Loss: 0.001895453198812902\n",
      "Epoch 0, Batch 67450, Loss: 0.0023503887932747602\n",
      "Epoch 0, Batch 67500, Loss: 0.0022362004965543747\n",
      "Epoch 0, Batch 67550, Loss: 0.0021654271986335516\n",
      "Epoch 0, Batch 67600, Loss: 0.001967571908608079\n",
      "Epoch 0, Batch 67650, Loss: 0.002213119762018323\n",
      "Epoch 0, Batch 67700, Loss: 0.002316130558028817\n",
      "Epoch 0, Batch 67750, Loss: 0.002118162577971816\n",
      "Epoch 0, Batch 67800, Loss: 0.002026740927249193\n",
      "Epoch 0, Batch 67850, Loss: 0.0017205917974933982\n",
      "Epoch 0, Batch 67900, Loss: 0.001255093258805573\n",
      "Epoch 0, Batch 67950, Loss: 0.0009720706148073077\n",
      "Epoch 0, Batch 68000, Loss: 0.0010447127278894186\n",
      "Epoch 0, Batch 68050, Loss: 0.0010707010515034199\n",
      "Epoch 0, Batch 68100, Loss: 0.457899808883667\n",
      "Epoch 0, Batch 68150, Loss: 0.0017671858659014106\n",
      "Epoch 0, Batch 68200, Loss: 0.0023709225933998823\n",
      "Epoch 0, Batch 68250, Loss: 0.0023307455703616142\n",
      "Epoch 0, Batch 68300, Loss: 0.0017160155111923814\n",
      "Epoch 0, Batch 68350, Loss: 0.001389242592267692\n",
      "Epoch 0, Batch 68400, Loss: 0.0018176976591348648\n",
      "Epoch 0, Batch 68450, Loss: 0.0017768575344234705\n",
      "Epoch 0, Batch 68500, Loss: 0.0016334825195372105\n",
      "Epoch 0, Batch 68550, Loss: 0.00279574585147202\n",
      "Epoch 0, Batch 68600, Loss: 0.0017729694955050945\n",
      "Epoch 0, Batch 68650, Loss: 0.001819913275539875\n",
      "Epoch 0, Batch 68700, Loss: 0.0040624914690852165\n",
      "Epoch 0, Batch 68750, Loss: 0.003910865634679794\n",
      "Epoch 0, Batch 68800, Loss: 0.002614933531731367\n",
      "Epoch 0, Batch 68850, Loss: 0.0024861134588718414\n",
      "Epoch 0, Batch 68900, Loss: 0.003058468224480748\n",
      "Epoch 0, Batch 68950, Loss: 0.0032546648290008307\n",
      "Epoch 0, Batch 69000, Loss: 0.004014716017991304\n",
      "Epoch 0, Batch 69050, Loss: 0.0023190598003566265\n",
      "Epoch 0, Batch 69100, Loss: 0.0018642893992364407\n",
      "Epoch 0, Batch 69150, Loss: 0.0019862758927047253\n",
      "Epoch 0, Batch 69200, Loss: 0.001504043466411531\n",
      "Epoch 0, Batch 69250, Loss: 0.0013107877457514405\n",
      "Epoch 0, Batch 69300, Loss: 0.001265935250557959\n",
      "Epoch 0, Batch 69350, Loss: 0.0022845957428216934\n",
      "Epoch 0, Batch 69400, Loss: 0.002425114857032895\n",
      "Epoch 0, Batch 69450, Loss: 0.002552603604272008\n",
      "Epoch 0, Batch 69500, Loss: 0.002284139394760132\n",
      "Epoch 0, Batch 69550, Loss: 0.0020915598142892122\n",
      "Epoch 0, Batch 69600, Loss: 0.002367309294641018\n",
      "Epoch 0, Batch 69650, Loss: 0.002322104061022401\n",
      "Epoch 0, Batch 69700, Loss: 0.0015301392413675785\n",
      "Epoch 0, Batch 69750, Loss: 0.002084617502987385\n",
      "Epoch 0, Batch 69800, Loss: 0.0022759141866117716\n",
      "Epoch 0, Batch 69850, Loss: 0.001586700091138482\n",
      "Epoch 0, Batch 69900, Loss: 0.0012278164504095912\n",
      "Epoch 0, Batch 69950, Loss: 0.0018828300526365638\n",
      "Epoch 0, Batch 70000, Loss: 0.0025098572950810194\n",
      "Epoch 0, Batch 70050, Loss: 0.003250829176977277\n",
      "Epoch 0, Batch 70100, Loss: 0.003718918887898326\n",
      "Epoch 0, Batch 70150, Loss: 0.002785064047202468\n",
      "Epoch 0, Batch 70200, Loss: 0.0028948672115802765\n",
      "Epoch 0, Batch 70250, Loss: 0.00207202835008502\n",
      "Epoch 0, Batch 70300, Loss: 0.001855190610513091\n",
      "Epoch 0, Batch 70350, Loss: 0.0012689027935266495\n",
      "Epoch 0, Batch 70400, Loss: 0.001239514327608049\n",
      "Epoch 0, Batch 70450, Loss: 0.001444476656615734\n",
      "Epoch 0, Batch 70500, Loss: 0.0013958793133497238\n",
      "Epoch 0, Batch 70550, Loss: 0.0011168994242325425\n",
      "Epoch 0, Batch 70600, Loss: 0.0012265105033293366\n",
      "Epoch 0, Batch 70650, Loss: 0.0024987964425235987\n",
      "Epoch 0, Batch 70700, Loss: 0.002151215448975563\n",
      "Epoch 0, Batch 70750, Loss: 0.0014837568160146475\n",
      "Epoch 0, Batch 70800, Loss: 0.0014220341108739376\n",
      "Epoch 0, Batch 70850, Loss: 0.002581507433205843\n",
      "Epoch 0, Batch 70900, Loss: 0.0026208660565316677\n",
      "Epoch 0, Batch 70950, Loss: 0.00204723933711648\n",
      "Epoch 0, Batch 71000, Loss: 0.0028924974612891674\n",
      "Epoch 0, Batch 71050, Loss: 0.3636040687561035\n",
      "Epoch 0, Batch 71100, Loss: 0.0019323080778121948\n",
      "Epoch 0, Batch 71150, Loss: 0.002269415184855461\n",
      "Epoch 0, Batch 71200, Loss: 0.002517834771424532\n",
      "Epoch 0, Batch 71250, Loss: 0.0026048440486192703\n",
      "Epoch 0, Batch 71300, Loss: 0.0025586355477571487\n",
      "Epoch 0, Batch 71350, Loss: 0.002748318715021014\n",
      "Epoch 0, Batch 71400, Loss: 0.0028386139310896397\n",
      "Epoch 0, Batch 71450, Loss: 0.002823625458404422\n",
      "Epoch 0, Batch 71500, Loss: 0.0025306192692369223\n",
      "Epoch 0, Batch 71550, Loss: 0.003238811856135726\n",
      "Epoch 0, Batch 71600, Loss: 0.003202801337465644\n",
      "Epoch 0, Batch 71650, Loss: 0.0022920570336282253\n",
      "Epoch 0, Batch 71700, Loss: 0.0015682638622820377\n",
      "Epoch 0, Batch 71750, Loss: 0.0011658606817945838\n",
      "Epoch 0, Batch 71800, Loss: 0.0009026596089825034\n",
      "Epoch 0, Batch 71850, Loss: 0.0008228856022469699\n",
      "Epoch 0, Batch 71900, Loss: 0.0009419348789379001\n",
      "Epoch 0, Batch 71950, Loss: 0.001446602400392294\n",
      "Epoch 0, Batch 72000, Loss: 0.0014440000522881746\n",
      "Epoch 0, Batch 72050, Loss: 0.0012361130211502314\n",
      "Epoch 0, Batch 72100, Loss: 0.0011172457598149776\n",
      "Epoch 0, Batch 72150, Loss: 0.0011064773425459862\n",
      "Epoch 0, Batch 72200, Loss: 0.0008772870060056448\n",
      "Epoch 0, Batch 72250, Loss: 0.0013357165735214949\n",
      "Epoch 0, Batch 72300, Loss: 0.001417650142684579\n",
      "Epoch 0, Batch 72350, Loss: 0.0016473130090162158\n",
      "Epoch 0, Batch 72400, Loss: 0.002404589904472232\n",
      "Epoch 0, Batch 72450, Loss: 0.0026281068567186594\n",
      "Epoch 0, Batch 72500, Loss: 0.002407708205282688\n",
      "Epoch 0, Batch 72550, Loss: 0.002638940466567874\n",
      "Epoch 0, Batch 72600, Loss: 0.40973469614982605\n",
      "Epoch 0, Batch 72650, Loss: 0.0018783379346132278\n",
      "Epoch 0, Batch 72700, Loss: 0.0016944885719567537\n",
      "Epoch 0, Batch 72750, Loss: 0.0023465240374207497\n",
      "Epoch 0, Batch 72800, Loss: 0.0027639390900731087\n",
      "Epoch 0, Batch 72850, Loss: 0.0023848670534789562\n",
      "Epoch 0, Batch 72900, Loss: 0.002113903174176812\n",
      "Epoch 0, Batch 72950, Loss: 0.003463990055024624\n",
      "Epoch 0, Batch 73000, Loss: 0.0024097696878015995\n",
      "Epoch 0, Batch 73050, Loss: 0.0022923192009329796\n",
      "Epoch 0, Batch 73100, Loss: 0.0030743959359824657\n",
      "Epoch 0, Batch 73150, Loss: 0.002116674557328224\n",
      "Epoch 0, Batch 73200, Loss: 0.002400084864348173\n",
      "Epoch 0, Batch 73250, Loss: 0.001824966981075704\n",
      "Epoch 0, Batch 73300, Loss: 0.001969793578609824\n",
      "Epoch 0, Batch 73350, Loss: 0.001625693286769092\n",
      "Epoch 0, Batch 73400, Loss: 0.0024323747493326664\n",
      "Epoch 0, Batch 73450, Loss: 0.0028672346379607916\n",
      "Epoch 0, Batch 73500, Loss: 0.0025480822660028934\n",
      "Epoch 0, Batch 73550, Loss: 0.0021060805302113295\n",
      "Epoch 0, Batch 73600, Loss: 0.0021515546832233667\n",
      "Epoch 0, Batch 73650, Loss: 0.0014654436381533742\n",
      "Epoch 0, Batch 73700, Loss: 0.0014198283897712827\n",
      "Epoch 0, Batch 73750, Loss: 0.0011606401531025767\n",
      "Epoch 0, Batch 73800, Loss: 0.0011618091957643628\n",
      "Epoch 0, Batch 73850, Loss: 0.0019252764759585261\n",
      "Epoch 0, Batch 73900, Loss: 0.0019602272659540176\n",
      "Epoch 0, Batch 73950, Loss: 0.002213021507486701\n",
      "Epoch 0, Batch 74000, Loss: 0.0014253276167437434\n",
      "Epoch 0, Batch 74050, Loss: 0.001306991558521986\n",
      "Epoch 0, Batch 74100, Loss: 0.0014696569414809346\n",
      "Epoch 0, Batch 74150, Loss: 0.0016249307664111257\n",
      "Epoch 0, Batch 74200, Loss: 0.002928753150627017\n",
      "Epoch 0, Batch 74250, Loss: 0.0034979938063770533\n",
      "Epoch 0, Batch 74300, Loss: 0.0024533839896321297\n",
      "Epoch 0, Batch 74350, Loss: 0.002891329349949956\n",
      "Epoch 0, Batch 74400, Loss: 0.0034662457183003426\n",
      "Epoch 0, Batch 74450, Loss: 0.005669407080858946\n",
      "Epoch 0, Batch 74500, Loss: 0.0025231956969946623\n",
      "Epoch 0, Batch 74550, Loss: 0.0018388204043731093\n",
      "Epoch 0, Batch 74600, Loss: 0.002414159942418337\n",
      "Epoch 0, Batch 74650, Loss: 0.002495879540219903\n",
      "Epoch 0, Batch 74700, Loss: 0.0023934966884553432\n",
      "Epoch 0, Batch 74750, Loss: 0.0030185396317392588\n",
      "Epoch 0, Batch 74800, Loss: 0.0023113549686968327\n",
      "Epoch 0, Batch 74850, Loss: 0.001873301574960351\n",
      "Epoch 0, Batch 74900, Loss: 0.0017204445321112871\n",
      "Epoch 0, Batch 74950, Loss: 0.0015177822206169367\n",
      "Epoch 0, Batch 75000, Loss: 0.0022556826006621122\n",
      "Epoch 0, Batch 75050, Loss: 0.3822837769985199\n",
      "Epoch 0, Batch 75100, Loss: 0.0023937432561069727\n",
      "Epoch 0, Batch 75150, Loss: 0.002029075287282467\n",
      "Epoch 0, Batch 75200, Loss: 0.3937076926231384\n",
      "Epoch 0, Batch 75250, Loss: 0.0021749185398221016\n",
      "Epoch 0, Batch 75300, Loss: 0.0018514960538595915\n",
      "Epoch 0, Batch 75350, Loss: 0.0026046072598546743\n",
      "Epoch 0, Batch 75400, Loss: 0.002748318715021014\n",
      "Epoch 0, Batch 75450, Loss: 0.0023480691015720367\n",
      "Epoch 0, Batch 75500, Loss: 0.0024914955720305443\n",
      "Epoch 0, Batch 75550, Loss: 0.0018956451676785946\n",
      "Epoch 0, Batch 75600, Loss: 0.001674714614637196\n",
      "Epoch 0, Batch 75650, Loss: 0.3535149097442627\n",
      "Epoch 0, Batch 75700, Loss: 0.00445655407384038\n",
      "Epoch 0, Batch 75750, Loss: 0.0038647991605103016\n",
      "Epoch 0, Batch 75800, Loss: 0.0035641812719404697\n",
      "Epoch 0, Batch 75850, Loss: 0.0025202729739248753\n",
      "Epoch 0, Batch 75900, Loss: 0.002554940525442362\n",
      "Epoch 0, Batch 75950, Loss: 0.0025086035020649433\n",
      "Epoch 0, Batch 76000, Loss: 0.0033940591383725405\n",
      "Epoch 0, Batch 76050, Loss: 0.004109442699700594\n",
      "Epoch 0, Batch 76100, Loss: 0.002989414380863309\n",
      "Epoch 0, Batch 76150, Loss: 0.0027739491779357195\n",
      "Epoch 0, Batch 76200, Loss: 0.0029791968408972025\n",
      "Epoch 0, Batch 76250, Loss: 0.004129441920667887\n",
      "Epoch 0, Batch 76300, Loss: 0.0034233317710459232\n",
      "Epoch 0, Batch 76350, Loss: 0.002744832308962941\n",
      "Epoch 0, Batch 76400, Loss: 0.002824208466336131\n",
      "Epoch 0, Batch 76450, Loss: 0.0024655188899487257\n",
      "Epoch 0, Batch 76500, Loss: 0.002404377795755863\n",
      "Epoch 0, Batch 76550, Loss: 0.001977283740416169\n",
      "Epoch 0, Batch 76600, Loss: 0.0014812168665230274\n",
      "Epoch 0, Batch 76650, Loss: 0.0014231887180358171\n",
      "Epoch 0, Batch 76700, Loss: 0.0018541408935561776\n",
      "Epoch 0, Batch 76750, Loss: 0.0019057769095525146\n",
      "Epoch 0, Batch 76800, Loss: 0.0016025970689952374\n",
      "Epoch 0, Batch 76850, Loss: 0.001320467796176672\n",
      "Epoch 0, Batch 76900, Loss: 0.0020725736394524574\n",
      "Epoch 0, Batch 76950, Loss: 0.0026936696376651525\n",
      "Epoch 0, Batch 77000, Loss: 0.0027358669321984053\n",
      "Epoch 0, Batch 77050, Loss: 0.0029434363823384047\n",
      "Epoch 0, Batch 77100, Loss: 0.3698499798774719\n",
      "Epoch 0, Batch 77150, Loss: 0.002704204525798559\n",
      "Epoch 0, Batch 77200, Loss: 0.002942997496575117\n",
      "Epoch 0, Batch 77250, Loss: 0.002976990770548582\n",
      "Epoch 0, Batch 77300, Loss: 0.001911073923110962\n",
      "Epoch 0, Batch 77350, Loss: 0.0013437363086268306\n",
      "Epoch 0, Batch 77400, Loss: 0.0011071463814005256\n",
      "Epoch 0, Batch 77450, Loss: 0.001213940093293786\n",
      "Epoch 0, Batch 77500, Loss: 0.3936999440193176\n",
      "Epoch 0, Batch 77550, Loss: 0.0026795777957886457\n",
      "Epoch 0, Batch 77600, Loss: 0.0021501914598047733\n",
      "Epoch 0, Batch 77650, Loss: 0.002291236538439989\n",
      "Epoch 0, Batch 77700, Loss: 0.00271895551122725\n",
      "Epoch 0, Batch 77750, Loss: 0.0022492804564535618\n",
      "Epoch 0, Batch 77800, Loss: 0.002439050003886223\n",
      "Epoch 0, Batch 77850, Loss: 0.0026837147306650877\n",
      "Epoch 0, Batch 77900, Loss: 0.0023474490735679865\n",
      "Epoch 0, Batch 77950, Loss: 0.0027867015451192856\n",
      "Epoch 0, Batch 78000, Loss: 0.002661872887983918\n",
      "Epoch 0, Batch 78050, Loss: 0.002168562961742282\n",
      "Epoch 0, Batch 78100, Loss: 0.0017595156095921993\n",
      "Epoch 0, Batch 78150, Loss: 0.002073278883472085\n",
      "Epoch 0, Batch 78200, Loss: 0.002438483526930213\n",
      "Epoch 0, Batch 78250, Loss: 0.0018561783945187926\n",
      "Epoch 0, Batch 78300, Loss: 0.0020447818096727133\n",
      "Epoch 0, Batch 78350, Loss: 0.41896238923072815\n",
      "Epoch 0, Batch 78400, Loss: 0.0016310764476656914\n",
      "Epoch 0, Batch 78450, Loss: 0.0016452099662274122\n",
      "Epoch 0, Batch 78500, Loss: 0.0020656471606343985\n",
      "Epoch 0, Batch 78550, Loss: 0.0019175827037543058\n",
      "Epoch 0, Batch 78600, Loss: 0.0020906361751258373\n",
      "Epoch 0, Batch 78650, Loss: 0.0027234037406742573\n",
      "Epoch 0, Batch 78700, Loss: 0.0017477474175393581\n",
      "Epoch 0, Batch 78750, Loss: 0.0018262695521116257\n",
      "Epoch 0, Batch 78800, Loss: 0.002876295940950513\n",
      "Epoch 0, Batch 78850, Loss: 0.35760441422462463\n",
      "Epoch 0, Batch 78900, Loss: 0.0036584017798304558\n",
      "Epoch 0, Batch 78950, Loss: 0.0024999624583870173\n",
      "Epoch 0, Batch 79000, Loss: 0.004124348051846027\n",
      "Epoch 0, Batch 79050, Loss: 0.0025916954036802053\n",
      "Epoch 0, Batch 79100, Loss: 0.002489115810021758\n",
      "Epoch 0, Batch 79150, Loss: 0.0028590266592800617\n",
      "Epoch 0, Batch 79200, Loss: 0.0021494778338819742\n",
      "Epoch 0, Batch 79250, Loss: 0.0015512119280174375\n",
      "Epoch 0, Batch 79300, Loss: 0.0014056370127946138\n",
      "Epoch 0, Batch 79350, Loss: 0.0022692247293889523\n",
      "Epoch 0, Batch 79400, Loss: 0.002058156067505479\n",
      "Epoch 0, Batch 79450, Loss: 0.0020347919780761003\n",
      "Epoch 0, Batch 79500, Loss: 0.0016099256463348866\n",
      "Epoch 0, Batch 79550, Loss: 0.001358353067189455\n",
      "Epoch 0, Batch 79600, Loss: 0.002143976278603077\n",
      "Epoch 0, Batch 79650, Loss: 0.0033998307771980762\n",
      "Epoch 0, Batch 79700, Loss: 0.0031633672770112753\n",
      "Epoch 0, Batch 79750, Loss: 0.0023809820413589478\n",
      "Epoch 0, Batch 79800, Loss: 0.0017775645246729255\n",
      "Epoch 0, Batch 79850, Loss: 0.0017592418007552624\n",
      "Epoch 0, Batch 79900, Loss: 0.0013573411852121353\n",
      "Epoch 0, Batch 79950, Loss: 0.0012489970540627837\n",
      "Epoch 0, Batch 80000, Loss: 0.001437551574781537\n",
      "Epoch 0, Batch 80050, Loss: 0.001352643477730453\n",
      "Epoch 0, Batch 80100, Loss: 0.001298475544899702\n",
      "Epoch 0, Batch 80150, Loss: 0.001233691698871553\n",
      "Epoch 0, Batch 80200, Loss: 0.0017989750485867262\n",
      "Epoch 0, Batch 80250, Loss: 0.0012933153193444014\n",
      "Epoch 0, Batch 80300, Loss: 0.0014677307335659862\n",
      "Epoch 0, Batch 80350, Loss: 0.0020949484314769506\n",
      "Epoch 0, Batch 80400, Loss: 0.0017972876084968448\n",
      "Epoch 0, Batch 80450, Loss: 0.0020485783461481333\n",
      "Epoch 0, Batch 80500, Loss: 0.0016404647612944245\n",
      "Epoch 0, Batch 80550, Loss: 0.001265164464712143\n",
      "Epoch 0, Batch 80600, Loss: 0.0014166751643642783\n",
      "Epoch 0, Batch 80650, Loss: 0.0025589161086827517\n",
      "Epoch 0, Batch 80700, Loss: 0.002743074670433998\n",
      "Epoch 0, Batch 80750, Loss: 0.0020375887397676706\n",
      "Epoch 0, Batch 80800, Loss: 0.0020764439832419157\n",
      "Epoch 0, Batch 80850, Loss: 0.0029174278024584055\n",
      "Epoch 0, Batch 80900, Loss: 0.0022970852442085743\n",
      "Epoch 0, Batch 80950, Loss: 0.0017889287555590272\n",
      "Epoch 0, Batch 81000, Loss: 0.002190627856180072\n",
      "Epoch 0, Batch 81050, Loss: 0.00211896700784564\n",
      "Epoch 0, Batch 81100, Loss: 0.002414463320747018\n",
      "Epoch 0, Batch 81150, Loss: 0.0019318850245326757\n",
      "Epoch 0, Batch 81200, Loss: 0.0026523892302066088\n",
      "Epoch 0, Batch 81250, Loss: 0.002334971446543932\n",
      "Epoch 0, Batch 81300, Loss: 0.001963516231626272\n",
      "Epoch 0, Batch 81350, Loss: 0.0022504497319459915\n",
      "Epoch 0, Batch 81400, Loss: 0.002802229253575206\n",
      "Epoch 0, Batch 81450, Loss: 0.00309323170222342\n",
      "Epoch 0, Batch 81500, Loss: 0.0032885351683944464\n",
      "Epoch 0, Batch 81550, Loss: 0.002939848927780986\n",
      "Epoch 0, Batch 81600, Loss: 0.0030187005177140236\n",
      "Epoch 0, Batch 81650, Loss: 0.3661399185657501\n",
      "Epoch 0, Batch 81700, Loss: 0.003075398737564683\n",
      "Epoch 0, Batch 81750, Loss: 0.00238489150069654\n",
      "Epoch 0, Batch 81800, Loss: 0.002594094257801771\n",
      "Epoch 0, Batch 81850, Loss: 0.00242271414026618\n",
      "Epoch 0, Batch 81900, Loss: 0.40944400429725647\n",
      "Epoch 0, Batch 81950, Loss: 0.39233916997909546\n",
      "Epoch 0, Batch 82000, Loss: 0.0016206474974751472\n",
      "Epoch 0, Batch 82050, Loss: 0.001325199264101684\n",
      "Epoch 0, Batch 82100, Loss: 0.0014904726995155215\n",
      "Epoch 0, Batch 82150, Loss: 0.001530350768007338\n",
      "Epoch 0, Batch 82200, Loss: 0.001172271673567593\n",
      "Epoch 0, Batch 82250, Loss: 0.0013087248662486672\n",
      "Epoch 0, Batch 82300, Loss: 0.0019288533367216587\n",
      "Epoch 0, Batch 82350, Loss: 0.0036086386535316706\n",
      "Epoch 0, Batch 82400, Loss: 0.004063910339027643\n",
      "Epoch 0, Batch 82450, Loss: 0.004442770034074783\n",
      "Epoch 0, Batch 82500, Loss: 0.002662641927599907\n",
      "Epoch 0, Batch 82550, Loss: 0.0024273626040667295\n",
      "Epoch 0, Batch 82600, Loss: 0.0021901694126427174\n",
      "Epoch 0, Batch 82650, Loss: 0.0020924806594848633\n",
      "Epoch 0, Batch 82700, Loss: 0.0018275610636919737\n",
      "Epoch 0, Batch 82750, Loss: 0.00226020161062479\n",
      "Epoch 0, Batch 82800, Loss: 0.0025912567507475615\n",
      "Epoch 0, Batch 82850, Loss: 0.002741553820669651\n",
      "Epoch 0, Batch 82900, Loss: 0.0018984150374308228\n",
      "Epoch 0, Batch 82950, Loss: 0.0015644156374037266\n",
      "Epoch 0, Batch 83000, Loss: 0.0020535194780677557\n",
      "Epoch 0, Batch 83050, Loss: 0.4147951006889343\n",
      "Epoch 0, Batch 83100, Loss: 0.0016899489564821124\n",
      "Epoch 0, Batch 83150, Loss: 0.0018593918066471815\n",
      "Epoch 0, Batch 83200, Loss: 0.0016889485996216536\n",
      "Epoch 0, Batch 83250, Loss: 0.0019661374390125275\n",
      "Epoch 0, Batch 83300, Loss: 0.0018388994503766298\n",
      "Epoch 0, Batch 83350, Loss: 0.0013328812783583999\n",
      "Epoch 0, Batch 83400, Loss: 0.001150685828179121\n",
      "Epoch 0, Batch 83450, Loss: 0.002176509937271476\n",
      "Epoch 0, Batch 83500, Loss: 0.0028520377818495035\n",
      "Epoch 0, Batch 83550, Loss: 0.0024007412139326334\n",
      "Epoch 0, Batch 83600, Loss: 0.0016841921024024487\n",
      "Epoch 0, Batch 83650, Loss: 0.001502782222814858\n",
      "Epoch 0, Batch 83700, Loss: 0.0015017460100352764\n",
      "Epoch 0, Batch 83750, Loss: 0.0018203869694843888\n",
      "Epoch 0, Batch 83800, Loss: 0.0025809481739997864\n",
      "Epoch 0, Batch 83850, Loss: 0.002398648066446185\n",
      "Epoch 0, Batch 83900, Loss: 0.001941801281645894\n",
      "Epoch 0, Batch 83950, Loss: 0.0018772019539028406\n",
      "Epoch 0, Batch 84000, Loss: 0.0016491548158228397\n",
      "Epoch 0, Batch 84050, Loss: 0.0014550706837326288\n",
      "Epoch 0, Batch 84100, Loss: 0.0010926671093329787\n",
      "Epoch 0, Batch 84150, Loss: 0.0017764196963980794\n",
      "Epoch 0, Batch 84200, Loss: 0.0013448193203657866\n",
      "Epoch 0, Batch 84250, Loss: 0.0019078970653936267\n",
      "Epoch 0, Batch 84300, Loss: 0.0015293603064492345\n",
      "Epoch 0, Batch 84350, Loss: 0.002270050812512636\n",
      "Epoch 0, Batch 84400, Loss: 0.001678441883996129\n",
      "Epoch 0, Batch 84450, Loss: 0.0026604316662997007\n",
      "Epoch 0, Batch 84500, Loss: 0.0021194729488343\n",
      "Epoch 0, Batch 84550, Loss: 0.0019928349647670984\n",
      "Epoch 0, Batch 84600, Loss: 0.002082417719066143\n",
      "Epoch 0, Batch 84650, Loss: 0.0016861201729625463\n",
      "Epoch 0, Batch 84700, Loss: 0.0019186616409569979\n",
      "Epoch 0, Batch 84750, Loss: 0.001968874130398035\n",
      "Epoch 0, Batch 84800, Loss: 0.001986404648050666\n",
      "Epoch 0, Batch 84850, Loss: 0.001837873482145369\n",
      "Epoch 0, Batch 84900, Loss: 0.0015353141352534294\n",
      "Epoch 0, Batch 84950, Loss: 0.0015400801785290241\n",
      "Epoch 0, Batch 85000, Loss: 0.0018299559596925974\n",
      "Epoch 0, Batch 85050, Loss: 0.001853367080911994\n",
      "Epoch 0, Batch 85100, Loss: 0.0013993177562952042\n",
      "Epoch 0, Batch 85150, Loss: 0.0010877849999815226\n",
      "Epoch 0, Batch 85200, Loss: 0.0013834218261763453\n",
      "Epoch 0, Batch 85250, Loss: 0.001929855439811945\n",
      "Epoch 0, Batch 85300, Loss: 0.0014926824951544404\n",
      "Epoch 0, Batch 85350, Loss: 0.001384585164487362\n",
      "Epoch 0, Batch 85400, Loss: 0.0010519583011046052\n",
      "Epoch 0, Batch 85450, Loss: 0.0011120395502075553\n",
      "Epoch 0, Batch 85500, Loss: 0.0012993660056963563\n",
      "Epoch 0, Batch 85550, Loss: 0.0010690168710425496\n",
      "Epoch 0, Batch 85600, Loss: 0.0016613551415503025\n",
      "Epoch 0, Batch 85650, Loss: 0.0013298236299306154\n",
      "Epoch 0, Batch 85700, Loss: 0.0010616324143484235\n",
      "Epoch 0, Batch 85750, Loss: 0.0016033181454986334\n",
      "Epoch 0, Batch 85800, Loss: 0.0014574003871530294\n",
      "Epoch 0, Batch 85850, Loss: 0.0016164372209459543\n",
      "Epoch 0, Batch 85900, Loss: 0.001613781088963151\n",
      "Epoch 0, Batch 85950, Loss: 0.0013579655205830932\n",
      "Epoch 0, Batch 86000, Loss: 0.001409907010383904\n",
      "Epoch 0, Batch 86050, Loss: 0.0013908152468502522\n",
      "Epoch 0, Batch 86100, Loss: 0.001765190390869975\n",
      "Epoch 0, Batch 86150, Loss: 0.0025927822571247816\n",
      "Epoch 0, Batch 86200, Loss: 0.0025353406090289354\n",
      "Epoch 0, Batch 86250, Loss: 0.0029318607412278652\n",
      "Epoch 0, Batch 86300, Loss: 0.003515435615554452\n",
      "Epoch 0, Batch 86350, Loss: 0.003566294675692916\n",
      "Epoch 0, Batch 86400, Loss: 0.0026477226056158543\n",
      "Epoch 0, Batch 86450, Loss: 0.0028665238060057163\n",
      "Epoch 0, Batch 86500, Loss: 0.0023710839450359344\n",
      "Epoch 0, Batch 86550, Loss: 0.0019559760112315416\n",
      "Epoch 0, Batch 86600, Loss: 0.002187452046200633\n",
      "Epoch 0, Batch 86650, Loss: 0.0021449073683470488\n",
      "Epoch 0, Batch 86700, Loss: 0.0019116487819701433\n",
      "Epoch 0, Batch 86750, Loss: 0.0013495360035449266\n",
      "Epoch 0, Batch 86800, Loss: 0.0011949646286666393\n",
      "Epoch 0, Batch 86850, Loss: 0.0017292993143200874\n",
      "Epoch 0, Batch 86900, Loss: 0.002567916177213192\n",
      "Epoch 0, Batch 86950, Loss: 0.002154846675693989\n",
      "Epoch 0, Batch 87000, Loss: 0.0024817849043756723\n",
      "Epoch 0, Batch 87050, Loss: 0.0016988503048196435\n",
      "Epoch 0, Batch 87100, Loss: 0.0025702142156660557\n",
      "Epoch 0, Batch 87150, Loss: 0.002169713145121932\n",
      "Epoch 0, Batch 87200, Loss: 0.002944919979199767\n",
      "Epoch 0, Batch 87250, Loss: 0.002310293959453702\n",
      "Epoch 0, Batch 87300, Loss: 0.0021558876615017653\n",
      "Epoch 0, Batch 87350, Loss: 0.001993002137169242\n",
      "Epoch 0, Batch 87400, Loss: 0.0016693619545549154\n",
      "Epoch 0, Batch 87450, Loss: 0.0015945341438055038\n",
      "Epoch 0, Batch 87500, Loss: 0.0018180159386247396\n",
      "Epoch 0, Batch 87550, Loss: 0.0018021712312474847\n",
      "Epoch 0, Batch 87600, Loss: 0.002024538116529584\n",
      "Epoch 0, Batch 87650, Loss: 0.002218382665887475\n",
      "Epoch 0, Batch 87700, Loss: 0.0020168607588857412\n",
      "Epoch 0, Batch 87750, Loss: 0.0020364520605653524\n",
      "Epoch 0, Batch 87800, Loss: 0.0020925994031131268\n",
      "Epoch 0, Batch 87850, Loss: 0.0021580993197858334\n",
      "Epoch 0, Batch 87900, Loss: 0.002961360150948167\n",
      "Epoch 0, Batch 87950, Loss: 0.0025779043789952993\n",
      "Epoch 0, Batch 88000, Loss: 0.003536056727170944\n",
      "Epoch 0, Batch 88050, Loss: 0.002692808862775564\n",
      "Epoch 0, Batch 88100, Loss: 0.003160648513585329\n",
      "Epoch 0, Batch 88150, Loss: 0.0023850547149777412\n",
      "Epoch 0, Batch 88200, Loss: 0.002051088958978653\n",
      "Epoch 0, Batch 88250, Loss: 0.0023478867951780558\n",
      "Epoch 0, Batch 88300, Loss: 0.002046308247372508\n",
      "Epoch 0, Batch 88350, Loss: 0.0029868781566619873\n",
      "Epoch 0, Batch 88400, Loss: 0.001972559140995145\n",
      "Epoch 0, Batch 88450, Loss: 0.001452980563044548\n",
      "Epoch 0, Batch 88500, Loss: 0.0012837363174185157\n",
      "Epoch 0, Batch 88550, Loss: 0.001562820514664054\n",
      "Epoch 0, Batch 88600, Loss: 0.0015892867231741548\n",
      "Epoch 0, Batch 88650, Loss: 0.0014097910607233644\n",
      "Epoch 0, Batch 88700, Loss: 0.0014620453584939241\n",
      "Epoch 0, Batch 88750, Loss: 0.0014729974791407585\n",
      "Epoch 0, Batch 88800, Loss: 0.0015046776970848441\n",
      "Epoch 0, Batch 88850, Loss: 0.002162007614970207\n",
      "Epoch 0, Batch 88900, Loss: 0.0014758415054529905\n",
      "Epoch 0, Batch 88950, Loss: 0.0014010777231305838\n",
      "Epoch 0, Batch 89000, Loss: 0.001397576997987926\n",
      "Epoch 0, Batch 89050, Loss: 0.0022821747697889805\n",
      "Epoch 0, Batch 89100, Loss: 0.002766262972727418\n",
      "Epoch 0, Batch 89150, Loss: 0.0024343307595700026\n",
      "Epoch 0, Batch 89200, Loss: 0.002130182459950447\n",
      "Epoch 0, Batch 89250, Loss: 0.0027797494549304247\n",
      "Epoch 0, Batch 89300, Loss: 0.0029883140232414007\n",
      "Epoch 0, Batch 89350, Loss: 0.0022636044304817915\n",
      "Epoch 0, Batch 89400, Loss: 0.0022986361291259527\n",
      "Epoch 0, Batch 89450, Loss: 0.3597300946712494\n",
      "Epoch 0, Batch 89500, Loss: 0.0030326179694384336\n",
      "Epoch 0, Batch 89550, Loss: 0.002220782218500972\n",
      "Epoch 0, Batch 89600, Loss: 0.0023977726232260466\n",
      "Epoch 0, Batch 89650, Loss: 0.0025367126800119877\n",
      "Epoch 0, Batch 89700, Loss: 0.0020696562714874744\n",
      "Epoch 0, Batch 89750, Loss: 0.0018730355659499764\n",
      "Epoch 0, Batch 89800, Loss: 0.0017538232496008277\n",
      "Epoch 0, Batch 89850, Loss: 0.002855989383533597\n",
      "Epoch 0, Batch 89900, Loss: 0.003275098744779825\n",
      "Epoch 0, Batch 89950, Loss: 0.0027692150324583054\n",
      "Epoch 0, Batch 90000, Loss: 0.0022590116132050753\n",
      "Epoch 0, Batch 90050, Loss: 0.002387823536992073\n",
      "Epoch 0, Batch 90100, Loss: 0.0024821204133331776\n",
      "Epoch 0, Batch 90150, Loss: 0.0017346401000395417\n",
      "Epoch 0, Batch 90200, Loss: 0.002310055773705244\n",
      "Epoch 0, Batch 90250, Loss: 0.0018161130137741566\n",
      "Epoch 0, Batch 90300, Loss: 0.002970451721921563\n",
      "Epoch 0, Batch 90350, Loss: 0.0027384120039641857\n",
      "Epoch 0, Batch 90400, Loss: 0.0022626982536166906\n",
      "Epoch 0, Batch 90450, Loss: 0.0019267230527475476\n",
      "Epoch 0, Batch 90500, Loss: 0.003147495212033391\n",
      "Epoch 0, Batch 90550, Loss: 0.005510347429662943\n",
      "Epoch 0, Batch 90600, Loss: 0.005669376812875271\n",
      "Epoch 0, Batch 90650, Loss: 0.0035623193252831697\n",
      "Epoch 0, Batch 90700, Loss: 0.003625022480264306\n",
      "Epoch 0, Batch 90750, Loss: 0.0027147079817950726\n",
      "Epoch 0, Batch 90800, Loss: 0.0019073000876232982\n",
      "Epoch 0, Batch 90850, Loss: 0.001277002040296793\n",
      "Epoch 0, Batch 90900, Loss: 0.0013393558328971267\n",
      "Epoch 0, Batch 90950, Loss: 0.0012700965162366629\n",
      "Epoch 0, Batch 91000, Loss: 0.0015746179269626737\n",
      "Epoch 0, Batch 91050, Loss: 0.001898371265269816\n",
      "Epoch 0, Batch 91100, Loss: 0.0016143439570441842\n",
      "Epoch 0, Batch 91150, Loss: 0.0019428941886872053\n",
      "Epoch 0, Batch 91200, Loss: 0.0023537534289062023\n",
      "Epoch 0, Batch 91250, Loss: 0.003358728252351284\n",
      "Epoch 0, Batch 91300, Loss: 0.0018680617213249207\n",
      "Epoch 0, Batch 91350, Loss: 0.0014210991794243455\n",
      "Epoch 0, Batch 91400, Loss: 0.3941337466239929\n",
      "Epoch 0, Batch 91450, Loss: 0.002371351234614849\n",
      "Epoch 0, Batch 91500, Loss: 0.004072805866599083\n",
      "Epoch 0, Batch 91550, Loss: 0.003765210509300232\n",
      "Epoch 0, Batch 91600, Loss: 0.0024101308081299067\n",
      "Epoch 0, Batch 91650, Loss: 0.001975521445274353\n",
      "Epoch 0, Batch 91700, Loss: 0.0014067748561501503\n",
      "Epoch 0, Batch 91750, Loss: 0.0015673177549615502\n",
      "Epoch 0, Batch 91800, Loss: 0.0020678408909589052\n",
      "Epoch 0, Batch 91850, Loss: 0.0014252692926675081\n",
      "Epoch 0, Batch 91900, Loss: 0.0011059101670980453\n",
      "Epoch 0, Batch 91950, Loss: 0.0014008465223014355\n",
      "Epoch 0, Batch 92000, Loss: 0.0014924524584785104\n",
      "Epoch 0, Batch 92050, Loss: 0.001593013177625835\n",
      "Epoch 0, Batch 92100, Loss: 0.001737865386530757\n",
      "Epoch 0, Batch 92150, Loss: 0.0026500422973185778\n",
      "Epoch 0, Batch 92200, Loss: 0.0031535320449620485\n",
      "Epoch 0, Batch 92250, Loss: 0.0023826865945011377\n",
      "Epoch 0, Batch 92300, Loss: 0.0018579325405880809\n",
      "Epoch 0, Batch 92350, Loss: 0.002949334215372801\n",
      "Epoch 0, Batch 92400, Loss: 0.0035387524403631687\n",
      "Epoch 0, Batch 92450, Loss: 0.0034117423929274082\n",
      "Epoch 0, Batch 92500, Loss: 0.0027455566450953484\n",
      "Epoch 0, Batch 92550, Loss: 0.0025780710857361555\n",
      "Epoch 0, Batch 92600, Loss: 0.0021749024745076895\n",
      "Epoch 0, Batch 92650, Loss: 0.002154309768229723\n",
      "Epoch 0, Batch 92700, Loss: 0.0017282181652262807\n",
      "Epoch 0, Batch 92750, Loss: 0.0018547509098425508\n",
      "Epoch 0, Batch 92800, Loss: 0.0014229532098397613\n",
      "Epoch 0, Batch 92850, Loss: 0.001549533219076693\n",
      "Epoch 0, Batch 92900, Loss: 0.001647486467845738\n",
      "Epoch 0, Batch 92950, Loss: 0.0012708844151347876\n",
      "Epoch 0, Batch 93000, Loss: 0.0023685446940362453\n",
      "Epoch 0, Batch 93050, Loss: 0.0027503499295562506\n",
      "Epoch 0, Batch 93100, Loss: 0.0021904921159148216\n",
      "Epoch 0, Batch 93150, Loss: 0.003155339043587446\n",
      "Epoch 0, Batch 93200, Loss: 0.0022141807712614536\n",
      "Epoch 0, Batch 93250, Loss: 0.0038129326421767473\n",
      "Epoch 0, Batch 93300, Loss: 0.0023259534500539303\n",
      "Epoch 0, Batch 93350, Loss: 0.0021313377656042576\n",
      "Epoch 0, Batch 93400, Loss: 0.001996072707697749\n",
      "Epoch 0, Batch 93450, Loss: 0.0019046033266931772\n",
      "Epoch 0, Batch 93500, Loss: 0.0024680690839886665\n",
      "Epoch 0, Batch 93550, Loss: 0.0019369670189917088\n",
      "Epoch 0, Batch 93600, Loss: 0.0017180753638967872\n",
      "Epoch 0, Batch 93650, Loss: 0.001331372419372201\n",
      "Epoch 0, Batch 93700, Loss: 0.001100305118598044\n",
      "Epoch 0, Batch 93750, Loss: 0.0010968124261125922\n",
      "Epoch 0, Batch 93800, Loss: 0.001090346835553646\n",
      "Epoch 0, Batch 93850, Loss: 0.0016347730997949839\n",
      "Epoch 0, Batch 93900, Loss: 0.0014743220526725054\n",
      "Epoch 0, Batch 93950, Loss: 0.0017720224568620324\n",
      "Epoch 0, Batch 94000, Loss: 0.002210344420745969\n",
      "Epoch 0, Batch 94050, Loss: 0.0015381902921944857\n",
      "Epoch 0, Batch 94100, Loss: 0.0025378945283591747\n",
      "Epoch 0, Batch 94150, Loss: 0.0025648782029747963\n",
      "Epoch 0, Batch 94200, Loss: 0.0025980405043810606\n",
      "Epoch 0, Batch 94250, Loss: 0.0024760286323726177\n",
      "Epoch 0, Batch 94300, Loss: 0.003541438141837716\n",
      "Epoch 0, Batch 94350, Loss: 0.0032303007319569588\n",
      "Epoch 0, Batch 94400, Loss: 0.0024516487028449774\n",
      "Epoch 0, Batch 94450, Loss: 0.0015812612837180495\n",
      "Epoch 0, Batch 94500, Loss: 0.0016201691469177604\n",
      "Epoch 0, Batch 94550, Loss: 0.00131482002325356\n",
      "Epoch 0, Batch 94600, Loss: 0.0016148072900250554\n",
      "Epoch 0, Batch 94650, Loss: 0.001289575477130711\n",
      "Epoch 0, Batch 94700, Loss: 0.001225838204845786\n",
      "Epoch 0, Batch 94750, Loss: 0.4017311632633209\n",
      "Epoch 0, Batch 94800, Loss: 0.0018277725903317332\n",
      "Epoch 0, Batch 94850, Loss: 0.0013462610077112913\n",
      "Epoch 0, Batch 94900, Loss: 0.001235776231624186\n",
      "Epoch 0, Batch 94950, Loss: 0.0011138326954096556\n",
      "Epoch 0, Batch 95000, Loss: 0.4114251434803009\n",
      "Epoch 0, Batch 95050, Loss: 0.0017932308837771416\n",
      "Epoch 0, Batch 95100, Loss: 0.0017871127929538488\n",
      "Epoch 0, Batch 95150, Loss: 0.0018294983310624957\n",
      "Epoch 0, Batch 95200, Loss: 0.002385512227192521\n",
      "Epoch 0, Batch 95250, Loss: 0.001671483158133924\n",
      "Epoch 0, Batch 95300, Loss: 0.002643365180119872\n",
      "Epoch 0, Batch 95350, Loss: 0.0034957565367221832\n",
      "Epoch 0, Batch 95400, Loss: 0.0025814385153353214\n",
      "Epoch 0, Batch 95450, Loss: 0.002230054698884487\n",
      "Epoch 0, Batch 95500, Loss: 0.002847113413736224\n",
      "Epoch 0, Batch 95550, Loss: 0.002862710738554597\n",
      "Epoch 0, Batch 95600, Loss: 0.0031788034830242395\n",
      "Epoch 0, Batch 95650, Loss: 0.002157194772735238\n",
      "Epoch 0, Batch 95700, Loss: 0.002927752211689949\n",
      "Epoch 0, Batch 95750, Loss: 0.002966485219076276\n",
      "Epoch 0, Batch 95800, Loss: 0.0030468027107417583\n",
      "Epoch 0, Batch 95850, Loss: 0.0028929305262863636\n",
      "Epoch 0, Batch 95900, Loss: 0.0022565710823982954\n",
      "Epoch 0, Batch 95950, Loss: 0.003789043053984642\n",
      "Epoch 0, Batch 96000, Loss: 0.0034307606983929873\n",
      "Epoch 0, Batch 96050, Loss: 0.002384680323302746\n",
      "Epoch 0, Batch 96100, Loss: 0.002029254799708724\n",
      "Epoch 0, Batch 96150, Loss: 0.0022844793274998665\n",
      "Epoch 0, Batch 96200, Loss: 0.001789217465557158\n",
      "Epoch 0, Batch 96250, Loss: 0.0015098839066922665\n",
      "Epoch 0, Batch 96300, Loss: 0.0016288927290588617\n",
      "Epoch 0, Batch 96350, Loss: 0.0018109825905412436\n",
      "Epoch 0, Batch 96400, Loss: 0.0016130029689520597\n",
      "Epoch 0, Batch 96450, Loss: 0.003536379663273692\n",
      "Epoch 0, Batch 96500, Loss: 0.002737490925937891\n",
      "Epoch 0, Batch 96550, Loss: 0.3781150281429291\n",
      "Epoch 0, Batch 96600, Loss: 0.002474649576470256\n",
      "Epoch 0, Batch 96650, Loss: 0.0022400114685297012\n",
      "Epoch 0, Batch 96700, Loss: 0.0014974571531638503\n",
      "Epoch 0, Batch 96750, Loss: 0.0013449705438688397\n",
      "Epoch 0, Batch 96800, Loss: 0.0016243215650320053\n",
      "Epoch 0, Batch 96850, Loss: 0.0015351049369201064\n",
      "Epoch 0, Batch 96900, Loss: 0.0015201217029243708\n",
      "Epoch 0, Batch 96950, Loss: 0.0015445735771209002\n",
      "Epoch 0, Batch 97000, Loss: 0.0012191957794129848\n",
      "Epoch 0, Batch 97050, Loss: 0.001651307800784707\n",
      "Epoch 0, Batch 97100, Loss: 0.0014823686797171831\n",
      "Epoch 0, Batch 97150, Loss: 0.0012484542094171047\n",
      "Epoch 0, Batch 97200, Loss: 0.0012530252570286393\n",
      "Epoch 0, Batch 97250, Loss: 0.0021524401381611824\n",
      "Epoch 0, Batch 97300, Loss: 0.0015233935555443168\n",
      "Epoch 0, Batch 97350, Loss: 0.0013087281258776784\n",
      "Epoch 0, Batch 97400, Loss: 0.001683538779616356\n",
      "Epoch 0, Batch 97450, Loss: 0.0016169169684872031\n",
      "Epoch 0, Batch 97500, Loss: 0.002247077412903309\n",
      "Epoch 0, Batch 97550, Loss: 0.0018061671871691942\n",
      "Epoch 0, Batch 97600, Loss: 0.0020278040319681168\n",
      "Epoch 0, Batch 97650, Loss: 0.0014293310232460499\n",
      "Epoch 0, Batch 97700, Loss: 0.002132843481376767\n",
      "Epoch 0, Batch 97750, Loss: 0.00216235825791955\n",
      "Epoch 0, Batch 97800, Loss: 0.0014741523191332817\n",
      "Epoch 0, Batch 97850, Loss: 0.0019521091599017382\n",
      "Epoch 0, Batch 97900, Loss: 0.0021622658241540194\n",
      "Epoch 0, Batch 97950, Loss: 0.0012778552481904626\n",
      "Epoch 0, Batch 98000, Loss: 0.002271587261930108\n",
      "Epoch 0, Batch 98050, Loss: 0.0026641401927918196\n",
      "Epoch 0, Batch 98100, Loss: 0.0022513491567224264\n",
      "Epoch 0, Batch 98150, Loss: 0.0019335263641551137\n",
      "Epoch 0, Batch 98200, Loss: 0.002425476908683777\n",
      "Epoch 0, Batch 98250, Loss: 0.001835282426327467\n",
      "Epoch 0, Batch 98300, Loss: 0.002179723000153899\n",
      "Epoch 0, Batch 98350, Loss: 0.002080760197713971\n",
      "Epoch 0, Batch 98400, Loss: 0.002814515493810177\n",
      "Epoch 0, Batch 98450, Loss: 0.004834725521504879\n",
      "Epoch 0, Batch 98500, Loss: 0.003926985897123814\n",
      "Epoch 0, Batch 98550, Loss: 0.002690319437533617\n",
      "Epoch 0, Batch 98600, Loss: 0.002288111252710223\n",
      "Epoch 0, Batch 98650, Loss: 0.37972399592399597\n",
      "Epoch 0, Batch 98700, Loss: 0.003948405385017395\n",
      "Epoch 0, Batch 98750, Loss: 0.0029470869340002537\n",
      "Epoch 0, Batch 98800, Loss: 0.003165705129504204\n",
      "Epoch 0, Batch 98850, Loss: 0.0020335866138339043\n",
      "Epoch 0, Batch 98900, Loss: 0.0025047140661627054\n",
      "Epoch 0, Batch 98950, Loss: 0.0027621514163911343\n",
      "Epoch 0, Batch 99000, Loss: 0.0020298748277127743\n",
      "Epoch 0, Batch 99050, Loss: 0.002040968043729663\n",
      "Epoch 0, Batch 99100, Loss: 0.002241195412352681\n",
      "Epoch 0, Batch 99150, Loss: 0.0020287304650992155\n",
      "Epoch 0, Batch 99200, Loss: 0.0015798857202753425\n",
      "Epoch 0, Batch 99250, Loss: 0.0012841073330491781\n",
      "Epoch 0, Batch 99300, Loss: 0.0013758159475401044\n",
      "Epoch 0, Batch 99350, Loss: 0.0020390150602906942\n",
      "Epoch 0, Batch 99400, Loss: 0.0018260248471051455\n",
      "Epoch 0, Batch 99450, Loss: 0.002248184522613883\n",
      "Epoch 0, Batch 99500, Loss: 0.0029658616986125708\n",
      "Epoch 0, Batch 99550, Loss: 0.002310184994712472\n",
      "Epoch 0, Batch 99600, Loss: 0.001996516715735197\n",
      "Epoch 0, Batch 99650, Loss: 0.0017196008702740073\n",
      "Epoch 0, Batch 99700, Loss: 0.001894748886115849\n",
      "Epoch 0, Batch 99750, Loss: 0.0021263640373945236\n",
      "Epoch 0, Batch 99800, Loss: 0.0018721099477261305\n",
      "Epoch 0, Batch 99850, Loss: 0.0019849061500281096\n",
      "Epoch 0, Batch 99900, Loss: 0.002410788321867585\n",
      "Epoch 0, Batch 99950, Loss: 0.0025297831743955612\n",
      "Epoch 0, Batch 100000, Loss: 0.3731529116630554\n",
      "Epoch 0, Batch 100050, Loss: 0.0020430791191756725\n",
      "Epoch 0, Batch 100100, Loss: 0.002199032111093402\n",
      "Epoch 0, Batch 100150, Loss: 0.0019045897061005235\n",
      "Epoch 0, Batch 100200, Loss: 0.0017946545267477632\n",
      "Epoch 0, Batch 100250, Loss: 0.001931822975166142\n",
      "Epoch 0, Batch 100300, Loss: 0.0018791279289871454\n",
      "Epoch 0, Batch 100350, Loss: 0.0027676408644765615\n",
      "Epoch 0, Batch 100400, Loss: 0.002593399491161108\n",
      "Epoch 0, Batch 100450, Loss: 0.0027683295775204897\n",
      "Epoch 0, Batch 100500, Loss: 0.002523139351978898\n",
      "Epoch 0, Batch 100550, Loss: 0.0016687428578734398\n",
      "Epoch 0, Batch 100600, Loss: 0.001438577426597476\n",
      "Epoch 0, Batch 100650, Loss: 0.0015539787709712982\n",
      "Epoch 0, Batch 100700, Loss: 0.0021060823928564787\n",
      "Epoch 0, Batch 100750, Loss: 0.0020076187793165445\n",
      "Epoch 0, Batch 100800, Loss: 0.0016621550312265754\n",
      "Epoch 0, Batch 100850, Loss: 0.0014696656726300716\n",
      "Epoch 0, Batch 100900, Loss: 0.0017056770157068968\n",
      "Epoch 0, Batch 100950, Loss: 0.0020258284639567137\n",
      "Epoch 0, Batch 101000, Loss: 0.002898295409977436\n",
      "Epoch 0, Batch 101050, Loss: 0.0033078829292207956\n",
      "Epoch 0, Batch 101100, Loss: 0.0023856523912400007\n",
      "Epoch 0, Batch 101150, Loss: 0.0019640245009213686\n",
      "Epoch 0, Batch 101200, Loss: 0.002053201664239168\n",
      "Epoch 0, Batch 101250, Loss: 0.001498128636740148\n",
      "Epoch 0, Batch 101300, Loss: 0.0014332704013213515\n",
      "Epoch 0, Batch 101350, Loss: 0.0019596582278609276\n",
      "Epoch 0, Batch 101400, Loss: 0.0021699590142816305\n",
      "Epoch 0, Batch 101450, Loss: 0.001985027687624097\n",
      "Epoch 0, Batch 101500, Loss: 0.0023776458110660315\n",
      "Epoch 0, Batch 101550, Loss: 0.002494622254744172\n",
      "Epoch 0, Batch 101600, Loss: 0.0018882602453231812\n",
      "Epoch 0, Batch 101650, Loss: 0.0029203537851572037\n",
      "Epoch 0, Batch 101700, Loss: 0.002593561075627804\n",
      "Epoch 0, Batch 101750, Loss: 0.003237133612856269\n",
      "Epoch 0, Batch 101800, Loss: 0.0023484257981181145\n",
      "Epoch 0, Batch 101850, Loss: 0.0030232141725718975\n",
      "Epoch 0, Batch 101900, Loss: 0.002948364242911339\n",
      "Epoch 0, Batch 101950, Loss: 0.3949691951274872\n",
      "Epoch 0, Batch 102000, Loss: 0.003505903296172619\n",
      "Epoch 0, Batch 102050, Loss: 0.002283860696479678\n",
      "Epoch 0, Batch 102100, Loss: 0.002783355303108692\n",
      "Epoch 0, Batch 102150, Loss: 0.002503344789147377\n",
      "Epoch 0, Batch 102200, Loss: 0.003392579732462764\n",
      "Epoch 0, Batch 102250, Loss: 0.0025864120107144117\n",
      "Epoch 0, Batch 102300, Loss: 0.001658199355006218\n",
      "Epoch 0, Batch 102350, Loss: 0.0018344306154176593\n",
      "Epoch 0, Batch 102400, Loss: 0.001390929683111608\n",
      "Epoch 0, Batch 102450, Loss: 0.0011539356783032417\n",
      "Epoch 0, Batch 102500, Loss: 0.0012123254127800465\n",
      "Epoch 0, Batch 102550, Loss: 0.0012175518786534667\n",
      "Epoch 0, Batch 102600, Loss: 0.0015878668054938316\n",
      "Epoch 0, Batch 102650, Loss: 0.0015187598764896393\n",
      "Epoch 0, Batch 102700, Loss: 0.0018114151898771524\n",
      "Epoch 0, Batch 102750, Loss: 0.0015876594698056579\n",
      "Epoch 0, Batch 102800, Loss: 0.0011220299638807774\n",
      "Epoch 0, Batch 102850, Loss: 0.0008692098781466484\n",
      "Epoch 0, Batch 102900, Loss: 0.0015120157040655613\n",
      "Epoch 0, Batch 102950, Loss: 0.0014193442184478045\n",
      "Epoch 0, Batch 103000, Loss: 0.0013567451387643814\n",
      "Epoch 0, Batch 103050, Loss: 0.0014130391646176577\n",
      "Epoch 0, Batch 103100, Loss: 0.0018999628955498338\n",
      "Epoch 0, Batch 103150, Loss: 0.0022366023622453213\n",
      "Epoch 0, Batch 103200, Loss: 0.001790604437701404\n",
      "Epoch 0, Batch 103250, Loss: 0.002141155069693923\n",
      "Epoch 0, Batch 103300, Loss: 0.0024131678510457277\n",
      "Epoch 0, Batch 103350, Loss: 0.0017507874872535467\n",
      "Epoch 0, Batch 103400, Loss: 0.0016226187581196427\n",
      "Epoch 0, Batch 103450, Loss: 0.0019866121001541615\n",
      "Epoch 0, Batch 103500, Loss: 0.0018790662288665771\n",
      "Epoch 0, Batch 103550, Loss: 0.0021171944681555033\n",
      "Epoch 0, Batch 103600, Loss: 0.0024085461627691984\n",
      "Epoch 0, Batch 103650, Loss: 0.0018076094565913081\n",
      "Epoch 0, Batch 103700, Loss: 0.0014166230103000998\n",
      "Epoch 0, Batch 103750, Loss: 0.0017339647747576237\n",
      "Epoch 0, Batch 103800, Loss: 0.0012990474933758378\n",
      "Epoch 0, Batch 103850, Loss: 0.0013150825398042798\n",
      "Epoch 0, Batch 103900, Loss: 0.0018173157004639506\n",
      "Epoch 0, Batch 103950, Loss: 0.001645428710617125\n",
      "Epoch 0, Batch 104000, Loss: 0.0010854513384401798\n",
      "Epoch 0, Batch 104050, Loss: 0.0015836574602872133\n",
      "Epoch 0, Batch 104100, Loss: 0.0011995397508144379\n",
      "Epoch 0, Batch 104150, Loss: 0.0011973190121352673\n",
      "Epoch 0, Batch 104200, Loss: 0.0009126318618655205\n",
      "Epoch 0, Batch 104250, Loss: 0.000985807040706277\n",
      "Epoch 0, Batch 104300, Loss: 0.0008258941234089434\n",
      "Epoch 0, Batch 104350, Loss: 0.0014783259248360991\n",
      "Epoch 0, Batch 104400, Loss: 0.0018640622729435563\n",
      "Epoch 0, Batch 104450, Loss: 0.0016980415675789118\n",
      "Epoch 0, Batch 104500, Loss: 0.002721790922805667\n",
      "Epoch 0, Batch 104550, Loss: 0.002163042314350605\n",
      "Epoch 0, Batch 104600, Loss: 0.0019809426739811897\n",
      "Epoch 0, Batch 104650, Loss: 0.0011799248168244958\n",
      "Epoch 0, Batch 104700, Loss: 0.0015633997973054647\n",
      "Epoch 0, Batch 104750, Loss: 0.0014614361571148038\n",
      "Epoch 0, Batch 104800, Loss: 0.0022273326758295298\n",
      "Epoch 0, Batch 104850, Loss: 0.0017146815080195665\n",
      "Epoch 0, Batch 104900, Loss: 0.002229879377409816\n",
      "Epoch 0, Batch 104950, Loss: 0.0020188845228403807\n",
      "Epoch 0, Batch 105000, Loss: 0.0018490435322746634\n",
      "Epoch 0, Batch 105050, Loss: 0.001956033520400524\n",
      "Epoch 0, Batch 105100, Loss: 0.001656953478232026\n",
      "Epoch 0, Batch 105150, Loss: 0.0014011148596182466\n",
      "Epoch 0, Batch 105200, Loss: 0.0013826732756569982\n",
      "Epoch 0, Batch 105250, Loss: 0.002229823498055339\n",
      "Epoch 0, Batch 105300, Loss: 0.001998968655243516\n",
      "Epoch 0, Batch 105350, Loss: 0.0021072530653327703\n",
      "Epoch 0, Batch 105400, Loss: 0.0030992631800472736\n",
      "Epoch 0, Batch 105450, Loss: 0.0023393582087010145\n",
      "Epoch 0, Batch 105500, Loss: 0.0030778355430811644\n",
      "Epoch 0, Batch 105550, Loss: 0.0025576341431587934\n",
      "Epoch 0, Batch 105600, Loss: 0.0020904424600303173\n",
      "Epoch 0, Batch 105650, Loss: 0.003012001048773527\n",
      "Epoch 0, Batch 105700, Loss: 0.0018894706154242158\n",
      "Epoch 0, Batch 105750, Loss: 0.002186126308515668\n",
      "Epoch 0, Batch 105800, Loss: 0.002054699696600437\n",
      "Epoch 0, Batch 105850, Loss: 0.002034328179433942\n",
      "Epoch 0, Batch 105900, Loss: 0.001446627196855843\n",
      "Epoch 0, Batch 105950, Loss: 0.00166641129180789\n",
      "Epoch 0, Batch 106000, Loss: 0.0011815661564469337\n",
      "Epoch 0, Batch 106050, Loss: 0.001527220942080021\n",
      "Epoch 0, Batch 106100, Loss: 0.0015250357100740075\n",
      "Epoch 0, Batch 106150, Loss: 0.0017413273453712463\n",
      "Epoch 0, Batch 106200, Loss: 0.0015665944665670395\n",
      "Epoch 0, Batch 106250, Loss: 0.001511079608462751\n",
      "Epoch 0, Batch 106300, Loss: 0.001448502647690475\n",
      "Epoch 0, Batch 106350, Loss: 0.0017923712730407715\n",
      "Epoch 0, Batch 106400, Loss: 0.0023688480723649263\n",
      "Epoch 0, Batch 106450, Loss: 0.0024840128608047962\n",
      "Epoch 0, Batch 106500, Loss: 0.0017820497741922736\n",
      "Epoch 0, Batch 106550, Loss: 0.0029667175840586424\n",
      "Epoch 0, Batch 106600, Loss: 0.002626479137688875\n",
      "Epoch 0, Batch 106650, Loss: 0.002187799196690321\n",
      "Epoch 0, Batch 106700, Loss: 0.002115184674039483\n",
      "Epoch 0, Batch 106750, Loss: 0.0020557946991175413\n",
      "Epoch 0, Batch 106800, Loss: 0.0022304279264062643\n",
      "Epoch 0, Batch 106850, Loss: 0.0014600370777770877\n",
      "Epoch 0, Batch 106900, Loss: 0.38387826085090637\n",
      "Epoch 0, Batch 106950, Loss: 0.002352643059566617\n",
      "Epoch 0, Batch 107000, Loss: 0.003663615556433797\n",
      "Epoch 0, Batch 107050, Loss: 0.002364909276366234\n",
      "Epoch 0, Batch 107100, Loss: 0.0019680808763951063\n",
      "Epoch 0, Batch 107150, Loss: 0.0022235033102333546\n",
      "Epoch 0, Batch 107200, Loss: 0.0017624403117224574\n",
      "Epoch 0, Batch 107250, Loss: 0.0017915614880621433\n",
      "Epoch 0, Batch 107300, Loss: 0.0023525767028331757\n",
      "Epoch 0, Batch 107350, Loss: 0.0018503885949030519\n",
      "Epoch 0, Batch 107400, Loss: 0.0015278004575520754\n",
      "Epoch 0, Batch 107450, Loss: 0.0014264172641560435\n",
      "Epoch 0, Batch 107500, Loss: 0.0016332773957401514\n",
      "Epoch 0, Batch 107550, Loss: 0.0013232908677309752\n",
      "Epoch 0, Batch 107600, Loss: 0.0013030258705839515\n",
      "Epoch 0, Batch 107650, Loss: 0.001941679627634585\n",
      "Epoch 0, Batch 107700, Loss: 0.0014774963492527604\n",
      "Epoch 0, Batch 107750, Loss: 0.0017201092559844255\n",
      "Epoch 0, Batch 107800, Loss: 0.001978578744456172\n",
      "Epoch 0, Batch 107850, Loss: 0.002582770772278309\n",
      "Epoch 0, Batch 107900, Loss: 0.002422979334369302\n",
      "Epoch 0, Batch 107950, Loss: 0.0016012894921004772\n",
      "Epoch 0, Batch 108000, Loss: 0.001262259786017239\n",
      "Epoch 0, Batch 108050, Loss: 0.0009471562225371599\n",
      "Epoch 0, Batch 108100, Loss: 0.0012922267196699977\n",
      "Epoch 0, Batch 108150, Loss: 0.0013193268096074462\n",
      "Epoch 0, Batch 108200, Loss: 0.00203680875711143\n",
      "Epoch 0, Batch 108250, Loss: 0.002170023275539279\n",
      "Epoch 0, Batch 108300, Loss: 0.0025506147649139166\n",
      "Epoch 0, Batch 108350, Loss: 0.004904804285615683\n",
      "Epoch 0, Batch 108400, Loss: 0.003774822223931551\n",
      "Epoch 0, Batch 108450, Loss: 0.0026141272392123938\n",
      "Epoch 0, Batch 108500, Loss: 0.002737423637881875\n",
      "Epoch 0, Batch 108550, Loss: 0.002969384426251054\n",
      "Epoch 0, Batch 108600, Loss: 0.0033804746344685555\n",
      "Epoch 0, Batch 108650, Loss: 0.003734209341928363\n",
      "Epoch 0, Batch 108700, Loss: 0.002725473139435053\n",
      "Epoch 0, Batch 108750, Loss: 0.0025268292520195246\n",
      "Epoch 0, Batch 108800, Loss: 0.0032753385603427887\n",
      "Epoch 0, Batch 108850, Loss: 0.0024485336616635323\n",
      "Epoch 0, Batch 108900, Loss: 0.0033290251158177853\n",
      "Epoch 0, Batch 108950, Loss: 0.002699418691918254\n",
      "Epoch 0, Batch 109000, Loss: 0.0024057175032794476\n",
      "Epoch 0, Batch 109050, Loss: 0.0017344681546092033\n",
      "Epoch 0, Batch 109100, Loss: 0.0020720523316413164\n",
      "Epoch 0, Batch 109150, Loss: 0.002025105059146881\n",
      "Epoch 0, Batch 109200, Loss: 0.0017888887086883187\n",
      "Epoch 0, Batch 109250, Loss: 0.001918747671879828\n",
      "Epoch 0, Batch 109300, Loss: 0.002023712731897831\n",
      "Epoch 0, Batch 109350, Loss: 0.00177201593760401\n",
      "Epoch 0, Batch 109400, Loss: 0.0015340797835960984\n",
      "Epoch 0, Batch 109450, Loss: 0.001430755713954568\n",
      "Epoch 0, Batch 109500, Loss: 0.0016107492847368121\n",
      "Epoch 0, Batch 109550, Loss: 0.0023945788852870464\n",
      "Epoch 0, Batch 109600, Loss: 0.002417617943137884\n",
      "Epoch 0, Batch 109650, Loss: 0.002122696256265044\n",
      "Epoch 0, Batch 109700, Loss: 0.0018144474597647786\n",
      "Epoch 0, Batch 109750, Loss: 0.002026190282776952\n",
      "Epoch 0, Batch 109800, Loss: 0.0018587775994092226\n",
      "Epoch 0, Batch 109850, Loss: 0.0018590246327221394\n",
      "Epoch 0, Batch 109900, Loss: 0.0021303717512637377\n",
      "Epoch 0, Batch 109950, Loss: 0.0017754650907590985\n",
      "Epoch 0, Batch 110000, Loss: 0.00144178606569767\n",
      "Epoch 0, Batch 110050, Loss: 0.0017592415679246187\n",
      "Epoch 0, Batch 110100, Loss: 0.001795560005120933\n",
      "Epoch 0, Batch 110150, Loss: 0.002006013412028551\n",
      "Epoch 0, Batch 110200, Loss: 0.001882724347524345\n",
      "Epoch 0, Batch 110250, Loss: 0.001790753216482699\n",
      "Epoch 0, Batch 110300, Loss: 0.0018916138214990497\n",
      "Epoch 0, Batch 110350, Loss: 0.0013347802450880408\n",
      "Epoch 0, Batch 110400, Loss: 0.0012197437463328242\n",
      "Epoch 0, Batch 110450, Loss: 0.001813256647437811\n",
      "Epoch 0, Batch 110500, Loss: 0.0013768153730779886\n",
      "Epoch 0, Batch 110550, Loss: 0.0010811897227540612\n",
      "Epoch 0, Batch 110600, Loss: 0.001319277798756957\n",
      "Epoch 0, Batch 110650, Loss: 0.0013174202758818865\n",
      "Epoch 0, Batch 110700, Loss: 0.0011571242939680815\n",
      "Epoch 0, Batch 110750, Loss: 0.0009006672189570963\n",
      "Epoch 0, Batch 110800, Loss: 0.0009151333943009377\n",
      "Epoch 0, Batch 110850, Loss: 0.00125754508189857\n",
      "Epoch 0, Batch 110900, Loss: 0.0015073928516358137\n",
      "Epoch 0, Batch 110950, Loss: 0.0014778327895328403\n",
      "Epoch 0, Batch 111000, Loss: 0.0014994272496551275\n",
      "Epoch 0, Batch 111050, Loss: 0.0011741487542167306\n",
      "Epoch 0, Batch 111100, Loss: 0.0013537544291466475\n",
      "Epoch 0, Batch 111150, Loss: 0.002398389857262373\n",
      "Epoch 0, Batch 111200, Loss: 0.00230008945800364\n",
      "Epoch 0, Batch 111250, Loss: 0.001871313201263547\n",
      "Epoch 0, Batch 111300, Loss: 0.0018949911464005709\n",
      "Epoch 0, Batch 111350, Loss: 0.002226318931207061\n",
      "Epoch 0, Batch 111400, Loss: 0.002419977681711316\n",
      "Epoch 0, Batch 111450, Loss: 0.003360054222866893\n",
      "Epoch 0, Batch 111500, Loss: 0.0019462080672383308\n",
      "Epoch 0, Batch 111550, Loss: 0.0016192860202863812\n",
      "Epoch 0, Batch 111600, Loss: 0.001295145833864808\n",
      "Epoch 0, Batch 111650, Loss: 0.001514812815003097\n",
      "Epoch 0, Batch 111700, Loss: 0.0022241317201405764\n",
      "Epoch 0, Batch 111750, Loss: 0.001547530060634017\n",
      "Epoch 0, Batch 111800, Loss: 0.0014440239174291492\n",
      "Epoch 0, Batch 111850, Loss: 0.3888266384601593\n",
      "Epoch 0, Batch 111900, Loss: 0.002517069922760129\n",
      "Epoch 0, Batch 111950, Loss: 0.0022031781263649464\n",
      "Epoch 0, Batch 112000, Loss: 0.0016810750821605325\n",
      "Epoch 0, Batch 112050, Loss: 0.001571395667269826\n",
      "Epoch 0, Batch 112100, Loss: 0.0017290603136643767\n",
      "Epoch 0, Batch 112150, Loss: 0.0017468698788434267\n",
      "Epoch 0, Batch 112200, Loss: 0.0020009891595691442\n",
      "Epoch 0, Batch 112250, Loss: 0.001671313657425344\n",
      "Epoch 0, Batch 112300, Loss: 0.0018605770310387015\n",
      "Epoch 0, Batch 112350, Loss: 0.002539020963013172\n",
      "Epoch 0, Batch 112400, Loss: 0.0023917839862406254\n",
      "Epoch 0, Batch 112450, Loss: 0.002212319988757372\n",
      "Epoch 0, Batch 112500, Loss: 0.0021760286763310432\n",
      "Epoch 1, Batch 50, Loss: 0.0015387479215860367\n",
      "Epoch 1, Batch 100, Loss: 0.0017737741582095623\n",
      "Epoch 1, Batch 150, Loss: 0.3659493923187256\n",
      "Epoch 1, Batch 200, Loss: 0.002907944144681096\n",
      "Epoch 1, Batch 250, Loss: 0.003048453712835908\n",
      "Epoch 1, Batch 300, Loss: 0.0028737469110637903\n",
      "Epoch 1, Batch 350, Loss: 0.0037712205667048693\n",
      "Epoch 1, Batch 400, Loss: 0.002333524636924267\n",
      "Epoch 1, Batch 450, Loss: 0.0015497501008212566\n",
      "Epoch 1, Batch 500, Loss: 0.0012788664316758513\n",
      "Epoch 1, Batch 550, Loss: 0.4127529561519623\n",
      "Epoch 1, Batch 600, Loss: 0.003669991623610258\n",
      "Epoch 1, Batch 650, Loss: 0.0026434818282723427\n",
      "Epoch 1, Batch 700, Loss: 0.0027574789710342884\n",
      "Epoch 1, Batch 750, Loss: 0.00331651559099555\n",
      "Epoch 1, Batch 800, Loss: 0.0029640954453498125\n",
      "Epoch 1, Batch 850, Loss: 0.002408432075753808\n",
      "Epoch 1, Batch 900, Loss: 0.0016978636849671602\n",
      "Epoch 1, Batch 950, Loss: 0.0018840229604393244\n",
      "Epoch 1, Batch 1000, Loss: 0.001649431069381535\n",
      "Epoch 1, Batch 1050, Loss: 0.001853225752711296\n",
      "Epoch 1, Batch 1100, Loss: 0.0023613357916474342\n",
      "Epoch 1, Batch 1150, Loss: 0.00209531607106328\n",
      "Epoch 1, Batch 1200, Loss: 0.002890241565182805\n",
      "Epoch 1, Batch 1250, Loss: 0.0021519367583096027\n",
      "Epoch 1, Batch 1300, Loss: 0.0018643199000507593\n",
      "Epoch 1, Batch 1350, Loss: 0.003211480099707842\n",
      "Epoch 1, Batch 1400, Loss: 0.002853038953617215\n",
      "Epoch 1, Batch 1450, Loss: 0.001998601481318474\n",
      "Epoch 1, Batch 1500, Loss: 0.0017039430094882846\n",
      "Epoch 1, Batch 1550, Loss: 0.0020091913174837828\n",
      "Epoch 1, Batch 1600, Loss: 0.0019960294011980295\n",
      "Epoch 1, Batch 1650, Loss: 0.001351126586087048\n",
      "Epoch 1, Batch 1700, Loss: 0.002478186972439289\n",
      "Epoch 1, Batch 1750, Loss: 0.0017735006986185908\n",
      "Epoch 1, Batch 1800, Loss: 0.0020294305868446827\n",
      "Epoch 1, Batch 1850, Loss: 0.0017121138516813517\n",
      "Epoch 1, Batch 1900, Loss: 0.0017839288339018822\n",
      "Epoch 1, Batch 1950, Loss: 0.001699907472357154\n",
      "Epoch 1, Batch 2000, Loss: 0.0015517027350142598\n",
      "Epoch 1, Batch 2050, Loss: 0.0015428178012371063\n",
      "Epoch 1, Batch 2100, Loss: 0.002458439441397786\n",
      "Epoch 1, Batch 2150, Loss: 0.0019119533244520426\n",
      "Epoch 1, Batch 2200, Loss: 0.0018643367802724242\n",
      "Epoch 1, Batch 2250, Loss: 0.0020041661337018013\n",
      "Epoch 1, Batch 2300, Loss: 0.001878082286566496\n",
      "Epoch 1, Batch 2350, Loss: 0.002144185360521078\n",
      "Epoch 1, Batch 2400, Loss: 0.0016920012421905994\n",
      "Epoch 1, Batch 2450, Loss: 0.0018431097269058228\n",
      "Epoch 1, Batch 2500, Loss: 0.002299090614542365\n",
      "Epoch 1, Batch 2550, Loss: 0.001920267823152244\n",
      "Epoch 1, Batch 2600, Loss: 0.0017290321411564946\n",
      "Epoch 1, Batch 2650, Loss: 0.0014236101415008307\n",
      "Epoch 1, Batch 2700, Loss: 0.0013707861071452498\n",
      "Epoch 1, Batch 2750, Loss: 0.8335026502609253\n",
      "Epoch 1, Batch 2800, Loss: 0.36422666907310486\n",
      "Epoch 1, Batch 2850, Loss: 0.004243548959493637\n",
      "Epoch 1, Batch 2900, Loss: 0.0025691422633826733\n",
      "Epoch 1, Batch 2950, Loss: 0.0017922197002917528\n",
      "Epoch 1, Batch 3000, Loss: 0.001533427624963224\n",
      "Epoch 1, Batch 3050, Loss: 0.0015242494409903884\n",
      "Epoch 1, Batch 3100, Loss: 0.0015531880781054497\n",
      "Epoch 1, Batch 3150, Loss: 0.0014305192744359374\n",
      "Epoch 1, Batch 3200, Loss: 0.0013542314991354942\n",
      "Epoch 1, Batch 3250, Loss: 0.0016129683936014771\n",
      "Epoch 1, Batch 3300, Loss: 0.0015085411723703146\n",
      "Epoch 1, Batch 3350, Loss: 0.0028509735129773617\n",
      "Epoch 1, Batch 3400, Loss: 0.0033951804507523775\n",
      "Epoch 1, Batch 3450, Loss: 0.002634830540046096\n",
      "Epoch 1, Batch 3500, Loss: 0.005146726965904236\n",
      "Epoch 1, Batch 3550, Loss: 0.003827350679785013\n",
      "Epoch 1, Batch 3600, Loss: 0.003060990711674094\n",
      "Epoch 1, Batch 3650, Loss: 0.0038138963282108307\n",
      "Epoch 1, Batch 3700, Loss: 0.00287445355206728\n",
      "Epoch 1, Batch 3750, Loss: 0.0029388656839728355\n",
      "Epoch 1, Batch 3800, Loss: 0.003209686605259776\n",
      "Epoch 1, Batch 3850, Loss: 0.0023022261448204517\n",
      "Epoch 1, Batch 3900, Loss: 0.002002857392653823\n",
      "Epoch 1, Batch 3950, Loss: 0.0017575620440766215\n",
      "Epoch 1, Batch 4000, Loss: 0.0014413857134059072\n",
      "Epoch 1, Batch 4050, Loss: 0.0015210167039185762\n",
      "Epoch 1, Batch 4100, Loss: 0.0013476016465574503\n",
      "Epoch 1, Batch 4150, Loss: 0.0013573230244219303\n",
      "Epoch 1, Batch 4200, Loss: 0.0011590669164434075\n",
      "Epoch 1, Batch 4250, Loss: 0.0012041334994137287\n",
      "Epoch 1, Batch 4300, Loss: 0.001139557221904397\n",
      "Epoch 1, Batch 4350, Loss: 0.001171971671283245\n",
      "Epoch 1, Batch 4400, Loss: 0.0013107312843203545\n",
      "Epoch 1, Batch 4450, Loss: 0.0016128963325172663\n",
      "Epoch 1, Batch 4500, Loss: 0.0020361740607768297\n",
      "Epoch 1, Batch 4550, Loss: 0.0038828039541840553\n",
      "Epoch 1, Batch 4600, Loss: 0.003125392831861973\n",
      "Epoch 1, Batch 4650, Loss: 0.003192292992025614\n",
      "Epoch 1, Batch 4700, Loss: 0.003111554542556405\n",
      "Epoch 1, Batch 4750, Loss: 0.003212681971490383\n",
      "Epoch 1, Batch 4800, Loss: 0.003677795175462961\n",
      "Epoch 1, Batch 4850, Loss: 0.0024590755347162485\n",
      "Epoch 1, Batch 4900, Loss: 0.0015177929308265448\n",
      "Epoch 1, Batch 4950, Loss: 0.0021112856920808554\n",
      "Epoch 1, Batch 5000, Loss: 0.0026140136178582907\n",
      "Epoch 1, Batch 5050, Loss: 0.003061494790017605\n",
      "Epoch 1, Batch 5100, Loss: 0.003364047734066844\n",
      "Epoch 1, Batch 5150, Loss: 0.00316687417216599\n",
      "Epoch 1, Batch 5200, Loss: 0.002208121819421649\n",
      "Epoch 1, Batch 5250, Loss: 0.0015233242884278297\n",
      "Epoch 1, Batch 5300, Loss: 0.0015545979840680957\n",
      "Epoch 1, Batch 5350, Loss: 0.0017458217917010188\n",
      "Epoch 1, Batch 5400, Loss: 0.0019545257091522217\n",
      "Epoch 1, Batch 5450, Loss: 0.002394902054220438\n",
      "Epoch 1, Batch 5500, Loss: 0.0021521386224776506\n",
      "Epoch 1, Batch 5550, Loss: 0.0017238056752830744\n",
      "Epoch 1, Batch 5600, Loss: 0.001375991152599454\n",
      "Epoch 1, Batch 5650, Loss: 0.0011737748282030225\n",
      "Epoch 1, Batch 5700, Loss: 0.001359161571599543\n",
      "Epoch 1, Batch 5750, Loss: 0.0010978113859891891\n",
      "Epoch 1, Batch 5800, Loss: 0.0012919461587443948\n",
      "Epoch 1, Batch 5850, Loss: 0.001253311987966299\n",
      "Epoch 1, Batch 5900, Loss: 0.0012877427507191896\n",
      "Epoch 1, Batch 5950, Loss: 0.001062234048731625\n",
      "Epoch 1, Batch 6000, Loss: 0.00200168089941144\n",
      "Epoch 1, Batch 6050, Loss: 0.001492379349656403\n",
      "Epoch 1, Batch 6100, Loss: 0.0017793788574635983\n",
      "Epoch 1, Batch 6150, Loss: 0.0013845422072336078\n",
      "Epoch 1, Batch 6200, Loss: 0.0015712084714323282\n",
      "Epoch 1, Batch 6250, Loss: 0.0011783229419961572\n",
      "Epoch 1, Batch 6300, Loss: 0.0013953496236354113\n",
      "Epoch 1, Batch 6350, Loss: 0.0016808627406135201\n",
      "Epoch 1, Batch 6400, Loss: 0.0015366824809461832\n",
      "Epoch 1, Batch 6450, Loss: 0.0015848710900172591\n",
      "Epoch 1, Batch 6500, Loss: 0.002114723902195692\n",
      "Epoch 1, Batch 6550, Loss: 0.0017006541602313519\n",
      "Epoch 1, Batch 6600, Loss: 0.0025025210343301296\n",
      "Epoch 1, Batch 6650, Loss: 0.00225676316767931\n",
      "Epoch 1, Batch 6700, Loss: 0.002352945040911436\n",
      "Epoch 1, Batch 6750, Loss: 0.0019522885559126735\n",
      "Epoch 1, Batch 6800, Loss: 0.0024234724696725607\n",
      "Epoch 1, Batch 6850, Loss: 0.0034184365067631006\n",
      "Epoch 1, Batch 6900, Loss: 0.0034425240010023117\n",
      "Epoch 1, Batch 6950, Loss: 0.004082417115569115\n",
      "Epoch 1, Batch 7000, Loss: 0.002645428292453289\n",
      "Epoch 1, Batch 7050, Loss: 0.0038672578521072865\n",
      "Epoch 1, Batch 7100, Loss: 0.002922584768384695\n",
      "Epoch 1, Batch 7150, Loss: 0.35593557357788086\n",
      "Epoch 1, Batch 7200, Loss: 0.00320671615190804\n",
      "Epoch 1, Batch 7250, Loss: 0.0021970041561871767\n",
      "Epoch 1, Batch 7300, Loss: 0.002903648419305682\n",
      "Epoch 1, Batch 7350, Loss: 0.0024154740385711193\n",
      "Epoch 1, Batch 7400, Loss: 0.0032399888150393963\n",
      "Epoch 1, Batch 7450, Loss: 0.002897838829085231\n",
      "Epoch 1, Batch 7500, Loss: 0.0020867418497800827\n",
      "Epoch 1, Batch 7550, Loss: 0.002587315160781145\n",
      "Epoch 1, Batch 7600, Loss: 0.004565829411149025\n",
      "Epoch 1, Batch 7650, Loss: 0.0037203487008810043\n",
      "Epoch 1, Batch 7700, Loss: 0.0025675781071186066\n",
      "Epoch 1, Batch 7750, Loss: 0.0028674458153545856\n",
      "Epoch 1, Batch 7800, Loss: 0.002371366135776043\n",
      "Epoch 1, Batch 7850, Loss: 0.002574313199147582\n",
      "Epoch 1, Batch 7900, Loss: 0.0024115124251693487\n",
      "Epoch 1, Batch 7950, Loss: 0.0019154070178046823\n",
      "Epoch 1, Batch 8000, Loss: 0.0015737598296254873\n",
      "Epoch 1, Batch 8050, Loss: 0.001259071403183043\n",
      "Epoch 1, Batch 8100, Loss: 0.0010025912197306752\n",
      "Epoch 1, Batch 8150, Loss: 0.0008272271370515227\n",
      "Epoch 1, Batch 8200, Loss: 0.0012798794778063893\n",
      "Epoch 1, Batch 8250, Loss: 0.002083195373415947\n",
      "Epoch 1, Batch 8300, Loss: 0.0018738156650215387\n",
      "Epoch 1, Batch 8350, Loss: 0.0014163694577291608\n",
      "Epoch 1, Batch 8400, Loss: 0.0010730582289397717\n",
      "Epoch 1, Batch 8450, Loss: 0.0013539466308429837\n",
      "Epoch 1, Batch 8500, Loss: 0.001340543502010405\n",
      "Epoch 1, Batch 8550, Loss: 0.0017095126677304506\n",
      "Epoch 1, Batch 8600, Loss: 0.0021904439199715853\n",
      "Epoch 1, Batch 8650, Loss: 0.0022280525881797075\n",
      "Epoch 1, Batch 8700, Loss: 0.0022527037654072046\n",
      "Epoch 1, Batch 8750, Loss: 0.002317735692486167\n",
      "Epoch 1, Batch 8800, Loss: 0.001888165483251214\n",
      "Epoch 1, Batch 8850, Loss: 0.0021387734450399876\n",
      "Epoch 1, Batch 8900, Loss: 0.0029176250100135803\n",
      "Epoch 1, Batch 8950, Loss: 0.0020350583363324404\n",
      "Epoch 1, Batch 9000, Loss: 0.0015751038445159793\n",
      "Epoch 1, Batch 9050, Loss: 0.3889886736869812\n",
      "Epoch 1, Batch 9100, Loss: 0.0020501401741057634\n",
      "Epoch 1, Batch 9150, Loss: 0.002048919443041086\n",
      "Epoch 1, Batch 9200, Loss: 0.0024430048651993275\n",
      "Epoch 1, Batch 9250, Loss: 0.0018438047263771296\n",
      "Epoch 1, Batch 9300, Loss: 0.0012984484201297164\n",
      "Epoch 1, Batch 9350, Loss: 0.0016270733904093504\n",
      "Epoch 1, Batch 9400, Loss: 0.002325111534446478\n",
      "Epoch 1, Batch 9450, Loss: 0.002240073634311557\n",
      "Epoch 1, Batch 9500, Loss: 0.0020121310371905565\n",
      "Epoch 1, Batch 9550, Loss: 0.0020355393644422293\n",
      "Epoch 1, Batch 9600, Loss: 0.0037583757657557726\n",
      "Epoch 1, Batch 9650, Loss: 0.003262939862906933\n",
      "Epoch 1, Batch 9700, Loss: 0.0022448133677244186\n",
      "Epoch 1, Batch 9750, Loss: 0.0019203461706638336\n",
      "Epoch 1, Batch 9800, Loss: 0.002420592587441206\n",
      "Epoch 1, Batch 9850, Loss: 0.0026646715123206377\n",
      "Epoch 1, Batch 9900, Loss: 0.0031561253126710653\n",
      "Epoch 1, Batch 9950, Loss: 0.002765203360468149\n",
      "Epoch 1, Batch 10000, Loss: 0.002269159769639373\n",
      "Epoch 1, Batch 10050, Loss: 0.0029281587339937687\n",
      "Epoch 1, Batch 10100, Loss: 0.0020111738704144955\n",
      "Epoch 1, Batch 10150, Loss: 0.0016071002464741468\n",
      "Epoch 1, Batch 10200, Loss: 0.0015004865126684308\n",
      "Epoch 1, Batch 10250, Loss: 0.001484735868871212\n",
      "Epoch 1, Batch 10300, Loss: 0.001746638328768313\n",
      "Epoch 1, Batch 10350, Loss: 0.0017860792577266693\n",
      "Epoch 1, Batch 10400, Loss: 0.0017448456492275\n",
      "Epoch 1, Batch 10450, Loss: 0.0024826654698699713\n",
      "Epoch 1, Batch 10500, Loss: 0.002085499931126833\n",
      "Epoch 1, Batch 10550, Loss: 0.0021653734147548676\n",
      "Epoch 1, Batch 10600, Loss: 0.002212146297097206\n",
      "Epoch 1, Batch 10650, Loss: 0.0018211125861853361\n",
      "Epoch 1, Batch 10700, Loss: 0.002081002574414015\n",
      "Epoch 1, Batch 10750, Loss: 0.0019088221015408635\n",
      "Epoch 1, Batch 10800, Loss: 0.003850232344120741\n",
      "Epoch 1, Batch 10850, Loss: 0.003174438141286373\n",
      "Epoch 1, Batch 10900, Loss: 0.002323400229215622\n",
      "Epoch 1, Batch 10950, Loss: 0.0023954722564667463\n",
      "Epoch 1, Batch 11000, Loss: 0.002048108959570527\n",
      "Epoch 1, Batch 11050, Loss: 0.002769858343526721\n",
      "Epoch 1, Batch 11100, Loss: 0.002170537831261754\n",
      "Epoch 1, Batch 11150, Loss: 0.0017246517818421125\n",
      "Epoch 1, Batch 11200, Loss: 0.001589187071658671\n",
      "Epoch 1, Batch 11250, Loss: 0.0016436444129794836\n",
      "Epoch 1, Batch 11300, Loss: 0.0016637209337204695\n",
      "Epoch 1, Batch 11350, Loss: 0.002115808892995119\n",
      "Epoch 1, Batch 11400, Loss: 0.0016653474885970354\n",
      "Epoch 1, Batch 11450, Loss: 0.0014488983433693647\n",
      "Epoch 1, Batch 11500, Loss: 0.001512625953182578\n",
      "Epoch 1, Batch 11550, Loss: 0.001370391109958291\n",
      "Epoch 1, Batch 11600, Loss: 0.0024225381202995777\n",
      "Epoch 1, Batch 11650, Loss: 0.0020516174845397472\n",
      "Epoch 1, Batch 11700, Loss: 0.0024821492843329906\n",
      "Epoch 1, Batch 11750, Loss: 0.0024248340632766485\n",
      "Epoch 1, Batch 11800, Loss: 0.0024268985725939274\n",
      "Epoch 1, Batch 11850, Loss: 0.0017370362766087055\n",
      "Epoch 1, Batch 11900, Loss: 0.0013877374585717916\n",
      "Epoch 1, Batch 11950, Loss: 0.0014060315443202853\n",
      "Epoch 1, Batch 12000, Loss: 0.0013088238192722201\n",
      "Epoch 1, Batch 12050, Loss: 0.0018543909536674619\n",
      "Epoch 1, Batch 12100, Loss: 0.00174627429805696\n",
      "Epoch 1, Batch 12150, Loss: 0.001957010244950652\n",
      "Epoch 1, Batch 12200, Loss: 0.0014166231267154217\n",
      "Epoch 1, Batch 12250, Loss: 0.0013546643313020468\n",
      "Epoch 1, Batch 12300, Loss: 0.0018271803855895996\n",
      "Epoch 1, Batch 12350, Loss: 0.0032227695919573307\n",
      "Epoch 1, Batch 12400, Loss: 0.0027900831773877144\n",
      "Epoch 1, Batch 12450, Loss: 0.002137520583346486\n",
      "Epoch 1, Batch 12500, Loss: 0.0020761454943567514\n",
      "Epoch 1, Batch 12550, Loss: 0.002685995539650321\n",
      "Epoch 1, Batch 12600, Loss: 0.0024928725324571133\n",
      "Epoch 1, Batch 12650, Loss: 0.002379032550379634\n",
      "Epoch 1, Batch 12700, Loss: 0.0017014702316373587\n",
      "Epoch 1, Batch 12750, Loss: 0.0020117717795073986\n",
      "Epoch 1, Batch 12800, Loss: 0.002369681606069207\n",
      "Epoch 1, Batch 12850, Loss: 0.0019365851767361164\n",
      "Epoch 1, Batch 12900, Loss: 0.0014174702810123563\n",
      "Epoch 1, Batch 12950, Loss: 0.0013302069855853915\n",
      "Epoch 1, Batch 13000, Loss: 0.0011462782276794314\n",
      "Epoch 1, Batch 13050, Loss: 0.0015990645624697208\n",
      "Epoch 1, Batch 13100, Loss: 0.0017830334836617112\n",
      "Epoch 1, Batch 13150, Loss: 0.002018833765760064\n",
      "Epoch 1, Batch 13200, Loss: 0.0018928389763459563\n",
      "Epoch 1, Batch 13250, Loss: 0.0013679912080988288\n",
      "Epoch 1, Batch 13300, Loss: 0.0012123023625463247\n",
      "Epoch 1, Batch 13350, Loss: 0.0014037317596375942\n",
      "Epoch 1, Batch 13400, Loss: 0.0011691565159708261\n",
      "Epoch 1, Batch 13450, Loss: 0.001070427242666483\n",
      "Epoch 1, Batch 13500, Loss: 0.001160788582637906\n",
      "Epoch 1, Batch 13550, Loss: 0.0014322219649329782\n",
      "Epoch 1, Batch 13600, Loss: 0.4078206419944763\n",
      "Epoch 1, Batch 13650, Loss: 0.0019050746923312545\n",
      "Epoch 1, Batch 13700, Loss: 0.0019912454299628735\n",
      "Epoch 1, Batch 13750, Loss: 0.00197876850143075\n",
      "Epoch 1, Batch 13800, Loss: 0.0014719691826030612\n",
      "Epoch 1, Batch 13850, Loss: 0.0013450037222355604\n",
      "Epoch 1, Batch 13900, Loss: 0.0011288415407761931\n",
      "Epoch 1, Batch 13950, Loss: 0.0010812327964231372\n",
      "Epoch 1, Batch 14000, Loss: 0.0013029825640842319\n",
      "Epoch 1, Batch 14050, Loss: 0.0013349690707400441\n",
      "Epoch 1, Batch 14100, Loss: 0.0014965924201533198\n",
      "Epoch 1, Batch 14150, Loss: 0.0016091844299808145\n",
      "Epoch 1, Batch 14200, Loss: 0.0015081817982718349\n",
      "Epoch 1, Batch 14250, Loss: 0.00111694959923625\n",
      "Epoch 1, Batch 14300, Loss: 0.0018111334647983313\n",
      "Epoch 1, Batch 14350, Loss: 0.002198209287598729\n",
      "Epoch 1, Batch 14400, Loss: 0.0027474944945424795\n",
      "Epoch 1, Batch 14450, Loss: 0.004152955953031778\n",
      "Epoch 1, Batch 14500, Loss: 0.0023870854638516903\n",
      "Epoch 1, Batch 14550, Loss: 0.002495809691026807\n",
      "Epoch 1, Batch 14600, Loss: 0.002395787974819541\n",
      "Epoch 1, Batch 14650, Loss: 0.0021618911996483803\n",
      "Epoch 1, Batch 14700, Loss: 0.0020871292799711227\n",
      "Epoch 1, Batch 14750, Loss: 0.0019865985959768295\n",
      "Epoch 1, Batch 14800, Loss: 0.0013916153693571687\n",
      "Epoch 1, Batch 14850, Loss: 0.0013292754301801324\n",
      "Epoch 1, Batch 14900, Loss: 0.001209528069011867\n",
      "Epoch 1, Batch 14950, Loss: 0.0010580155067145824\n",
      "Epoch 1, Batch 15000, Loss: 0.0012395805679261684\n",
      "Epoch 1, Batch 15050, Loss: 0.0011064643040299416\n",
      "Epoch 1, Batch 15100, Loss: 0.0017547419993206859\n",
      "Epoch 1, Batch 15150, Loss: 0.0020623737946152687\n",
      "Epoch 1, Batch 15200, Loss: 0.0016819763695821166\n",
      "Epoch 1, Batch 15250, Loss: 0.0015123572666198015\n",
      "Epoch 1, Batch 15300, Loss: 0.0014809041749686003\n",
      "Epoch 1, Batch 15350, Loss: 0.001695755054242909\n",
      "Epoch 1, Batch 15400, Loss: 0.0027373689226806164\n",
      "Epoch 1, Batch 15450, Loss: 0.0019305577734485269\n",
      "Epoch 1, Batch 15500, Loss: 0.0016495861345902085\n",
      "Epoch 1, Batch 15550, Loss: 0.0013392434921115637\n",
      "Epoch 1, Batch 15600, Loss: 0.0010609308956190944\n",
      "Epoch 1, Batch 15650, Loss: 0.0012594740837812424\n",
      "Epoch 1, Batch 15700, Loss: 0.0010792742250487208\n",
      "Epoch 1, Batch 15750, Loss: 0.0011783251538872719\n",
      "Epoch 1, Batch 15800, Loss: 0.0009835663950070739\n",
      "Epoch 1, Batch 15850, Loss: 0.00087695789989084\n",
      "Epoch 1, Batch 15900, Loss: 0.0007515078177675605\n",
      "Epoch 1, Batch 15950, Loss: 0.0006760070100426674\n",
      "Epoch 1, Batch 16000, Loss: 0.0015615660231560469\n",
      "Epoch 1, Batch 16050, Loss: 0.0015204160008579493\n",
      "Epoch 1, Batch 16100, Loss: 0.001387858297675848\n",
      "Epoch 1, Batch 16150, Loss: 0.0018801266560330987\n",
      "Epoch 1, Batch 16200, Loss: 0.002774858148768544\n",
      "Epoch 1, Batch 16250, Loss: 0.0019362730672582984\n",
      "Epoch 1, Batch 16300, Loss: 0.0020504638087004423\n",
      "Epoch 1, Batch 16350, Loss: 0.001955027226358652\n",
      "Epoch 1, Batch 16400, Loss: 0.0021192997228354216\n",
      "Epoch 1, Batch 16450, Loss: 0.0014721495099365711\n",
      "Epoch 1, Batch 16500, Loss: 0.0015605126973241568\n",
      "Epoch 1, Batch 16550, Loss: 0.0017499420791864395\n",
      "Epoch 1, Batch 16600, Loss: 0.002330812392756343\n",
      "Epoch 1, Batch 16650, Loss: 0.0028482635971158743\n",
      "Epoch 1, Batch 16700, Loss: 0.00267545017413795\n",
      "Epoch 1, Batch 16750, Loss: 0.0031390846706926823\n",
      "Epoch 1, Batch 16800, Loss: 0.0019175217021256685\n",
      "Epoch 1, Batch 16850, Loss: 0.0019600249361246824\n",
      "Epoch 1, Batch 16900, Loss: 0.0018341424874961376\n",
      "Epoch 1, Batch 16950, Loss: 0.001705729286186397\n",
      "Epoch 1, Batch 17000, Loss: 0.0016233051428571343\n",
      "Epoch 1, Batch 17050, Loss: 0.0013851383700966835\n",
      "Epoch 1, Batch 17100, Loss: 0.001454408629797399\n",
      "Epoch 1, Batch 17150, Loss: 0.0016903127543628216\n",
      "Epoch 1, Batch 17200, Loss: 0.0018265192629769444\n",
      "Epoch 1, Batch 17250, Loss: 0.00221604248508811\n",
      "Epoch 1, Batch 17300, Loss: 0.0019423195626586676\n",
      "Epoch 1, Batch 17350, Loss: 0.0016266258899122477\n",
      "Epoch 1, Batch 17400, Loss: 0.0021663657389581203\n",
      "Epoch 1, Batch 17450, Loss: 0.36154788732528687\n",
      "Epoch 1, Batch 17500, Loss: 0.0030721283983439207\n",
      "Epoch 1, Batch 17550, Loss: 0.003191685304045677\n",
      "Epoch 1, Batch 17600, Loss: 0.0028855951968580484\n",
      "Epoch 1, Batch 17650, Loss: 0.0020664650946855545\n",
      "Epoch 1, Batch 17700, Loss: 0.001990433083847165\n",
      "Epoch 1, Batch 17750, Loss: 0.0016475282609462738\n",
      "Epoch 1, Batch 17800, Loss: 0.0014148104237392545\n",
      "Epoch 1, Batch 17850, Loss: 0.0023520339746028185\n",
      "Epoch 1, Batch 17900, Loss: 0.0019098432967439294\n",
      "Epoch 1, Batch 17950, Loss: 0.001949166995473206\n",
      "Epoch 1, Batch 18000, Loss: 0.00174021627753973\n",
      "Epoch 1, Batch 18050, Loss: 0.0027836549561470747\n",
      "Epoch 1, Batch 18100, Loss: 0.0022959106136113405\n",
      "Epoch 1, Batch 18150, Loss: 0.0021971967071294785\n",
      "Epoch 1, Batch 18200, Loss: 0.00425324821844697\n",
      "Epoch 1, Batch 18250, Loss: 0.0034005206543952227\n",
      "Epoch 1, Batch 18300, Loss: 0.0038552216719835997\n",
      "Epoch 1, Batch 18350, Loss: 0.0031446656212210655\n",
      "Epoch 1, Batch 18400, Loss: 0.003671575104817748\n",
      "Epoch 1, Batch 18450, Loss: 0.0022365637123584747\n",
      "Epoch 1, Batch 18500, Loss: 0.001829837798140943\n",
      "Epoch 1, Batch 18550, Loss: 0.00201338529586792\n",
      "Epoch 1, Batch 18600, Loss: 0.0038582608103752136\n",
      "Epoch 1, Batch 18650, Loss: 0.00260996725410223\n",
      "Epoch 1, Batch 18700, Loss: 0.002237586537376046\n",
      "Epoch 1, Batch 18750, Loss: 0.0029716144781559706\n",
      "Epoch 1, Batch 18800, Loss: 0.0026314686983823776\n",
      "Epoch 1, Batch 18850, Loss: 0.0024016904644668102\n",
      "Epoch 1, Batch 18900, Loss: 0.003169282106682658\n",
      "Epoch 1, Batch 18950, Loss: 0.0030806283466517925\n",
      "Epoch 1, Batch 19000, Loss: 0.0021687860134989023\n",
      "Epoch 1, Batch 19050, Loss: 0.002722381614148617\n",
      "Epoch 1, Batch 19100, Loss: 0.0024226128589361906\n",
      "Epoch 1, Batch 19150, Loss: 0.002716027433052659\n",
      "Epoch 1, Batch 19200, Loss: 0.003196811769157648\n",
      "Epoch 1, Batch 19250, Loss: 0.0024338257499039173\n",
      "Epoch 1, Batch 19300, Loss: 0.0020931456238031387\n",
      "Epoch 1, Batch 19350, Loss: 0.0021636318415403366\n",
      "Epoch 1, Batch 19400, Loss: 0.0024286031257361174\n",
      "Epoch 1, Batch 19450, Loss: 0.0025240040849894285\n",
      "Epoch 1, Batch 19500, Loss: 0.38321948051452637\n",
      "Epoch 1, Batch 19550, Loss: 0.0021268015261739492\n",
      "Epoch 1, Batch 19600, Loss: 0.0013924603117629886\n",
      "Epoch 1, Batch 19650, Loss: 0.0015888502821326256\n",
      "Epoch 1, Batch 19700, Loss: 0.002377789933234453\n",
      "Epoch 1, Batch 19750, Loss: 0.002100745216012001\n",
      "Epoch 1, Batch 19800, Loss: 0.0015229718992486596\n",
      "Epoch 1, Batch 19850, Loss: 0.0013521242653951049\n",
      "Epoch 1, Batch 19900, Loss: 0.0017274805577471852\n",
      "Epoch 1, Batch 19950, Loss: 0.0012159449979662895\n",
      "Epoch 1, Batch 20000, Loss: 0.0011167412158101797\n",
      "Epoch 1, Batch 20050, Loss: 0.001737996470183134\n",
      "Epoch 1, Batch 20100, Loss: 0.002194075146690011\n",
      "Epoch 1, Batch 20150, Loss: 0.003331615589559078\n",
      "Epoch 1, Batch 20200, Loss: 0.001796833355911076\n",
      "Epoch 1, Batch 20250, Loss: 0.002183014526963234\n",
      "Epoch 1, Batch 20300, Loss: 0.0039571598172187805\n",
      "Epoch 1, Batch 20350, Loss: 0.0028826019261032343\n",
      "Epoch 1, Batch 20400, Loss: 0.002717158757150173\n",
      "Epoch 1, Batch 20450, Loss: 0.001909460173919797\n",
      "Epoch 1, Batch 20500, Loss: 0.0023867797572165728\n",
      "Epoch 1, Batch 20550, Loss: 0.0027700213249772787\n",
      "Epoch 1, Batch 20600, Loss: 0.0023097610101103783\n",
      "Epoch 1, Batch 20650, Loss: 0.0022737670224159956\n",
      "Epoch 1, Batch 20700, Loss: 0.0017240504967048764\n",
      "Epoch 1, Batch 20750, Loss: 0.002116294577717781\n",
      "Epoch 1, Batch 20800, Loss: 0.0020666595082730055\n",
      "Epoch 1, Batch 20850, Loss: 0.001821722835302353\n",
      "Epoch 1, Batch 20900, Loss: 0.001214496442116797\n",
      "Epoch 1, Batch 20950, Loss: 0.0014459633966907859\n",
      "Epoch 1, Batch 21000, Loss: 0.0020740025211125612\n",
      "Epoch 1, Batch 21050, Loss: 0.0016854117857292295\n",
      "Epoch 1, Batch 21100, Loss: 0.002171326894313097\n",
      "Epoch 1, Batch 21150, Loss: 0.0025312858633697033\n",
      "Epoch 1, Batch 21200, Loss: 0.3731640875339508\n",
      "Epoch 1, Batch 21250, Loss: 0.003010610118508339\n",
      "Epoch 1, Batch 21300, Loss: 0.0023816805332899094\n",
      "Epoch 1, Batch 21350, Loss: 0.0023271432146430016\n",
      "Epoch 1, Batch 21400, Loss: 0.001855952781625092\n",
      "Epoch 1, Batch 21450, Loss: 0.0019030319526791573\n",
      "Epoch 1, Batch 21500, Loss: 0.002115389797836542\n",
      "Epoch 1, Batch 21550, Loss: 0.0033482592552900314\n",
      "Epoch 1, Batch 21600, Loss: 0.0021072307135909796\n",
      "Epoch 1, Batch 21650, Loss: 0.0015844119479879737\n",
      "Epoch 1, Batch 21700, Loss: 0.0012204245431348681\n",
      "Epoch 1, Batch 21750, Loss: 0.001484474167227745\n",
      "Epoch 1, Batch 21800, Loss: 0.0017369122942909598\n",
      "Epoch 1, Batch 21850, Loss: 0.0026392529252916574\n",
      "Epoch 1, Batch 21900, Loss: 0.0027867157477885485\n",
      "Epoch 1, Batch 21950, Loss: 0.0029276711866259575\n",
      "Epoch 1, Batch 22000, Loss: 0.397977739572525\n",
      "Epoch 1, Batch 22050, Loss: 0.005571227055042982\n",
      "Epoch 1, Batch 22100, Loss: 0.0031530093401670456\n",
      "Epoch 1, Batch 22150, Loss: 0.32582584023475647\n",
      "Epoch 1, Batch 22200, Loss: 0.00482119619846344\n",
      "Epoch 1, Batch 22250, Loss: 0.003546949243173003\n",
      "Epoch 1, Batch 22300, Loss: 0.003318542381748557\n",
      "Epoch 1, Batch 22350, Loss: 0.0023830546997487545\n",
      "Epoch 1, Batch 22400, Loss: 0.0017993799410760403\n",
      "Epoch 1, Batch 22450, Loss: 0.0028710237238556147\n",
      "Epoch 1, Batch 22500, Loss: 0.002753255655989051\n",
      "Epoch 1, Batch 22550, Loss: 0.0030842714477330446\n",
      "Epoch 1, Batch 22600, Loss: 0.003013534704223275\n",
      "Epoch 1, Batch 22650, Loss: 0.0028370169457048178\n",
      "Epoch 1, Batch 22700, Loss: 0.0028578497003763914\n",
      "Epoch 1, Batch 22750, Loss: 0.00325207132846117\n",
      "Epoch 1, Batch 22800, Loss: 0.003887736704200506\n",
      "Epoch 1, Batch 22850, Loss: 0.003165930276736617\n",
      "Epoch 1, Batch 22900, Loss: 0.0029724931810051203\n",
      "Epoch 1, Batch 22950, Loss: 0.0025542788207530975\n",
      "Epoch 1, Batch 23000, Loss: 0.0022496874444186687\n",
      "Epoch 1, Batch 23050, Loss: 0.002497804816812277\n",
      "Epoch 1, Batch 23100, Loss: 0.0024226210080087185\n",
      "Epoch 1, Batch 23150, Loss: 0.00198940047994256\n",
      "Epoch 1, Batch 23200, Loss: 0.0018682880327105522\n",
      "Epoch 1, Batch 23250, Loss: 0.0016679762629792094\n",
      "Epoch 1, Batch 23300, Loss: 0.0024811977054923773\n",
      "Epoch 1, Batch 23350, Loss: 0.0028688039164990187\n",
      "Epoch 1, Batch 23400, Loss: 0.0022808965295553207\n",
      "Epoch 1, Batch 23450, Loss: 0.0022323871962726116\n",
      "Epoch 1, Batch 23500, Loss: 0.36393237113952637\n",
      "Epoch 1, Batch 23550, Loss: 0.004379219375550747\n",
      "Epoch 1, Batch 23600, Loss: 0.003627213416621089\n",
      "Epoch 1, Batch 23650, Loss: 0.00421025650575757\n",
      "Epoch 1, Batch 23700, Loss: 0.37686529755592346\n",
      "Epoch 1, Batch 23750, Loss: 0.0024343247059732676\n",
      "Epoch 1, Batch 23800, Loss: 0.002085217507556081\n",
      "Epoch 1, Batch 23850, Loss: 0.0021988863591104746\n",
      "Epoch 1, Batch 23900, Loss: 0.001686704228632152\n",
      "Epoch 1, Batch 23950, Loss: 0.36801573634147644\n",
      "Epoch 1, Batch 24000, Loss: 0.0025143478997051716\n",
      "Epoch 1, Batch 24050, Loss: 0.002072688424959779\n",
      "Epoch 1, Batch 24100, Loss: 0.00238200556486845\n",
      "Epoch 1, Batch 24150, Loss: 0.002315242076292634\n",
      "Epoch 1, Batch 24200, Loss: 0.0020414323080331087\n",
      "Epoch 1, Batch 24250, Loss: 0.0020180344581604004\n",
      "Epoch 1, Batch 24300, Loss: 0.0018057288834825158\n",
      "Epoch 1, Batch 24350, Loss: 0.0020351156126707792\n",
      "Epoch 1, Batch 24400, Loss: 0.0021354437340050936\n",
      "Epoch 1, Batch 24450, Loss: 0.002764337696135044\n",
      "Epoch 1, Batch 24500, Loss: 0.002313287928700447\n",
      "Epoch 1, Batch 24550, Loss: 0.0016268568579107523\n",
      "Epoch 1, Batch 24600, Loss: 0.0011930655455216765\n",
      "Epoch 1, Batch 24650, Loss: 0.0010913388105109334\n",
      "Epoch 1, Batch 24700, Loss: 0.001317235641181469\n",
      "Epoch 1, Batch 24750, Loss: 0.0010191949550062418\n",
      "Epoch 1, Batch 24800, Loss: 0.001239950768649578\n",
      "Epoch 1, Batch 24850, Loss: 0.0014002477983012795\n",
      "Epoch 1, Batch 24900, Loss: 0.0013559329090639949\n",
      "Epoch 1, Batch 24950, Loss: 0.0012510169763118029\n",
      "Epoch 1, Batch 25000, Loss: 0.0011169126955792308\n",
      "Epoch 1, Batch 25050, Loss: 0.001564502832479775\n",
      "Epoch 1, Batch 25100, Loss: 0.001954426523298025\n",
      "Epoch 1, Batch 25150, Loss: 0.0013705181190744042\n",
      "Epoch 1, Batch 25200, Loss: 0.0012090741656720638\n",
      "Epoch 1, Batch 25250, Loss: 0.0016290599014610052\n",
      "Epoch 1, Batch 25300, Loss: 0.0018194566946476698\n",
      "Epoch 1, Batch 25350, Loss: 0.0019017963204532862\n",
      "Epoch 1, Batch 25400, Loss: 0.0021235274616628885\n",
      "Epoch 1, Batch 25450, Loss: 0.002368961228057742\n",
      "Epoch 1, Batch 25500, Loss: 0.3272528350353241\n",
      "Epoch 1, Batch 25550, Loss: 0.0032402602955698967\n",
      "Epoch 1, Batch 25600, Loss: 0.004023364279419184\n",
      "Epoch 1, Batch 25650, Loss: 0.003017776645720005\n",
      "Epoch 1, Batch 25700, Loss: 0.002008815761655569\n",
      "Epoch 1, Batch 25750, Loss: 0.001700992346741259\n",
      "Epoch 1, Batch 25800, Loss: 0.0024840140249580145\n",
      "Epoch 1, Batch 25850, Loss: 0.0025252485647797585\n",
      "Epoch 1, Batch 25900, Loss: 0.002383195562288165\n",
      "Epoch 1, Batch 25950, Loss: 0.0016467191744595766\n",
      "Epoch 1, Batch 26000, Loss: 0.0013291577342897654\n",
      "Epoch 1, Batch 26050, Loss: 0.0010176401119679213\n",
      "Epoch 1, Batch 26100, Loss: 0.0013099561911076307\n",
      "Epoch 1, Batch 26150, Loss: 0.0017505055293440819\n",
      "Epoch 1, Batch 26200, Loss: 0.4291761517524719\n",
      "Epoch 1, Batch 26250, Loss: 0.0011693743290379643\n",
      "Epoch 1, Batch 26300, Loss: 0.0017305080546066165\n",
      "Epoch 1, Batch 26350, Loss: 0.0032379559706896544\n",
      "Epoch 1, Batch 26400, Loss: 0.003541615093126893\n",
      "Epoch 1, Batch 26450, Loss: 0.002905137138441205\n",
      "Epoch 1, Batch 26500, Loss: 0.0023748355451971292\n",
      "Epoch 1, Batch 26550, Loss: 0.0016901686321943998\n",
      "Epoch 1, Batch 26600, Loss: 0.0014864143449813128\n",
      "Epoch 1, Batch 26650, Loss: 0.0014902390539646149\n",
      "Epoch 1, Batch 26700, Loss: 0.0015736372442916036\n",
      "Epoch 1, Batch 26750, Loss: 0.0019266073359176517\n",
      "Epoch 1, Batch 26800, Loss: 0.0023308638483285904\n",
      "Epoch 1, Batch 26850, Loss: 0.0035588331520557404\n",
      "Epoch 1, Batch 26900, Loss: 0.0031949791591614485\n",
      "Epoch 1, Batch 26950, Loss: 0.007086101919412613\n",
      "Epoch 1, Batch 27000, Loss: 0.006120381876826286\n",
      "Epoch 1, Batch 27050, Loss: 0.004417619202286005\n",
      "Epoch 1, Batch 27100, Loss: 0.004491780884563923\n",
      "Epoch 1, Batch 27150, Loss: 0.0031741454731673002\n",
      "Epoch 1, Batch 27200, Loss: 0.00272138393484056\n",
      "Epoch 1, Batch 27250, Loss: 0.002757719252258539\n",
      "Epoch 1, Batch 27300, Loss: 0.0020481625106185675\n",
      "Epoch 1, Batch 27350, Loss: 0.003020885167643428\n",
      "Epoch 1, Batch 27400, Loss: 0.002293302910402417\n",
      "Epoch 1, Batch 27450, Loss: 0.001638886984437704\n",
      "Epoch 1, Batch 27500, Loss: 0.0014705262146890163\n",
      "Epoch 1, Batch 27550, Loss: 0.0017784030642360449\n",
      "Epoch 1, Batch 27600, Loss: 0.002453337889164686\n",
      "Epoch 1, Batch 27650, Loss: 0.0027545946650207043\n",
      "Epoch 1, Batch 27700, Loss: 0.002898701000958681\n",
      "Epoch 1, Batch 27750, Loss: 0.0026481703389436007\n",
      "Epoch 1, Batch 27800, Loss: 0.0021265442483127117\n",
      "Epoch 1, Batch 27850, Loss: 0.00281919096596539\n",
      "Epoch 1, Batch 27900, Loss: 0.3526814579963684\n",
      "Epoch 1, Batch 27950, Loss: 0.0031579516362398863\n",
      "Epoch 1, Batch 28000, Loss: 0.0018610259285196662\n",
      "Epoch 1, Batch 28050, Loss: 0.0014325992669910192\n",
      "Epoch 1, Batch 28100, Loss: 0.0014145515160635114\n",
      "Epoch 1, Batch 28150, Loss: 0.0018122573383152485\n",
      "Epoch 1, Batch 28200, Loss: 0.001725969836115837\n",
      "Epoch 1, Batch 28250, Loss: 0.0015100212767720222\n",
      "Epoch 1, Batch 28300, Loss: 0.0013843171764165163\n",
      "Epoch 1, Batch 28350, Loss: 0.0015201414935290813\n",
      "Epoch 1, Batch 28400, Loss: 0.0011495767394080758\n",
      "Epoch 1, Batch 28450, Loss: 0.002890409668907523\n",
      "Epoch 1, Batch 28500, Loss: 0.0030125845223665237\n",
      "Epoch 1, Batch 28550, Loss: 0.0035322383046150208\n",
      "Epoch 1, Batch 28600, Loss: 0.002255347091704607\n",
      "Epoch 1, Batch 28650, Loss: 0.0020573833025991917\n",
      "Epoch 1, Batch 28700, Loss: 0.40394318103790283\n",
      "Epoch 1, Batch 28750, Loss: 0.002263938542455435\n",
      "Epoch 1, Batch 28800, Loss: 0.0017858677310869098\n",
      "Epoch 1, Batch 28850, Loss: 0.0018148686503991485\n",
      "Epoch 1, Batch 28900, Loss: 0.0017247593495994806\n",
      "Epoch 1, Batch 28950, Loss: 0.0015216374304145575\n",
      "Epoch 1, Batch 29000, Loss: 0.392166405916214\n",
      "Epoch 1, Batch 29050, Loss: 0.0021097136195749044\n",
      "Epoch 1, Batch 29100, Loss: 0.0022499116603285074\n",
      "Epoch 1, Batch 29150, Loss: 0.001958461944013834\n",
      "Epoch 1, Batch 29200, Loss: 0.0022388207726180553\n",
      "Epoch 1, Batch 29250, Loss: 0.002717740833759308\n",
      "Epoch 1, Batch 29300, Loss: 0.00162201514467597\n",
      "Epoch 1, Batch 29350, Loss: 0.002053407719358802\n",
      "Epoch 1, Batch 29400, Loss: 0.002055928809568286\n",
      "Epoch 1, Batch 29450, Loss: 0.0013104520039632916\n",
      "Epoch 1, Batch 29500, Loss: 0.0012298738583922386\n",
      "Epoch 1, Batch 29550, Loss: 0.0013172925682738423\n",
      "Epoch 1, Batch 29600, Loss: 0.0014206708874553442\n",
      "Epoch 1, Batch 29650, Loss: 0.0019426696235314012\n",
      "Epoch 1, Batch 29700, Loss: 0.001957993721589446\n",
      "Epoch 1, Batch 29750, Loss: 0.0021392153576016426\n",
      "Epoch 1, Batch 29800, Loss: 0.37108245491981506\n",
      "Epoch 1, Batch 29850, Loss: 0.0017902577528730035\n",
      "Epoch 1, Batch 29900, Loss: 0.0019194164779037237\n",
      "Epoch 1, Batch 29950, Loss: 0.001752746175043285\n",
      "Epoch 1, Batch 30000, Loss: 0.002389571163803339\n",
      "Epoch 1, Batch 30050, Loss: 0.002359652193263173\n",
      "Epoch 1, Batch 30100, Loss: 0.0020933900959789753\n",
      "Epoch 1, Batch 30150, Loss: 0.0024742342066019773\n",
      "Epoch 1, Batch 30200, Loss: 0.002807000419124961\n",
      "Epoch 1, Batch 30250, Loss: 0.0017311214469373226\n",
      "Epoch 1, Batch 30300, Loss: 0.00243971636518836\n",
      "Epoch 1, Batch 30350, Loss: 0.0016735497629269958\n",
      "Epoch 1, Batch 30400, Loss: 0.0025218017399311066\n",
      "Epoch 1, Batch 30450, Loss: 0.38848400115966797\n",
      "Epoch 1, Batch 30500, Loss: 0.0037003287579864264\n",
      "Epoch 1, Batch 30550, Loss: 0.0024735990446060896\n",
      "Epoch 1, Batch 30600, Loss: 0.002837824635207653\n",
      "Epoch 1, Batch 30650, Loss: 0.002201910363510251\n",
      "Epoch 1, Batch 30700, Loss: 0.0017258849693462253\n",
      "Epoch 1, Batch 30750, Loss: 0.0020362234208732843\n",
      "Epoch 1, Batch 30800, Loss: 0.001667230506427586\n",
      "Epoch 1, Batch 30850, Loss: 0.0014563254080712795\n",
      "Epoch 1, Batch 30900, Loss: 0.0015217688633129\n",
      "Epoch 1, Batch 30950, Loss: 0.0012175011215731502\n",
      "Epoch 1, Batch 31000, Loss: 0.002119851065799594\n",
      "Epoch 1, Batch 31050, Loss: 0.003039376577362418\n",
      "Epoch 1, Batch 31100, Loss: 0.002250756835564971\n",
      "Epoch 1, Batch 31150, Loss: 0.001728614210151136\n",
      "Epoch 1, Batch 31200, Loss: 0.002148901578038931\n",
      "Epoch 1, Batch 31250, Loss: 0.003343133023008704\n",
      "Epoch 1, Batch 31300, Loss: 0.002517189597710967\n",
      "Epoch 1, Batch 31350, Loss: 0.0025059953331947327\n",
      "Epoch 1, Batch 31400, Loss: 0.002029426395893097\n",
      "Epoch 1, Batch 31450, Loss: 0.002193209482356906\n",
      "Epoch 1, Batch 31500, Loss: 0.0017766279634088278\n",
      "Epoch 1, Batch 31550, Loss: 0.002013328718021512\n",
      "Epoch 1, Batch 31600, Loss: 0.0029425048269331455\n",
      "Epoch 1, Batch 31650, Loss: 0.002340379636734724\n",
      "Epoch 1, Batch 31700, Loss: 0.0022786776535212994\n",
      "Epoch 1, Batch 31750, Loss: 0.0018334508640691638\n",
      "Epoch 1, Batch 31800, Loss: 0.39550548791885376\n",
      "Epoch 1, Batch 31850, Loss: 0.0023651958908885717\n",
      "Epoch 1, Batch 31900, Loss: 0.002265459857881069\n",
      "Epoch 1, Batch 31950, Loss: 0.0031431210227310658\n",
      "Epoch 1, Batch 32000, Loss: 0.003463669214397669\n",
      "Epoch 1, Batch 32050, Loss: 0.0034253632184118032\n",
      "Epoch 1, Batch 32100, Loss: 0.0026497046928852797\n",
      "Epoch 1, Batch 32150, Loss: 0.003328730119392276\n",
      "Epoch 1, Batch 32200, Loss: 0.004232830833643675\n",
      "Epoch 1, Batch 32250, Loss: 0.003321145661175251\n",
      "Epoch 1, Batch 32300, Loss: 0.002915751188993454\n",
      "Epoch 1, Batch 32350, Loss: 0.002987300744280219\n",
      "Epoch 1, Batch 32400, Loss: 0.001718713203445077\n",
      "Epoch 1, Batch 32450, Loss: 0.0017180454451590776\n",
      "Epoch 1, Batch 32500, Loss: 0.002019444014877081\n",
      "Epoch 1, Batch 32550, Loss: 0.0024568773806095123\n",
      "Epoch 1, Batch 32600, Loss: 0.0023877699859440327\n",
      "Epoch 1, Batch 32650, Loss: 0.002200466115027666\n",
      "Epoch 1, Batch 32700, Loss: 0.001524273306131363\n",
      "Epoch 1, Batch 32750, Loss: 0.0013338050339370966\n",
      "Epoch 1, Batch 32800, Loss: 0.42909562587738037\n",
      "Epoch 1, Batch 32850, Loss: 0.002124158199876547\n",
      "Epoch 1, Batch 32900, Loss: 0.0017400130163878202\n",
      "Epoch 1, Batch 32950, Loss: 0.0011907393345609307\n",
      "Epoch 1, Batch 33000, Loss: 0.0012957174330949783\n",
      "Epoch 1, Batch 33050, Loss: 0.0018586735241115093\n",
      "Epoch 1, Batch 33100, Loss: 0.41480752825737\n",
      "Epoch 1, Batch 33150, Loss: 0.0018805725267156959\n",
      "Epoch 1, Batch 33200, Loss: 0.0018957402789965272\n",
      "Epoch 1, Batch 33250, Loss: 0.0014194714603945613\n",
      "Epoch 1, Batch 33300, Loss: 0.0010912823490798473\n",
      "Epoch 1, Batch 33350, Loss: 0.0010698584374040365\n",
      "Epoch 1, Batch 33400, Loss: 0.0011200057342648506\n",
      "Epoch 1, Batch 33450, Loss: 0.0010789697989821434\n",
      "Epoch 1, Batch 33500, Loss: 0.0018494524993002415\n",
      "Epoch 1, Batch 33550, Loss: 0.002854434307664633\n",
      "Epoch 1, Batch 33600, Loss: 0.0029789956752210855\n",
      "Epoch 1, Batch 33650, Loss: 0.0025313752703368664\n",
      "Epoch 1, Batch 33700, Loss: 0.0030095779802650213\n",
      "Epoch 1, Batch 33750, Loss: 0.003636020701378584\n",
      "Epoch 1, Batch 33800, Loss: 0.0029291794635355473\n",
      "Epoch 1, Batch 33850, Loss: 0.002902683336287737\n",
      "Epoch 1, Batch 33900, Loss: 0.0029447046108543873\n",
      "Epoch 1, Batch 33950, Loss: 0.0027584906201809645\n",
      "Epoch 1, Batch 34000, Loss: 0.0028472612611949444\n",
      "Epoch 1, Batch 34050, Loss: 0.0024477129336446524\n",
      "Epoch 1, Batch 34100, Loss: 0.0021515560802072287\n",
      "Epoch 1, Batch 34150, Loss: 0.0016791349044069648\n",
      "Epoch 1, Batch 34200, Loss: 0.0013706638710573316\n",
      "Epoch 1, Batch 34250, Loss: 0.0026270579546689987\n",
      "Epoch 1, Batch 34300, Loss: 0.003401164896786213\n",
      "Epoch 1, Batch 34350, Loss: 0.0023343218490481377\n",
      "Epoch 1, Batch 34400, Loss: 0.003153179306536913\n",
      "Epoch 1, Batch 34450, Loss: 0.0020908904261887074\n",
      "Epoch 1, Batch 34500, Loss: 0.0021475476678460836\n",
      "Epoch 1, Batch 34550, Loss: 0.002231351565569639\n",
      "Epoch 1, Batch 34600, Loss: 0.0018719928339123726\n",
      "Epoch 1, Batch 34650, Loss: 0.0016744676977396011\n",
      "Epoch 1, Batch 34700, Loss: 0.0015659444034099579\n",
      "Epoch 1, Batch 34750, Loss: 0.0023331320844590664\n",
      "Epoch 1, Batch 34800, Loss: 0.001586100086569786\n",
      "Epoch 1, Batch 34850, Loss: 0.0013800951419398189\n",
      "Epoch 1, Batch 34900, Loss: 0.0013971534790471196\n",
      "Epoch 1, Batch 34950, Loss: 0.0015488119097426534\n",
      "Epoch 1, Batch 35000, Loss: 0.00136905862018466\n",
      "Epoch 1, Batch 35050, Loss: 0.0013041944475844502\n",
      "Epoch 1, Batch 35100, Loss: 0.0011528566246852279\n",
      "Epoch 1, Batch 35150, Loss: 0.0015944334445521235\n",
      "Epoch 1, Batch 35200, Loss: 0.0018372955964878201\n",
      "Epoch 1, Batch 35250, Loss: 0.0012991182738915086\n",
      "Epoch 1, Batch 35300, Loss: 0.41928791999816895\n",
      "Epoch 1, Batch 35350, Loss: 0.00121030630543828\n",
      "Epoch 1, Batch 35400, Loss: 0.42606523633003235\n",
      "Epoch 1, Batch 35450, Loss: 0.001786110457032919\n",
      "Epoch 1, Batch 35500, Loss: 0.0016485367668792605\n",
      "Epoch 1, Batch 35550, Loss: 0.0019581469241529703\n",
      "Epoch 1, Batch 35600, Loss: 0.0014128689654171467\n",
      "Epoch 1, Batch 35650, Loss: 0.0010597131913527846\n",
      "Epoch 1, Batch 35700, Loss: 0.0013952042208984494\n",
      "Epoch 1, Batch 35750, Loss: 0.0020502982661128044\n",
      "Epoch 1, Batch 35800, Loss: 0.0019440952455624938\n",
      "Epoch 1, Batch 35850, Loss: 0.001611887477338314\n",
      "Epoch 1, Batch 35900, Loss: 0.0015666871331632137\n",
      "Epoch 1, Batch 35950, Loss: 0.001768867252394557\n",
      "Epoch 1, Batch 36000, Loss: 0.0025725080631673336\n",
      "Epoch 1, Batch 36050, Loss: 0.002020623767748475\n",
      "Epoch 1, Batch 36100, Loss: 0.0018876786343753338\n",
      "Epoch 1, Batch 36150, Loss: 0.0016533838352188468\n",
      "Epoch 1, Batch 36200, Loss: 0.0021811628248542547\n",
      "Epoch 1, Batch 36250, Loss: 0.002649835078045726\n",
      "Epoch 1, Batch 36300, Loss: 0.0021669254638254642\n",
      "Epoch 1, Batch 36350, Loss: 0.0020076900254935026\n",
      "Epoch 1, Batch 36400, Loss: 0.002566187409684062\n",
      "Epoch 1, Batch 36450, Loss: 0.0020644005853682756\n",
      "Epoch 1, Batch 36500, Loss: 0.0039000995457172394\n",
      "Epoch 1, Batch 36550, Loss: 0.0032309298403561115\n",
      "Epoch 1, Batch 36600, Loss: 0.0024294324684888124\n",
      "Epoch 1, Batch 36650, Loss: 0.0018044435419142246\n",
      "Epoch 1, Batch 36700, Loss: 0.0019614160992205143\n",
      "Epoch 1, Batch 36750, Loss: 0.002718508243560791\n",
      "Epoch 1, Batch 36800, Loss: 0.001783418352715671\n",
      "Epoch 1, Batch 36850, Loss: 0.0019188693258911371\n",
      "Epoch 1, Batch 36900, Loss: 0.0016428582603111863\n",
      "Epoch 1, Batch 36950, Loss: 0.0017931610345840454\n",
      "Epoch 1, Batch 37000, Loss: 0.0016395417042076588\n",
      "Epoch 1, Batch 37050, Loss: 0.001422989647835493\n",
      "Epoch 1, Batch 37100, Loss: 0.0015951599925756454\n",
      "Epoch 1, Batch 37150, Loss: 0.001152724027633667\n",
      "Epoch 1, Batch 37200, Loss: 0.0012681713560596108\n",
      "Epoch 1, Batch 37250, Loss: 0.0020263849291950464\n",
      "Epoch 1, Batch 37300, Loss: 0.0025984388776123524\n",
      "Epoch 1, Batch 37350, Loss: 0.0024731664452701807\n",
      "Epoch 1, Batch 37400, Loss: 0.0018842490389943123\n",
      "Epoch 1, Batch 37450, Loss: 0.0016330957878381014\n",
      "Epoch 1, Batch 37500, Loss: 0.0009997327579185367\n",
      "Epoch 1, Batch 37550, Loss: 0.0011633228277787566\n",
      "Epoch 1, Batch 37600, Loss: 0.0017936438089236617\n",
      "Epoch 1, Batch 37650, Loss: 0.0016660388791933656\n",
      "Epoch 1, Batch 37700, Loss: 0.003141961060464382\n",
      "Epoch 1, Batch 37750, Loss: 0.0020297777373343706\n",
      "Epoch 1, Batch 37800, Loss: 0.350496768951416\n",
      "Epoch 1, Batch 37850, Loss: 0.003604569938033819\n",
      "Epoch 1, Batch 37900, Loss: 0.0023639292921870947\n",
      "Epoch 1, Batch 37950, Loss: 0.001989210257306695\n",
      "Epoch 1, Batch 38000, Loss: 0.0018048739293590188\n",
      "Epoch 1, Batch 38050, Loss: 0.0017311910632997751\n",
      "Epoch 1, Batch 38100, Loss: 0.0029212264344096184\n",
      "Epoch 1, Batch 38150, Loss: 0.003636143868789077\n",
      "Epoch 1, Batch 38200, Loss: 0.0022224360145628452\n",
      "Epoch 1, Batch 38250, Loss: 0.001896982779726386\n",
      "Epoch 1, Batch 38300, Loss: 0.0015418080147355795\n",
      "Epoch 1, Batch 38350, Loss: 0.001736265025101602\n",
      "Epoch 1, Batch 38400, Loss: 0.001734985038638115\n",
      "Epoch 1, Batch 38450, Loss: 0.0025007331278175116\n",
      "Epoch 1, Batch 38500, Loss: 0.003942047245800495\n",
      "Epoch 1, Batch 38550, Loss: 0.002254343358799815\n",
      "Epoch 1, Batch 38600, Loss: 0.0015896270051598549\n",
      "Epoch 1, Batch 38650, Loss: 0.0015861710999161005\n",
      "Epoch 1, Batch 38700, Loss: 0.0014250280801206827\n",
      "Epoch 1, Batch 38750, Loss: 0.0024201252963393927\n",
      "Epoch 1, Batch 38800, Loss: 0.0025876241270452738\n",
      "Epoch 1, Batch 38850, Loss: 0.0031202235259115696\n",
      "Epoch 1, Batch 38900, Loss: 0.002420657780021429\n",
      "Epoch 1, Batch 38950, Loss: 0.0027598950546234846\n",
      "Epoch 1, Batch 39000, Loss: 0.0022408519871532917\n",
      "Epoch 1, Batch 39050, Loss: 0.002021088032051921\n",
      "Epoch 1, Batch 39100, Loss: 0.001956491731107235\n",
      "Epoch 1, Batch 39150, Loss: 0.001670785597525537\n",
      "Epoch 1, Batch 39200, Loss: 0.0017564741428941488\n",
      "Epoch 1, Batch 39250, Loss: 0.0015040576690807939\n",
      "Epoch 1, Batch 39300, Loss: 0.002899732207879424\n",
      "Epoch 1, Batch 39350, Loss: 0.0022263096179813147\n",
      "Epoch 1, Batch 39400, Loss: 0.0017712436383590102\n",
      "Epoch 1, Batch 39450, Loss: 0.0017234069528058171\n",
      "Epoch 1, Batch 39500, Loss: 0.0027272214647382498\n",
      "Epoch 1, Batch 39550, Loss: 0.003326485864818096\n",
      "Epoch 1, Batch 39600, Loss: 0.004298078361898661\n",
      "Epoch 1, Batch 39650, Loss: 0.0037886076606810093\n",
      "Epoch 1, Batch 39700, Loss: 0.002605657558888197\n",
      "Epoch 1, Batch 39750, Loss: 0.003596787340939045\n",
      "Epoch 1, Batch 39800, Loss: 0.0038449352141469717\n",
      "Epoch 1, Batch 39850, Loss: 0.0025554352905601263\n",
      "Epoch 1, Batch 39900, Loss: 0.002709820168092847\n",
      "Epoch 1, Batch 39950, Loss: 0.0035477650817483664\n",
      "Epoch 1, Batch 40000, Loss: 0.0028600601945072412\n",
      "Epoch 1, Batch 40050, Loss: 0.00407314533367753\n",
      "Epoch 1, Batch 40100, Loss: 0.0027409784961491823\n",
      "Epoch 1, Batch 40150, Loss: 0.0029560872353613377\n",
      "Epoch 1, Batch 40200, Loss: 0.002995629794895649\n",
      "Epoch 1, Batch 40250, Loss: 0.0031771231442689896\n",
      "Epoch 1, Batch 40300, Loss: 0.0020380623172968626\n",
      "Epoch 1, Batch 40350, Loss: 0.4113122224807739\n",
      "Epoch 1, Batch 40400, Loss: 0.3962654173374176\n",
      "Epoch 1, Batch 40450, Loss: 0.002650528447702527\n",
      "Epoch 1, Batch 40500, Loss: 0.001859690877608955\n",
      "Epoch 1, Batch 40550, Loss: 0.0022704869043082\n",
      "Epoch 1, Batch 40600, Loss: 0.0022678636014461517\n",
      "Epoch 1, Batch 40650, Loss: 0.002018723404034972\n",
      "Epoch 1, Batch 40700, Loss: 0.0017910576425492764\n",
      "Epoch 1, Batch 40750, Loss: 0.001825530081987381\n",
      "Epoch 1, Batch 40800, Loss: 0.0026841629296541214\n",
      "Epoch 1, Batch 40850, Loss: 0.00258562876842916\n",
      "Epoch 1, Batch 40900, Loss: 0.002135707065463066\n",
      "Epoch 1, Batch 40950, Loss: 0.0030575997661799192\n",
      "Epoch 1, Batch 41000, Loss: 0.003088048193603754\n",
      "Epoch 1, Batch 41050, Loss: 0.0023519156966358423\n",
      "Epoch 1, Batch 41100, Loss: 0.0017852497985586524\n",
      "Epoch 1, Batch 41150, Loss: 0.003110624849796295\n",
      "Epoch 1, Batch 41200, Loss: 0.003927757032215595\n",
      "Epoch 1, Batch 41250, Loss: 0.0033450701739639044\n",
      "Epoch 1, Batch 41300, Loss: 0.002998837735503912\n",
      "Epoch 1, Batch 41350, Loss: 0.002886948874220252\n",
      "Epoch 1, Batch 41400, Loss: 0.0037404214963316917\n",
      "Epoch 1, Batch 41450, Loss: 0.0026463656686246395\n",
      "Epoch 1, Batch 41500, Loss: 0.0031389789655804634\n",
      "Epoch 1, Batch 41550, Loss: 0.002000676468014717\n",
      "Epoch 1, Batch 41600, Loss: 0.0017439813818782568\n",
      "Epoch 1, Batch 41650, Loss: 0.0015755972126498818\n",
      "Epoch 1, Batch 41700, Loss: 0.0016201791586354375\n",
      "Epoch 1, Batch 41750, Loss: 0.0015915834810584784\n",
      "Epoch 1, Batch 41800, Loss: 0.0011406036792322993\n",
      "Epoch 1, Batch 41850, Loss: 0.0012332568876445293\n",
      "Epoch 1, Batch 41900, Loss: 0.001141514745540917\n",
      "Epoch 1, Batch 41950, Loss: 0.0016112150624394417\n",
      "Epoch 1, Batch 42000, Loss: 0.0016025063814595342\n",
      "Epoch 1, Batch 42050, Loss: 0.0019208495505154133\n",
      "Epoch 1, Batch 42100, Loss: 0.001930955913849175\n",
      "Epoch 1, Batch 42150, Loss: 0.0014961601700633764\n",
      "Epoch 1, Batch 42200, Loss: 0.3954373300075531\n",
      "Epoch 1, Batch 42250, Loss: 0.0031029116362333298\n",
      "Epoch 1, Batch 42300, Loss: 0.001921897055581212\n",
      "Epoch 1, Batch 42350, Loss: 0.00510672340169549\n",
      "Epoch 1, Batch 42400, Loss: 0.0037914870772510767\n",
      "Epoch 1, Batch 42450, Loss: 0.0030123433098196983\n",
      "Epoch 1, Batch 42500, Loss: 0.0027490619104355574\n",
      "Epoch 1, Batch 42550, Loss: 0.0027933702804148197\n",
      "Epoch 1, Batch 42600, Loss: 0.002675351221114397\n",
      "Epoch 1, Batch 42650, Loss: 0.0025684998836368322\n",
      "Epoch 1, Batch 42700, Loss: 0.002477844012901187\n",
      "Epoch 1, Batch 42750, Loss: 0.0026681330054998398\n",
      "Epoch 1, Batch 42800, Loss: 0.002568997675552964\n",
      "Epoch 1, Batch 42850, Loss: 0.3678171932697296\n",
      "Epoch 1, Batch 42900, Loss: 0.0022312540095299482\n",
      "Epoch 1, Batch 42950, Loss: 0.0017830233555287123\n",
      "Epoch 1, Batch 43000, Loss: 0.0017917758086696267\n",
      "Epoch 1, Batch 43050, Loss: 0.39155182242393494\n",
      "Epoch 1, Batch 43100, Loss: 0.36015066504478455\n",
      "Epoch 1, Batch 43150, Loss: 0.0026274435222148895\n",
      "Epoch 1, Batch 43200, Loss: 0.0028046690858900547\n",
      "Epoch 1, Batch 43250, Loss: 0.0033928495831787586\n",
      "Epoch 1, Batch 43300, Loss: 0.0025017031002789736\n",
      "Epoch 1, Batch 43350, Loss: 0.0018929282668977976\n",
      "Epoch 1, Batch 43400, Loss: 0.003423515474423766\n",
      "Epoch 1, Batch 43450, Loss: 0.0035773133859038353\n",
      "Epoch 1, Batch 43500, Loss: 0.0027580291498452425\n",
      "Epoch 1, Batch 43550, Loss: 0.0025609140284359455\n",
      "Epoch 1, Batch 43600, Loss: 0.0020732951816171408\n",
      "Epoch 1, Batch 43650, Loss: 0.3898893892765045\n",
      "Epoch 1, Batch 43700, Loss: 0.0026306742802262306\n",
      "Epoch 1, Batch 43750, Loss: 0.0021329689770936966\n",
      "Epoch 1, Batch 43800, Loss: 0.002483999589458108\n",
      "Epoch 1, Batch 43850, Loss: 0.001870251726359129\n",
      "Epoch 1, Batch 43900, Loss: 0.001269372645765543\n",
      "Epoch 1, Batch 43950, Loss: 0.0013409031089395285\n",
      "Epoch 1, Batch 44000, Loss: 0.0016163010150194168\n",
      "Epoch 1, Batch 44050, Loss: 0.0018378224922344089\n",
      "Epoch 1, Batch 44100, Loss: 0.0018075763946399093\n",
      "Epoch 1, Batch 44150, Loss: 0.0017284805653616786\n",
      "Epoch 1, Batch 44200, Loss: 0.0015825347509235144\n",
      "Epoch 1, Batch 44250, Loss: 0.0019423606572672725\n",
      "Epoch 1, Batch 44300, Loss: 0.0015202418435364962\n",
      "Epoch 1, Batch 44350, Loss: 0.0019897897727787495\n",
      "Epoch 1, Batch 44400, Loss: 0.001418468775227666\n",
      "Epoch 1, Batch 44450, Loss: 0.0020488137379288673\n",
      "Epoch 1, Batch 44500, Loss: 0.42322784662246704\n",
      "Epoch 1, Batch 44550, Loss: 0.0017959489487111568\n",
      "Epoch 1, Batch 44600, Loss: 0.0018651620484888554\n",
      "Epoch 1, Batch 44650, Loss: 0.0024496959522366524\n",
      "Epoch 1, Batch 44700, Loss: 0.0019288032781332731\n",
      "Epoch 1, Batch 44750, Loss: 0.0015685961116105318\n",
      "Epoch 1, Batch 44800, Loss: 0.0013977746712043881\n",
      "Epoch 1, Batch 44850, Loss: 0.001488740905188024\n",
      "Epoch 1, Batch 44900, Loss: 0.0015941980527713895\n",
      "Epoch 1, Batch 44950, Loss: 0.0018373709172010422\n",
      "Epoch 1, Batch 45000, Loss: 0.40132445096969604\n",
      "Epoch 1, Batch 45050, Loss: 0.0025706528685986996\n",
      "Epoch 1, Batch 45100, Loss: 0.0024238729383796453\n",
      "Epoch 1, Batch 45150, Loss: 0.0028892478439956903\n",
      "Epoch 1, Batch 45200, Loss: 0.003935074433684349\n",
      "Epoch 1, Batch 45250, Loss: 0.003038211027160287\n",
      "Epoch 1, Batch 45300, Loss: 0.003059073118492961\n",
      "Epoch 1, Batch 45350, Loss: 0.002472715452313423\n",
      "Epoch 1, Batch 45400, Loss: 0.002319161081686616\n",
      "Epoch 1, Batch 45450, Loss: 0.002490311861038208\n",
      "Epoch 1, Batch 45500, Loss: 0.0018763972911983728\n",
      "Epoch 1, Batch 45550, Loss: 0.0021318683866411448\n",
      "Epoch 1, Batch 45600, Loss: 0.002215269021689892\n",
      "Epoch 1, Batch 45650, Loss: 0.0020391757134348154\n",
      "Epoch 1, Batch 45700, Loss: 0.0013190957251936197\n",
      "Epoch 1, Batch 45750, Loss: 0.0011220071464776993\n",
      "Epoch 1, Batch 45800, Loss: 0.0009623278165236115\n",
      "Epoch 1, Batch 45850, Loss: 0.0009514487464912236\n",
      "Epoch 1, Batch 45900, Loss: 0.0012870995560660958\n",
      "Epoch 1, Batch 45950, Loss: 0.0012859830167144537\n",
      "Epoch 1, Batch 46000, Loss: 0.0010755856055766344\n",
      "Epoch 1, Batch 46050, Loss: 0.0009362830314785242\n",
      "Epoch 1, Batch 46100, Loss: 0.00119296635966748\n",
      "Epoch 1, Batch 46150, Loss: 0.00156977993901819\n",
      "Epoch 1, Batch 46200, Loss: 0.0021771397441625595\n",
      "Epoch 1, Batch 46250, Loss: 0.0017068261513486505\n",
      "Epoch 1, Batch 46300, Loss: 0.0012611286947503686\n",
      "Epoch 1, Batch 46350, Loss: 0.0015606634551659226\n",
      "Epoch 1, Batch 46400, Loss: 0.001877611968666315\n",
      "Epoch 1, Batch 46450, Loss: 0.0023946184664964676\n",
      "Epoch 1, Batch 46500, Loss: 0.002620581304654479\n",
      "Epoch 1, Batch 46550, Loss: 0.0038126884028315544\n",
      "Epoch 1, Batch 46600, Loss: 0.36764824390411377\n",
      "Epoch 1, Batch 46650, Loss: 0.0037074112333357334\n",
      "Epoch 1, Batch 46700, Loss: 0.0024248044937849045\n",
      "Epoch 1, Batch 46750, Loss: 0.0020556459203362465\n",
      "Epoch 1, Batch 46800, Loss: 0.0014700285391882062\n",
      "Epoch 1, Batch 46850, Loss: 0.0020927689038217068\n",
      "Epoch 1, Batch 46900, Loss: 0.0018758766818791628\n",
      "Epoch 1, Batch 46950, Loss: 0.002196056768298149\n",
      "Epoch 1, Batch 47000, Loss: 0.00206355401314795\n",
      "Epoch 1, Batch 47050, Loss: 0.0018278536153957248\n",
      "Epoch 1, Batch 47100, Loss: 0.002215492306277156\n",
      "Epoch 1, Batch 47150, Loss: 0.001621738774701953\n",
      "Epoch 1, Batch 47200, Loss: 0.0015875049866735935\n",
      "Epoch 1, Batch 47250, Loss: 0.0015132746193557978\n",
      "Epoch 1, Batch 47300, Loss: 0.001830046996474266\n",
      "Epoch 1, Batch 47350, Loss: 0.0035560387186706066\n",
      "Epoch 1, Batch 47400, Loss: 0.003867071121931076\n",
      "Epoch 1, Batch 47450, Loss: 0.003368319710716605\n",
      "Epoch 1, Batch 47500, Loss: 0.004213433247059584\n",
      "Epoch 1, Batch 47550, Loss: 0.0027562014292925596\n",
      "Epoch 1, Batch 47600, Loss: 0.0027020806446671486\n",
      "Epoch 1, Batch 47650, Loss: 0.0023307716473937035\n",
      "Epoch 1, Batch 47700, Loss: 0.0016219462268054485\n",
      "Epoch 1, Batch 47750, Loss: 0.0019397980067878962\n",
      "Epoch 1, Batch 47800, Loss: 0.00331769697368145\n",
      "Epoch 1, Batch 47850, Loss: 0.00216792244464159\n",
      "Epoch 1, Batch 47900, Loss: 0.0028859779704362154\n",
      "Epoch 1, Batch 47950, Loss: 0.002652502153068781\n",
      "Epoch 1, Batch 48000, Loss: 0.0029226436745375395\n",
      "Epoch 1, Batch 48050, Loss: 0.0024156589061021805\n",
      "Epoch 1, Batch 48100, Loss: 0.002087324159219861\n",
      "Epoch 1, Batch 48150, Loss: 0.0018617906607687473\n",
      "Epoch 1, Batch 48200, Loss: 0.0033393646590411663\n",
      "Epoch 1, Batch 48250, Loss: 0.003190096002072096\n",
      "Epoch 1, Batch 48300, Loss: 0.003059731563553214\n",
      "Epoch 1, Batch 48350, Loss: 0.0024362087715417147\n",
      "Epoch 1, Batch 48400, Loss: 0.002660654950886965\n",
      "Epoch 1, Batch 48450, Loss: 0.003923468757420778\n",
      "Epoch 1, Batch 48500, Loss: 0.003323598997667432\n",
      "Epoch 1, Batch 48550, Loss: 0.006773908622562885\n",
      "Epoch 1, Batch 48600, Loss: 0.003869246458634734\n",
      "Epoch 1, Batch 48650, Loss: 0.0026429055724292994\n",
      "Epoch 1, Batch 48700, Loss: 0.0021594869904220104\n",
      "Epoch 1, Batch 48750, Loss: 0.0015975574497133493\n",
      "Epoch 1, Batch 48800, Loss: 0.003912738524377346\n",
      "Epoch 1, Batch 48850, Loss: 0.003282253397628665\n",
      "Epoch 1, Batch 48900, Loss: 0.0039631980471313\n",
      "Epoch 1, Batch 48950, Loss: 0.004414471331983805\n",
      "Epoch 1, Batch 49000, Loss: 0.004241009708493948\n",
      "Epoch 1, Batch 49050, Loss: 0.003152829362079501\n",
      "Epoch 1, Batch 49100, Loss: 0.0037347760517150164\n",
      "Epoch 1, Batch 49150, Loss: 0.002742149867117405\n",
      "Epoch 1, Batch 49200, Loss: 0.0019804337061941624\n",
      "Epoch 1, Batch 49250, Loss: 0.002703104168176651\n",
      "Epoch 1, Batch 49300, Loss: 0.0022289766930043697\n",
      "Epoch 1, Batch 49350, Loss: 0.0016298361588269472\n",
      "Epoch 1, Batch 49400, Loss: 0.0015642197104170918\n",
      "Epoch 1, Batch 49450, Loss: 0.0014372861478477716\n",
      "Epoch 1, Batch 49500, Loss: 0.0011615398107096553\n",
      "Epoch 1, Batch 49550, Loss: 0.0014687995426356792\n",
      "Epoch 1, Batch 49600, Loss: 0.0016789577202871442\n",
      "Epoch 1, Batch 49650, Loss: 0.0014473446644842625\n",
      "Epoch 1, Batch 49700, Loss: 0.0015202461509034038\n",
      "Epoch 1, Batch 49750, Loss: 0.002088542329147458\n",
      "Epoch 1, Batch 49800, Loss: 0.0014820349169895053\n",
      "Epoch 1, Batch 49850, Loss: 0.002703149104490876\n",
      "Epoch 1, Batch 49900, Loss: 0.0022323124576359987\n",
      "Epoch 1, Batch 49950, Loss: 0.00316159357316792\n",
      "Epoch 1, Batch 50000, Loss: 0.0026852628216147423\n",
      "Epoch 1, Batch 50050, Loss: 0.0033905196469277143\n",
      "Epoch 1, Batch 50100, Loss: 0.0033963352907449007\n",
      "Epoch 1, Batch 50150, Loss: 0.004154558293521404\n",
      "Epoch 1, Batch 50200, Loss: 0.002825403120368719\n",
      "Epoch 1, Batch 50250, Loss: 0.002315278397873044\n",
      "Epoch 1, Batch 50300, Loss: 0.002198997884988785\n",
      "Epoch 1, Batch 50350, Loss: 0.0017618159763514996\n",
      "Epoch 1, Batch 50400, Loss: 0.002325509674847126\n",
      "Epoch 1, Batch 50450, Loss: 0.0022073942236602306\n",
      "Epoch 1, Batch 50500, Loss: 0.00197625276632607\n",
      "Epoch 1, Batch 50550, Loss: 0.002617459511384368\n",
      "Epoch 1, Batch 50600, Loss: 0.0022646526340395212\n",
      "Epoch 1, Batch 50650, Loss: 0.002205074531957507\n",
      "Epoch 1, Batch 50700, Loss: 0.002874134574085474\n",
      "Epoch 1, Batch 50750, Loss: 0.0028123431839048862\n",
      "Epoch 1, Batch 50800, Loss: 0.0020263062324374914\n",
      "Epoch 1, Batch 50850, Loss: 0.0019636156503111124\n",
      "Epoch 1, Batch 50900, Loss: 0.0026446778792887926\n",
      "Epoch 1, Batch 50950, Loss: 0.002427341416478157\n",
      "Epoch 1, Batch 51000, Loss: 0.0020117454696446657\n",
      "Epoch 1, Batch 51050, Loss: 0.0022179263178259134\n",
      "Epoch 1, Batch 51100, Loss: 0.3758324086666107\n",
      "Epoch 1, Batch 51150, Loss: 0.0018484097672626376\n",
      "Epoch 1, Batch 51200, Loss: 0.0018540655728429556\n",
      "Epoch 1, Batch 51250, Loss: 0.0017739171162247658\n",
      "Epoch 1, Batch 51300, Loss: 0.0017546025337651372\n",
      "Epoch 1, Batch 51350, Loss: 0.0016351738013327122\n",
      "Epoch 1, Batch 51400, Loss: 0.00131951121147722\n",
      "Epoch 1, Batch 51450, Loss: 0.0011243139160797\n",
      "Epoch 1, Batch 51500, Loss: 0.0012409328483045101\n",
      "Epoch 1, Batch 51550, Loss: 0.0011955255176872015\n",
      "Epoch 1, Batch 51600, Loss: 0.0016750656068325043\n",
      "Epoch 1, Batch 51650, Loss: 0.0014769018162041903\n",
      "Epoch 1, Batch 51700, Loss: 0.0010778105352073908\n",
      "Epoch 1, Batch 51750, Loss: 0.0013712779618799686\n",
      "Epoch 1, Batch 51800, Loss: 0.40940913558006287\n",
      "Epoch 1, Batch 51850, Loss: 0.0014039215166121721\n",
      "Epoch 1, Batch 51900, Loss: 0.0014379826607182622\n",
      "Epoch 1, Batch 51950, Loss: 0.0014880747767165303\n",
      "Epoch 1, Batch 52000, Loss: 0.0016057800967246294\n",
      "Epoch 1, Batch 52050, Loss: 0.0014620943693444133\n",
      "Epoch 1, Batch 52100, Loss: 0.002293934114277363\n",
      "Epoch 1, Batch 52150, Loss: 0.0021979832090437412\n",
      "Epoch 1, Batch 52200, Loss: 0.001591736450791359\n",
      "Epoch 1, Batch 52250, Loss: 0.0017574772937223315\n",
      "Epoch 1, Batch 52300, Loss: 0.001759215141646564\n",
      "Epoch 1, Batch 52350, Loss: 0.0016502485377714038\n",
      "Epoch 1, Batch 52400, Loss: 0.0012218045303598046\n",
      "Epoch 1, Batch 52450, Loss: 0.0011086870217695832\n",
      "Epoch 1, Batch 52500, Loss: 0.001140057691372931\n",
      "Epoch 1, Batch 52550, Loss: 0.0011296669254079461\n",
      "Epoch 1, Batch 52600, Loss: 0.0019081272184848785\n",
      "Epoch 1, Batch 52650, Loss: 0.0017173929372802377\n",
      "Epoch 1, Batch 52700, Loss: 0.0020057011861354113\n",
      "Epoch 1, Batch 52750, Loss: 0.0020393747836351395\n",
      "Epoch 1, Batch 52800, Loss: 0.0018193715950474143\n",
      "Epoch 1, Batch 52850, Loss: 0.0013980051735416055\n",
      "Epoch 1, Batch 52900, Loss: 0.0010333519894629717\n",
      "Epoch 1, Batch 52950, Loss: 0.0019042090279981494\n",
      "Epoch 1, Batch 53000, Loss: 0.001778414472937584\n",
      "Epoch 1, Batch 53050, Loss: 0.002009582007303834\n",
      "Epoch 1, Batch 53100, Loss: 0.0026356319431215525\n",
      "Epoch 1, Batch 53150, Loss: 0.0025280897971242666\n",
      "Epoch 1, Batch 53200, Loss: 0.0028142174705863\n",
      "Epoch 1, Batch 53250, Loss: 0.002134930342435837\n",
      "Epoch 1, Batch 53300, Loss: 0.0014806172112002969\n",
      "Epoch 1, Batch 53350, Loss: 0.001468004658818245\n",
      "Epoch 1, Batch 53400, Loss: 0.0014178393175825477\n",
      "Epoch 1, Batch 53450, Loss: 0.0031934035941958427\n",
      "Epoch 1, Batch 53500, Loss: 0.003098449669778347\n",
      "Epoch 1, Batch 53550, Loss: 0.0032066863495856524\n",
      "Epoch 1, Batch 53600, Loss: 0.003855695715174079\n",
      "Epoch 1, Batch 53650, Loss: 0.003289051353931427\n",
      "Epoch 1, Batch 53700, Loss: 0.002083973027765751\n",
      "Epoch 1, Batch 53750, Loss: 0.0019513122970238328\n",
      "Epoch 1, Batch 53800, Loss: 0.0023605297319591045\n",
      "Epoch 1, Batch 53850, Loss: 0.0016186960274353623\n",
      "Epoch 1, Batch 53900, Loss: 0.0016890587285161018\n",
      "Epoch 1, Batch 53950, Loss: 0.0013963067904114723\n",
      "Epoch 1, Batch 54000, Loss: 0.0013288059271872044\n",
      "Epoch 1, Batch 54050, Loss: 0.001459020539186895\n",
      "Epoch 1, Batch 54100, Loss: 0.0016613242914900184\n",
      "Epoch 1, Batch 54150, Loss: 0.0025822436437010765\n",
      "Epoch 1, Batch 54200, Loss: 0.0018447431502863765\n",
      "Epoch 1, Batch 54250, Loss: 0.002253614366054535\n",
      "Epoch 1, Batch 54300, Loss: 0.00472502363845706\n",
      "Epoch 1, Batch 54350, Loss: 0.002873086603358388\n",
      "Epoch 1, Batch 54400, Loss: 0.002908650552853942\n",
      "Epoch 1, Batch 54450, Loss: 0.002157997339963913\n",
      "Epoch 1, Batch 54500, Loss: 0.0014798527117818594\n",
      "Epoch 1, Batch 54550, Loss: 0.0016095961909741163\n",
      "Epoch 1, Batch 54600, Loss: 0.0020084448624402285\n",
      "Epoch 1, Batch 54650, Loss: 0.002007005736231804\n",
      "Epoch 1, Batch 54700, Loss: 0.003380811307579279\n",
      "Epoch 1, Batch 54750, Loss: 0.004649769980460405\n",
      "Epoch 1, Batch 54800, Loss: 0.002418041229248047\n",
      "Epoch 1, Batch 54850, Loss: 0.001774400006979704\n",
      "Epoch 1, Batch 54900, Loss: 0.0020706879440695047\n",
      "Epoch 1, Batch 54950, Loss: 0.001761739724315703\n",
      "Epoch 1, Batch 55000, Loss: 0.001817925600335002\n",
      "Epoch 1, Batch 55050, Loss: 0.002689527813345194\n",
      "Epoch 1, Batch 55100, Loss: 0.0026419879868626595\n",
      "Epoch 1, Batch 55150, Loss: 0.001949836383573711\n",
      "Epoch 1, Batch 55200, Loss: 0.002018926665186882\n",
      "Epoch 1, Batch 55250, Loss: 0.0020202123560011387\n",
      "Epoch 1, Batch 55300, Loss: 0.001740443054586649\n",
      "Epoch 1, Batch 55350, Loss: 0.0026966219302266836\n",
      "Epoch 1, Batch 55400, Loss: 0.0018899550195783377\n",
      "Epoch 1, Batch 55450, Loss: 0.0018092177342623472\n",
      "Epoch 1, Batch 55500, Loss: 0.002523487200960517\n",
      "Epoch 1, Batch 55550, Loss: 0.002393039409071207\n",
      "Epoch 1, Batch 55600, Loss: 0.002468518679961562\n",
      "Epoch 1, Batch 55650, Loss: 0.0021718915086239576\n",
      "Epoch 1, Batch 55700, Loss: 0.0017406947445124388\n",
      "Epoch 1, Batch 55750, Loss: 0.001542187063023448\n",
      "Epoch 1, Batch 55800, Loss: 0.0018539043376222253\n",
      "Epoch 1, Batch 55850, Loss: 0.0019623127300292253\n",
      "Epoch 1, Batch 55900, Loss: 0.0021665398962795734\n",
      "Epoch 1, Batch 55950, Loss: 0.0024044772144407034\n",
      "Epoch 1, Batch 56000, Loss: 0.0019049659604206681\n",
      "Epoch 1, Batch 56050, Loss: 0.0028722439892590046\n",
      "Epoch 1, Batch 56100, Loss: 0.002985541708767414\n",
      "Epoch 1, Batch 56150, Loss: 0.002401001052930951\n",
      "Epoch 1, Batch 56200, Loss: 0.003042826894670725\n",
      "Epoch 1, Batch 56250, Loss: 0.0022722401190549135\n",
      "Epoch 1, Batch 56300, Loss: 0.0016336635453626513\n",
      "Epoch 1, Batch 56350, Loss: 0.0020726011134684086\n",
      "Epoch 1, Batch 56400, Loss: 0.002133962232619524\n",
      "Epoch 1, Batch 56450, Loss: 0.0015789367025718093\n",
      "Epoch 1, Batch 56500, Loss: 0.002070746850222349\n",
      "Epoch 1, Batch 56550, Loss: 0.0023104026913642883\n",
      "Epoch 1, Batch 56600, Loss: 0.002627546899020672\n",
      "Epoch 1, Batch 56650, Loss: 0.0020855297334492207\n",
      "Epoch 1, Batch 56700, Loss: 0.0024067724589258432\n",
      "Epoch 1, Batch 56750, Loss: 0.0021456896793097258\n",
      "Epoch 1, Batch 56800, Loss: 0.0019409264205023646\n",
      "Epoch 1, Batch 56850, Loss: 0.0017329836264252663\n",
      "Epoch 1, Batch 56900, Loss: 0.0013459721812978387\n",
      "Epoch 1, Batch 56950, Loss: 0.0010245249141007662\n",
      "Epoch 1, Batch 57000, Loss: 0.0008795955218374729\n",
      "Epoch 1, Batch 57050, Loss: 0.0008684952044859529\n",
      "Epoch 1, Batch 57100, Loss: 0.0011554539669305086\n",
      "Epoch 1, Batch 57150, Loss: 0.3834201395511627\n",
      "Epoch 1, Batch 57200, Loss: 0.001385358045808971\n",
      "Epoch 1, Batch 57250, Loss: 0.0013965293765068054\n",
      "Epoch 1, Batch 57300, Loss: 0.0017341679194942117\n",
      "Epoch 1, Batch 57350, Loss: 0.002296475926414132\n",
      "Epoch 1, Batch 57400, Loss: 0.0020279393065720797\n",
      "Epoch 1, Batch 57450, Loss: 0.0023294228594750166\n",
      "Epoch 1, Batch 57500, Loss: 0.0035004031378775835\n",
      "Epoch 1, Batch 57550, Loss: 0.3962894380092621\n",
      "Epoch 1, Batch 57600, Loss: 0.0027242160867899656\n",
      "Epoch 1, Batch 57650, Loss: 0.0022811286617070436\n",
      "Epoch 1, Batch 57700, Loss: 0.0016591812018305063\n",
      "Epoch 1, Batch 57750, Loss: 0.002304263412952423\n",
      "Epoch 1, Batch 57800, Loss: 0.0016272104112431407\n",
      "Epoch 1, Batch 57850, Loss: 0.0015806208830326796\n",
      "Epoch 1, Batch 57900, Loss: 0.001302628661505878\n",
      "Epoch 1, Batch 57950, Loss: 0.001615743967704475\n",
      "Epoch 1, Batch 58000, Loss: 0.0017318599857389927\n",
      "Epoch 1, Batch 58050, Loss: 0.0019403627375140786\n",
      "Epoch 1, Batch 58100, Loss: 0.002367326756939292\n",
      "Epoch 1, Batch 58150, Loss: 0.0024412290658801794\n",
      "Epoch 1, Batch 58200, Loss: 0.002034274162724614\n",
      "Epoch 1, Batch 58250, Loss: 0.001542199868708849\n",
      "Epoch 1, Batch 58300, Loss: 0.001497231307439506\n",
      "Epoch 1, Batch 58350, Loss: 0.0012720241211354733\n",
      "Epoch 1, Batch 58400, Loss: 0.0010852760169655085\n",
      "Epoch 1, Batch 58450, Loss: 0.0008573279483243823\n",
      "Epoch 1, Batch 58500, Loss: 0.0013143873075023293\n",
      "Epoch 1, Batch 58550, Loss: 0.0009123119525611401\n",
      "Epoch 1, Batch 58600, Loss: 0.0013884254731237888\n",
      "Epoch 1, Batch 58650, Loss: 0.0015300504164770246\n",
      "Epoch 1, Batch 58700, Loss: 0.002362096682190895\n",
      "Epoch 1, Batch 58750, Loss: 0.0018384028226137161\n",
      "Epoch 1, Batch 58800, Loss: 0.0014421319356188178\n",
      "Epoch 1, Batch 58850, Loss: 0.0018629094120115042\n",
      "Epoch 1, Batch 58900, Loss: 0.0019207665463909507\n",
      "Epoch 1, Batch 58950, Loss: 0.0019633984193205833\n",
      "Epoch 1, Batch 59000, Loss: 0.0020206919871270657\n",
      "Epoch 1, Batch 59050, Loss: 0.0016808906802907586\n",
      "Epoch 1, Batch 59100, Loss: 0.0027459454722702503\n",
      "Epoch 1, Batch 59150, Loss: 0.002139062387868762\n",
      "Epoch 1, Batch 59200, Loss: 0.0015732767060399055\n",
      "Epoch 1, Batch 59250, Loss: 0.0016750507056713104\n",
      "Epoch 1, Batch 59300, Loss: 0.002206573262810707\n",
      "Epoch 1, Batch 59350, Loss: 0.003753544995561242\n",
      "Epoch 1, Batch 59400, Loss: 0.002073870273306966\n",
      "Epoch 1, Batch 59450, Loss: 0.002087460597977042\n",
      "Epoch 1, Batch 59500, Loss: 0.0018661776557564735\n",
      "Epoch 1, Batch 59550, Loss: 0.0018141912296414375\n",
      "Epoch 1, Batch 59600, Loss: 0.002967383246868849\n",
      "Epoch 1, Batch 59650, Loss: 0.0023221357259899378\n",
      "Epoch 1, Batch 59700, Loss: 0.0022002907935529947\n",
      "Epoch 1, Batch 59750, Loss: 0.002657983684912324\n",
      "Epoch 1, Batch 59800, Loss: 0.0016902117058634758\n",
      "Epoch 1, Batch 59850, Loss: 0.0018991040997207165\n",
      "Epoch 1, Batch 59900, Loss: 0.002481338568031788\n",
      "Epoch 1, Batch 59950, Loss: 0.0024569586385041475\n",
      "Epoch 1, Batch 60000, Loss: 0.0029870595317333937\n",
      "Epoch 1, Batch 60050, Loss: 0.001931150909513235\n",
      "Epoch 1, Batch 60100, Loss: 0.0018545760540291667\n",
      "Epoch 1, Batch 60150, Loss: 0.0016071479767560959\n",
      "Epoch 1, Batch 60200, Loss: 0.0012832906795665622\n",
      "Epoch 1, Batch 60250, Loss: 0.002590952441096306\n",
      "Epoch 1, Batch 60300, Loss: 0.0024634567089378834\n",
      "Epoch 1, Batch 60350, Loss: 0.0018949097720906138\n",
      "Epoch 1, Batch 60400, Loss: 0.0016770416405051947\n",
      "Epoch 1, Batch 60450, Loss: 0.0016190113965421915\n",
      "Epoch 1, Batch 60500, Loss: 0.0017549742478877306\n",
      "Epoch 1, Batch 60550, Loss: 0.0013784820912405849\n",
      "Epoch 1, Batch 60600, Loss: 0.001484737149439752\n",
      "Epoch 1, Batch 60650, Loss: 0.0014925291761755943\n",
      "Epoch 1, Batch 60700, Loss: 0.002055490156635642\n",
      "Epoch 1, Batch 60750, Loss: 0.0018649609992280602\n",
      "Epoch 1, Batch 60800, Loss: 0.0017298008315265179\n",
      "Epoch 1, Batch 60850, Loss: 0.0012311358004808426\n",
      "Epoch 1, Batch 60900, Loss: 0.0009940136224031448\n",
      "Epoch 1, Batch 60950, Loss: 0.0011252769036218524\n",
      "Epoch 1, Batch 61000, Loss: 0.0014106535818427801\n",
      "Epoch 1, Batch 61050, Loss: 0.0013488715048879385\n",
      "Epoch 1, Batch 61100, Loss: 0.0024882208090275526\n",
      "Epoch 1, Batch 61150, Loss: 0.0017526213778182864\n",
      "Epoch 1, Batch 61200, Loss: 0.0036403739359229803\n",
      "Epoch 1, Batch 61250, Loss: 0.0027769063599407673\n",
      "Epoch 1, Batch 61300, Loss: 0.0023648343048989773\n",
      "Epoch 1, Batch 61350, Loss: 0.0022192674223333597\n",
      "Epoch 1, Batch 61400, Loss: 0.0021925410255789757\n",
      "Epoch 1, Batch 61450, Loss: 0.002111362759023905\n",
      "Epoch 1, Batch 61500, Loss: 0.0023420597426593304\n",
      "Epoch 1, Batch 61550, Loss: 0.0017877579666674137\n",
      "Epoch 1, Batch 61600, Loss: 0.002690140623599291\n",
      "Epoch 1, Batch 61650, Loss: 0.0018468258203938603\n",
      "Epoch 1, Batch 61700, Loss: 0.0015881082508713007\n",
      "Epoch 1, Batch 61750, Loss: 0.0016940273344516754\n",
      "Epoch 1, Batch 61800, Loss: 0.0015793073689565063\n",
      "Epoch 1, Batch 61850, Loss: 0.0014885863056406379\n",
      "Epoch 1, Batch 61900, Loss: 0.001199830905534327\n",
      "Epoch 1, Batch 61950, Loss: 0.001575860776938498\n",
      "Epoch 1, Batch 62000, Loss: 0.0019274911610409617\n",
      "Epoch 1, Batch 62050, Loss: 0.001486432389356196\n",
      "Epoch 1, Batch 62100, Loss: 0.0012703606626018882\n",
      "Epoch 1, Batch 62150, Loss: 0.0015450268983840942\n",
      "Epoch 1, Batch 62200, Loss: 0.0015098706353455782\n",
      "Epoch 1, Batch 62250, Loss: 0.0028853220865130424\n",
      "Epoch 1, Batch 62300, Loss: 0.0034366068430244923\n",
      "Epoch 1, Batch 62350, Loss: 0.002686220221221447\n",
      "Epoch 1, Batch 62400, Loss: 0.0024797064252197742\n",
      "Epoch 1, Batch 62450, Loss: 0.002705708611756563\n",
      "Epoch 1, Batch 62500, Loss: 0.40247857570648193\n",
      "Epoch 1, Batch 62550, Loss: 0.0029693155083805323\n",
      "Epoch 1, Batch 62600, Loss: 0.004434193018823862\n",
      "Epoch 1, Batch 62650, Loss: 0.0028110668063163757\n",
      "Epoch 1, Batch 62700, Loss: 0.002251632045954466\n",
      "Epoch 1, Batch 62750, Loss: 0.0018923672614619136\n",
      "Epoch 1, Batch 62800, Loss: 0.001770497066900134\n",
      "Epoch 1, Batch 62850, Loss: 0.0016312065999954939\n",
      "Epoch 1, Batch 62900, Loss: 0.0015004592714831233\n",
      "Epoch 1, Batch 62950, Loss: 0.0013968218117952347\n",
      "Epoch 1, Batch 63000, Loss: 0.0016054946463555098\n",
      "Epoch 1, Batch 63050, Loss: 0.0018715496407821774\n",
      "Epoch 1, Batch 63100, Loss: 0.0014651066157966852\n",
      "Epoch 1, Batch 63150, Loss: 0.0016092793084681034\n",
      "Epoch 1, Batch 63200, Loss: 0.0014382436638697982\n",
      "Epoch 1, Batch 63250, Loss: 0.0014861325034871697\n",
      "Epoch 1, Batch 63300, Loss: 0.0019544761162251234\n",
      "Epoch 1, Batch 63350, Loss: 0.0020852060988545418\n",
      "Epoch 1, Batch 63400, Loss: 0.003252477617934346\n",
      "Epoch 1, Batch 63450, Loss: 0.003904954995959997\n",
      "Epoch 1, Batch 63500, Loss: 0.002944040345028043\n",
      "Epoch 1, Batch 63550, Loss: 0.0020743811037391424\n",
      "Epoch 1, Batch 63600, Loss: 0.003093017265200615\n",
      "Epoch 1, Batch 63650, Loss: 0.0023846253752708435\n",
      "Epoch 1, Batch 63700, Loss: 0.0026399963535368443\n",
      "Epoch 1, Batch 63750, Loss: 0.0022391865495592356\n",
      "Epoch 1, Batch 63800, Loss: 0.0017772963037714362\n",
      "Epoch 1, Batch 63850, Loss: 0.0013310684589669108\n",
      "Epoch 1, Batch 63900, Loss: 0.0014127058675512671\n",
      "Epoch 1, Batch 63950, Loss: 0.002048275899142027\n",
      "Epoch 1, Batch 64000, Loss: 0.0026370862033218145\n",
      "Epoch 1, Batch 64050, Loss: 0.0026075602509081364\n",
      "Epoch 1, Batch 64100, Loss: 0.002243359573185444\n",
      "Epoch 1, Batch 64150, Loss: 0.002654785057529807\n",
      "Epoch 1, Batch 64200, Loss: 0.0021064234897494316\n",
      "Epoch 1, Batch 64250, Loss: 0.0016558837378397584\n",
      "Epoch 1, Batch 64300, Loss: 0.002205273602157831\n",
      "Epoch 1, Batch 64350, Loss: 0.0017692989204078913\n",
      "Epoch 1, Batch 64400, Loss: 0.0012843637960031629\n",
      "Epoch 1, Batch 64450, Loss: 0.0010940955253317952\n",
      "Epoch 1, Batch 64500, Loss: 0.0013059136690571904\n",
      "Epoch 1, Batch 64550, Loss: 0.0019881839398294687\n",
      "Epoch 1, Batch 64600, Loss: 0.0024263719096779823\n",
      "Epoch 1, Batch 64650, Loss: 0.0026055595371872187\n",
      "Epoch 1, Batch 64700, Loss: 0.0017920067766681314\n",
      "Epoch 1, Batch 64750, Loss: 0.00143938057590276\n",
      "Epoch 1, Batch 64800, Loss: 0.0012210438726469874\n",
      "Epoch 1, Batch 64850, Loss: 0.0011283712228760123\n",
      "Epoch 1, Batch 64900, Loss: 0.0010032504796981812\n",
      "Epoch 1, Batch 64950, Loss: 0.00198296713642776\n",
      "Epoch 1, Batch 65000, Loss: 0.0027792463079094887\n",
      "Epoch 1, Batch 65050, Loss: 0.002023902954533696\n",
      "Epoch 1, Batch 65100, Loss: 0.002183477859944105\n",
      "Epoch 1, Batch 65150, Loss: 0.0019431739347055554\n",
      "Epoch 1, Batch 65200, Loss: 0.001830791705287993\n",
      "Epoch 1, Batch 65250, Loss: 0.0017134563531726599\n",
      "Epoch 1, Batch 65300, Loss: 0.0020235958509147167\n",
      "Epoch 1, Batch 65350, Loss: 0.002284010872244835\n",
      "Epoch 1, Batch 65400, Loss: 0.002048755995929241\n",
      "Epoch 1, Batch 65450, Loss: 0.0035964122507721186\n",
      "Epoch 1, Batch 65500, Loss: 0.002723250538110733\n",
      "Epoch 1, Batch 65550, Loss: 0.002850511809810996\n",
      "Epoch 1, Batch 65600, Loss: 0.0029711362440139055\n",
      "Epoch 1, Batch 65650, Loss: 0.0024227951653301716\n",
      "Epoch 1, Batch 65700, Loss: 0.0016303891316056252\n",
      "Epoch 1, Batch 65750, Loss: 0.001476586563512683\n",
      "Epoch 1, Batch 65800, Loss: 0.0014818658819422126\n",
      "Epoch 1, Batch 65850, Loss: 0.0018387127202004194\n",
      "Epoch 1, Batch 65900, Loss: 0.0018698112107813358\n",
      "Epoch 1, Batch 65950, Loss: 0.0018892716616392136\n",
      "Epoch 1, Batch 66000, Loss: 0.0017314457800239325\n",
      "Epoch 1, Batch 66050, Loss: 0.0017597009427845478\n",
      "Epoch 1, Batch 66100, Loss: 0.0019615301862359047\n",
      "Epoch 1, Batch 66150, Loss: 0.002034869510680437\n",
      "Epoch 1, Batch 66200, Loss: 0.00241802423261106\n",
      "Epoch 1, Batch 66250, Loss: 0.0022007031366229057\n",
      "Epoch 1, Batch 66300, Loss: 0.0033773186150938272\n",
      "Epoch 1, Batch 66350, Loss: 0.0025286448653787374\n",
      "Epoch 1, Batch 66400, Loss: 0.002182888798415661\n",
      "Epoch 1, Batch 66450, Loss: 0.0019142875680699944\n",
      "Epoch 1, Batch 66500, Loss: 0.002022466855123639\n",
      "Epoch 1, Batch 66550, Loss: 0.002791635226458311\n",
      "Epoch 1, Batch 66600, Loss: 0.0025030842516571283\n",
      "Epoch 1, Batch 66650, Loss: 0.0020057386718690395\n",
      "Epoch 1, Batch 66700, Loss: 0.0015329794259741902\n",
      "Epoch 1, Batch 66750, Loss: 0.0014763958752155304\n",
      "Epoch 1, Batch 66800, Loss: 0.4283038377761841\n",
      "Epoch 1, Batch 66850, Loss: 0.00181109260302037\n",
      "Epoch 1, Batch 66900, Loss: 0.0027427664026618004\n",
      "Epoch 1, Batch 66950, Loss: 0.00179024669341743\n",
      "Epoch 1, Batch 67000, Loss: 0.0017208978533744812\n",
      "Epoch 1, Batch 67050, Loss: 0.002396597992628813\n",
      "Epoch 1, Batch 67100, Loss: 0.0023421659134328365\n",
      "Epoch 1, Batch 67150, Loss: 0.0021549337543547153\n",
      "Epoch 1, Batch 67200, Loss: 0.001958525739610195\n",
      "Epoch 1, Batch 67250, Loss: 0.0016921203350648284\n",
      "Epoch 1, Batch 67300, Loss: 0.002204291755333543\n",
      "Epoch 1, Batch 67350, Loss: 0.0017887740395963192\n",
      "Epoch 1, Batch 67400, Loss: 0.0020458288490772247\n",
      "Epoch 1, Batch 67450, Loss: 0.0023180677089840174\n",
      "Epoch 1, Batch 67500, Loss: 0.0016800645971670747\n",
      "Epoch 1, Batch 67550, Loss: 0.001588137587532401\n",
      "Epoch 1, Batch 67600, Loss: 0.0015635226154699922\n",
      "Epoch 1, Batch 67650, Loss: 0.0020919323433190584\n",
      "Epoch 1, Batch 67700, Loss: 0.002278178697451949\n",
      "Epoch 1, Batch 67750, Loss: 0.002348664216697216\n",
      "Epoch 1, Batch 67800, Loss: 0.0019321736181154847\n",
      "Epoch 1, Batch 67850, Loss: 0.0019053840078413486\n",
      "Epoch 1, Batch 67900, Loss: 0.0016492067370563745\n",
      "Epoch 1, Batch 67950, Loss: 0.0015054696705192327\n",
      "Epoch 1, Batch 68000, Loss: 0.0017594096716493368\n",
      "Epoch 1, Batch 68050, Loss: 0.0016374787082895637\n",
      "Epoch 1, Batch 68100, Loss: 0.001756540616042912\n",
      "Epoch 1, Batch 68150, Loss: 0.0014278548769652843\n",
      "Epoch 1, Batch 68200, Loss: 0.0015740457456558943\n",
      "Epoch 1, Batch 68250, Loss: 0.001182488864287734\n",
      "Epoch 1, Batch 68300, Loss: 0.0013060856144875288\n",
      "Epoch 1, Batch 68350, Loss: 0.002374597592279315\n",
      "Epoch 1, Batch 68400, Loss: 0.00194234075024724\n",
      "Epoch 1, Batch 68450, Loss: 0.003802284598350525\n",
      "Epoch 1, Batch 68500, Loss: 0.0032634709496051073\n",
      "Epoch 1, Batch 68550, Loss: 0.0025089988484978676\n",
      "Epoch 1, Batch 68600, Loss: 0.002996627939864993\n",
      "Epoch 1, Batch 68650, Loss: 0.0031931509729474783\n",
      "Epoch 1, Batch 68700, Loss: 0.0025024113710969687\n",
      "Epoch 1, Batch 68750, Loss: 0.002734690671786666\n",
      "Epoch 1, Batch 68800, Loss: 0.002966377418488264\n",
      "Epoch 1, Batch 68850, Loss: 0.002639608457684517\n",
      "Epoch 1, Batch 68900, Loss: 0.002545962342992425\n",
      "Epoch 1, Batch 68950, Loss: 0.0032063762191683054\n",
      "Epoch 1, Batch 69000, Loss: 0.003229076974093914\n",
      "Epoch 1, Batch 69050, Loss: 0.004151972010731697\n",
      "Epoch 1, Batch 69100, Loss: 0.002496642293408513\n",
      "Epoch 1, Batch 69150, Loss: 0.0018871314823627472\n",
      "Epoch 1, Batch 69200, Loss: 0.002236954402178526\n",
      "Epoch 1, Batch 69250, Loss: 0.0015834736404940486\n",
      "Epoch 1, Batch 69300, Loss: 0.001824014587327838\n",
      "Epoch 1, Batch 69350, Loss: 0.0019362046150490642\n",
      "Epoch 1, Batch 69400, Loss: 0.39490798115730286\n",
      "Epoch 1, Batch 69450, Loss: 0.0025134673342108727\n",
      "Epoch 1, Batch 69500, Loss: 0.0024245416279882193\n",
      "Epoch 1, Batch 69550, Loss: 0.0025697057135403156\n",
      "Epoch 1, Batch 69600, Loss: 0.0021060467697679996\n",
      "Epoch 1, Batch 69650, Loss: 0.38840678334236145\n",
      "Epoch 1, Batch 69700, Loss: 0.0018807131564244628\n",
      "Epoch 1, Batch 69750, Loss: 0.001223703846335411\n",
      "Epoch 1, Batch 69800, Loss: 0.0013499786145985126\n",
      "Epoch 1, Batch 69850, Loss: 0.001071182661689818\n",
      "Epoch 1, Batch 69900, Loss: 0.0008944853907451034\n",
      "Epoch 1, Batch 69950, Loss: 0.0016548081766813993\n",
      "Epoch 1, Batch 70000, Loss: 0.0016850047977641225\n",
      "Epoch 1, Batch 70050, Loss: 0.0024145375937223434\n",
      "Epoch 1, Batch 70100, Loss: 0.003199199214577675\n",
      "Epoch 1, Batch 70150, Loss: 0.00219598482362926\n",
      "Epoch 1, Batch 70200, Loss: 0.0020276177674531937\n",
      "Epoch 1, Batch 70250, Loss: 0.0018308596918359399\n",
      "Epoch 1, Batch 70300, Loss: 0.001711319200694561\n",
      "Epoch 1, Batch 70350, Loss: 0.001714350888505578\n",
      "Epoch 1, Batch 70400, Loss: 0.0013101458316668868\n",
      "Epoch 1, Batch 70450, Loss: 0.0020999140106141567\n",
      "Epoch 1, Batch 70500, Loss: 0.0018899772549048066\n",
      "Epoch 1, Batch 70550, Loss: 0.0012467439519241452\n",
      "Epoch 1, Batch 70600, Loss: 0.0013930010609328747\n",
      "Epoch 1, Batch 70650, Loss: 0.0022410324309021235\n",
      "Epoch 1, Batch 70700, Loss: 0.3506423532962799\n",
      "Epoch 1, Batch 70750, Loss: 0.002390514127910137\n",
      "Epoch 1, Batch 70800, Loss: 0.0024788975715637207\n",
      "Epoch 1, Batch 70850, Loss: 0.0017238217405974865\n",
      "Epoch 1, Batch 70900, Loss: 0.002003065077587962\n",
      "Epoch 1, Batch 70950, Loss: 0.0017264238558709621\n",
      "Epoch 1, Batch 71000, Loss: 0.0024411382619291544\n",
      "Epoch 1, Batch 71050, Loss: 0.002316336380317807\n",
      "Epoch 1, Batch 71100, Loss: 0.002550524892285466\n",
      "Epoch 1, Batch 71150, Loss: 0.003229932626709342\n",
      "Epoch 1, Batch 71200, Loss: 0.003512317780405283\n",
      "Epoch 1, Batch 71250, Loss: 0.004280254244804382\n",
      "Epoch 1, Batch 71300, Loss: 0.002439385512843728\n",
      "Epoch 1, Batch 71350, Loss: 0.0021533030085265636\n",
      "Epoch 1, Batch 71400, Loss: 0.0015419342089444399\n",
      "Epoch 1, Batch 71450, Loss: 0.0018952579703181982\n",
      "Epoch 1, Batch 71500, Loss: 0.0026999786496162415\n",
      "Epoch 1, Batch 71550, Loss: 0.003880706150084734\n",
      "Epoch 1, Batch 71600, Loss: 0.0026621841825544834\n",
      "Epoch 1, Batch 71650, Loss: 0.002427522325888276\n",
      "Epoch 1, Batch 71700, Loss: 0.0029158485122025013\n",
      "Epoch 1, Batch 71750, Loss: 0.0025789598003029823\n",
      "Epoch 1, Batch 71800, Loss: 0.0034553678706288338\n",
      "Epoch 1, Batch 71850, Loss: 0.0027280396316200495\n",
      "Epoch 1, Batch 71900, Loss: 0.002399918856099248\n",
      "Epoch 1, Batch 71950, Loss: 0.394736111164093\n",
      "Epoch 1, Batch 72000, Loss: 0.003539646277204156\n",
      "Epoch 1, Batch 72050, Loss: 0.0037855461705476046\n",
      "Epoch 1, Batch 72100, Loss: 0.0034135677851736546\n",
      "Epoch 1, Batch 72150, Loss: 0.002738750074058771\n",
      "Epoch 1, Batch 72200, Loss: 0.709659218788147\n",
      "Epoch 1, Batch 72250, Loss: 0.00357192475348711\n",
      "Epoch 1, Batch 72300, Loss: 0.003235217649489641\n",
      "Epoch 1, Batch 72350, Loss: 0.0024494100362062454\n",
      "Epoch 1, Batch 72400, Loss: 0.002054967451840639\n",
      "Epoch 1, Batch 72450, Loss: 0.0023680778685957193\n",
      "Epoch 1, Batch 72500, Loss: 0.002720363438129425\n",
      "Epoch 1, Batch 72550, Loss: 0.0020877618808299303\n",
      "Epoch 1, Batch 72600, Loss: 0.0022021266631782055\n",
      "Epoch 1, Batch 72650, Loss: 0.002505824202671647\n",
      "Epoch 1, Batch 72700, Loss: 0.0021380113903433084\n",
      "Epoch 1, Batch 72750, Loss: 0.002024612622335553\n",
      "Epoch 1, Batch 72800, Loss: 0.002267492236569524\n",
      "Epoch 1, Batch 72850, Loss: 0.0019122629892081022\n",
      "Epoch 1, Batch 72900, Loss: 0.0018736704951152205\n",
      "Epoch 1, Batch 72950, Loss: 0.0021698717027902603\n",
      "Epoch 1, Batch 73000, Loss: 0.0019938223995268345\n",
      "Epoch 1, Batch 73050, Loss: 0.0016605656128376722\n",
      "Epoch 1, Batch 73100, Loss: 0.0018197335302829742\n",
      "Epoch 1, Batch 73150, Loss: 0.0015511236852034926\n",
      "Epoch 1, Batch 73200, Loss: 0.002204993274062872\n",
      "Epoch 1, Batch 73250, Loss: 0.0024439345579594374\n",
      "Epoch 1, Batch 73300, Loss: 0.0022636447101831436\n",
      "Epoch 1, Batch 73350, Loss: 0.0014308056561276317\n",
      "Epoch 1, Batch 73400, Loss: 0.001989359501749277\n",
      "Epoch 1, Batch 73450, Loss: 0.0017515553627163172\n",
      "Epoch 1, Batch 73500, Loss: 0.002607465721666813\n",
      "Epoch 1, Batch 73550, Loss: 0.002165296347811818\n",
      "Epoch 1, Batch 73600, Loss: 0.0021392435301095247\n",
      "Epoch 1, Batch 73650, Loss: 0.002804511459544301\n",
      "Epoch 1, Batch 73700, Loss: 0.0025892937555909157\n",
      "Epoch 1, Batch 73750, Loss: 0.0022883208002895117\n",
      "Epoch 1, Batch 73800, Loss: 0.0024500954896211624\n",
      "Epoch 1, Batch 73850, Loss: 0.0018757862271741033\n",
      "Epoch 1, Batch 73900, Loss: 0.001536948373541236\n",
      "Epoch 1, Batch 73950, Loss: 0.0030803640838712454\n",
      "Epoch 1, Batch 74000, Loss: 0.0033972440287470818\n",
      "Epoch 1, Batch 74050, Loss: 0.0029792976565659046\n",
      "Epoch 1, Batch 74100, Loss: 0.002833733567968011\n",
      "Epoch 1, Batch 74150, Loss: 0.0019289946649223566\n",
      "Epoch 1, Batch 74200, Loss: 0.0017270642565563321\n",
      "Epoch 1, Batch 74250, Loss: 0.001497779507189989\n",
      "Epoch 1, Batch 74300, Loss: 0.0021045173052698374\n",
      "Epoch 1, Batch 74350, Loss: 0.0020029929000884295\n",
      "Epoch 1, Batch 74400, Loss: 0.002511747879907489\n",
      "Epoch 1, Batch 74450, Loss: 0.002664295956492424\n",
      "Epoch 1, Batch 74500, Loss: 0.002250197110697627\n",
      "Epoch 1, Batch 74550, Loss: 0.0025173239409923553\n",
      "Epoch 1, Batch 74600, Loss: 0.0022228120360523462\n",
      "Epoch 1, Batch 74650, Loss: 0.001690688426606357\n",
      "Epoch 1, Batch 74700, Loss: 0.001287464052438736\n",
      "Epoch 1, Batch 74750, Loss: 0.0013437693705782294\n",
      "Epoch 1, Batch 74800, Loss: 0.0016129935393109918\n",
      "Epoch 1, Batch 74850, Loss: 0.0013856961159035563\n",
      "Epoch 1, Batch 74900, Loss: 0.0022114827297627926\n",
      "Epoch 1, Batch 74950, Loss: 0.0025417653378099203\n",
      "Epoch 1, Batch 75000, Loss: 0.0035104870330542326\n",
      "Epoch 1, Batch 75050, Loss: 0.003153694560751319\n",
      "Epoch 1, Batch 75100, Loss: 0.00334180542267859\n",
      "Epoch 1, Batch 75150, Loss: 0.003354259068146348\n",
      "Epoch 1, Batch 75200, Loss: 0.0027564256452023983\n",
      "Epoch 1, Batch 75250, Loss: 0.002438453957438469\n",
      "Epoch 1, Batch 75300, Loss: 0.0024158970918506384\n",
      "Epoch 1, Batch 75350, Loss: 0.0018285835394635797\n",
      "Epoch 1, Batch 75400, Loss: 0.002690731082111597\n",
      "Epoch 1, Batch 75450, Loss: 0.0031108353286981583\n",
      "Epoch 1, Batch 75500, Loss: 0.0029565119184553623\n",
      "Epoch 1, Batch 75550, Loss: 0.002010442316532135\n",
      "Epoch 1, Batch 75600, Loss: 0.0021414821967482567\n",
      "Epoch 1, Batch 75650, Loss: 0.002577129751443863\n",
      "Epoch 1, Batch 75700, Loss: 0.0027528549544513226\n",
      "Epoch 1, Batch 75750, Loss: 0.0021564706694334745\n",
      "Epoch 1, Batch 75800, Loss: 0.0022839773446321487\n",
      "Epoch 1, Batch 75850, Loss: 0.0026460965164005756\n",
      "Epoch 1, Batch 75900, Loss: 0.002493160543963313\n",
      "Epoch 1, Batch 75950, Loss: 0.002636223565787077\n",
      "Epoch 1, Batch 76000, Loss: 0.0029414095915853977\n",
      "Epoch 1, Batch 76050, Loss: 0.003511507762596011\n",
      "Epoch 1, Batch 76100, Loss: 0.003641582326963544\n",
      "Epoch 1, Batch 76150, Loss: 0.002732247579842806\n",
      "Epoch 1, Batch 76200, Loss: 0.0027700290083885193\n",
      "Epoch 1, Batch 76250, Loss: 0.002098523546010256\n",
      "Epoch 1, Batch 76300, Loss: 0.001735677826218307\n",
      "Epoch 1, Batch 76350, Loss: 0.0015536838909611106\n",
      "Epoch 1, Batch 76400, Loss: 0.0013764755567535758\n",
      "Epoch 1, Batch 76450, Loss: 0.0015229019336402416\n",
      "Epoch 1, Batch 76500, Loss: 0.001355106825940311\n",
      "Epoch 1, Batch 76550, Loss: 0.0019111318979412317\n",
      "Epoch 1, Batch 76600, Loss: 0.0014472556067630649\n",
      "Epoch 1, Batch 76650, Loss: 0.001031374791637063\n",
      "Epoch 1, Batch 76700, Loss: 0.0011792088625952601\n",
      "Epoch 1, Batch 76750, Loss: 0.002013016492128372\n",
      "Epoch 1, Batch 76800, Loss: 0.00221026549115777\n",
      "Epoch 1, Batch 76850, Loss: 0.0020194165408611298\n",
      "Epoch 1, Batch 76900, Loss: 0.0020955235231667757\n",
      "Epoch 1, Batch 76950, Loss: 0.002431277185678482\n",
      "Epoch 1, Batch 77000, Loss: 0.0018360018730163574\n",
      "Epoch 1, Batch 77050, Loss: 0.0023285350762307644\n",
      "Epoch 1, Batch 77100, Loss: 0.002636366756632924\n",
      "Epoch 1, Batch 77150, Loss: 0.003488387679681182\n",
      "Epoch 1, Batch 77200, Loss: 0.0030874432995915413\n",
      "Epoch 1, Batch 77250, Loss: 0.0035945437848567963\n",
      "Epoch 1, Batch 77300, Loss: 0.003250187262892723\n",
      "Epoch 1, Batch 77350, Loss: 0.33670181035995483\n",
      "Epoch 1, Batch 77400, Loss: 0.002212182153016329\n",
      "Epoch 1, Batch 77450, Loss: 0.0020552866626530886\n",
      "Epoch 1, Batch 77500, Loss: 0.002035630401223898\n",
      "Epoch 1, Batch 77550, Loss: 0.0017991135828197002\n",
      "Epoch 1, Batch 77600, Loss: 0.001972232013940811\n",
      "Epoch 1, Batch 77650, Loss: 0.001587553066201508\n",
      "Epoch 1, Batch 77700, Loss: 0.0010571223683655262\n",
      "Epoch 1, Batch 77750, Loss: 0.0019371112575754523\n",
      "Epoch 1, Batch 77800, Loss: 0.002109107095748186\n",
      "Epoch 1, Batch 77850, Loss: 0.002699180506169796\n",
      "Epoch 1, Batch 77900, Loss: 0.002168577630072832\n",
      "Epoch 1, Batch 77950, Loss: 0.001697971485555172\n",
      "Epoch 1, Batch 78000, Loss: 0.0014108519535511732\n",
      "Epoch 1, Batch 78050, Loss: 0.0016701034037396312\n",
      "Epoch 1, Batch 78100, Loss: 0.001776758930645883\n",
      "Epoch 1, Batch 78150, Loss: 0.0013604345731437206\n",
      "Epoch 1, Batch 78200, Loss: 0.0011989810736849904\n",
      "Epoch 1, Batch 78250, Loss: 0.001359304878860712\n",
      "Epoch 1, Batch 78300, Loss: 0.0015577187296003103\n",
      "Epoch 1, Batch 78350, Loss: 0.0031162628438323736\n",
      "Epoch 1, Batch 78400, Loss: 0.0024601519107818604\n",
      "Epoch 1, Batch 78450, Loss: 0.0022568488493561745\n",
      "Epoch 1, Batch 78500, Loss: 0.001542740734294057\n",
      "Epoch 1, Batch 78550, Loss: 0.0019324746681377292\n",
      "Epoch 1, Batch 78600, Loss: 0.0016614235937595367\n",
      "Epoch 1, Batch 78650, Loss: 0.002195860957726836\n",
      "Epoch 1, Batch 78700, Loss: 0.001678347704000771\n",
      "Epoch 1, Batch 78750, Loss: 0.0018375390209257603\n",
      "Epoch 1, Batch 78800, Loss: 0.0016231302870437503\n",
      "Epoch 1, Batch 78850, Loss: 0.0021440736018121243\n",
      "Epoch 1, Batch 78900, Loss: 0.002504151314496994\n",
      "Epoch 1, Batch 78950, Loss: 0.0016791477100923657\n",
      "Epoch 1, Batch 79000, Loss: 0.41599881649017334\n",
      "Epoch 1, Batch 79050, Loss: 0.0027231210842728615\n",
      "Epoch 1, Batch 79100, Loss: 0.002576785394921899\n",
      "Epoch 1, Batch 79150, Loss: 0.002184426411986351\n",
      "Epoch 1, Batch 79200, Loss: 0.0041360026225447655\n",
      "Epoch 1, Batch 79250, Loss: 0.004048295319080353\n",
      "Epoch 1, Batch 79300, Loss: 0.3649108409881592\n",
      "Epoch 1, Batch 79350, Loss: 0.0028137678746134043\n",
      "Epoch 1, Batch 79400, Loss: 0.0024283137172460556\n",
      "Epoch 1, Batch 79450, Loss: 0.0031799504067748785\n",
      "Epoch 1, Batch 79500, Loss: 0.003560641547665\n",
      "Epoch 1, Batch 79550, Loss: 0.0032107061706483364\n",
      "Epoch 1, Batch 79600, Loss: 0.0022735639940947294\n",
      "Epoch 1, Batch 79650, Loss: 0.00222266698256135\n",
      "Epoch 1, Batch 79700, Loss: 0.002252106787636876\n",
      "Epoch 1, Batch 79750, Loss: 0.0018134873826056719\n",
      "Epoch 1, Batch 79800, Loss: 0.0021528699435293674\n",
      "Epoch 1, Batch 79850, Loss: 0.0020458162762224674\n",
      "Epoch 1, Batch 79900, Loss: 0.0015287132700905204\n",
      "Epoch 1, Batch 79950, Loss: 0.001435759593732655\n",
      "Epoch 1, Batch 80000, Loss: 0.0012419171398505569\n",
      "Epoch 1, Batch 80050, Loss: 0.001306254300288856\n",
      "Epoch 1, Batch 80100, Loss: 0.001355435699224472\n",
      "Epoch 1, Batch 80150, Loss: 0.0016287310281768441\n",
      "Epoch 1, Batch 80200, Loss: 0.0018472502706572413\n",
      "Epoch 1, Batch 80250, Loss: 0.0017953406786546111\n",
      "Epoch 1, Batch 80300, Loss: 0.0014814042951911688\n",
      "Epoch 1, Batch 80350, Loss: 0.0015627325046807528\n",
      "Epoch 1, Batch 80400, Loss: 0.002601091517135501\n",
      "Epoch 1, Batch 80450, Loss: 0.0027095775585621595\n",
      "Epoch 1, Batch 80500, Loss: 0.0023289460223168135\n",
      "Epoch 1, Batch 80550, Loss: 0.0022549862042069435\n",
      "Epoch 1, Batch 80600, Loss: 0.002000512322410941\n",
      "Epoch 1, Batch 80650, Loss: 0.0020763897337019444\n",
      "Epoch 1, Batch 80700, Loss: 0.0018627216340973973\n",
      "Epoch 1, Batch 80750, Loss: 0.0018473757663741708\n",
      "Epoch 1, Batch 80800, Loss: 0.002440110081806779\n",
      "Epoch 1, Batch 80850, Loss: 0.002195325680077076\n",
      "Epoch 1, Batch 80900, Loss: 0.0026434524916112423\n",
      "Epoch 1, Batch 80950, Loss: 0.0022337650880217552\n",
      "Epoch 1, Batch 81000, Loss: 0.3852955102920532\n",
      "Epoch 1, Batch 81050, Loss: 0.003107030875980854\n",
      "Epoch 1, Batch 81100, Loss: 0.002521664369851351\n",
      "Epoch 1, Batch 81150, Loss: 0.4161822199821472\n",
      "Epoch 1, Batch 81200, Loss: 0.0016715414822101593\n",
      "Epoch 1, Batch 81250, Loss: 0.0015434586675837636\n",
      "Epoch 1, Batch 81300, Loss: 0.001166702015325427\n",
      "Epoch 1, Batch 81350, Loss: 0.0014460493111982942\n",
      "Epoch 1, Batch 81400, Loss: 0.0017443862743675709\n",
      "Epoch 1, Batch 81450, Loss: 0.4208531677722931\n",
      "Epoch 1, Batch 81500, Loss: 0.0019773158710449934\n",
      "Epoch 1, Batch 81550, Loss: 0.0024578282609581947\n",
      "Epoch 1, Batch 81600, Loss: 0.0016462273197248578\n",
      "Epoch 1, Batch 81650, Loss: 0.0022847347427159548\n",
      "Epoch 1, Batch 81700, Loss: 0.0027676946483552456\n",
      "Epoch 1, Batch 81750, Loss: 0.003840617137029767\n",
      "Epoch 1, Batch 81800, Loss: 0.002469440456479788\n",
      "Epoch 1, Batch 81850, Loss: 0.0027404283173382282\n",
      "Epoch 1, Batch 81900, Loss: 0.003769812872633338\n",
      "Epoch 1, Batch 81950, Loss: 0.0026410690043121576\n",
      "Epoch 1, Batch 82000, Loss: 0.0018148309318348765\n",
      "Epoch 1, Batch 82050, Loss: 0.0014148231130093336\n",
      "Epoch 1, Batch 82100, Loss: 0.0016823421465232968\n",
      "Epoch 1, Batch 82150, Loss: 0.0016003926284611225\n",
      "Epoch 1, Batch 82200, Loss: 0.0018268985440954566\n",
      "Epoch 1, Batch 82250, Loss: 0.0020961433183401823\n",
      "Epoch 1, Batch 82300, Loss: 0.0022959911730140448\n",
      "Epoch 1, Batch 82350, Loss: 0.001735492842271924\n",
      "Epoch 1, Batch 82400, Loss: 0.001808095839805901\n",
      "Epoch 1, Batch 82450, Loss: 0.0017495091306045651\n",
      "Epoch 1, Batch 82500, Loss: 0.0022660596296191216\n",
      "Epoch 1, Batch 82550, Loss: 0.0029595675878226757\n",
      "Epoch 1, Batch 82600, Loss: 0.0027690082788467407\n",
      "Epoch 1, Batch 82650, Loss: 0.0022034351713955402\n",
      "Epoch 1, Batch 82700, Loss: 0.002064161468297243\n",
      "Epoch 1, Batch 82750, Loss: 0.0020228116773068905\n",
      "Epoch 1, Batch 82800, Loss: 0.0022518497426062822\n",
      "Epoch 1, Batch 82850, Loss: 0.0018032200168818235\n",
      "Epoch 1, Batch 82900, Loss: 0.0015434063971042633\n",
      "Epoch 1, Batch 82950, Loss: 0.0013938783667981625\n",
      "Epoch 1, Batch 83000, Loss: 0.0010988748399540782\n",
      "Epoch 1, Batch 83050, Loss: 0.43711429834365845\n",
      "Epoch 1, Batch 83100, Loss: 0.002381419064477086\n",
      "Epoch 1, Batch 83150, Loss: 0.002080896869301796\n",
      "Epoch 1, Batch 83200, Loss: 0.0015865882160142064\n",
      "Epoch 1, Batch 83250, Loss: 0.0017455529887229204\n",
      "Epoch 1, Batch 83300, Loss: 0.0022853019181638956\n",
      "Epoch 1, Batch 83350, Loss: 0.002934189047664404\n",
      "Epoch 1, Batch 83400, Loss: 0.002561511006206274\n",
      "Epoch 1, Batch 83450, Loss: 0.0029054395854473114\n",
      "Epoch 1, Batch 83500, Loss: 0.002336736535653472\n",
      "Epoch 1, Batch 83550, Loss: 0.0018363926792517304\n",
      "Epoch 1, Batch 83600, Loss: 0.0019072111463174224\n",
      "Epoch 1, Batch 83650, Loss: 0.002181077841669321\n",
      "Epoch 1, Batch 83700, Loss: 0.0031071635894477367\n",
      "Epoch 1, Batch 83750, Loss: 0.0023311185650527477\n",
      "Epoch 1, Batch 83800, Loss: 0.002258448861539364\n",
      "Epoch 1, Batch 83850, Loss: 0.0014580190181732178\n",
      "Epoch 1, Batch 83900, Loss: 0.0010858519235625863\n",
      "Epoch 1, Batch 83950, Loss: 0.43152135610580444\n",
      "Epoch 1, Batch 84000, Loss: 0.0024682702496647835\n",
      "Epoch 1, Batch 84050, Loss: 0.002636208198964596\n",
      "Epoch 1, Batch 84100, Loss: 0.002141423523426056\n",
      "Epoch 1, Batch 84150, Loss: 0.002452031010761857\n",
      "Epoch 1, Batch 84200, Loss: 0.002527965232729912\n",
      "Epoch 1, Batch 84250, Loss: 0.0036796596832573414\n",
      "Epoch 1, Batch 84300, Loss: 0.002685920801013708\n",
      "Epoch 1, Batch 84350, Loss: 0.002000656211748719\n",
      "Epoch 1, Batch 84400, Loss: 0.41117221117019653\n",
      "Epoch 1, Batch 84450, Loss: 0.0019732967484742403\n",
      "Epoch 1, Batch 84500, Loss: 0.0016749330097809434\n",
      "Epoch 1, Batch 84550, Loss: 0.0013093280140310526\n",
      "Epoch 1, Batch 84600, Loss: 0.0012327599106356502\n",
      "Epoch 1, Batch 84650, Loss: 0.001780626131221652\n",
      "Epoch 1, Batch 84700, Loss: 0.0020580494310706854\n",
      "Epoch 1, Batch 84750, Loss: 0.0019446690566837788\n",
      "Epoch 1, Batch 84800, Loss: 0.0017695956630632281\n",
      "Epoch 1, Batch 84850, Loss: 0.0014128496404737234\n",
      "Epoch 1, Batch 84900, Loss: 0.0016291034407913685\n",
      "Epoch 1, Batch 84950, Loss: 0.003202571766451001\n",
      "Epoch 1, Batch 85000, Loss: 0.002224275842308998\n",
      "Epoch 1, Batch 85050, Loss: 0.36700937151908875\n",
      "Epoch 1, Batch 85100, Loss: 0.0029415879398584366\n",
      "Epoch 1, Batch 85150, Loss: 0.00305034383200109\n",
      "Epoch 1, Batch 85200, Loss: 0.002604507142677903\n",
      "Epoch 1, Batch 85250, Loss: 0.00202570715919137\n",
      "Epoch 1, Batch 85300, Loss: 0.0019012339180335402\n",
      "Epoch 1, Batch 85350, Loss: 0.002292546210810542\n",
      "Epoch 1, Batch 85400, Loss: 0.002861696993932128\n",
      "Epoch 1, Batch 85450, Loss: 0.0020960583351552486\n",
      "Epoch 1, Batch 85500, Loss: 0.0027390336617827415\n",
      "Epoch 1, Batch 85550, Loss: 0.0031502479687333107\n",
      "Epoch 1, Batch 85600, Loss: 0.0023077758960425854\n",
      "Epoch 1, Batch 85650, Loss: 0.0017075837822631001\n",
      "Epoch 1, Batch 85700, Loss: 0.0015324704581871629\n",
      "Epoch 1, Batch 85750, Loss: 0.002179586561396718\n",
      "Epoch 1, Batch 85800, Loss: 0.0026302069891244173\n",
      "Epoch 1, Batch 85850, Loss: 0.0024793026968836784\n",
      "Epoch 1, Batch 85900, Loss: 0.002567945746704936\n",
      "Epoch 1, Batch 85950, Loss: 0.0019535606261342764\n",
      "Epoch 1, Batch 86000, Loss: 0.002083251718431711\n",
      "Epoch 1, Batch 86050, Loss: 0.0016872205305844545\n",
      "Epoch 1, Batch 86100, Loss: 0.0012596296146512032\n",
      "Epoch 1, Batch 86150, Loss: 0.0012324476847425103\n",
      "Epoch 1, Batch 86200, Loss: 0.0014326402451843023\n",
      "Epoch 1, Batch 86250, Loss: 0.0021138752344995737\n",
      "Epoch 1, Batch 86300, Loss: 0.0019862966146320105\n",
      "Epoch 1, Batch 86350, Loss: 0.001960228430107236\n",
      "Epoch 1, Batch 86400, Loss: 0.0016400370514020324\n",
      "Epoch 1, Batch 86450, Loss: 0.0014845018740743399\n",
      "Epoch 1, Batch 86500, Loss: 0.0018480016151443124\n",
      "Epoch 1, Batch 86550, Loss: 0.3580215871334076\n",
      "Epoch 1, Batch 86600, Loss: 0.002252208534628153\n",
      "Epoch 1, Batch 86650, Loss: 0.002484487369656563\n",
      "Epoch 1, Batch 86700, Loss: 0.0018441635183990002\n",
      "Epoch 1, Batch 86750, Loss: 0.001913696643896401\n",
      "Epoch 1, Batch 86800, Loss: 0.0022100817877799273\n",
      "Epoch 1, Batch 86850, Loss: 0.003003608202561736\n",
      "Epoch 1, Batch 86900, Loss: 0.0022229300811886787\n",
      "Epoch 1, Batch 86950, Loss: 0.0025306097231805325\n",
      "Epoch 1, Batch 87000, Loss: 0.0022278560791164637\n",
      "Epoch 1, Batch 87050, Loss: 0.0023154891096055508\n",
      "Epoch 1, Batch 87100, Loss: 0.0018444163724780083\n",
      "Epoch 1, Batch 87150, Loss: 0.0016223823186010122\n",
      "Epoch 1, Batch 87200, Loss: 0.0013514052843675017\n",
      "Epoch 1, Batch 87250, Loss: 0.001955847954377532\n",
      "Epoch 1, Batch 87300, Loss: 0.0015197546454146504\n",
      "Epoch 1, Batch 87350, Loss: 0.0016994851175695658\n",
      "Epoch 1, Batch 87400, Loss: 0.0013940028147771955\n",
      "Epoch 1, Batch 87450, Loss: 0.0017293667187914252\n",
      "Epoch 1, Batch 87500, Loss: 0.0015111754182726145\n",
      "Epoch 1, Batch 87550, Loss: 0.0015645887469872832\n",
      "Epoch 1, Batch 87600, Loss: 0.0017720815958455205\n",
      "Epoch 1, Batch 87650, Loss: 0.0023669330403208733\n",
      "Epoch 1, Batch 87700, Loss: 0.002309666248038411\n",
      "Epoch 1, Batch 87750, Loss: 0.0015087977517396212\n",
      "Epoch 1, Batch 87800, Loss: 0.0022933315485715866\n",
      "Epoch 1, Batch 87850, Loss: 0.001740927342325449\n",
      "Epoch 1, Batch 87900, Loss: 0.0024469634518027306\n",
      "Epoch 1, Batch 87950, Loss: 0.00355229782871902\n",
      "Epoch 1, Batch 88000, Loss: 0.002754517365247011\n",
      "Epoch 1, Batch 88050, Loss: 0.0025107755791395903\n",
      "Epoch 1, Batch 88100, Loss: 0.0020614424720406532\n",
      "Epoch 1, Batch 88150, Loss: 0.0018524483311921358\n",
      "Epoch 1, Batch 88200, Loss: 0.003321222960948944\n",
      "Epoch 1, Batch 88250, Loss: 0.0030845662113279104\n",
      "Epoch 1, Batch 88300, Loss: 0.0023165815509855747\n",
      "Epoch 1, Batch 88350, Loss: 0.0016082313377410173\n",
      "Epoch 1, Batch 88400, Loss: 0.0025717669632285833\n",
      "Epoch 1, Batch 88450, Loss: 0.002965412801131606\n",
      "Epoch 1, Batch 88500, Loss: 0.0025033303536474705\n",
      "Epoch 1, Batch 88550, Loss: 0.001884865458123386\n",
      "Epoch 1, Batch 88600, Loss: 0.0019476206507533789\n",
      "Epoch 1, Batch 88650, Loss: 0.0018828562460839748\n",
      "Epoch 1, Batch 88700, Loss: 0.0025368686765432358\n",
      "Epoch 1, Batch 88750, Loss: 0.002159055322408676\n",
      "Epoch 1, Batch 88800, Loss: 0.0015672516310587525\n",
      "Epoch 1, Batch 88850, Loss: 0.0014517182717099786\n",
      "Epoch 1, Batch 88900, Loss: 0.001257481286302209\n",
      "Epoch 1, Batch 88950, Loss: 0.0010053642326965928\n",
      "Epoch 1, Batch 89000, Loss: 0.0011935880174860358\n",
      "Epoch 1, Batch 89050, Loss: 0.0014558358816429973\n",
      "Epoch 1, Batch 89100, Loss: 0.001355753862299025\n",
      "Epoch 1, Batch 89150, Loss: 0.0019651330076158047\n",
      "Epoch 1, Batch 89200, Loss: 0.002006669295951724\n",
      "Epoch 1, Batch 89250, Loss: 0.0023665642365813255\n",
      "Epoch 1, Batch 89300, Loss: 0.0019032229902222753\n",
      "Epoch 1, Batch 89350, Loss: 0.0014467943692579865\n",
      "Epoch 1, Batch 89400, Loss: 0.001334844739176333\n",
      "Epoch 1, Batch 89450, Loss: 0.0011757517931982875\n",
      "Epoch 1, Batch 89500, Loss: 0.0012581469491124153\n",
      "Epoch 1, Batch 89550, Loss: 0.001536847441457212\n",
      "Epoch 1, Batch 89600, Loss: 0.0028627936262637377\n",
      "Epoch 1, Batch 89650, Loss: 0.002212471328675747\n",
      "Epoch 1, Batch 89700, Loss: 0.001814739196561277\n",
      "Epoch 1, Batch 89750, Loss: 0.0019826313946396112\n",
      "Epoch 1, Batch 89800, Loss: 0.001664358889684081\n",
      "Epoch 1, Batch 89850, Loss: 0.001534852897748351\n",
      "Epoch 1, Batch 89900, Loss: 0.0015439701965078712\n",
      "Epoch 1, Batch 89950, Loss: 0.001135059166699648\n",
      "Epoch 1, Batch 90000, Loss: 0.0013924118829891086\n",
      "Epoch 1, Batch 90050, Loss: 0.0017339003970846534\n",
      "Epoch 1, Batch 90100, Loss: 0.0017731337575241923\n",
      "Epoch 1, Batch 90150, Loss: 0.002683612983673811\n",
      "Epoch 1, Batch 90200, Loss: 0.0031161955557763577\n",
      "Epoch 1, Batch 90250, Loss: 0.0024901041761040688\n",
      "Epoch 1, Batch 90300, Loss: 0.004488803446292877\n",
      "Epoch 1, Batch 90350, Loss: 0.0026071364991366863\n",
      "Epoch 1, Batch 90400, Loss: 0.001985845621675253\n",
      "Epoch 1, Batch 90450, Loss: 0.0014692717231810093\n",
      "Epoch 1, Batch 90500, Loss: 0.0014699856983497739\n",
      "Epoch 1, Batch 90550, Loss: 0.00195961887948215\n",
      "Epoch 1, Batch 90600, Loss: 0.0014968902105465531\n",
      "Epoch 1, Batch 90650, Loss: 0.0013202994596213102\n",
      "Epoch 1, Batch 90700, Loss: 0.0014294295106083155\n",
      "Epoch 1, Batch 90750, Loss: 0.002106288680806756\n",
      "Epoch 1, Batch 90800, Loss: 0.0027274650055915117\n",
      "Epoch 1, Batch 90850, Loss: 0.003966628573834896\n",
      "Epoch 1, Batch 90900, Loss: 0.004264963790774345\n",
      "Epoch 1, Batch 90950, Loss: 0.003241534112021327\n",
      "Epoch 1, Batch 91000, Loss: 0.003517579287290573\n",
      "Epoch 1, Batch 91050, Loss: 0.001797311007976532\n",
      "Epoch 1, Batch 91100, Loss: 0.0023223389871418476\n",
      "Epoch 1, Batch 91150, Loss: 0.0017393601592630148\n",
      "Epoch 1, Batch 91200, Loss: 0.001435214770026505\n",
      "Epoch 1, Batch 91250, Loss: 0.001506997854448855\n",
      "Epoch 1, Batch 91300, Loss: 0.0012053174432367086\n",
      "Epoch 1, Batch 91350, Loss: 0.0014974435325711966\n",
      "Epoch 1, Batch 91400, Loss: 0.002373466035351157\n",
      "Epoch 1, Batch 91450, Loss: 0.002108069136738777\n",
      "Epoch 1, Batch 91500, Loss: 0.0026145654264837503\n",
      "Epoch 1, Batch 91550, Loss: 0.0022582057863473892\n",
      "Epoch 1, Batch 91600, Loss: 0.001546340761706233\n",
      "Epoch 1, Batch 91650, Loss: 0.0015944041078910232\n",
      "Epoch 1, Batch 91700, Loss: 0.0019542917143553495\n",
      "Epoch 1, Batch 91750, Loss: 0.00269607687368989\n",
      "Epoch 1, Batch 91800, Loss: 0.002538664499297738\n",
      "Epoch 1, Batch 91850, Loss: 0.0027363025583326817\n",
      "Epoch 1, Batch 91900, Loss: 0.0025506187230348587\n",
      "Epoch 1, Batch 91950, Loss: 0.002656583208590746\n",
      "Epoch 1, Batch 92000, Loss: 0.00362362340092659\n",
      "Epoch 1, Batch 92050, Loss: 0.0028108747210353613\n",
      "Epoch 1, Batch 92100, Loss: 0.0015560671454295516\n",
      "Epoch 1, Batch 92150, Loss: 0.0014791112625971437\n",
      "Epoch 1, Batch 92200, Loss: 0.0024877863470464945\n",
      "Epoch 1, Batch 92250, Loss: 0.001750161056406796\n",
      "Epoch 1, Batch 92300, Loss: 0.001644827309064567\n",
      "Epoch 1, Batch 92350, Loss: 0.0016121712978929281\n",
      "Epoch 1, Batch 92400, Loss: 0.0014216657727956772\n",
      "Epoch 1, Batch 92450, Loss: 0.0015215192688629031\n",
      "Epoch 1, Batch 92500, Loss: 0.002104402519762516\n",
      "Epoch 1, Batch 92550, Loss: 0.0015924553154036403\n",
      "Epoch 1, Batch 92600, Loss: 0.0017042752588167787\n",
      "Epoch 1, Batch 92650, Loss: 0.0025463297497481108\n",
      "Epoch 1, Batch 92700, Loss: 0.003979390487074852\n",
      "Epoch 1, Batch 92750, Loss: 0.0025499623734503984\n",
      "Epoch 1, Batch 92800, Loss: 0.0015813547652214766\n",
      "Epoch 1, Batch 92850, Loss: 0.0015802037669345737\n",
      "Epoch 1, Batch 92900, Loss: 0.0013783135218545794\n",
      "Epoch 1, Batch 92950, Loss: 0.0013304073363542557\n",
      "Epoch 1, Batch 93000, Loss: 0.0013231259072199464\n",
      "Epoch 1, Batch 93050, Loss: 0.0018098887521773577\n",
      "Epoch 1, Batch 93100, Loss: 0.0013765846379101276\n",
      "Epoch 1, Batch 93150, Loss: 0.0012226620456203818\n",
      "Epoch 1, Batch 93200, Loss: 0.0014468689914792776\n",
      "Epoch 1, Batch 93250, Loss: 0.0016440310282632709\n",
      "Epoch 1, Batch 93300, Loss: 0.002009542193263769\n",
      "Epoch 1, Batch 93350, Loss: 0.0015258095227181911\n",
      "Epoch 1, Batch 93400, Loss: 0.0017342264764010906\n",
      "Epoch 1, Batch 93450, Loss: 0.00201908010058105\n",
      "Epoch 1, Batch 93500, Loss: 0.0016347822966054082\n",
      "Epoch 1, Batch 93550, Loss: 0.002256323117762804\n",
      "Epoch 1, Batch 93600, Loss: 0.001501924591138959\n",
      "Epoch 1, Batch 93650, Loss: 0.001730851479806006\n",
      "Epoch 1, Batch 93700, Loss: 0.0019486581441015005\n",
      "Epoch 1, Batch 93750, Loss: 0.002303261309862137\n",
      "Epoch 1, Batch 93800, Loss: 0.0031639891676604748\n",
      "Epoch 1, Batch 93850, Loss: 0.002095769625157118\n",
      "Epoch 1, Batch 93900, Loss: 0.32287198305130005\n",
      "Epoch 1, Batch 93950, Loss: 0.002699516015127301\n",
      "Epoch 1, Batch 94000, Loss: 0.0019249268807470798\n",
      "Epoch 1, Batch 94050, Loss: 0.00248126988299191\n",
      "Epoch 1, Batch 94100, Loss: 0.39770394563674927\n",
      "Epoch 1, Batch 94150, Loss: 0.001854878501035273\n",
      "Epoch 1, Batch 94200, Loss: 0.0015768017619848251\n",
      "Epoch 1, Batch 94250, Loss: 0.002023362321779132\n",
      "Epoch 1, Batch 94300, Loss: 0.0013688030885532498\n",
      "Epoch 1, Batch 94350, Loss: 0.0016044698422774673\n",
      "Epoch 1, Batch 94400, Loss: 0.00240935105830431\n",
      "Epoch 1, Batch 94450, Loss: 0.0026641134172677994\n",
      "Epoch 1, Batch 94500, Loss: 0.3868682086467743\n",
      "Epoch 1, Batch 94550, Loss: 0.0022598805371671915\n",
      "Epoch 1, Batch 94600, Loss: 0.0016923067159950733\n",
      "Epoch 1, Batch 94650, Loss: 0.0022764948662370443\n",
      "Epoch 1, Batch 94700, Loss: 0.0017409075517207384\n",
      "Epoch 1, Batch 94750, Loss: 0.002074754796922207\n",
      "Epoch 1, Batch 94800, Loss: 0.0019540772773325443\n",
      "Epoch 1, Batch 94850, Loss: 0.0017849048599600792\n",
      "Epoch 1, Batch 94900, Loss: 0.0018406674498692155\n",
      "Epoch 1, Batch 94950, Loss: 0.001868087099865079\n",
      "Epoch 1, Batch 95000, Loss: 0.002098616911098361\n",
      "Epoch 1, Batch 95050, Loss: 0.0024221776984632015\n",
      "Epoch 1, Batch 95100, Loss: 0.0015391989145427942\n",
      "Epoch 1, Batch 95150, Loss: 0.0016377707943320274\n",
      "Epoch 1, Batch 95200, Loss: 0.0014439438236877322\n",
      "Epoch 1, Batch 95250, Loss: 0.0011761372443288565\n",
      "Epoch 1, Batch 95300, Loss: 0.001178858452476561\n",
      "Epoch 1, Batch 95350, Loss: 0.001030939631164074\n",
      "Epoch 1, Batch 95400, Loss: 0.0011567467590793967\n",
      "Epoch 1, Batch 95450, Loss: 0.0014807777479290962\n",
      "Epoch 1, Batch 95500, Loss: 0.002453771885484457\n",
      "Epoch 1, Batch 95550, Loss: 0.002168291714042425\n",
      "Epoch 1, Batch 95600, Loss: 0.0015647558029741049\n",
      "Epoch 1, Batch 95650, Loss: 0.0013046973617747426\n",
      "Epoch 1, Batch 95700, Loss: 0.0017519170651212335\n",
      "Epoch 1, Batch 95750, Loss: 0.0014718780294060707\n",
      "Epoch 1, Batch 95800, Loss: 0.001397398766130209\n",
      "Epoch 1, Batch 95850, Loss: 0.001665902673266828\n",
      "Epoch 1, Batch 95900, Loss: 0.0032309822272509336\n",
      "Epoch 1, Batch 95950, Loss: 0.0031305551528930664\n",
      "Epoch 1, Batch 96000, Loss: 0.002582207787781954\n",
      "Epoch 1, Batch 96050, Loss: 0.002948872046545148\n",
      "Epoch 1, Batch 96100, Loss: 0.0021418770775198936\n",
      "Epoch 1, Batch 96150, Loss: 0.0018012257060036063\n",
      "Epoch 1, Batch 96200, Loss: 0.0012695204932242632\n",
      "Epoch 1, Batch 96250, Loss: 0.0009522729669697583\n",
      "Epoch 1, Batch 96300, Loss: 0.0011980128474533558\n",
      "Epoch 1, Batch 96350, Loss: 0.0011893112678080797\n",
      "Epoch 1, Batch 96400, Loss: 0.0012786037987098098\n",
      "Epoch 1, Batch 96450, Loss: 0.002501881681382656\n",
      "Epoch 1, Batch 96500, Loss: 0.0025070763658732176\n",
      "Epoch 1, Batch 96550, Loss: 0.0032952658366411924\n",
      "Epoch 1, Batch 96600, Loss: 0.003177052363753319\n",
      "Epoch 1, Batch 96650, Loss: 0.004414549097418785\n",
      "Epoch 1, Batch 96700, Loss: 0.005090302787721157\n",
      "Epoch 1, Batch 96750, Loss: 0.005236885044723749\n",
      "Epoch 1, Batch 96800, Loss: 0.007152106612920761\n",
      "Epoch 1, Batch 96850, Loss: 0.00361891882494092\n",
      "Epoch 1, Batch 96900, Loss: 0.003992416430264711\n",
      "Epoch 1, Batch 96950, Loss: 0.0029812115244567394\n",
      "Epoch 1, Batch 97000, Loss: 0.0030700592324137688\n",
      "Epoch 1, Batch 97050, Loss: 0.0032569561153650284\n",
      "Epoch 1, Batch 97100, Loss: 0.002337429206818342\n",
      "Epoch 1, Batch 97150, Loss: 0.002601683372631669\n",
      "Epoch 1, Batch 97200, Loss: 0.0029064470436424017\n",
      "Epoch 1, Batch 97250, Loss: 0.0022029343526810408\n",
      "Epoch 1, Batch 97300, Loss: 0.00212297891266644\n",
      "Epoch 1, Batch 97350, Loss: 0.0030641728080809116\n",
      "Epoch 1, Batch 97400, Loss: 0.0028749192133545876\n",
      "Epoch 1, Batch 97450, Loss: 0.0016257526585832238\n",
      "Epoch 1, Batch 97500, Loss: 0.0013203213457018137\n",
      "Epoch 1, Batch 97550, Loss: 0.0017345583764836192\n",
      "Epoch 1, Batch 97600, Loss: 0.001478198217228055\n",
      "Epoch 1, Batch 97650, Loss: 0.0016809634398669004\n",
      "Epoch 1, Batch 97700, Loss: 0.0032661922741681337\n",
      "Epoch 1, Batch 97750, Loss: 0.002767274621874094\n",
      "Epoch 1, Batch 97800, Loss: 0.003192042000591755\n",
      "Epoch 1, Batch 97850, Loss: 0.0023300359025597572\n",
      "Epoch 1, Batch 97900, Loss: 0.0013409730745479465\n",
      "Epoch 1, Batch 97950, Loss: 0.0012990809045732021\n",
      "Epoch 1, Batch 98000, Loss: 0.0012109269155189395\n",
      "Epoch 1, Batch 98050, Loss: 0.001204618252813816\n",
      "Epoch 1, Batch 98100, Loss: 0.0018307991558685899\n",
      "Epoch 1, Batch 98150, Loss: 0.0022419423330575228\n",
      "Epoch 1, Batch 98200, Loss: 0.40772244334220886\n",
      "Epoch 1, Batch 98250, Loss: 0.0033188601955771446\n",
      "Epoch 1, Batch 98300, Loss: 0.002471120096743107\n",
      "Epoch 1, Batch 98350, Loss: 0.0027175238355994225\n",
      "Epoch 1, Batch 98400, Loss: 0.001959144603461027\n",
      "Epoch 1, Batch 98450, Loss: 0.0034440732561051846\n",
      "Epoch 1, Batch 98500, Loss: 0.003481467254459858\n",
      "Epoch 1, Batch 98550, Loss: 0.0027429601177573204\n",
      "Epoch 1, Batch 98600, Loss: 0.0032749013043940067\n",
      "Epoch 1, Batch 98650, Loss: 0.002920340746641159\n",
      "Epoch 1, Batch 98700, Loss: 0.002447074744850397\n",
      "Epoch 1, Batch 98750, Loss: 0.0024910049978643656\n",
      "Epoch 1, Batch 98800, Loss: 0.003281752346083522\n",
      "Epoch 1, Batch 98850, Loss: 0.002430344233289361\n",
      "Epoch 1, Batch 98900, Loss: 0.0022721088025718927\n",
      "Epoch 1, Batch 98950, Loss: 0.002520450158044696\n",
      "Epoch 1, Batch 99000, Loss: 0.0018248691922053695\n",
      "Epoch 1, Batch 99050, Loss: 0.0019645942375063896\n",
      "Epoch 1, Batch 99100, Loss: 0.0019767004996538162\n",
      "Epoch 1, Batch 99150, Loss: 0.0028563332743942738\n",
      "Epoch 1, Batch 99200, Loss: 0.0023222779855132103\n",
      "Epoch 1, Batch 99250, Loss: 0.00199272483587265\n",
      "Epoch 1, Batch 99300, Loss: 0.001862834906205535\n",
      "Epoch 1, Batch 99350, Loss: 0.0016395397251471877\n",
      "Epoch 1, Batch 99400, Loss: 0.0022420554887503386\n",
      "Epoch 1, Batch 99450, Loss: 0.002305143978446722\n",
      "Epoch 1, Batch 99500, Loss: 0.0016239337855949998\n",
      "Epoch 1, Batch 99550, Loss: 0.001547325518913567\n",
      "Epoch 1, Batch 99600, Loss: 0.0016975930193439126\n",
      "Epoch 1, Batch 99650, Loss: 0.0017985457088798285\n",
      "Epoch 1, Batch 99700, Loss: 0.0016139433719217777\n",
      "Epoch 1, Batch 99750, Loss: 0.002010591793805361\n",
      "Epoch 1, Batch 99800, Loss: 0.0014001287054270506\n",
      "Epoch 1, Batch 99850, Loss: 0.001116537838242948\n",
      "Epoch 1, Batch 99900, Loss: 0.0010270070051774383\n",
      "Epoch 1, Batch 99950, Loss: 0.0016233434434980154\n",
      "Epoch 1, Batch 100000, Loss: 0.0016107239061966538\n",
      "Epoch 1, Batch 100050, Loss: 0.0019937215838581324\n",
      "Epoch 1, Batch 100100, Loss: 0.0031407505739480257\n",
      "Epoch 1, Batch 100150, Loss: 0.002982750302180648\n",
      "Epoch 1, Batch 100200, Loss: 0.3606576919555664\n",
      "Epoch 1, Batch 100250, Loss: 0.003117714310064912\n",
      "Epoch 1, Batch 100300, Loss: 0.002398740965873003\n",
      "Epoch 1, Batch 100350, Loss: 0.0019346422050148249\n",
      "Epoch 1, Batch 100400, Loss: 0.001506028464064002\n",
      "Epoch 1, Batch 100450, Loss: 0.0019092111615464091\n",
      "Epoch 1, Batch 100500, Loss: 0.002430426189675927\n",
      "Epoch 1, Batch 100550, Loss: 0.0027496342081576586\n",
      "Epoch 1, Batch 100600, Loss: 0.0029536220245063305\n",
      "Epoch 1, Batch 100650, Loss: 0.0037501431070268154\n",
      "Epoch 1, Batch 100700, Loss: 0.001992761390283704\n",
      "Epoch 1, Batch 100750, Loss: 0.0024323260877281427\n",
      "Epoch 1, Batch 100800, Loss: 0.0023110033944249153\n",
      "Epoch 1, Batch 100850, Loss: 0.0021973280236124992\n",
      "Epoch 1, Batch 100900, Loss: 0.36174947023391724\n",
      "Epoch 1, Batch 100950, Loss: 0.0037648575380444527\n",
      "Epoch 1, Batch 101000, Loss: 0.003170764073729515\n",
      "Epoch 1, Batch 101050, Loss: 0.0034779550042003393\n",
      "Epoch 1, Batch 101100, Loss: 0.0038886263500899076\n",
      "Epoch 1, Batch 101150, Loss: 0.004431992769241333\n",
      "Epoch 1, Batch 101200, Loss: 0.003567222272977233\n",
      "Epoch 1, Batch 101250, Loss: 0.0025647480506449938\n",
      "Epoch 1, Batch 101300, Loss: 0.002784861484542489\n",
      "Epoch 1, Batch 101350, Loss: 0.002564229303970933\n",
      "Epoch 1, Batch 101400, Loss: 0.0025668013840913773\n",
      "Epoch 1, Batch 101450, Loss: 0.3999766409397125\n",
      "Epoch 1, Batch 101500, Loss: 0.002462533302605152\n",
      "Epoch 1, Batch 101550, Loss: 0.0020019470248371363\n",
      "Epoch 1, Batch 101600, Loss: 0.0016163698164746165\n",
      "Epoch 1, Batch 101650, Loss: 0.0012233146699145436\n",
      "Epoch 1, Batch 101700, Loss: 0.0018305758712813258\n",
      "Epoch 1, Batch 101750, Loss: 0.001282940967939794\n",
      "Epoch 1, Batch 101800, Loss: 0.0017794318264350295\n",
      "Epoch 1, Batch 101850, Loss: 0.0025140242651104927\n",
      "Epoch 1, Batch 101900, Loss: 0.0019757389090955257\n",
      "Epoch 1, Batch 101950, Loss: 0.0019401258323341608\n",
      "Epoch 1, Batch 102000, Loss: 0.001744128530845046\n",
      "Epoch 1, Batch 102050, Loss: 0.001669401885010302\n",
      "Epoch 1, Batch 102100, Loss: 0.0016329449135810137\n",
      "Epoch 1, Batch 102150, Loss: 0.0012549624079838395\n",
      "Epoch 1, Batch 102200, Loss: 0.002700843382626772\n",
      "Epoch 1, Batch 102250, Loss: 0.0019368425710126758\n",
      "Epoch 1, Batch 102300, Loss: 0.0016054356237873435\n",
      "Epoch 1, Batch 102350, Loss: 0.0013804706977680326\n",
      "Epoch 1, Batch 102400, Loss: 0.0025671187322586775\n",
      "Epoch 1, Batch 102450, Loss: 0.002380761317908764\n",
      "Epoch 1, Batch 102500, Loss: 0.002314954064786434\n",
      "Epoch 1, Batch 102550, Loss: 0.0018448458286002278\n",
      "Epoch 1, Batch 102600, Loss: 0.0012768579181283712\n",
      "Epoch 1, Batch 102650, Loss: 0.0012598141329362988\n",
      "Epoch 1, Batch 102700, Loss: 0.0018809379544109106\n",
      "Epoch 1, Batch 102750, Loss: 0.001813374925404787\n",
      "Epoch 1, Batch 102800, Loss: 0.0017984542064368725\n",
      "Epoch 1, Batch 102850, Loss: 0.003923991695046425\n",
      "Epoch 1, Batch 102900, Loss: 0.00424604769796133\n",
      "Epoch 1, Batch 102950, Loss: 0.002489248523488641\n",
      "Epoch 1, Batch 103000, Loss: 0.0019420746248215437\n",
      "Epoch 1, Batch 103050, Loss: 0.0018293540924787521\n",
      "Epoch 1, Batch 103100, Loss: 0.0016724044689908624\n",
      "Epoch 1, Batch 103150, Loss: 0.0017523119458928704\n",
      "Epoch 1, Batch 103200, Loss: 0.0014451057650148869\n",
      "Epoch 1, Batch 103250, Loss: 0.0036609682720154524\n",
      "Epoch 1, Batch 103300, Loss: 0.003533590817824006\n",
      "Epoch 1, Batch 103350, Loss: 0.002165992045775056\n",
      "Epoch 1, Batch 103400, Loss: 0.0033345273695886135\n",
      "Epoch 1, Batch 103450, Loss: 0.003879827680066228\n",
      "Epoch 1, Batch 103500, Loss: 0.003370906924828887\n",
      "Epoch 1, Batch 103550, Loss: 0.003008850384503603\n",
      "Epoch 1, Batch 103600, Loss: 0.002585617359727621\n",
      "Epoch 1, Batch 103650, Loss: 0.38242414593696594\n",
      "Epoch 1, Batch 103700, Loss: 0.00311452173627913\n",
      "Epoch 1, Batch 103750, Loss: 0.0022348077036440372\n",
      "Epoch 1, Batch 103800, Loss: 0.002052479423582554\n",
      "Epoch 1, Batch 103850, Loss: 0.002170865423977375\n",
      "Epoch 1, Batch 103900, Loss: 0.001533042173832655\n",
      "Epoch 1, Batch 103950, Loss: 0.001647702418267727\n",
      "Epoch 1, Batch 104000, Loss: 0.002881332067772746\n",
      "Epoch 1, Batch 104050, Loss: 0.002941465936601162\n",
      "Epoch 1, Batch 104100, Loss: 0.0022134752944111824\n",
      "Epoch 1, Batch 104150, Loss: 0.0019102165242657065\n",
      "Epoch 1, Batch 104200, Loss: 0.0024017139803618193\n",
      "Epoch 1, Batch 104250, Loss: 0.0022906148806214333\n",
      "Epoch 1, Batch 104300, Loss: 0.001793818548321724\n",
      "Epoch 1, Batch 104350, Loss: 0.0018463078886270523\n",
      "Epoch 1, Batch 104400, Loss: 0.0020723524503409863\n",
      "Epoch 1, Batch 104450, Loss: 0.0016981001244857907\n",
      "Epoch 1, Batch 104500, Loss: 0.3706858158111572\n",
      "Epoch 1, Batch 104550, Loss: 0.001276317285373807\n",
      "Epoch 1, Batch 104600, Loss: 0.001362424693070352\n",
      "Epoch 1, Batch 104650, Loss: 0.0013541870284825563\n",
      "Epoch 1, Batch 104700, Loss: 0.0010681136045604944\n",
      "Epoch 1, Batch 104750, Loss: 0.0008789784624241292\n",
      "Epoch 1, Batch 104800, Loss: 0.0012269410071894526\n",
      "Epoch 1, Batch 104850, Loss: 0.0021471588406711817\n",
      "Epoch 1, Batch 104900, Loss: 0.0014103634748607874\n",
      "Epoch 1, Batch 104950, Loss: 0.0017965625738725066\n",
      "Epoch 1, Batch 105000, Loss: 0.0034259685780853033\n",
      "Epoch 1, Batch 105050, Loss: 0.002734101377427578\n",
      "Epoch 1, Batch 105100, Loss: 0.0025616774801164865\n",
      "Epoch 1, Batch 105150, Loss: 0.002150213345885277\n",
      "Epoch 1, Batch 105200, Loss: 0.0022033140994608402\n",
      "Epoch 1, Batch 105250, Loss: 0.0019405524944886565\n",
      "Epoch 1, Batch 105300, Loss: 0.0016618611989542842\n",
      "Epoch 1, Batch 105350, Loss: 0.3467872738838196\n",
      "Epoch 1, Batch 105400, Loss: 0.002249398734420538\n",
      "Epoch 1, Batch 105450, Loss: 0.0026602959260344505\n",
      "Epoch 1, Batch 105500, Loss: 0.0018409246113151312\n",
      "Epoch 1, Batch 105550, Loss: 0.001592910150066018\n",
      "Epoch 1, Batch 105600, Loss: 0.0015334978234022856\n",
      "Epoch 1, Batch 105650, Loss: 0.001693397993221879\n",
      "Epoch 1, Batch 105700, Loss: 0.001547453342936933\n",
      "Epoch 1, Batch 105750, Loss: 0.0013464809162542224\n",
      "Epoch 1, Batch 105800, Loss: 0.0020718665327876806\n",
      "Epoch 1, Batch 105850, Loss: 0.3445335924625397\n",
      "Epoch 1, Batch 105900, Loss: 0.0026987893506884575\n",
      "Epoch 1, Batch 105950, Loss: 0.00223780726082623\n",
      "Epoch 1, Batch 106000, Loss: 0.002138917800039053\n",
      "Epoch 1, Batch 106050, Loss: 0.0026904079131782055\n",
      "Epoch 1, Batch 106100, Loss: 0.0024988760706037283\n",
      "Epoch 1, Batch 106150, Loss: 0.002126422943547368\n",
      "Epoch 1, Batch 106200, Loss: 0.002343993866816163\n",
      "Epoch 1, Batch 106250, Loss: 0.0018511435482650995\n",
      "Epoch 1, Batch 106300, Loss: 0.001789851114153862\n",
      "Epoch 1, Batch 106350, Loss: 0.0018384194700047374\n",
      "Epoch 1, Batch 106400, Loss: 0.0021723154932260513\n",
      "Epoch 1, Batch 106450, Loss: 0.002948801266029477\n",
      "Epoch 1, Batch 106500, Loss: 0.0027169857639819384\n",
      "Epoch 1, Batch 106550, Loss: 0.0025535293389111757\n",
      "Epoch 1, Batch 106600, Loss: 0.00273665483109653\n",
      "Epoch 1, Batch 106650, Loss: 0.0027430446352809668\n",
      "Epoch 1, Batch 106700, Loss: 0.0018010413041338325\n",
      "Epoch 1, Batch 106750, Loss: 0.0019156377529725432\n",
      "Epoch 1, Batch 106800, Loss: 0.0016317241825163364\n",
      "Epoch 1, Batch 106850, Loss: 0.0018309539882466197\n",
      "Epoch 1, Batch 106900, Loss: 0.0022511195857077837\n",
      "Epoch 1, Batch 106950, Loss: 0.002963089384138584\n",
      "Epoch 1, Batch 107000, Loss: 0.0023875434417277575\n",
      "Epoch 1, Batch 107050, Loss: 0.0023022955283522606\n",
      "Epoch 1, Batch 107100, Loss: 0.002195139182731509\n",
      "Epoch 1, Batch 107150, Loss: 0.001863136189058423\n",
      "Epoch 1, Batch 107200, Loss: 0.0018348859157413244\n",
      "Epoch 1, Batch 107250, Loss: 0.0018851050408557057\n",
      "Epoch 1, Batch 107300, Loss: 0.0019072734285145998\n",
      "Epoch 1, Batch 107350, Loss: 0.0018824111903086305\n",
      "Epoch 1, Batch 107400, Loss: 0.00226367125287652\n",
      "Epoch 1, Batch 107450, Loss: 0.0027830014005303383\n",
      "Epoch 1, Batch 107500, Loss: 0.002052992582321167\n",
      "Epoch 1, Batch 107550, Loss: 0.002540730871260166\n",
      "Epoch 1, Batch 107600, Loss: 0.0031676487997174263\n",
      "Epoch 1, Batch 107650, Loss: 0.002320546656847\n",
      "Epoch 1, Batch 107700, Loss: 0.002037118189036846\n",
      "Epoch 1, Batch 107750, Loss: 0.0023133275099098682\n",
      "Epoch 1, Batch 107800, Loss: 0.002637035446241498\n",
      "Epoch 1, Batch 107850, Loss: 0.002257821150124073\n",
      "Epoch 1, Batch 107900, Loss: 0.0019567874260246754\n",
      "Epoch 1, Batch 107950, Loss: 0.0014968577306717634\n",
      "Epoch 1, Batch 108000, Loss: 0.0017978971591219306\n",
      "Epoch 1, Batch 108050, Loss: 0.002119552344083786\n",
      "Epoch 1, Batch 108100, Loss: 0.0013659765245392919\n",
      "Epoch 1, Batch 108150, Loss: 0.4073081910610199\n",
      "Epoch 1, Batch 108200, Loss: 0.002821527887135744\n",
      "Epoch 1, Batch 108250, Loss: 0.001668754150159657\n",
      "Epoch 1, Batch 108300, Loss: 0.0016024692449718714\n",
      "Epoch 1, Batch 108350, Loss: 0.001390642486512661\n",
      "Epoch 1, Batch 108400, Loss: 0.0016455530421808362\n",
      "Epoch 1, Batch 108450, Loss: 0.001897243200801313\n",
      "Epoch 1, Batch 108500, Loss: 0.0012999165337532759\n",
      "Epoch 1, Batch 108550, Loss: 0.0020912669133394957\n",
      "Epoch 1, Batch 108600, Loss: 0.0019361203303560615\n",
      "Epoch 1, Batch 108650, Loss: 0.002026443835347891\n",
      "Epoch 1, Batch 108700, Loss: 0.0015807932941243052\n",
      "Epoch 1, Batch 108750, Loss: 0.0014546550810337067\n",
      "Epoch 1, Batch 108800, Loss: 0.001526823383755982\n",
      "Epoch 1, Batch 108850, Loss: 0.00112611660733819\n",
      "Epoch 1, Batch 108900, Loss: 0.0012971980031579733\n",
      "Epoch 1, Batch 108950, Loss: 0.002205335069447756\n",
      "Epoch 1, Batch 109000, Loss: 0.0022845743224024773\n",
      "Epoch 1, Batch 109050, Loss: 0.39518222212791443\n",
      "Epoch 1, Batch 109100, Loss: 0.0016490041743963957\n",
      "Epoch 1, Batch 109150, Loss: 0.0011507930466905236\n",
      "Epoch 1, Batch 109200, Loss: 0.0010721207363530993\n",
      "Epoch 1, Batch 109250, Loss: 0.0016920429188758135\n",
      "Epoch 1, Batch 109300, Loss: 0.0020365410018712282\n",
      "Epoch 1, Batch 109350, Loss: 0.0016692300559952855\n",
      "Epoch 1, Batch 109400, Loss: 0.001518108882009983\n",
      "Epoch 1, Batch 109450, Loss: 0.0021392428316175938\n",
      "Epoch 1, Batch 109500, Loss: 0.0024411892518401146\n",
      "Epoch 1, Batch 109550, Loss: 0.002017992315813899\n",
      "Epoch 1, Batch 109600, Loss: 0.40923139452934265\n",
      "Epoch 1, Batch 109650, Loss: 0.001686380128376186\n",
      "Epoch 1, Batch 109700, Loss: 0.001784385647624731\n",
      "Epoch 1, Batch 109750, Loss: 0.0014532182831317186\n",
      "Epoch 1, Batch 109800, Loss: 0.0014949701726436615\n",
      "Epoch 1, Batch 109850, Loss: 0.0015964234480634332\n",
      "Epoch 1, Batch 109900, Loss: 0.4387916624546051\n",
      "Epoch 1, Batch 109950, Loss: 0.0011582322185859084\n",
      "Epoch 1, Batch 110000, Loss: 0.00121586536988616\n",
      "Epoch 1, Batch 110050, Loss: 0.0022407383657991886\n",
      "Epoch 1, Batch 110100, Loss: 0.002055495511740446\n",
      "Epoch 1, Batch 110150, Loss: 0.0035499893128871918\n",
      "Epoch 1, Batch 110200, Loss: 0.36420783400535583\n",
      "Epoch 1, Batch 110250, Loss: 0.002586234826594591\n",
      "Epoch 1, Batch 110300, Loss: 0.0032350190449506044\n",
      "Epoch 1, Batch 110350, Loss: 0.002676605712622404\n",
      "Epoch 1, Batch 110400, Loss: 0.002403808059170842\n",
      "Epoch 1, Batch 110450, Loss: 0.0017730628605931997\n",
      "Epoch 1, Batch 110500, Loss: 0.0018312965985387564\n",
      "Epoch 1, Batch 110550, Loss: 0.002036737510934472\n",
      "Epoch 1, Batch 110600, Loss: 0.0021840312983840704\n",
      "Epoch 1, Batch 110650, Loss: 0.002708073705434799\n",
      "Epoch 1, Batch 110700, Loss: 0.0019220748217776418\n",
      "Epoch 1, Batch 110750, Loss: 0.0018287486163899302\n",
      "Epoch 1, Batch 110800, Loss: 0.002771108178421855\n",
      "Epoch 1, Batch 110850, Loss: 0.002650659531354904\n",
      "Epoch 1, Batch 110900, Loss: 0.001912322361022234\n",
      "Epoch 1, Batch 110950, Loss: 0.0027888561598956585\n",
      "Epoch 1, Batch 111000, Loss: 0.00254144542850554\n",
      "Epoch 1, Batch 111050, Loss: 0.00189922284334898\n",
      "Epoch 1, Batch 111100, Loss: 0.002542435657233\n",
      "Epoch 1, Batch 111150, Loss: 0.0019686634186655283\n",
      "Epoch 1, Batch 111200, Loss: 0.003665961790829897\n",
      "Epoch 1, Batch 111250, Loss: 0.0032137481030076742\n",
      "Epoch 1, Batch 111300, Loss: 0.003415209474042058\n",
      "Epoch 1, Batch 111350, Loss: 0.0022378447465598583\n",
      "Epoch 1, Batch 111400, Loss: 0.0019036580342799425\n",
      "Epoch 1, Batch 111450, Loss: 0.001561904326081276\n",
      "Epoch 1, Batch 111500, Loss: 0.0021898357663303614\n",
      "Epoch 1, Batch 111550, Loss: 0.001922684721648693\n",
      "Epoch 1, Batch 111600, Loss: 0.0016431999392807484\n",
      "Epoch 1, Batch 111650, Loss: 0.0015611567068845034\n",
      "Epoch 1, Batch 111700, Loss: 0.0015720046358183026\n",
      "Epoch 1, Batch 111750, Loss: 0.001469966839067638\n",
      "Epoch 1, Batch 111800, Loss: 0.3930424451828003\n",
      "Epoch 1, Batch 111850, Loss: 0.0027316042687743902\n",
      "Epoch 1, Batch 111900, Loss: 0.002598098712041974\n",
      "Epoch 1, Batch 111950, Loss: 0.0020977549720555544\n",
      "Epoch 1, Batch 112000, Loss: 0.0022454429417848587\n",
      "Epoch 1, Batch 112050, Loss: 0.0018034339882433414\n",
      "Epoch 1, Batch 112100, Loss: 0.0018682488007470965\n",
      "Epoch 1, Batch 112150, Loss: 0.0023289017844945192\n",
      "Epoch 1, Batch 112200, Loss: 0.002455639885738492\n",
      "Epoch 1, Batch 112250, Loss: 0.0019275560043752193\n",
      "Epoch 1, Batch 112300, Loss: 0.0024890315253287554\n",
      "Epoch 1, Batch 112350, Loss: 0.3678782284259796\n",
      "Epoch 1, Batch 112400, Loss: 0.0018880236893892288\n",
      "Epoch 1, Batch 112450, Loss: 0.0019106894033029675\n",
      "Epoch 1, Batch 112500, Loss: 0.001698268810287118\n",
      "Epoch 2, Batch 50, Loss: 0.001809680717997253\n",
      "Epoch 2, Batch 100, Loss: 0.0014334372244775295\n",
      "Epoch 2, Batch 150, Loss: 0.0012955130077898502\n",
      "Epoch 2, Batch 200, Loss: 0.8014101982116699\n",
      "Epoch 2, Batch 250, Loss: 0.0013168146833777428\n",
      "Epoch 2, Batch 300, Loss: 0.001253753900527954\n",
      "Epoch 2, Batch 350, Loss: 0.001103934831917286\n",
      "Epoch 2, Batch 400, Loss: 0.001424770918674767\n",
      "Epoch 2, Batch 450, Loss: 0.0017585837049409747\n",
      "Epoch 2, Batch 500, Loss: 0.0016112590674310923\n",
      "Epoch 2, Batch 550, Loss: 0.0025359520222991705\n",
      "Epoch 2, Batch 600, Loss: 0.0023611963260918856\n",
      "Epoch 2, Batch 650, Loss: 0.0036127702333033085\n",
      "Epoch 2, Batch 700, Loss: 0.0030303101520985365\n",
      "Epoch 2, Batch 750, Loss: 0.002336757490411401\n",
      "Epoch 2, Batch 800, Loss: 0.0022964386735111475\n",
      "Epoch 2, Batch 850, Loss: 0.0025333070661872625\n",
      "Epoch 2, Batch 900, Loss: 0.0017576342215761542\n",
      "Epoch 2, Batch 950, Loss: 0.0018362683476880193\n",
      "Epoch 2, Batch 1000, Loss: 0.002598779508844018\n",
      "Epoch 2, Batch 1050, Loss: 0.002124708378687501\n",
      "Epoch 2, Batch 1100, Loss: 0.0019434160785749555\n",
      "Epoch 2, Batch 1150, Loss: 0.002490795450285077\n",
      "Epoch 2, Batch 1200, Loss: 0.003423712681978941\n",
      "Epoch 2, Batch 1250, Loss: 0.0019277660176157951\n",
      "Epoch 2, Batch 1300, Loss: 0.0028012224938720465\n",
      "Epoch 2, Batch 1350, Loss: 0.0022531577851623297\n",
      "Epoch 2, Batch 1400, Loss: 0.0025926411617547274\n",
      "Epoch 2, Batch 1450, Loss: 0.0035152549389749765\n",
      "Epoch 2, Batch 1500, Loss: 0.002429373562335968\n",
      "Epoch 2, Batch 1550, Loss: 0.0027940692380070686\n",
      "Epoch 2, Batch 1600, Loss: 0.002977960277348757\n",
      "Epoch 2, Batch 1650, Loss: 0.002172998618334532\n",
      "Epoch 2, Batch 1700, Loss: 0.0017684197518974543\n",
      "Epoch 2, Batch 1750, Loss: 0.0014717411249876022\n",
      "Epoch 2, Batch 1800, Loss: 0.001973685109987855\n",
      "Epoch 2, Batch 1850, Loss: 0.0016755486140027642\n",
      "Epoch 2, Batch 1900, Loss: 0.0016670592594891787\n",
      "Epoch 2, Batch 1950, Loss: 0.0015795552171766758\n",
      "Epoch 2, Batch 2000, Loss: 0.0015756681095808744\n",
      "Epoch 2, Batch 2050, Loss: 0.0019396942807361484\n",
      "Epoch 2, Batch 2100, Loss: 0.0016017213929444551\n",
      "Epoch 2, Batch 2150, Loss: 0.0020839031785726547\n",
      "Epoch 2, Batch 2200, Loss: 0.0016453319694846869\n",
      "Epoch 2, Batch 2250, Loss: 0.001297204988077283\n",
      "Epoch 2, Batch 2300, Loss: 0.00179016194306314\n",
      "Epoch 2, Batch 2350, Loss: 0.002050400013104081\n",
      "Epoch 2, Batch 2400, Loss: 0.002222814131528139\n",
      "Epoch 2, Batch 2450, Loss: 0.0024645780213177204\n",
      "Epoch 2, Batch 2500, Loss: 0.002800067886710167\n",
      "Epoch 2, Batch 2550, Loss: 0.41412264108657837\n",
      "Epoch 2, Batch 2600, Loss: 0.0030605373904109\n",
      "Epoch 2, Batch 2650, Loss: 0.00270757800899446\n",
      "Epoch 2, Batch 2700, Loss: 0.002420685486868024\n",
      "Epoch 2, Batch 2750, Loss: 0.0019050410483032465\n",
      "Epoch 2, Batch 2800, Loss: 0.40332499146461487\n",
      "Epoch 2, Batch 2850, Loss: 0.002434234833344817\n",
      "Epoch 2, Batch 2900, Loss: 0.00318068522028625\n",
      "Epoch 2, Batch 2950, Loss: 0.0024305193219333887\n",
      "Epoch 2, Batch 3000, Loss: 0.002090785186737776\n",
      "Epoch 2, Batch 3050, Loss: 0.0025787099730223417\n",
      "Epoch 2, Batch 3100, Loss: 0.0018634917214512825\n",
      "Epoch 2, Batch 3150, Loss: 0.0016190782189369202\n",
      "Epoch 2, Batch 3200, Loss: 0.0019344347529113293\n",
      "Epoch 2, Batch 3250, Loss: 0.0016994238831102848\n",
      "Epoch 2, Batch 3300, Loss: 0.0020822109654545784\n",
      "Epoch 2, Batch 3350, Loss: 0.00205373321659863\n",
      "Epoch 2, Batch 3400, Loss: 0.0022294693626463413\n",
      "Epoch 2, Batch 3450, Loss: 0.0024491227231919765\n",
      "Epoch 2, Batch 3500, Loss: 0.0017302115447819233\n",
      "Epoch 2, Batch 3550, Loss: 0.0014862255193293095\n",
      "Epoch 2, Batch 3600, Loss: 0.002104881452396512\n",
      "Epoch 2, Batch 3650, Loss: 0.0016417561564594507\n",
      "Epoch 2, Batch 3700, Loss: 0.0011643798789009452\n",
      "Epoch 2, Batch 3750, Loss: 0.0015753370244055986\n",
      "Epoch 2, Batch 3800, Loss: 0.00165635219309479\n",
      "Epoch 2, Batch 3850, Loss: 0.0014424900291487575\n",
      "Epoch 2, Batch 3900, Loss: 0.001522202044725418\n",
      "Epoch 2, Batch 3950, Loss: 0.001331666368059814\n",
      "Epoch 2, Batch 4000, Loss: 0.0016683416906744242\n",
      "Epoch 2, Batch 4050, Loss: 0.002090614754706621\n",
      "Epoch 2, Batch 4100, Loss: 0.0013256840175017715\n",
      "Epoch 2, Batch 4150, Loss: 0.0022105304524302483\n",
      "Epoch 2, Batch 4200, Loss: 0.002673339331522584\n",
      "Epoch 2, Batch 4250, Loss: 0.002632084069773555\n",
      "Epoch 2, Batch 4300, Loss: 0.003333242144435644\n",
      "Epoch 2, Batch 4350, Loss: 0.003999381326138973\n",
      "Epoch 2, Batch 4400, Loss: 0.0022031893022358418\n",
      "Epoch 2, Batch 4450, Loss: 0.0018802299164235592\n",
      "Epoch 2, Batch 4500, Loss: 0.0014794653980061412\n",
      "Epoch 2, Batch 4550, Loss: 0.38729074597358704\n",
      "Epoch 2, Batch 4600, Loss: 0.0023698192089796066\n",
      "Epoch 2, Batch 4650, Loss: 0.002628954127430916\n",
      "Epoch 2, Batch 4700, Loss: 0.0030294498428702354\n",
      "Epoch 2, Batch 4750, Loss: 0.40406206250190735\n",
      "Epoch 2, Batch 4800, Loss: 0.001724080415442586\n",
      "Epoch 2, Batch 4850, Loss: 0.002592122182250023\n",
      "Epoch 2, Batch 4900, Loss: 0.0018220923375338316\n",
      "Epoch 2, Batch 4950, Loss: 0.0020590610802173615\n",
      "Epoch 2, Batch 5000, Loss: 0.0017094771610572934\n",
      "Epoch 2, Batch 5050, Loss: 0.0016613919287919998\n",
      "Epoch 2, Batch 5100, Loss: 0.0017515101935714483\n",
      "Epoch 2, Batch 5150, Loss: 0.001258927513845265\n",
      "Epoch 2, Batch 5200, Loss: 0.001986063551157713\n",
      "Epoch 2, Batch 5250, Loss: 0.0019861680921167135\n",
      "Epoch 2, Batch 5300, Loss: 0.0014537298120558262\n",
      "Epoch 2, Batch 5350, Loss: 0.001886384328827262\n",
      "Epoch 2, Batch 5400, Loss: 0.002174098277464509\n",
      "Epoch 2, Batch 5450, Loss: 0.0016095357714220881\n",
      "Epoch 2, Batch 5500, Loss: 0.0020727680530399084\n",
      "Epoch 2, Batch 5550, Loss: 0.0019175588386133313\n",
      "Epoch 2, Batch 5600, Loss: 0.001500629587098956\n",
      "Epoch 2, Batch 5650, Loss: 0.001693839207291603\n",
      "Epoch 2, Batch 5700, Loss: 0.0027058827690780163\n",
      "Epoch 2, Batch 5750, Loss: 0.0022995437029749155\n",
      "Epoch 2, Batch 5800, Loss: 0.0023957788944244385\n",
      "Epoch 2, Batch 5850, Loss: 0.0016919473418965936\n",
      "Epoch 2, Batch 5900, Loss: 0.0014339733170345426\n",
      "Epoch 2, Batch 5950, Loss: 0.0013952862937003374\n",
      "Epoch 2, Batch 6000, Loss: 0.0013695525703951716\n",
      "Epoch 2, Batch 6050, Loss: 0.0013054299633949995\n",
      "Epoch 2, Batch 6100, Loss: 0.0021292236633598804\n",
      "Epoch 2, Batch 6150, Loss: 0.0029235095717012882\n",
      "Epoch 2, Batch 6200, Loss: 0.0030845580622553825\n",
      "Epoch 2, Batch 6250, Loss: 0.002628289395943284\n",
      "Epoch 2, Batch 6300, Loss: 0.0035102004185318947\n",
      "Epoch 2, Batch 6350, Loss: 0.0026862791273742914\n",
      "Epoch 2, Batch 6400, Loss: 0.0020622997544705868\n",
      "Epoch 2, Batch 6450, Loss: 0.002549511846154928\n",
      "Epoch 2, Batch 6500, Loss: 0.0029173369985073805\n",
      "Epoch 2, Batch 6550, Loss: 0.0029282281175255775\n",
      "Epoch 2, Batch 6600, Loss: 0.0025080349296331406\n",
      "Epoch 2, Batch 6650, Loss: 0.0024214850272983313\n",
      "Epoch 2, Batch 6700, Loss: 0.00278824707493186\n",
      "Epoch 2, Batch 6750, Loss: 0.0022600963711738586\n",
      "Epoch 2, Batch 6800, Loss: 0.0022824753541499376\n",
      "Epoch 2, Batch 6850, Loss: 0.407694935798645\n",
      "Epoch 2, Batch 6900, Loss: 0.37056639790534973\n",
      "Epoch 2, Batch 6950, Loss: 0.0022900495678186417\n",
      "Epoch 2, Batch 7000, Loss: 0.0017998703988268971\n",
      "Epoch 2, Batch 7050, Loss: 0.001751614734530449\n",
      "Epoch 2, Batch 7100, Loss: 0.0015241061337292194\n",
      "Epoch 2, Batch 7150, Loss: 0.0015674425521865487\n",
      "Epoch 2, Batch 7200, Loss: 0.0015165159711614251\n",
      "Epoch 2, Batch 7250, Loss: 0.0017816814361140132\n",
      "Epoch 2, Batch 7300, Loss: 0.002176266862079501\n",
      "Epoch 2, Batch 7350, Loss: 0.0034091556444764137\n",
      "Epoch 2, Batch 7400, Loss: 0.0033341285306960344\n",
      "Epoch 2, Batch 7450, Loss: 0.00229082815349102\n",
      "Epoch 2, Batch 7500, Loss: 0.0015017041005194187\n",
      "Epoch 2, Batch 7550, Loss: 0.0016541616059839725\n",
      "Epoch 2, Batch 7600, Loss: 0.001865685684606433\n",
      "Epoch 2, Batch 7650, Loss: 0.0018380089895799756\n",
      "Epoch 2, Batch 7700, Loss: 0.0013085947139188647\n",
      "Epoch 2, Batch 7750, Loss: 0.3798723518848419\n",
      "Epoch 2, Batch 7800, Loss: 0.0024985666386783123\n",
      "Epoch 2, Batch 7850, Loss: 0.0021945408079773188\n",
      "Epoch 2, Batch 7900, Loss: 0.0013914710143581033\n",
      "Epoch 2, Batch 7950, Loss: 0.0015638736076653004\n",
      "Epoch 2, Batch 8000, Loss: 0.3976843059062958\n",
      "Epoch 2, Batch 8050, Loss: 0.0018213799921795726\n",
      "Epoch 2, Batch 8100, Loss: 0.002151023130863905\n",
      "Epoch 2, Batch 8150, Loss: 0.001910533756017685\n",
      "Epoch 2, Batch 8200, Loss: 0.0015387332532554865\n",
      "Epoch 2, Batch 8250, Loss: 0.0017791077261790633\n",
      "Epoch 2, Batch 8300, Loss: 0.0014266627840697765\n",
      "Epoch 2, Batch 8350, Loss: 0.0013728138292208314\n",
      "Epoch 2, Batch 8400, Loss: 0.00104811682831496\n",
      "Epoch 2, Batch 8450, Loss: 0.0010451092384755611\n",
      "Epoch 2, Batch 8500, Loss: 0.0008699792088009417\n",
      "Epoch 2, Batch 8550, Loss: 0.0009880312718451023\n",
      "Epoch 2, Batch 8600, Loss: 0.001355506363324821\n",
      "Epoch 2, Batch 8650, Loss: 0.0017168004997074604\n",
      "Epoch 2, Batch 8700, Loss: 0.0013318054843693972\n",
      "Epoch 2, Batch 8750, Loss: 0.0014823185047134757\n",
      "Epoch 2, Batch 8800, Loss: 0.001882110140286386\n",
      "Epoch 2, Batch 8850, Loss: 0.0019072521245107055\n",
      "Epoch 2, Batch 8900, Loss: 0.001565713668242097\n",
      "Epoch 2, Batch 8950, Loss: 0.001671999809332192\n",
      "Epoch 2, Batch 9000, Loss: 0.0017892264295369387\n",
      "Epoch 2, Batch 9050, Loss: 0.0011906120926141739\n",
      "Epoch 2, Batch 9100, Loss: 0.001289116800762713\n",
      "Epoch 2, Batch 9150, Loss: 0.002021388616412878\n",
      "Epoch 2, Batch 9200, Loss: 0.003796688746660948\n",
      "Epoch 2, Batch 9250, Loss: 0.002845723181962967\n",
      "Epoch 2, Batch 9300, Loss: 0.002303820801898837\n",
      "Epoch 2, Batch 9350, Loss: 0.00168230093549937\n",
      "Epoch 2, Batch 9400, Loss: 0.001936324406415224\n",
      "Epoch 2, Batch 9450, Loss: 0.0016308933263644576\n",
      "Epoch 2, Batch 9500, Loss: 0.0020138106774538755\n",
      "Epoch 2, Batch 9550, Loss: 0.0014219393488019705\n",
      "Epoch 2, Batch 9600, Loss: 0.0010807376820594072\n",
      "Epoch 2, Batch 9650, Loss: 0.0010016349842771888\n",
      "Epoch 2, Batch 9700, Loss: 0.0010686208261176944\n",
      "Epoch 2, Batch 9750, Loss: 0.001259750104509294\n",
      "Epoch 2, Batch 9800, Loss: 0.0015267619164660573\n",
      "Epoch 2, Batch 9850, Loss: 0.00166987010743469\n",
      "Epoch 2, Batch 9900, Loss: 0.0016630407189950347\n",
      "Epoch 2, Batch 9950, Loss: 0.0021204364020377398\n",
      "Epoch 2, Batch 10000, Loss: 0.0030876442324370146\n",
      "Epoch 2, Batch 10050, Loss: 0.002327227033674717\n",
      "Epoch 2, Batch 10100, Loss: 0.00185131817124784\n",
      "Epoch 2, Batch 10150, Loss: 0.001995331607758999\n",
      "Epoch 2, Batch 10200, Loss: 0.0017906732391566038\n",
      "Epoch 2, Batch 10250, Loss: 0.002035001991316676\n",
      "Epoch 2, Batch 10300, Loss: 0.40485242009162903\n",
      "Epoch 2, Batch 10350, Loss: 0.002777588088065386\n",
      "Epoch 2, Batch 10400, Loss: 0.003201852785423398\n",
      "Epoch 2, Batch 10450, Loss: 0.4053497910499573\n",
      "Epoch 2, Batch 10500, Loss: 0.0024352462496608496\n",
      "Epoch 2, Batch 10550, Loss: 0.002396814990788698\n",
      "Epoch 2, Batch 10600, Loss: 0.004018227104097605\n",
      "Epoch 2, Batch 10650, Loss: 0.0023997812531888485\n",
      "Epoch 2, Batch 10700, Loss: 0.0029859577771276236\n",
      "Epoch 2, Batch 10750, Loss: 0.003802377264946699\n",
      "Epoch 2, Batch 10800, Loss: 0.0032384428195655346\n",
      "Epoch 2, Batch 10850, Loss: 0.002414962276816368\n",
      "Epoch 2, Batch 10900, Loss: 0.001854808651842177\n",
      "Epoch 2, Batch 10950, Loss: 0.0016341164009645581\n",
      "Epoch 2, Batch 11000, Loss: 0.0014655333943665028\n",
      "Epoch 2, Batch 11050, Loss: 0.0018001082353293896\n",
      "Epoch 2, Batch 11100, Loss: 0.0016096712788566947\n",
      "Epoch 2, Batch 11150, Loss: 0.0017116694943979383\n",
      "Epoch 2, Batch 11200, Loss: 0.0019092551665380597\n",
      "Epoch 2, Batch 11250, Loss: 0.0020081547554582357\n",
      "Epoch 2, Batch 11300, Loss: 0.002203114330768585\n",
      "Epoch 2, Batch 11350, Loss: 0.001977092819288373\n",
      "Epoch 2, Batch 11400, Loss: 0.0020281190518289804\n",
      "Epoch 2, Batch 11450, Loss: 0.0017688035732135177\n",
      "Epoch 2, Batch 11500, Loss: 0.0019227355951443315\n",
      "Epoch 2, Batch 11550, Loss: 0.0019599399529397488\n",
      "Epoch 2, Batch 11600, Loss: 0.0013274741359055042\n",
      "Epoch 2, Batch 11650, Loss: 0.0013728596968576312\n",
      "Epoch 2, Batch 11700, Loss: 0.001427573966793716\n",
      "Epoch 2, Batch 11750, Loss: 0.0014769906410947442\n",
      "Epoch 2, Batch 11800, Loss: 0.0017080290708690882\n",
      "Epoch 2, Batch 11850, Loss: 0.0026596346870064735\n",
      "Epoch 2, Batch 11900, Loss: 0.003906016005203128\n",
      "Epoch 2, Batch 11950, Loss: 0.0040526664815843105\n",
      "Epoch 2, Batch 12000, Loss: 0.00256837485358119\n",
      "Epoch 2, Batch 12050, Loss: 0.0020029041916131973\n",
      "Epoch 2, Batch 12100, Loss: 0.0027165531646460295\n",
      "Epoch 2, Batch 12150, Loss: 0.002502121962606907\n",
      "Epoch 2, Batch 12200, Loss: 0.0024023656733334064\n",
      "Epoch 2, Batch 12250, Loss: 0.0022618607617914677\n",
      "Epoch 2, Batch 12300, Loss: 0.0015584593638777733\n",
      "Epoch 2, Batch 12350, Loss: 0.0018677051411941648\n",
      "Epoch 2, Batch 12400, Loss: 0.001654419000260532\n",
      "Epoch 2, Batch 12450, Loss: 0.0019270575139671564\n",
      "Epoch 2, Batch 12500, Loss: 0.39476510882377625\n",
      "Epoch 2, Batch 12550, Loss: 0.0021052067168056965\n",
      "Epoch 2, Batch 12600, Loss: 0.0027303406968712807\n",
      "Epoch 2, Batch 12650, Loss: 0.004285880830138922\n",
      "Epoch 2, Batch 12700, Loss: 0.003120794892311096\n",
      "Epoch 2, Batch 12750, Loss: 0.0022081665229052305\n",
      "Epoch 2, Batch 12800, Loss: 0.41345393657684326\n",
      "Epoch 2, Batch 12850, Loss: 0.0017372309230268002\n",
      "Epoch 2, Batch 12900, Loss: 0.0019284395966678858\n",
      "Epoch 2, Batch 12950, Loss: 0.0012629155535250902\n",
      "Epoch 2, Batch 13000, Loss: 0.001475876197218895\n",
      "Epoch 2, Batch 13050, Loss: 0.001167725189588964\n",
      "Epoch 2, Batch 13100, Loss: 0.0013008321402594447\n",
      "Epoch 2, Batch 13150, Loss: 0.002238851971924305\n",
      "Epoch 2, Batch 13200, Loss: 0.0027468123007565737\n",
      "Epoch 2, Batch 13250, Loss: 0.004983227699995041\n",
      "Epoch 2, Batch 13300, Loss: 0.3755045235157013\n",
      "Epoch 2, Batch 13350, Loss: 0.003183032851666212\n",
      "Epoch 2, Batch 13400, Loss: 0.0030143666081130505\n",
      "Epoch 2, Batch 13450, Loss: 0.0028366365004330873\n",
      "Epoch 2, Batch 13500, Loss: 0.0023792008869349957\n",
      "Epoch 2, Batch 13550, Loss: 0.0025537237524986267\n",
      "Epoch 2, Batch 13600, Loss: 0.00236071296967566\n",
      "Epoch 2, Batch 13650, Loss: 0.002303076209500432\n",
      "Epoch 2, Batch 13700, Loss: 0.002393681090325117\n",
      "Epoch 2, Batch 13750, Loss: 0.0023348727263510227\n",
      "Epoch 2, Batch 13800, Loss: 0.0017180147115141153\n",
      "Epoch 2, Batch 13850, Loss: 0.0013700402341783047\n",
      "Epoch 2, Batch 13900, Loss: 0.0017029219307005405\n",
      "Epoch 2, Batch 13950, Loss: 0.0015272449236363173\n",
      "Epoch 2, Batch 14000, Loss: 0.0012282999232411385\n",
      "Epoch 2, Batch 14050, Loss: 0.001630411366932094\n",
      "Epoch 2, Batch 14100, Loss: 0.0017455299384891987\n",
      "Epoch 2, Batch 14150, Loss: 0.0016529285348951817\n",
      "Epoch 2, Batch 14200, Loss: 0.001971926772966981\n",
      "Epoch 2, Batch 14250, Loss: 0.002236871048808098\n",
      "Epoch 2, Batch 14300, Loss: 0.0037536034360527992\n",
      "Epoch 2, Batch 14350, Loss: 0.36535438895225525\n",
      "Epoch 2, Batch 14400, Loss: 0.0027864708099514246\n",
      "Epoch 2, Batch 14450, Loss: 0.0028871370013803244\n",
      "Epoch 2, Batch 14500, Loss: 0.002732242690399289\n",
      "Epoch 2, Batch 14550, Loss: 0.002166682155802846\n",
      "Epoch 2, Batch 14600, Loss: 0.0034431014209985733\n",
      "Epoch 2, Batch 14650, Loss: 0.002705356338992715\n",
      "Epoch 2, Batch 14700, Loss: 0.0027748935390263796\n",
      "Epoch 2, Batch 14750, Loss: 0.0035041039809584618\n",
      "Epoch 2, Batch 14800, Loss: 0.0031408595386892557\n",
      "Epoch 2, Batch 14850, Loss: 0.0021378188394010067\n",
      "Epoch 2, Batch 14900, Loss: 0.002807012991979718\n",
      "Epoch 2, Batch 14950, Loss: 0.003714408492669463\n",
      "Epoch 2, Batch 15000, Loss: 0.003236645134165883\n",
      "Epoch 2, Batch 15050, Loss: 0.002288982504978776\n",
      "Epoch 2, Batch 15100, Loss: 0.0022079525515437126\n",
      "Epoch 2, Batch 15150, Loss: 0.001972838304936886\n",
      "Epoch 2, Batch 15200, Loss: 0.001396929263137281\n",
      "Epoch 2, Batch 15250, Loss: 0.002228653756901622\n",
      "Epoch 2, Batch 15300, Loss: 0.0025224797427654266\n",
      "Epoch 2, Batch 15350, Loss: 0.0022423001937568188\n",
      "Epoch 2, Batch 15400, Loss: 0.003103474620729685\n",
      "Epoch 2, Batch 15450, Loss: 0.0021526918280869722\n",
      "Epoch 2, Batch 15500, Loss: 0.0034257695078849792\n",
      "Epoch 2, Batch 15550, Loss: 0.0026200776919722557\n",
      "Epoch 2, Batch 15600, Loss: 0.003257158910855651\n",
      "Epoch 2, Batch 15650, Loss: 0.0035073019098490477\n",
      "Epoch 2, Batch 15700, Loss: 0.002654206706210971\n",
      "Epoch 2, Batch 15750, Loss: 0.002932876581326127\n",
      "Epoch 2, Batch 15800, Loss: 0.0030133877880871296\n",
      "Epoch 2, Batch 15850, Loss: 0.0021208964753896\n",
      "Epoch 2, Batch 15900, Loss: 0.0016133284661918879\n",
      "Epoch 2, Batch 15950, Loss: 0.0015461491420865059\n",
      "Epoch 2, Batch 16000, Loss: 0.0015664263628423214\n",
      "Epoch 2, Batch 16050, Loss: 0.0018997805891558528\n",
      "Epoch 2, Batch 16100, Loss: 0.001249447581358254\n",
      "Epoch 2, Batch 16150, Loss: 0.0019682031124830246\n",
      "Epoch 2, Batch 16200, Loss: 0.002014978788793087\n",
      "Epoch 2, Batch 16250, Loss: 0.0017381084617227316\n",
      "Epoch 2, Batch 16300, Loss: 0.0016252531204372644\n",
      "Epoch 2, Batch 16350, Loss: 0.0015673107700422406\n",
      "Epoch 2, Batch 16400, Loss: 0.0016343699535354972\n",
      "Epoch 2, Batch 16450, Loss: 0.0013987746788188815\n",
      "Epoch 2, Batch 16500, Loss: 0.0014473292976617813\n",
      "Epoch 2, Batch 16550, Loss: 0.0014407583512365818\n",
      "Epoch 2, Batch 16600, Loss: 0.0023515396751463413\n",
      "Epoch 2, Batch 16650, Loss: 0.002383906627073884\n",
      "Epoch 2, Batch 16700, Loss: 0.001972784986719489\n",
      "Epoch 2, Batch 16750, Loss: 0.0022701758425682783\n",
      "Epoch 2, Batch 16800, Loss: 0.0031390266958624125\n",
      "Epoch 2, Batch 16850, Loss: 0.0035219902638345957\n",
      "Epoch 2, Batch 16900, Loss: 0.0033291904255747795\n",
      "Epoch 2, Batch 16950, Loss: 0.00262653105892241\n",
      "Epoch 2, Batch 17000, Loss: 0.002609414514154196\n",
      "Epoch 2, Batch 17050, Loss: 0.0024319100193679333\n",
      "Epoch 2, Batch 17100, Loss: 0.001634056679904461\n",
      "Epoch 2, Batch 17150, Loss: 0.0013301621656864882\n",
      "Epoch 2, Batch 17200, Loss: 0.0014174238312989473\n",
      "Epoch 2, Batch 17250, Loss: 0.002945597982034087\n",
      "Epoch 2, Batch 17300, Loss: 0.0026664447505027056\n",
      "Epoch 2, Batch 17350, Loss: 0.003555949544534087\n",
      "Epoch 2, Batch 17400, Loss: 0.0032162300776690245\n",
      "Epoch 2, Batch 17450, Loss: 0.002280522370710969\n",
      "Epoch 2, Batch 17500, Loss: 0.002868749899789691\n",
      "Epoch 2, Batch 17550, Loss: 0.0026273636613041162\n",
      "Epoch 2, Batch 17600, Loss: 0.002796860644593835\n",
      "Epoch 2, Batch 17650, Loss: 0.002283327979966998\n",
      "Epoch 2, Batch 17700, Loss: 0.0017246924107894301\n",
      "Epoch 2, Batch 17750, Loss: 0.0014922990230843425\n",
      "Epoch 2, Batch 17800, Loss: 0.3671746551990509\n",
      "Epoch 2, Batch 17850, Loss: 0.0023659919388592243\n",
      "Epoch 2, Batch 17900, Loss: 0.0022522963117808104\n",
      "Epoch 2, Batch 17950, Loss: 0.0020758972968906164\n",
      "Epoch 2, Batch 18000, Loss: 0.0024259123019874096\n",
      "Epoch 2, Batch 18050, Loss: 0.0028333324007689953\n",
      "Epoch 2, Batch 18100, Loss: 0.0025350027717649937\n",
      "Epoch 2, Batch 18150, Loss: 0.002066686050966382\n",
      "Epoch 2, Batch 18200, Loss: 0.0021518405992537737\n",
      "Epoch 2, Batch 18250, Loss: 0.0018000518903136253\n",
      "Epoch 2, Batch 18300, Loss: 0.001644158735871315\n",
      "Epoch 2, Batch 18350, Loss: 0.0015133541310206056\n",
      "Epoch 2, Batch 18400, Loss: 0.001887461869046092\n",
      "Epoch 2, Batch 18450, Loss: 0.0019113087328150868\n",
      "Epoch 2, Batch 18500, Loss: 0.0017431937158107758\n",
      "Epoch 2, Batch 18550, Loss: 0.0013402198674157262\n",
      "Epoch 2, Batch 18600, Loss: 0.0015922053717076778\n",
      "Epoch 2, Batch 18650, Loss: 0.39527130126953125\n",
      "Epoch 2, Batch 18700, Loss: 0.003087548539042473\n",
      "Epoch 2, Batch 18750, Loss: 0.0028228771407157183\n",
      "Epoch 2, Batch 18800, Loss: 0.00254029780626297\n",
      "Epoch 2, Batch 18850, Loss: 0.0019870942924171686\n",
      "Epoch 2, Batch 18900, Loss: 0.001634781016036868\n",
      "Epoch 2, Batch 18950, Loss: 0.0017719819443300366\n",
      "Epoch 2, Batch 19000, Loss: 0.0015819829422980547\n",
      "Epoch 2, Batch 19050, Loss: 0.0014237634604796767\n",
      "Epoch 2, Batch 19100, Loss: 0.0022813635878264904\n",
      "Epoch 2, Batch 19150, Loss: 0.0023405810352414846\n",
      "Epoch 2, Batch 19200, Loss: 0.002130562672391534\n",
      "Epoch 2, Batch 19250, Loss: 0.0019177038921043277\n",
      "Epoch 2, Batch 19300, Loss: 0.0015843346482142806\n",
      "Epoch 2, Batch 19350, Loss: 0.0029034060426056385\n",
      "Epoch 2, Batch 19400, Loss: 0.0021710307337343693\n",
      "Epoch 2, Batch 19450, Loss: 0.0014366930117830634\n",
      "Epoch 2, Batch 19500, Loss: 0.002464061602950096\n",
      "Epoch 2, Batch 19550, Loss: 0.003060746006667614\n",
      "Epoch 2, Batch 19600, Loss: 0.0039845481514930725\n",
      "Epoch 2, Batch 19650, Loss: 0.0035407040268182755\n",
      "Epoch 2, Batch 19700, Loss: 0.0035109135787934065\n",
      "Epoch 2, Batch 19750, Loss: 0.0023357649333775043\n",
      "Epoch 2, Batch 19800, Loss: 0.002108532004058361\n",
      "Epoch 2, Batch 19850, Loss: 0.0018638059264048934\n",
      "Epoch 2, Batch 19900, Loss: 0.0014374766033142805\n",
      "Epoch 2, Batch 19950, Loss: 0.0018822656711563468\n",
      "Epoch 2, Batch 20000, Loss: 0.0016018444439396262\n",
      "Epoch 2, Batch 20050, Loss: 0.0014676160644739866\n",
      "Epoch 2, Batch 20100, Loss: 0.0012623706134036183\n",
      "Epoch 2, Batch 20150, Loss: 0.0017799012130126357\n",
      "Epoch 2, Batch 20200, Loss: 0.001873507397249341\n",
      "Epoch 2, Batch 20250, Loss: 0.0027432620991021395\n",
      "Epoch 2, Batch 20300, Loss: 0.0021759115625172853\n",
      "Epoch 2, Batch 20350, Loss: 0.002377777826040983\n",
      "Epoch 2, Batch 20400, Loss: 0.003411722369492054\n",
      "Epoch 2, Batch 20450, Loss: 0.002961953403428197\n",
      "Epoch 2, Batch 20500, Loss: 0.002693976741284132\n",
      "Epoch 2, Batch 20550, Loss: 0.0029184597078710794\n",
      "Epoch 2, Batch 20600, Loss: 0.0033703488297760487\n",
      "Epoch 2, Batch 20650, Loss: 0.0031919146422296762\n",
      "Epoch 2, Batch 20700, Loss: 0.0025975117459893227\n",
      "Epoch 2, Batch 20750, Loss: 0.0017244006739929318\n",
      "Epoch 2, Batch 20800, Loss: 0.0020324401557445526\n",
      "Epoch 2, Batch 20850, Loss: 0.0016641670372337103\n",
      "Epoch 2, Batch 20900, Loss: 0.001240590587258339\n",
      "Epoch 2, Batch 20950, Loss: 0.0011610941728577018\n",
      "Epoch 2, Batch 21000, Loss: 0.001280597411096096\n",
      "Epoch 2, Batch 21050, Loss: 0.0015154745196923614\n",
      "Epoch 2, Batch 21100, Loss: 0.002810187404975295\n",
      "Epoch 2, Batch 21150, Loss: 0.003335407469421625\n",
      "Epoch 2, Batch 21200, Loss: 0.002751379506662488\n",
      "Epoch 2, Batch 21250, Loss: 0.002551975892856717\n",
      "Epoch 2, Batch 21300, Loss: 0.0019277726532891393\n",
      "Epoch 2, Batch 21350, Loss: 0.0024405072908848524\n",
      "Epoch 2, Batch 21400, Loss: 0.0018389229662716389\n",
      "Epoch 2, Batch 21450, Loss: 0.0019505341770127416\n",
      "Epoch 2, Batch 21500, Loss: 0.0017987665487453341\n",
      "Epoch 2, Batch 21550, Loss: 0.0015504419570788741\n",
      "Epoch 2, Batch 21600, Loss: 0.001519958139397204\n",
      "Epoch 2, Batch 21650, Loss: 0.0011099980911239982\n",
      "Epoch 2, Batch 21700, Loss: 0.0010016807354986668\n",
      "Epoch 2, Batch 21750, Loss: 0.001284047611989081\n",
      "Epoch 2, Batch 21800, Loss: 0.0010643638670444489\n",
      "Epoch 2, Batch 21850, Loss: 0.0013042062055319548\n",
      "Epoch 2, Batch 21900, Loss: 0.0013398710871115327\n",
      "Epoch 2, Batch 21950, Loss: 0.0014127842150628567\n",
      "Epoch 2, Batch 22000, Loss: 0.0012556121218949556\n",
      "Epoch 2, Batch 22050, Loss: 0.0014846469275653362\n",
      "Epoch 2, Batch 22100, Loss: 0.0019260052358731627\n",
      "Epoch 2, Batch 22150, Loss: 0.0028663903940469027\n",
      "Epoch 2, Batch 22200, Loss: 0.0023882279638201\n",
      "Epoch 2, Batch 22250, Loss: 0.0020546806044876575\n",
      "Epoch 2, Batch 22300, Loss: 0.002074525225907564\n",
      "Epoch 2, Batch 22350, Loss: 0.002356234472244978\n",
      "Epoch 2, Batch 22400, Loss: 0.002907435642555356\n",
      "Epoch 2, Batch 22450, Loss: 0.002213113708421588\n",
      "Epoch 2, Batch 22500, Loss: 0.0018410374177619815\n",
      "Epoch 2, Batch 22550, Loss: 0.0024249895941466093\n",
      "Epoch 2, Batch 22600, Loss: 0.002662711776793003\n",
      "Epoch 2, Batch 22650, Loss: 0.00260175415314734\n",
      "Epoch 2, Batch 22700, Loss: 0.0017739050090312958\n",
      "Epoch 2, Batch 22750, Loss: 0.001561084995046258\n",
      "Epoch 2, Batch 22800, Loss: 0.0017370139248669147\n",
      "Epoch 2, Batch 22850, Loss: 0.002411121968179941\n",
      "Epoch 2, Batch 22900, Loss: 0.3730396330356598\n",
      "Epoch 2, Batch 22950, Loss: 0.0022576984483748674\n",
      "Epoch 2, Batch 23000, Loss: 0.0020598596893250942\n",
      "Epoch 2, Batch 23050, Loss: 0.0035722549073398113\n",
      "Epoch 2, Batch 23100, Loss: 0.002634433563798666\n",
      "Epoch 2, Batch 23150, Loss: 0.0026668161153793335\n",
      "Epoch 2, Batch 23200, Loss: 0.002369547262787819\n",
      "Epoch 2, Batch 23250, Loss: 0.0020146036986261606\n",
      "Epoch 2, Batch 23300, Loss: 0.0026309406384825706\n",
      "Epoch 2, Batch 23350, Loss: 0.002792786806821823\n",
      "Epoch 2, Batch 23400, Loss: 0.0026677700225263834\n",
      "Epoch 2, Batch 23450, Loss: 0.002836807630956173\n",
      "Epoch 2, Batch 23500, Loss: 0.0023331576958298683\n",
      "Epoch 2, Batch 23550, Loss: 0.0019406253704801202\n",
      "Epoch 2, Batch 23600, Loss: 0.001811237190850079\n",
      "Epoch 2, Batch 23650, Loss: 0.0015137706650421023\n",
      "Epoch 2, Batch 23700, Loss: 0.3857906460762024\n",
      "Epoch 2, Batch 23750, Loss: 0.003301289863884449\n",
      "Epoch 2, Batch 23800, Loss: 0.002181600546464324\n",
      "Epoch 2, Batch 23850, Loss: 0.004274262581020594\n",
      "Epoch 2, Batch 23900, Loss: 0.00288835889659822\n",
      "Epoch 2, Batch 23950, Loss: 0.3951435387134552\n",
      "Epoch 2, Batch 24000, Loss: 0.002668502042070031\n",
      "Epoch 2, Batch 24050, Loss: 0.0020345402881503105\n",
      "Epoch 2, Batch 24100, Loss: 0.0015571140684187412\n",
      "Epoch 2, Batch 24150, Loss: 0.001481276354752481\n",
      "Epoch 2, Batch 24200, Loss: 0.0033170466776937246\n",
      "Epoch 2, Batch 24250, Loss: 0.0035807527601718903\n",
      "Epoch 2, Batch 24300, Loss: 0.0023870167788118124\n",
      "Epoch 2, Batch 24350, Loss: 0.002017578575760126\n",
      "Epoch 2, Batch 24400, Loss: 0.0021335799247026443\n",
      "Epoch 2, Batch 24450, Loss: 0.002176697598770261\n",
      "Epoch 2, Batch 24500, Loss: 0.002232917584478855\n",
      "Epoch 2, Batch 24550, Loss: 0.002325667068362236\n",
      "Epoch 2, Batch 24600, Loss: 0.0021886934991925955\n",
      "Epoch 2, Batch 24650, Loss: 0.0016647023148834705\n",
      "Epoch 2, Batch 24700, Loss: 0.002082595368847251\n",
      "Epoch 2, Batch 24750, Loss: 0.001616408582776785\n",
      "Epoch 2, Batch 24800, Loss: 0.0019510902930051088\n",
      "Epoch 2, Batch 24850, Loss: 0.002333994721993804\n",
      "Epoch 2, Batch 24900, Loss: 0.3726848363876343\n",
      "Epoch 2, Batch 24950, Loss: 0.0023248910438269377\n",
      "Epoch 2, Batch 25000, Loss: 0.0021132694091647863\n",
      "Epoch 2, Batch 25050, Loss: 0.0019200327806174755\n",
      "Epoch 2, Batch 25100, Loss: 0.0013305316679179668\n",
      "Epoch 2, Batch 25150, Loss: 0.0018502399325370789\n",
      "Epoch 2, Batch 25200, Loss: 0.002245835494250059\n",
      "Epoch 2, Batch 25250, Loss: 0.001500160084106028\n",
      "Epoch 2, Batch 25300, Loss: 0.002426370745524764\n",
      "Epoch 2, Batch 25350, Loss: 0.0031598294153809547\n",
      "Epoch 2, Batch 25400, Loss: 0.00277464697137475\n",
      "Epoch 2, Batch 25450, Loss: 0.0032412621658295393\n",
      "Epoch 2, Batch 25500, Loss: 0.0038536577485501766\n",
      "Epoch 2, Batch 25550, Loss: 0.0031873586121946573\n",
      "Epoch 2, Batch 25600, Loss: 0.37230032682418823\n",
      "Epoch 2, Batch 25650, Loss: 0.0028224398847669363\n",
      "Epoch 2, Batch 25700, Loss: 0.0017242163885384798\n",
      "Epoch 2, Batch 25750, Loss: 0.0019729197956621647\n",
      "Epoch 2, Batch 25800, Loss: 0.0021515816915780306\n",
      "Epoch 2, Batch 25850, Loss: 0.0021656204480677843\n",
      "Epoch 2, Batch 25900, Loss: 0.0019738832488656044\n",
      "Epoch 2, Batch 25950, Loss: 0.002480288501828909\n",
      "Epoch 2, Batch 26000, Loss: 0.0021636304445564747\n",
      "Epoch 2, Batch 26050, Loss: 0.0025116123724728823\n",
      "Epoch 2, Batch 26100, Loss: 0.0024684721138328314\n",
      "Epoch 2, Batch 26150, Loss: 0.00247087306343019\n",
      "Epoch 2, Batch 26200, Loss: 0.001942848670296371\n",
      "Epoch 2, Batch 26250, Loss: 0.001991150202229619\n",
      "Epoch 2, Batch 26300, Loss: 0.0023399440106004477\n",
      "Epoch 2, Batch 26350, Loss: 0.0015583954518660903\n",
      "Epoch 2, Batch 26400, Loss: 0.0018540661549195647\n",
      "Epoch 2, Batch 26450, Loss: 0.0014739125035703182\n",
      "Epoch 2, Batch 26500, Loss: 0.00187761674169451\n",
      "Epoch 2, Batch 26550, Loss: 0.0015831590862944722\n",
      "Epoch 2, Batch 26600, Loss: 0.0012015956453979015\n",
      "Epoch 2, Batch 26650, Loss: 0.0013312848750501871\n",
      "Epoch 2, Batch 26700, Loss: 0.0018226783722639084\n",
      "Epoch 2, Batch 26750, Loss: 0.0016721489373594522\n",
      "Epoch 2, Batch 26800, Loss: 0.001362821669317782\n",
      "Epoch 2, Batch 26850, Loss: 0.00172195746563375\n",
      "Epoch 2, Batch 26900, Loss: 0.0021917615085840225\n",
      "Epoch 2, Batch 26950, Loss: 0.0026492001488804817\n",
      "Epoch 2, Batch 27000, Loss: 0.001909462851472199\n",
      "Epoch 2, Batch 27050, Loss: 0.0019137808121740818\n",
      "Epoch 2, Batch 27100, Loss: 0.0015969568630680442\n",
      "Epoch 2, Batch 27150, Loss: 0.0014501934638246894\n",
      "Epoch 2, Batch 27200, Loss: 0.0017697855364531279\n",
      "Epoch 2, Batch 27250, Loss: 0.0014471412869170308\n",
      "Epoch 2, Batch 27300, Loss: 0.001436037477105856\n",
      "Epoch 2, Batch 27350, Loss: 0.0014750984264537692\n",
      "Epoch 2, Batch 27400, Loss: 0.0018986164359375834\n",
      "Epoch 2, Batch 27450, Loss: 0.0019990112632513046\n",
      "Epoch 2, Batch 27500, Loss: 0.3886931836605072\n",
      "Epoch 2, Batch 27550, Loss: 0.0027110776863992214\n",
      "Epoch 2, Batch 27600, Loss: 0.0028934734873473644\n",
      "Epoch 2, Batch 27650, Loss: 0.001859398907981813\n",
      "Epoch 2, Batch 27700, Loss: 0.0019156644120812416\n",
      "Epoch 2, Batch 27750, Loss: 0.0024046944454312325\n",
      "Epoch 2, Batch 27800, Loss: 0.0018909623613581061\n",
      "Epoch 2, Batch 27850, Loss: 0.0014023586409166455\n",
      "Epoch 2, Batch 27900, Loss: 0.001469312934204936\n",
      "Epoch 2, Batch 27950, Loss: 0.0013999607181176543\n",
      "Epoch 2, Batch 28000, Loss: 0.001702524721622467\n",
      "Epoch 2, Batch 28050, Loss: 0.0033209924586117268\n",
      "Epoch 2, Batch 28100, Loss: 0.0031628345604985952\n",
      "Epoch 2, Batch 28150, Loss: 0.002714421134442091\n",
      "Epoch 2, Batch 28200, Loss: 0.0021181143820285797\n",
      "Epoch 2, Batch 28250, Loss: 0.002073334762826562\n",
      "Epoch 2, Batch 28300, Loss: 0.0020821853540837765\n",
      "Epoch 2, Batch 28350, Loss: 0.0015953911934047937\n",
      "Epoch 2, Batch 28400, Loss: 0.0016640780959278345\n",
      "Epoch 2, Batch 28450, Loss: 0.0018871395150199533\n",
      "Epoch 2, Batch 28500, Loss: 0.0015009609051048756\n",
      "Epoch 2, Batch 28550, Loss: 0.0012489877408370376\n",
      "Epoch 2, Batch 28600, Loss: 0.0010977538768202066\n",
      "Epoch 2, Batch 28650, Loss: 0.0016438461607322097\n",
      "Epoch 2, Batch 28700, Loss: 0.0024021004792302847\n",
      "Epoch 2, Batch 28750, Loss: 0.0031571851577609777\n",
      "Epoch 2, Batch 28800, Loss: 0.0029110123869031668\n",
      "Epoch 2, Batch 28850, Loss: 0.002528280485421419\n",
      "Epoch 2, Batch 28900, Loss: 0.003723828587681055\n",
      "Epoch 2, Batch 28950, Loss: 0.002969194669276476\n",
      "Epoch 2, Batch 29000, Loss: 0.00271980999968946\n",
      "Epoch 2, Batch 29050, Loss: 0.002656457247212529\n",
      "Epoch 2, Batch 29100, Loss: 0.003635160392150283\n",
      "Epoch 2, Batch 29150, Loss: 0.003732463112100959\n",
      "Epoch 2, Batch 29200, Loss: 0.00392884761095047\n",
      "Epoch 2, Batch 29250, Loss: 0.0026919199153780937\n",
      "Epoch 2, Batch 29300, Loss: 0.001904190517961979\n",
      "Epoch 2, Batch 29350, Loss: 0.002268267562612891\n",
      "Epoch 2, Batch 29400, Loss: 0.0018741157837212086\n",
      "Epoch 2, Batch 29450, Loss: 0.002427596366032958\n",
      "Epoch 2, Batch 29500, Loss: 0.0032564543653279543\n",
      "Epoch 2, Batch 29550, Loss: 0.0037023695185780525\n",
      "Epoch 2, Batch 29600, Loss: 0.003560481360182166\n",
      "Epoch 2, Batch 29650, Loss: 0.0035007582046091557\n",
      "Epoch 2, Batch 29700, Loss: 0.002904013730585575\n",
      "Epoch 2, Batch 29750, Loss: 0.003292889567092061\n",
      "Epoch 2, Batch 29800, Loss: 0.002623972948640585\n",
      "Epoch 2, Batch 29850, Loss: 0.001945700729265809\n",
      "Epoch 2, Batch 29900, Loss: 0.0023646054323762655\n",
      "Epoch 2, Batch 29950, Loss: 0.0025110114365816116\n",
      "Epoch 2, Batch 30000, Loss: 0.003774303011596203\n",
      "Epoch 2, Batch 30050, Loss: 0.0028706195298582315\n",
      "Epoch 2, Batch 30100, Loss: 0.0018067954806610942\n",
      "Epoch 2, Batch 30150, Loss: 0.0016469677211716771\n",
      "Epoch 2, Batch 30200, Loss: 0.0015231671277433634\n",
      "Epoch 2, Batch 30250, Loss: 0.0023241827730089426\n",
      "Epoch 2, Batch 30300, Loss: 0.002212482737377286\n",
      "Epoch 2, Batch 30350, Loss: 0.0032029524445533752\n",
      "Epoch 2, Batch 30400, Loss: 0.0040029617957770824\n",
      "Epoch 2, Batch 30450, Loss: 0.0029261719901114702\n",
      "Epoch 2, Batch 30500, Loss: 0.003099378664046526\n",
      "Epoch 2, Batch 30550, Loss: 0.0022808481007814407\n",
      "Epoch 2, Batch 30600, Loss: 0.0020645209588110447\n",
      "Epoch 2, Batch 30650, Loss: 0.0036401364486664534\n",
      "Epoch 2, Batch 30700, Loss: 0.0024533227551728487\n",
      "Epoch 2, Batch 30750, Loss: 0.0020676706917583942\n",
      "Epoch 2, Batch 30800, Loss: 0.0015366156585514545\n",
      "Epoch 2, Batch 30850, Loss: 0.0014556340174749494\n",
      "Epoch 2, Batch 30900, Loss: 0.0013050812995061278\n",
      "Epoch 2, Batch 30950, Loss: 0.0012324461713433266\n",
      "Epoch 2, Batch 31000, Loss: 0.0015612319111824036\n",
      "Epoch 2, Batch 31050, Loss: 0.001411758130416274\n",
      "Epoch 2, Batch 31100, Loss: 0.0014299977337941527\n",
      "Epoch 2, Batch 31150, Loss: 0.001240903977304697\n",
      "Epoch 2, Batch 31200, Loss: 0.0014901435934007168\n",
      "Epoch 2, Batch 31250, Loss: 0.0013752387603744864\n",
      "Epoch 2, Batch 31300, Loss: 0.0020095105282962322\n",
      "Epoch 2, Batch 31350, Loss: 0.002192950574681163\n",
      "Epoch 2, Batch 31400, Loss: 0.0021341710817068815\n",
      "Epoch 2, Batch 31450, Loss: 0.002346140332520008\n",
      "Epoch 2, Batch 31500, Loss: 0.002091980306431651\n",
      "Epoch 2, Batch 31550, Loss: 0.001552348374389112\n",
      "Epoch 2, Batch 31600, Loss: 0.0019266108283773065\n",
      "Epoch 2, Batch 31650, Loss: 0.003214804455637932\n",
      "Epoch 2, Batch 31700, Loss: 0.0029573554638773203\n",
      "Epoch 2, Batch 31750, Loss: 0.003606185782700777\n",
      "Epoch 2, Batch 31800, Loss: 0.002118155127391219\n",
      "Epoch 2, Batch 31850, Loss: 0.0025662039406597614\n",
      "Epoch 2, Batch 31900, Loss: 0.00217365357093513\n",
      "Epoch 2, Batch 31950, Loss: 0.0027525359764695168\n",
      "Epoch 2, Batch 32000, Loss: 0.00224886042997241\n",
      "Epoch 2, Batch 32050, Loss: 0.0026553478091955185\n",
      "Epoch 2, Batch 32100, Loss: 0.002136173425242305\n",
      "Epoch 2, Batch 32150, Loss: 0.002636356046423316\n",
      "Epoch 2, Batch 32200, Loss: 0.0034219895023852587\n",
      "Epoch 2, Batch 32250, Loss: 0.00275266170501709\n",
      "Epoch 2, Batch 32300, Loss: 0.0020129610784351826\n",
      "Epoch 2, Batch 32350, Loss: 0.003845062106847763\n",
      "Epoch 2, Batch 32400, Loss: 0.002743331016972661\n",
      "Epoch 2, Batch 32450, Loss: 0.0022505007218569517\n",
      "Epoch 2, Batch 32500, Loss: 0.0018052806844934821\n",
      "Epoch 2, Batch 32550, Loss: 0.001428807619959116\n",
      "Epoch 2, Batch 32600, Loss: 0.0015604295767843723\n",
      "Epoch 2, Batch 32650, Loss: 0.0016808481886982918\n",
      "Epoch 2, Batch 32700, Loss: 0.0013169742887839675\n",
      "Epoch 2, Batch 32750, Loss: 0.0013806414790451527\n",
      "Epoch 2, Batch 32800, Loss: 0.00113820715341717\n",
      "Epoch 2, Batch 32850, Loss: 0.001374690211378038\n",
      "Epoch 2, Batch 32900, Loss: 0.0016020705224946141\n",
      "Epoch 2, Batch 32950, Loss: 0.0012736099306493998\n",
      "Epoch 2, Batch 33000, Loss: 0.001544405473396182\n",
      "Epoch 2, Batch 33050, Loss: 0.001449721516110003\n",
      "Epoch 2, Batch 33100, Loss: 0.0014620217261835933\n",
      "Epoch 2, Batch 33150, Loss: 0.0019516187021508813\n",
      "Epoch 2, Batch 33200, Loss: 0.0015372250927612185\n",
      "Epoch 2, Batch 33250, Loss: 0.0024613281711935997\n",
      "Epoch 2, Batch 33300, Loss: 0.0024612490087747574\n",
      "Epoch 2, Batch 33350, Loss: 0.005025182384997606\n",
      "Epoch 2, Batch 33400, Loss: 0.0025984870735555887\n",
      "Epoch 2, Batch 33450, Loss: 0.0021246750839054585\n",
      "Epoch 2, Batch 33500, Loss: 0.0015916140982881188\n",
      "Epoch 2, Batch 33550, Loss: 0.0017917469376698136\n",
      "Epoch 2, Batch 33600, Loss: 0.0017410392174497247\n",
      "Epoch 2, Batch 33650, Loss: 0.0021791504696011543\n",
      "Epoch 2, Batch 33700, Loss: 0.0035180598497390747\n",
      "Epoch 2, Batch 33750, Loss: 0.0022281641140580177\n",
      "Epoch 2, Batch 33800, Loss: 0.0016886999364942312\n",
      "Epoch 2, Batch 33850, Loss: 0.0012148689711466432\n",
      "Epoch 2, Batch 33900, Loss: 0.0014500418910756707\n",
      "Epoch 2, Batch 33950, Loss: 0.0030360976234078407\n",
      "Epoch 2, Batch 34000, Loss: 0.0021274362225085497\n",
      "Epoch 2, Batch 34050, Loss: 0.001518970006145537\n",
      "Epoch 2, Batch 34100, Loss: 0.0011037960648536682\n",
      "Epoch 2, Batch 34150, Loss: 0.0012215538881719112\n",
      "Epoch 2, Batch 34200, Loss: 0.0014337231405079365\n",
      "Epoch 2, Batch 34250, Loss: 0.0017913378542289138\n",
      "Epoch 2, Batch 34300, Loss: 0.0020464444532990456\n",
      "Epoch 2, Batch 34350, Loss: 0.0017454104963690042\n",
      "Epoch 2, Batch 34400, Loss: 0.0019113963935524225\n",
      "Epoch 2, Batch 34450, Loss: 0.002397847594693303\n",
      "Epoch 2, Batch 34500, Loss: 0.001890985295176506\n",
      "Epoch 2, Batch 34550, Loss: 0.0020866456907242537\n",
      "Epoch 2, Batch 34600, Loss: 0.0034812919329851866\n",
      "Epoch 2, Batch 34650, Loss: 0.002553072990849614\n",
      "Epoch 2, Batch 34700, Loss: 0.003921408671885729\n",
      "Epoch 2, Batch 34750, Loss: 0.004313601180911064\n",
      "Epoch 2, Batch 34800, Loss: 0.0032027028501033783\n",
      "Epoch 2, Batch 34850, Loss: 0.0030031411442905664\n",
      "Epoch 2, Batch 34900, Loss: 0.0024990024976432323\n",
      "Epoch 2, Batch 34950, Loss: 0.0020798002369701862\n",
      "Epoch 2, Batch 35000, Loss: 0.0031891928520053625\n",
      "Epoch 2, Batch 35050, Loss: 0.002876101993024349\n",
      "Epoch 2, Batch 35100, Loss: 0.00314437341876328\n",
      "Epoch 2, Batch 35150, Loss: 0.3579712212085724\n",
      "Epoch 2, Batch 35200, Loss: 0.003874758956953883\n",
      "Epoch 2, Batch 35250, Loss: 0.0038812393322587013\n",
      "Epoch 2, Batch 35300, Loss: 0.002661381382495165\n",
      "Epoch 2, Batch 35350, Loss: 0.002525966614484787\n",
      "Epoch 2, Batch 35400, Loss: 0.0021073196548968554\n",
      "Epoch 2, Batch 35450, Loss: 0.001654092688113451\n",
      "Epoch 2, Batch 35500, Loss: 0.0017889501759782434\n",
      "Epoch 2, Batch 35550, Loss: 0.001905909739434719\n",
      "Epoch 2, Batch 35600, Loss: 0.001834680326282978\n",
      "Epoch 2, Batch 35650, Loss: 0.002978457370772958\n",
      "Epoch 2, Batch 35700, Loss: 0.0026535585056990385\n",
      "Epoch 2, Batch 35750, Loss: 0.002536663319915533\n",
      "Epoch 2, Batch 35800, Loss: 0.0026891608722507954\n",
      "Epoch 2, Batch 35850, Loss: 0.0025655573699623346\n",
      "Epoch 2, Batch 35900, Loss: 0.0026553801726549864\n",
      "Epoch 2, Batch 35950, Loss: 0.002347645815461874\n",
      "Epoch 2, Batch 36000, Loss: 0.001930947881191969\n",
      "Epoch 2, Batch 36050, Loss: 0.0015740966191515326\n",
      "Epoch 2, Batch 36100, Loss: 0.0011412850581109524\n",
      "Epoch 2, Batch 36150, Loss: 0.000962022109888494\n",
      "Epoch 2, Batch 36200, Loss: 0.0009484486654400826\n",
      "Epoch 2, Batch 36250, Loss: 0.0012517697177827358\n",
      "Epoch 2, Batch 36300, Loss: 0.0011794581077992916\n",
      "Epoch 2, Batch 36350, Loss: 0.00112270622048527\n",
      "Epoch 2, Batch 36400, Loss: 0.001170685631223023\n",
      "Epoch 2, Batch 36450, Loss: 0.0018472723895683885\n",
      "Epoch 2, Batch 36500, Loss: 0.0027261755894869566\n",
      "Epoch 2, Batch 36550, Loss: 0.002497351262718439\n",
      "Epoch 2, Batch 36600, Loss: 0.0020319963805377483\n",
      "Epoch 2, Batch 36650, Loss: 0.002056306228041649\n",
      "Epoch 2, Batch 36700, Loss: 0.0014265731442719698\n",
      "Epoch 2, Batch 36750, Loss: 0.0015228289412334561\n",
      "Epoch 2, Batch 36800, Loss: 0.0013283748412504792\n",
      "Epoch 2, Batch 36850, Loss: 0.0019968992564827204\n",
      "Epoch 2, Batch 36900, Loss: 0.0018726637354120612\n",
      "Epoch 2, Batch 36950, Loss: 0.3690565228462219\n",
      "Epoch 2, Batch 37000, Loss: 0.0020003768149763346\n",
      "Epoch 2, Batch 37050, Loss: 0.0014553561341017485\n",
      "Epoch 2, Batch 37100, Loss: 0.0015073149697855115\n",
      "Epoch 2, Batch 37150, Loss: 0.002689177868887782\n",
      "Epoch 2, Batch 37200, Loss: 0.002573953475803137\n",
      "Epoch 2, Batch 37250, Loss: 0.0027865106239914894\n",
      "Epoch 2, Batch 37300, Loss: 0.0019176095956936479\n",
      "Epoch 2, Batch 37350, Loss: 0.0024715671315789223\n",
      "Epoch 2, Batch 37400, Loss: 0.002040804596617818\n",
      "Epoch 2, Batch 37450, Loss: 0.0018308698199689388\n",
      "Epoch 2, Batch 37500, Loss: 0.0021983373444527388\n",
      "Epoch 2, Batch 37550, Loss: 0.002745587145909667\n",
      "Epoch 2, Batch 37600, Loss: 0.0023860817309468985\n",
      "Epoch 2, Batch 37650, Loss: 0.0017645246116444468\n",
      "Epoch 2, Batch 37700, Loss: 0.0013804492773488164\n",
      "Epoch 2, Batch 37750, Loss: 0.0014025949640199542\n",
      "Epoch 2, Batch 37800, Loss: 0.00215876754373312\n",
      "Epoch 2, Batch 37850, Loss: 0.0020557886455208063\n",
      "Epoch 2, Batch 37900, Loss: 0.0023388254921883345\n",
      "Epoch 2, Batch 37950, Loss: 0.001486859517171979\n",
      "Epoch 2, Batch 38000, Loss: 0.002298330655321479\n",
      "Epoch 2, Batch 38050, Loss: 0.0025226478464901447\n",
      "Epoch 2, Batch 38100, Loss: 0.002144296420738101\n",
      "Epoch 2, Batch 38150, Loss: 0.0019118296913802624\n",
      "Epoch 2, Batch 38200, Loss: 0.0016623528208583593\n",
      "Epoch 2, Batch 38250, Loss: 0.0033608730882406235\n",
      "Epoch 2, Batch 38300, Loss: 0.0020125622395426035\n",
      "Epoch 2, Batch 38350, Loss: 0.0035881877411156893\n",
      "Epoch 2, Batch 38400, Loss: 0.0032379289623349905\n",
      "Epoch 2, Batch 38450, Loss: 0.002611791482195258\n",
      "Epoch 2, Batch 38500, Loss: 0.0021487795747816563\n",
      "Epoch 2, Batch 38550, Loss: 0.0025826208293437958\n",
      "Epoch 2, Batch 38600, Loss: 0.0021200866904109716\n",
      "Epoch 2, Batch 38650, Loss: 0.004588861484080553\n",
      "Epoch 2, Batch 38700, Loss: 0.0026419316418468952\n",
      "Epoch 2, Batch 38750, Loss: 0.002555280923843384\n",
      "Epoch 2, Batch 38800, Loss: 0.001936727436259389\n",
      "Epoch 2, Batch 38850, Loss: 0.0020309400279074907\n",
      "Epoch 2, Batch 38900, Loss: 0.0019730450585484505\n",
      "Epoch 2, Batch 38950, Loss: 0.0016113845631480217\n",
      "Epoch 2, Batch 39000, Loss: 0.0019475150620564818\n",
      "Epoch 2, Batch 39050, Loss: 0.004211314953863621\n",
      "Epoch 2, Batch 39100, Loss: 0.3149607479572296\n",
      "Epoch 2, Batch 39150, Loss: 0.004094759467989206\n",
      "Epoch 2, Batch 39200, Loss: 0.0031714197248220444\n",
      "Epoch 2, Batch 39250, Loss: 0.0024641714990139008\n",
      "Epoch 2, Batch 39300, Loss: 0.002390423323959112\n",
      "Epoch 2, Batch 39350, Loss: 0.002441170858219266\n",
      "Epoch 2, Batch 39400, Loss: 0.0019103826489299536\n",
      "Epoch 2, Batch 39450, Loss: 0.0028980134520679712\n",
      "Epoch 2, Batch 39500, Loss: 0.0022761349100619555\n",
      "Epoch 2, Batch 39550, Loss: 0.0015848734183236957\n",
      "Epoch 2, Batch 39600, Loss: 0.0015941637102514505\n",
      "Epoch 2, Batch 39650, Loss: 0.0015096860006451607\n",
      "Epoch 2, Batch 39700, Loss: 0.0015066813211888075\n",
      "Epoch 2, Batch 39750, Loss: 0.001786393579095602\n",
      "Epoch 2, Batch 39800, Loss: 0.002393085975199938\n",
      "Epoch 2, Batch 39850, Loss: 0.0021783984266221523\n",
      "Epoch 2, Batch 39900, Loss: 0.001968950731679797\n",
      "Epoch 2, Batch 39950, Loss: 0.0021047298796474934\n",
      "Epoch 2, Batch 40000, Loss: 0.002623103791847825\n",
      "Epoch 2, Batch 40050, Loss: 0.0014472699258476496\n",
      "Epoch 2, Batch 40100, Loss: 0.0019780565053224564\n",
      "Epoch 2, Batch 40150, Loss: 0.0031826826743781567\n",
      "Epoch 2, Batch 40200, Loss: 0.0025427467189729214\n",
      "Epoch 2, Batch 40250, Loss: 0.36340394616127014\n",
      "Epoch 2, Batch 40300, Loss: 0.0024214168079197407\n",
      "Epoch 2, Batch 40350, Loss: 0.0018907435005530715\n",
      "Epoch 2, Batch 40400, Loss: 0.43007779121398926\n",
      "Epoch 2, Batch 40450, Loss: 0.0027760453522205353\n",
      "Epoch 2, Batch 40500, Loss: 0.002409958280622959\n",
      "Epoch 2, Batch 40550, Loss: 0.0019363142782822251\n",
      "Epoch 2, Batch 40600, Loss: 0.0019649488385766745\n",
      "Epoch 2, Batch 40650, Loss: 0.0016652896301820874\n",
      "Epoch 2, Batch 40700, Loss: 0.0018489235080778599\n",
      "Epoch 2, Batch 40750, Loss: 0.0022584577091038227\n",
      "Epoch 2, Batch 40800, Loss: 0.0020308266393840313\n",
      "Epoch 2, Batch 40850, Loss: 0.0032580688130110502\n",
      "Epoch 2, Batch 40900, Loss: 0.0022942880168557167\n",
      "Epoch 2, Batch 40950, Loss: 0.0022966766264289618\n",
      "Epoch 2, Batch 41000, Loss: 0.002294821199029684\n",
      "Epoch 2, Batch 41050, Loss: 0.003485672175884247\n",
      "Epoch 2, Batch 41100, Loss: 0.002374406671151519\n",
      "Epoch 2, Batch 41150, Loss: 0.0017608065390959382\n",
      "Epoch 2, Batch 41200, Loss: 0.0023688245564699173\n",
      "Epoch 2, Batch 41250, Loss: 0.0020271437242627144\n",
      "Epoch 2, Batch 41300, Loss: 0.0015272942837327719\n",
      "Epoch 2, Batch 41350, Loss: 0.0014375660102814436\n",
      "Epoch 2, Batch 41400, Loss: 0.002342706313356757\n",
      "Epoch 2, Batch 41450, Loss: 0.002040242310613394\n",
      "Epoch 2, Batch 41500, Loss: 0.0018195154843851924\n",
      "Epoch 2, Batch 41550, Loss: 0.001511043170467019\n",
      "Epoch 2, Batch 41600, Loss: 0.001401502056978643\n",
      "Epoch 2, Batch 41650, Loss: 0.0013882261700928211\n",
      "Epoch 2, Batch 41700, Loss: 0.0010333535028621554\n",
      "Epoch 2, Batch 41750, Loss: 0.0010407369118183851\n",
      "Epoch 2, Batch 41800, Loss: 0.002036648103967309\n",
      "Epoch 2, Batch 41850, Loss: 0.002474334789440036\n",
      "Epoch 2, Batch 41900, Loss: 0.001940105576068163\n",
      "Epoch 2, Batch 41950, Loss: 0.001880252966657281\n",
      "Epoch 2, Batch 42000, Loss: 0.0019901124760508537\n",
      "Epoch 2, Batch 42050, Loss: 0.0017373545560985804\n",
      "Epoch 2, Batch 42100, Loss: 0.0026600577402859926\n",
      "Epoch 2, Batch 42150, Loss: 0.002896720776334405\n",
      "Epoch 2, Batch 42200, Loss: 0.0022344046737998724\n",
      "Epoch 2, Batch 42250, Loss: 0.002550955396145582\n",
      "Epoch 2, Batch 42300, Loss: 0.0016039290931075811\n",
      "Epoch 2, Batch 42350, Loss: 0.0022697984240949154\n",
      "Epoch 2, Batch 42400, Loss: 0.0017983891302719712\n",
      "Epoch 2, Batch 42450, Loss: 0.0025565589312464\n",
      "Epoch 2, Batch 42500, Loss: 0.39277398586273193\n",
      "Epoch 2, Batch 42550, Loss: 0.002535299165174365\n",
      "Epoch 2, Batch 42600, Loss: 0.001752712414599955\n",
      "Epoch 2, Batch 42650, Loss: 0.001785566913895309\n",
      "Epoch 2, Batch 42700, Loss: 0.001617030706256628\n",
      "Epoch 2, Batch 42750, Loss: 0.0015541194006800652\n",
      "Epoch 2, Batch 42800, Loss: 0.0011971632484346628\n",
      "Epoch 2, Batch 42850, Loss: 0.001241517486050725\n",
      "Epoch 2, Batch 42900, Loss: 0.001931117381900549\n",
      "Epoch 2, Batch 42950, Loss: 0.002297125058248639\n",
      "Epoch 2, Batch 43000, Loss: 0.002250860445201397\n",
      "Epoch 2, Batch 43050, Loss: 0.0021569901145994663\n",
      "Epoch 2, Batch 43100, Loss: 0.0025258685927838087\n",
      "Epoch 2, Batch 43150, Loss: 0.003712745849043131\n",
      "Epoch 2, Batch 43200, Loss: 0.0029581908602267504\n",
      "Epoch 2, Batch 43250, Loss: 0.002463450888171792\n",
      "Epoch 2, Batch 43300, Loss: 0.0018636401509866118\n",
      "Epoch 2, Batch 43350, Loss: 0.0017551059136167169\n",
      "Epoch 2, Batch 43400, Loss: 0.0018494685646146536\n",
      "Epoch 2, Batch 43450, Loss: 0.0014641346642747521\n",
      "Epoch 2, Batch 43500, Loss: 0.0014475819189101458\n",
      "Epoch 2, Batch 43550, Loss: 0.0017165543977171183\n",
      "Epoch 2, Batch 43600, Loss: 0.0012121542822569609\n",
      "Epoch 2, Batch 43650, Loss: 0.0014764947118237615\n",
      "Epoch 2, Batch 43700, Loss: 0.0009510550298728049\n",
      "Epoch 2, Batch 43750, Loss: 0.0008253498235717416\n",
      "Epoch 2, Batch 43800, Loss: 0.0009952594991773367\n",
      "Epoch 2, Batch 43850, Loss: 0.0013340055011212826\n",
      "Epoch 2, Batch 43900, Loss: 0.0016735456883907318\n",
      "Epoch 2, Batch 43950, Loss: 0.0015931359957903624\n",
      "Epoch 2, Batch 44000, Loss: 0.00278608500957489\n",
      "Epoch 2, Batch 44050, Loss: 0.0023256572894752026\n",
      "Epoch 2, Batch 44100, Loss: 0.0031773762311786413\n",
      "Epoch 2, Batch 44150, Loss: 0.0023084755521267653\n",
      "Epoch 2, Batch 44200, Loss: 0.0023083847481757402\n",
      "Epoch 2, Batch 44250, Loss: 0.003938916604965925\n",
      "Epoch 2, Batch 44300, Loss: 0.003252585418522358\n",
      "Epoch 2, Batch 44350, Loss: 0.0030943069141358137\n",
      "Epoch 2, Batch 44400, Loss: 0.0027292876038700342\n",
      "Epoch 2, Batch 44450, Loss: 0.002601243555545807\n",
      "Epoch 2, Batch 44500, Loss: 0.0021688537672162056\n",
      "Epoch 2, Batch 44550, Loss: 0.003696232568472624\n",
      "Epoch 2, Batch 44600, Loss: 0.003284168429672718\n",
      "Epoch 2, Batch 44650, Loss: 0.0029699476435780525\n",
      "Epoch 2, Batch 44700, Loss: 0.0038674003444612026\n",
      "Epoch 2, Batch 44750, Loss: 0.0029597387183457613\n",
      "Epoch 2, Batch 44800, Loss: 0.001706524402834475\n",
      "Epoch 2, Batch 44850, Loss: 0.0017019726801663637\n",
      "Epoch 2, Batch 44900, Loss: 0.0011881691170856357\n",
      "Epoch 2, Batch 44950, Loss: 0.001257423311471939\n",
      "Epoch 2, Batch 45000, Loss: 0.0017749964026734233\n",
      "Epoch 2, Batch 45050, Loss: 0.0020303488709032536\n",
      "Epoch 2, Batch 45100, Loss: 0.0017621618462726474\n",
      "Epoch 2, Batch 45150, Loss: 0.001753476681187749\n",
      "Epoch 2, Batch 45200, Loss: 0.0018041942967101932\n",
      "Epoch 2, Batch 45250, Loss: 0.0019630410242825747\n",
      "Epoch 2, Batch 45300, Loss: 0.3665695786476135\n",
      "Epoch 2, Batch 45350, Loss: 0.0038791894912719727\n",
      "Epoch 2, Batch 45400, Loss: 0.002597671700641513\n",
      "Epoch 2, Batch 45450, Loss: 0.004338000901043415\n",
      "Epoch 2, Batch 45500, Loss: 0.003203832544386387\n",
      "Epoch 2, Batch 45550, Loss: 0.0023739750031381845\n",
      "Epoch 2, Batch 45600, Loss: 0.0020104774739593267\n",
      "Epoch 2, Batch 45650, Loss: 0.0019901618361473083\n",
      "Epoch 2, Batch 45700, Loss: 0.0022357916459441185\n",
      "Epoch 2, Batch 45750, Loss: 0.002838806714862585\n",
      "Epoch 2, Batch 45800, Loss: 0.3722783327102661\n",
      "Epoch 2, Batch 45850, Loss: 0.002176693407818675\n",
      "Epoch 2, Batch 45900, Loss: 0.0016272845678031445\n",
      "Epoch 2, Batch 45950, Loss: 0.001562577555887401\n",
      "Epoch 2, Batch 46000, Loss: 0.0013671561609953642\n",
      "Epoch 2, Batch 46050, Loss: 0.0018477351404726505\n",
      "Epoch 2, Batch 46100, Loss: 0.0013838978484272957\n",
      "Epoch 2, Batch 46150, Loss: 0.002215504413470626\n",
      "Epoch 2, Batch 46200, Loss: 0.0020136088132858276\n",
      "Epoch 2, Batch 46250, Loss: 0.001676076091825962\n",
      "Epoch 2, Batch 46300, Loss: 0.39109236001968384\n",
      "Epoch 2, Batch 46350, Loss: 0.0015362916747108102\n",
      "Epoch 2, Batch 46400, Loss: 0.002266407012939453\n",
      "Epoch 2, Batch 46450, Loss: 0.0020945414435118437\n",
      "Epoch 2, Batch 46500, Loss: 0.0023843380622565746\n",
      "Epoch 2, Batch 46550, Loss: 0.001317057991400361\n",
      "Epoch 2, Batch 46600, Loss: 0.001802853075787425\n",
      "Epoch 2, Batch 46650, Loss: 0.001455966616049409\n",
      "Epoch 2, Batch 46700, Loss: 0.0023891765158623457\n",
      "Epoch 2, Batch 46750, Loss: 0.002542538335546851\n",
      "Epoch 2, Batch 46800, Loss: 0.4014614224433899\n",
      "Epoch 2, Batch 46850, Loss: 0.0020596596878021955\n",
      "Epoch 2, Batch 46900, Loss: 0.0014684717170894146\n",
      "Epoch 2, Batch 46950, Loss: 0.001251148758456111\n",
      "Epoch 2, Batch 47000, Loss: 0.0010172610636800528\n",
      "Epoch 2, Batch 47050, Loss: 0.0015521300956606865\n",
      "Epoch 2, Batch 47100, Loss: 0.0011892984621226788\n",
      "Epoch 2, Batch 47150, Loss: 0.00134109309874475\n",
      "Epoch 2, Batch 47200, Loss: 0.3880791962146759\n",
      "Epoch 2, Batch 47250, Loss: 0.002167952246963978\n",
      "Epoch 2, Batch 47300, Loss: 0.0027883786242455244\n",
      "Epoch 2, Batch 47350, Loss: 0.0020107112359255552\n",
      "Epoch 2, Batch 47400, Loss: 0.002422767924144864\n",
      "Epoch 2, Batch 47450, Loss: 0.0021377357188612223\n",
      "Epoch 2, Batch 47500, Loss: 0.0023887036368250847\n",
      "Epoch 2, Batch 47550, Loss: 0.0017676139250397682\n",
      "Epoch 2, Batch 47600, Loss: 0.0021754829213023186\n",
      "Epoch 2, Batch 47650, Loss: 0.0017092862399294972\n",
      "Epoch 2, Batch 47700, Loss: 0.001387309399433434\n",
      "Epoch 2, Batch 47750, Loss: 0.0016877130838111043\n",
      "Epoch 2, Batch 47800, Loss: 0.0012348085874691606\n",
      "Epoch 2, Batch 47850, Loss: 0.0009401499992236495\n",
      "Epoch 2, Batch 47900, Loss: 0.37444251775741577\n",
      "Epoch 2, Batch 47950, Loss: 0.000960320932790637\n",
      "Epoch 2, Batch 48000, Loss: 0.0012169647961854935\n",
      "Epoch 2, Batch 48050, Loss: 0.0009587874519638717\n",
      "Epoch 2, Batch 48100, Loss: 0.0018941486487165093\n",
      "Epoch 2, Batch 48150, Loss: 0.0022059401962906122\n",
      "Epoch 2, Batch 48200, Loss: 0.002057170495390892\n",
      "Epoch 2, Batch 48250, Loss: 0.002590856049209833\n",
      "Epoch 2, Batch 48300, Loss: 0.004066298250108957\n",
      "Epoch 2, Batch 48350, Loss: 0.004095517098903656\n",
      "Epoch 2, Batch 48400, Loss: 0.004759819712489843\n",
      "Epoch 2, Batch 48450, Loss: 0.0037749058101326227\n",
      "Epoch 2, Batch 48500, Loss: 0.002993175992742181\n",
      "Epoch 2, Batch 48550, Loss: 0.0028025824576616287\n",
      "Epoch 2, Batch 48600, Loss: 0.004559328779578209\n",
      "Epoch 2, Batch 48650, Loss: 0.002795466920360923\n",
      "Epoch 2, Batch 48700, Loss: 0.0023389302659779787\n",
      "Epoch 2, Batch 48750, Loss: 0.0016755349934101105\n",
      "Epoch 2, Batch 48800, Loss: 0.0013841503532603383\n",
      "Epoch 2, Batch 48850, Loss: 0.0011565386084839702\n",
      "Epoch 2, Batch 48900, Loss: 0.0013075928436592221\n",
      "Epoch 2, Batch 48950, Loss: 0.0017332680290564895\n",
      "Epoch 2, Batch 49000, Loss: 0.0017308777896687388\n",
      "Epoch 2, Batch 49050, Loss: 0.0013546249829232693\n",
      "Epoch 2, Batch 49100, Loss: 0.0017692031105980277\n",
      "Epoch 2, Batch 49150, Loss: 0.002042038831859827\n",
      "Epoch 2, Batch 49200, Loss: 0.0028665862046182156\n",
      "Epoch 2, Batch 49250, Loss: 0.00145439594052732\n",
      "Epoch 2, Batch 49300, Loss: 0.0021070661023259163\n",
      "Epoch 2, Batch 49350, Loss: 0.0017698900774121284\n",
      "Epoch 2, Batch 49400, Loss: 0.0019416461000218987\n",
      "Epoch 2, Batch 49450, Loss: 0.0016446626977995038\n",
      "Epoch 2, Batch 49500, Loss: 0.0016250641783699393\n",
      "Epoch 2, Batch 49550, Loss: 0.0016060520429164171\n",
      "Epoch 2, Batch 49600, Loss: 0.0019280263222754002\n",
      "Epoch 2, Batch 49650, Loss: 0.0019353650277480483\n",
      "Epoch 2, Batch 49700, Loss: 0.0018009566701948643\n",
      "Epoch 2, Batch 49750, Loss: 0.0018487293273210526\n",
      "Epoch 2, Batch 49800, Loss: 0.0025826022028923035\n",
      "Epoch 2, Batch 49850, Loss: 0.002293410012498498\n",
      "Epoch 2, Batch 49900, Loss: 0.0024689927231520414\n",
      "Epoch 2, Batch 49950, Loss: 0.0016235198127105832\n",
      "Epoch 2, Batch 50000, Loss: 0.0009478710708208382\n",
      "Epoch 2, Batch 50050, Loss: 0.0010368573712185025\n",
      "Epoch 2, Batch 50100, Loss: 0.0009774870704859495\n",
      "Epoch 2, Batch 50150, Loss: 0.000856131489854306\n",
      "Epoch 2, Batch 50200, Loss: 0.0016169664449989796\n",
      "Epoch 2, Batch 50250, Loss: 0.001754670636728406\n",
      "Epoch 2, Batch 50300, Loss: 0.0016575793270021677\n",
      "Epoch 2, Batch 50350, Loss: 0.0012032062513753772\n",
      "Epoch 2, Batch 50400, Loss: 0.0021838219836354256\n",
      "Epoch 2, Batch 50450, Loss: 0.0015575162833556533\n",
      "Epoch 2, Batch 50500, Loss: 0.0025821698363870382\n",
      "Epoch 2, Batch 50550, Loss: 0.002354350173845887\n",
      "Epoch 2, Batch 50600, Loss: 0.002483546733856201\n",
      "Epoch 2, Batch 50650, Loss: 0.004266142379492521\n",
      "Epoch 2, Batch 50700, Loss: 0.001980785047635436\n",
      "Epoch 2, Batch 50750, Loss: 0.0024712567683309317\n",
      "Epoch 2, Batch 50800, Loss: 0.0027054103557020426\n",
      "Epoch 2, Batch 50850, Loss: 0.0029907417483627796\n",
      "Epoch 2, Batch 50900, Loss: 0.0026249289512634277\n",
      "Epoch 2, Batch 50950, Loss: 0.0024180824402719736\n",
      "Epoch 2, Batch 51000, Loss: 0.00277846516110003\n",
      "Epoch 2, Batch 51050, Loss: 0.001693575526587665\n",
      "Epoch 2, Batch 51100, Loss: 0.0019507355755195022\n",
      "Epoch 2, Batch 51150, Loss: 0.0020604499150067568\n",
      "Epoch 2, Batch 51200, Loss: 0.0015649101696908474\n",
      "Epoch 2, Batch 51250, Loss: 0.0014855307526886463\n",
      "Epoch 2, Batch 51300, Loss: 0.0017852586461231112\n",
      "Epoch 2, Batch 51350, Loss: 0.002144584897905588\n",
      "Epoch 2, Batch 51400, Loss: 0.43985772132873535\n",
      "Epoch 2, Batch 51450, Loss: 0.0012314780615270138\n",
      "Epoch 2, Batch 51500, Loss: 0.0015741052338853478\n",
      "Epoch 2, Batch 51550, Loss: 0.0016048471443355083\n",
      "Epoch 2, Batch 51600, Loss: 0.0017793833976611495\n",
      "Epoch 2, Batch 51650, Loss: 0.001813068171031773\n",
      "Epoch 2, Batch 51700, Loss: 0.0021744361147284508\n",
      "Epoch 2, Batch 51750, Loss: 0.0021518052089959383\n",
      "Epoch 2, Batch 51800, Loss: 0.0018562262412160635\n",
      "Epoch 2, Batch 51850, Loss: 0.0023448693100363016\n",
      "Epoch 2, Batch 51900, Loss: 0.0020122858695685863\n",
      "Epoch 2, Batch 51950, Loss: 0.0020875136833637953\n",
      "Epoch 2, Batch 52000, Loss: 0.001887212391011417\n",
      "Epoch 2, Batch 52050, Loss: 0.0016946163959801197\n",
      "Epoch 2, Batch 52100, Loss: 0.001496108714491129\n",
      "Epoch 2, Batch 52150, Loss: 0.0022402051836252213\n",
      "Epoch 2, Batch 52200, Loss: 0.0025058151222765446\n",
      "Epoch 2, Batch 52250, Loss: 0.00217793183401227\n",
      "Epoch 2, Batch 52300, Loss: 0.3291268050670624\n",
      "Epoch 2, Batch 52350, Loss: 0.0022930544801056385\n",
      "Epoch 2, Batch 52400, Loss: 0.0028164247050881386\n",
      "Epoch 2, Batch 52450, Loss: 0.002229838166385889\n",
      "Epoch 2, Batch 52500, Loss: 0.0020552929490804672\n",
      "Epoch 2, Batch 52550, Loss: 0.0019044653745368123\n",
      "Epoch 2, Batch 52600, Loss: 0.0016621057875454426\n",
      "Epoch 2, Batch 52650, Loss: 0.002122709760442376\n",
      "Epoch 2, Batch 52700, Loss: 0.0019901306368410587\n",
      "Epoch 2, Batch 52750, Loss: 0.0019289673073217273\n",
      "Epoch 2, Batch 52800, Loss: 0.002377528930082917\n",
      "Epoch 2, Batch 52850, Loss: 0.002577020088210702\n",
      "Epoch 2, Batch 52900, Loss: 0.001752277952618897\n",
      "Epoch 2, Batch 52950, Loss: 0.002175466623157263\n",
      "Epoch 2, Batch 53000, Loss: 0.0041486346162855625\n",
      "Epoch 2, Batch 53050, Loss: 0.004651524126529694\n",
      "Epoch 2, Batch 53100, Loss: 0.003987210802733898\n",
      "Epoch 2, Batch 53150, Loss: 0.0025060910265892744\n",
      "Epoch 2, Batch 53200, Loss: 0.002320535248145461\n",
      "Epoch 2, Batch 53250, Loss: 0.0024084823671728373\n",
      "Epoch 2, Batch 53300, Loss: 0.002469987142831087\n",
      "Epoch 2, Batch 53350, Loss: 0.001704252790659666\n",
      "Epoch 2, Batch 53400, Loss: 0.0012631091522052884\n",
      "Epoch 2, Batch 53450, Loss: 0.0015448593767359853\n",
      "Epoch 2, Batch 53500, Loss: 0.0014085826696828008\n",
      "Epoch 2, Batch 53550, Loss: 0.001057211309671402\n",
      "Epoch 2, Batch 53600, Loss: 0.4603634774684906\n",
      "Epoch 2, Batch 53650, Loss: 0.0010902496287599206\n",
      "Epoch 2, Batch 53700, Loss: 0.001196752768009901\n",
      "Epoch 2, Batch 53750, Loss: 0.0016398108564317226\n",
      "Epoch 2, Batch 53800, Loss: 0.0016341262962669134\n",
      "Epoch 2, Batch 53850, Loss: 0.002211586106568575\n",
      "Epoch 2, Batch 53900, Loss: 0.0033060996793210506\n",
      "Epoch 2, Batch 53950, Loss: 0.0026558698154985905\n",
      "Epoch 2, Batch 54000, Loss: 0.002960318000987172\n",
      "Epoch 2, Batch 54050, Loss: 0.0035952595062553883\n",
      "Epoch 2, Batch 54100, Loss: 0.0031742372084409\n",
      "Epoch 2, Batch 54150, Loss: 0.0033647629898041487\n",
      "Epoch 2, Batch 54200, Loss: 0.0023711451794952154\n",
      "Epoch 2, Batch 54250, Loss: 0.001458892598748207\n",
      "Epoch 2, Batch 54300, Loss: 0.001552706235088408\n",
      "Epoch 2, Batch 54350, Loss: 0.0013097862247377634\n",
      "Epoch 2, Batch 54400, Loss: 0.0017598813865333796\n",
      "Epoch 2, Batch 54450, Loss: 0.0019048701506108046\n",
      "Epoch 2, Batch 54500, Loss: 0.0015970775857567787\n",
      "Epoch 2, Batch 54550, Loss: 0.0011993048246949911\n",
      "Epoch 2, Batch 54600, Loss: 0.0020928513258695602\n",
      "Epoch 2, Batch 54650, Loss: 0.002090423833578825\n",
      "Epoch 2, Batch 54700, Loss: 0.002907278249040246\n",
      "Epoch 2, Batch 54750, Loss: 0.002534257248044014\n",
      "Epoch 2, Batch 54800, Loss: 0.3942618668079376\n",
      "Epoch 2, Batch 54850, Loss: 0.0015815142542123795\n",
      "Epoch 2, Batch 54900, Loss: 0.002845476847141981\n",
      "Epoch 2, Batch 54950, Loss: 0.0021642190404236317\n",
      "Epoch 2, Batch 55000, Loss: 0.38095787167549133\n",
      "Epoch 2, Batch 55050, Loss: 0.00277254288084805\n",
      "Epoch 2, Batch 55100, Loss: 0.0026005469262599945\n",
      "Epoch 2, Batch 55150, Loss: 0.0021252846345305443\n",
      "Epoch 2, Batch 55200, Loss: 0.0021075615659356117\n",
      "Epoch 2, Batch 55250, Loss: 0.0018946235068142414\n",
      "Epoch 2, Batch 55300, Loss: 0.0028648795560002327\n",
      "Epoch 2, Batch 55350, Loss: 0.001960618421435356\n",
      "Epoch 2, Batch 55400, Loss: 0.0020474621560424566\n",
      "Epoch 2, Batch 55450, Loss: 0.0014004502445459366\n",
      "Epoch 2, Batch 55500, Loss: 0.0014407536946237087\n",
      "Epoch 2, Batch 55550, Loss: 0.0018907192861661315\n",
      "Epoch 2, Batch 55600, Loss: 0.0020869176369160414\n",
      "Epoch 2, Batch 55650, Loss: 0.0022427565418183804\n",
      "Epoch 2, Batch 55700, Loss: 0.001916979905217886\n",
      "Epoch 2, Batch 55750, Loss: 0.0033336509950459003\n",
      "Epoch 2, Batch 55800, Loss: 0.0049160802736878395\n",
      "Epoch 2, Batch 55850, Loss: 0.003984123934060335\n",
      "Epoch 2, Batch 55900, Loss: 0.0023967158049345016\n",
      "Epoch 2, Batch 55950, Loss: 0.002975468523800373\n",
      "Epoch 2, Batch 56000, Loss: 0.0019652340561151505\n",
      "Epoch 2, Batch 56050, Loss: 0.0016359916189685464\n",
      "Epoch 2, Batch 56100, Loss: 0.0011948167812079191\n",
      "Epoch 2, Batch 56150, Loss: 0.0012563130585476756\n",
      "Epoch 2, Batch 56200, Loss: 0.0008224539342336357\n",
      "Epoch 2, Batch 56250, Loss: 0.0010131665039807558\n",
      "Epoch 2, Batch 56300, Loss: 0.0015710818115621805\n",
      "Epoch 2, Batch 56350, Loss: 0.0012301952810958028\n",
      "Epoch 2, Batch 56400, Loss: 0.0014599631540477276\n",
      "Epoch 2, Batch 56450, Loss: 0.0017117321258410811\n",
      "Epoch 2, Batch 56500, Loss: 0.0015967475483193994\n",
      "Epoch 2, Batch 56550, Loss: 0.001642689574509859\n",
      "Epoch 2, Batch 56600, Loss: 0.0017846178961917758\n",
      "Epoch 2, Batch 56650, Loss: 0.0025595363695174456\n",
      "Epoch 2, Batch 56700, Loss: 0.002486645244061947\n",
      "Epoch 2, Batch 56750, Loss: 0.0021269728895276785\n",
      "Epoch 2, Batch 56800, Loss: 0.0019812998361885548\n",
      "Epoch 2, Batch 56850, Loss: 0.0014477383811026812\n",
      "Epoch 2, Batch 56900, Loss: 0.3704235255718231\n",
      "Epoch 2, Batch 56950, Loss: 0.0041478946805000305\n",
      "Epoch 2, Batch 57000, Loss: 0.003326508915051818\n",
      "Epoch 2, Batch 57050, Loss: 0.002880859887227416\n",
      "Epoch 2, Batch 57100, Loss: 0.002824145834892988\n",
      "Epoch 2, Batch 57150, Loss: 0.002222577342763543\n",
      "Epoch 2, Batch 57200, Loss: 0.0025659441016614437\n",
      "Epoch 2, Batch 57250, Loss: 0.0018919840222224593\n",
      "Epoch 2, Batch 57300, Loss: 0.0021212021820247173\n",
      "Epoch 2, Batch 57350, Loss: 0.002656441880390048\n",
      "Epoch 2, Batch 57400, Loss: 0.002389826811850071\n",
      "Epoch 2, Batch 57450, Loss: 0.0019671551417559385\n",
      "Epoch 2, Batch 57500, Loss: 0.0014914971543475986\n",
      "Epoch 2, Batch 57550, Loss: 0.0021150170359760523\n",
      "Epoch 2, Batch 57600, Loss: 0.0019608493894338608\n",
      "Epoch 2, Batch 57650, Loss: 0.0024834584910422564\n",
      "Epoch 2, Batch 57700, Loss: 0.0034516206942498684\n",
      "Epoch 2, Batch 57750, Loss: 0.002860326785594225\n",
      "Epoch 2, Batch 57800, Loss: 0.0033837761729955673\n",
      "Epoch 2, Batch 57850, Loss: 0.0038191264029592276\n",
      "Epoch 2, Batch 57900, Loss: 0.00238024047575891\n",
      "Epoch 2, Batch 57950, Loss: 0.002716843970119953\n",
      "Epoch 2, Batch 58000, Loss: 0.0025587633717805147\n",
      "Epoch 2, Batch 58050, Loss: 0.004021842498332262\n",
      "Epoch 2, Batch 58100, Loss: 0.003134798491373658\n",
      "Epoch 2, Batch 58150, Loss: 0.3942001760005951\n",
      "Epoch 2, Batch 58200, Loss: 0.0025735225062817335\n",
      "Epoch 2, Batch 58250, Loss: 0.0021571177057921886\n",
      "Epoch 2, Batch 58300, Loss: 0.0023310778196901083\n",
      "Epoch 2, Batch 58350, Loss: 0.0018997957231476903\n",
      "Epoch 2, Batch 58400, Loss: 0.0013297906843945384\n",
      "Epoch 2, Batch 58450, Loss: 0.0016751644434407353\n",
      "Epoch 2, Batch 58500, Loss: 0.0023858018685132265\n",
      "Epoch 2, Batch 58550, Loss: 0.0023152863141149282\n",
      "Epoch 2, Batch 58600, Loss: 0.0019816579297184944\n",
      "Epoch 2, Batch 58650, Loss: 0.0017045590793713927\n",
      "Epoch 2, Batch 58700, Loss: 0.0018939597066491842\n",
      "Epoch 2, Batch 58750, Loss: 0.0017852545715868473\n",
      "Epoch 2, Batch 58800, Loss: 0.002451245905831456\n",
      "Epoch 2, Batch 58850, Loss: 0.0029843715019524097\n",
      "Epoch 2, Batch 58900, Loss: 0.002140130614861846\n",
      "Epoch 2, Batch 58950, Loss: 0.002558706793934107\n",
      "Epoch 2, Batch 59000, Loss: 0.002478727139532566\n",
      "Epoch 2, Batch 59050, Loss: 0.3602721691131592\n",
      "Epoch 2, Batch 59100, Loss: 0.0023973819334059954\n",
      "Epoch 2, Batch 59150, Loss: 0.003660990623757243\n",
      "Epoch 2, Batch 59200, Loss: 0.0030262386426329613\n",
      "Epoch 2, Batch 59250, Loss: 0.0039045209996402264\n",
      "Epoch 2, Batch 59300, Loss: 0.0030183179769665003\n",
      "Epoch 2, Batch 59350, Loss: 0.0026614656671881676\n",
      "Epoch 2, Batch 59400, Loss: 0.0017092261696234345\n",
      "Epoch 2, Batch 59450, Loss: 0.0027412925846874714\n",
      "Epoch 2, Batch 59500, Loss: 0.001928354031406343\n",
      "Epoch 2, Batch 59550, Loss: 0.0017676666611805558\n",
      "Epoch 2, Batch 59600, Loss: 0.002277691848576069\n",
      "Epoch 2, Batch 59650, Loss: 0.001804202445782721\n",
      "Epoch 2, Batch 59700, Loss: 0.0016288971528410912\n",
      "Epoch 2, Batch 59750, Loss: 0.0011862218379974365\n",
      "Epoch 2, Batch 59800, Loss: 0.001891910913400352\n",
      "Epoch 2, Batch 59850, Loss: 0.002698300639167428\n",
      "Epoch 2, Batch 59900, Loss: 0.002909498754888773\n",
      "Epoch 2, Batch 59950, Loss: 0.0025513481814414263\n",
      "Epoch 2, Batch 60000, Loss: 0.0018662819638848305\n",
      "Epoch 2, Batch 60050, Loss: 0.0016319770365953445\n",
      "Epoch 2, Batch 60100, Loss: 0.0022448631934821606\n",
      "Epoch 2, Batch 60150, Loss: 0.002336024073883891\n",
      "Epoch 2, Batch 60200, Loss: 0.0018814114155247808\n",
      "Epoch 2, Batch 60250, Loss: 0.0022324949968606234\n",
      "Epoch 2, Batch 60300, Loss: 0.0018062768504023552\n",
      "Epoch 2, Batch 60350, Loss: 0.002882207278162241\n",
      "Epoch 2, Batch 60400, Loss: 0.0029128980822861195\n",
      "Epoch 2, Batch 60450, Loss: 0.0025625175330787897\n",
      "Epoch 2, Batch 60500, Loss: 0.003260998986661434\n",
      "Epoch 2, Batch 60550, Loss: 0.0031634606420993805\n",
      "Epoch 2, Batch 60600, Loss: 0.002146753715351224\n",
      "Epoch 2, Batch 60650, Loss: 0.0028354846872389317\n",
      "Epoch 2, Batch 60700, Loss: 0.0025584485847502947\n",
      "Epoch 2, Batch 60750, Loss: 0.0015716676134616137\n",
      "Epoch 2, Batch 60800, Loss: 0.001783163519576192\n",
      "Epoch 2, Batch 60850, Loss: 0.0015106924111023545\n",
      "Epoch 2, Batch 60900, Loss: 0.002053083386272192\n",
      "Epoch 2, Batch 60950, Loss: 0.002210517879575491\n",
      "Epoch 2, Batch 61000, Loss: 0.3863384425640106\n",
      "Epoch 2, Batch 61050, Loss: 0.001831153640523553\n",
      "Epoch 2, Batch 61100, Loss: 0.0018502234015613794\n",
      "Epoch 2, Batch 61150, Loss: 0.0017323949141427875\n",
      "Epoch 2, Batch 61200, Loss: 0.0018099453300237656\n",
      "Epoch 2, Batch 61250, Loss: 0.001585071673616767\n",
      "Epoch 2, Batch 61300, Loss: 0.0017008824506774545\n",
      "Epoch 2, Batch 61350, Loss: 0.001454688492231071\n",
      "Epoch 2, Batch 61400, Loss: 0.0019085323438048363\n",
      "Epoch 2, Batch 61450, Loss: 0.0023017222993075848\n",
      "Epoch 2, Batch 61500, Loss: 0.0034700226970016956\n",
      "Epoch 2, Batch 61550, Loss: 0.0024593304842710495\n",
      "Epoch 2, Batch 61600, Loss: 0.002367217093706131\n",
      "Epoch 2, Batch 61650, Loss: 0.0020305239595472813\n",
      "Epoch 2, Batch 61700, Loss: 0.0017390380380675197\n",
      "Epoch 2, Batch 61750, Loss: 0.002755427034571767\n",
      "Epoch 2, Batch 61800, Loss: 0.0025233044289052486\n",
      "Epoch 2, Batch 61850, Loss: 0.0019639586098492146\n",
      "Epoch 2, Batch 61900, Loss: 0.0016580919036641717\n",
      "Epoch 2, Batch 61950, Loss: 0.0022255098447203636\n",
      "Epoch 2, Batch 62000, Loss: 0.002389384200796485\n",
      "Epoch 2, Batch 62050, Loss: 0.002503545954823494\n",
      "Epoch 2, Batch 62100, Loss: 0.0022435106802731752\n",
      "Epoch 2, Batch 62150, Loss: 0.0020992490462958813\n",
      "Epoch 2, Batch 62200, Loss: 0.0022504637017846107\n",
      "Epoch 2, Batch 62250, Loss: 0.0019770946819335222\n",
      "Epoch 2, Batch 62300, Loss: 0.3993932902812958\n",
      "Epoch 2, Batch 62350, Loss: 0.0018984641646966338\n",
      "Epoch 2, Batch 62400, Loss: 0.0024516137782484293\n",
      "Epoch 2, Batch 62450, Loss: 0.002107191365212202\n",
      "Epoch 2, Batch 62500, Loss: 0.0016816499410197139\n",
      "Epoch 2, Batch 62550, Loss: 0.0018687892006710172\n",
      "Epoch 2, Batch 62600, Loss: 0.002383098006248474\n",
      "Epoch 2, Batch 62650, Loss: 0.0017422556411474943\n",
      "Epoch 2, Batch 62700, Loss: 0.0017455995548516512\n",
      "Epoch 2, Batch 62750, Loss: 0.0016152728348970413\n",
      "Epoch 2, Batch 62800, Loss: 0.0018927310593426228\n",
      "Epoch 2, Batch 62850, Loss: 0.0025256406515836716\n",
      "Epoch 2, Batch 62900, Loss: 0.002699517412111163\n",
      "Epoch 2, Batch 62950, Loss: 0.0020006627310067415\n",
      "Epoch 2, Batch 63000, Loss: 0.0016568960854783654\n",
      "Epoch 2, Batch 63050, Loss: 0.0022927289828658104\n",
      "Epoch 2, Batch 63100, Loss: 0.003130262717604637\n",
      "Epoch 2, Batch 63150, Loss: 0.0026277375873178244\n",
      "Epoch 2, Batch 63200, Loss: 0.0019398427102714777\n",
      "Epoch 2, Batch 63250, Loss: 0.003262007376179099\n",
      "Epoch 2, Batch 63300, Loss: 0.002981032943353057\n",
      "Epoch 2, Batch 63350, Loss: 0.0025627256836742163\n",
      "Epoch 2, Batch 63400, Loss: 0.0026794623117893934\n",
      "Epoch 2, Batch 63450, Loss: 0.001869143801741302\n",
      "Epoch 2, Batch 63500, Loss: 0.0029297976288944483\n",
      "Epoch 2, Batch 63550, Loss: 0.0028524689842015505\n",
      "Epoch 2, Batch 63600, Loss: 0.0023632063530385494\n",
      "Epoch 2, Batch 63650, Loss: 0.0025740121491253376\n",
      "Epoch 2, Batch 63700, Loss: 0.0021151206456124783\n",
      "Epoch 2, Batch 63750, Loss: 0.0013650581240653992\n",
      "Epoch 2, Batch 63800, Loss: 0.0015753150219097733\n",
      "Epoch 2, Batch 63850, Loss: 0.0015641800127923489\n",
      "Epoch 2, Batch 63900, Loss: 0.0014554375084117055\n",
      "Epoch 2, Batch 63950, Loss: 0.0012840154813602567\n",
      "Epoch 2, Batch 64000, Loss: 0.0013196170330047607\n",
      "Epoch 2, Batch 64050, Loss: 0.001453048549592495\n",
      "Epoch 2, Batch 64100, Loss: 0.0023605325259268284\n",
      "Epoch 2, Batch 64150, Loss: 0.002848266391083598\n",
      "Epoch 2, Batch 64200, Loss: 0.002489475766196847\n",
      "Epoch 2, Batch 64250, Loss: 0.0023537343367934227\n",
      "Epoch 2, Batch 64300, Loss: 0.0019677996169775724\n",
      "Epoch 2, Batch 64350, Loss: 0.001961886417120695\n",
      "Epoch 2, Batch 64400, Loss: 0.0021021070424467325\n",
      "Epoch 2, Batch 64450, Loss: 0.0020345812663435936\n",
      "Epoch 2, Batch 64500, Loss: 0.0020487699657678604\n",
      "Epoch 2, Batch 64550, Loss: 0.0016674306243658066\n",
      "Epoch 2, Batch 64600, Loss: 0.0012062345631420612\n",
      "Epoch 2, Batch 64650, Loss: 0.0009835709352046251\n",
      "Epoch 2, Batch 64700, Loss: 0.0011851727031171322\n",
      "Epoch 2, Batch 64750, Loss: 0.0019112539011985064\n",
      "Epoch 2, Batch 64800, Loss: 0.0015700152143836021\n",
      "Epoch 2, Batch 64850, Loss: 0.0018697812920436263\n",
      "Epoch 2, Batch 64900, Loss: 0.002418690361082554\n",
      "Epoch 2, Batch 64950, Loss: 0.002366770524531603\n",
      "Epoch 2, Batch 65000, Loss: 0.0017486294964328408\n",
      "Epoch 2, Batch 65050, Loss: 0.0016024811193346977\n",
      "Epoch 2, Batch 65100, Loss: 0.0016805584309622645\n",
      "Epoch 2, Batch 65150, Loss: 0.0013475896557793021\n",
      "Epoch 2, Batch 65200, Loss: 0.0014232838293537498\n",
      "Epoch 2, Batch 65250, Loss: 0.002844560192897916\n",
      "Epoch 2, Batch 65300, Loss: 0.00230016210116446\n",
      "Epoch 2, Batch 65350, Loss: 0.0020584764424711466\n",
      "Epoch 2, Batch 65400, Loss: 0.0017460044473409653\n",
      "Epoch 2, Batch 65450, Loss: 0.0017974147340282798\n",
      "Epoch 2, Batch 65500, Loss: 0.0016035756561905146\n",
      "Epoch 2, Batch 65550, Loss: 0.001552237314172089\n",
      "Epoch 2, Batch 65600, Loss: 0.0015437495894730091\n",
      "Epoch 2, Batch 65650, Loss: 0.0017409938154742122\n",
      "Epoch 2, Batch 65700, Loss: 0.0018798031378537416\n",
      "Epoch 2, Batch 65750, Loss: 0.0028998793568462133\n",
      "Epoch 2, Batch 65800, Loss: 0.002927148249000311\n",
      "Epoch 2, Batch 65850, Loss: 0.0028740570414811373\n",
      "Epoch 2, Batch 65900, Loss: 0.0022150790318846703\n",
      "Epoch 2, Batch 65950, Loss: 0.0015655780443921685\n",
      "Epoch 2, Batch 66000, Loss: 0.0011374905006960034\n",
      "Epoch 2, Batch 66050, Loss: 0.0011937546078115702\n",
      "Epoch 2, Batch 66100, Loss: 0.0012054963735863566\n",
      "Epoch 2, Batch 66150, Loss: 0.0014904167037457228\n",
      "Epoch 2, Batch 66200, Loss: 0.0012619211338460445\n",
      "Epoch 2, Batch 66250, Loss: 0.0013539474457502365\n",
      "Epoch 2, Batch 66300, Loss: 0.0011272525880485773\n",
      "Epoch 2, Batch 66350, Loss: 0.0011287134839221835\n",
      "Epoch 2, Batch 66400, Loss: 0.0012040289584547281\n",
      "Epoch 2, Batch 66450, Loss: 0.001526369247585535\n",
      "Epoch 2, Batch 66500, Loss: 0.001744413166306913\n",
      "Epoch 2, Batch 66550, Loss: 0.0014158232370391488\n",
      "Epoch 2, Batch 66600, Loss: 0.0020452565513551235\n",
      "Epoch 2, Batch 66650, Loss: 0.0013562024105340242\n",
      "Epoch 2, Batch 66700, Loss: 0.001720764790661633\n",
      "Epoch 2, Batch 66750, Loss: 0.0023966666776686907\n",
      "Epoch 2, Batch 66800, Loss: 0.0024939037393778563\n",
      "Epoch 2, Batch 66850, Loss: 0.001936839078553021\n",
      "Epoch 2, Batch 66900, Loss: 0.002623488660901785\n",
      "Epoch 2, Batch 66950, Loss: 0.0021452337969094515\n",
      "Epoch 2, Batch 67000, Loss: 0.001898096059449017\n",
      "Epoch 2, Batch 67050, Loss: 0.0023619839921593666\n",
      "Epoch 2, Batch 67100, Loss: 0.0018250681459903717\n",
      "Epoch 2, Batch 67150, Loss: 0.0015125061618164182\n",
      "Epoch 2, Batch 67200, Loss: 0.0026174732483923435\n",
      "Epoch 2, Batch 67250, Loss: 0.0030940326396375895\n",
      "Epoch 2, Batch 67300, Loss: 0.0030426254961639643\n",
      "Epoch 2, Batch 67350, Loss: 0.002354875672608614\n",
      "Epoch 2, Batch 67400, Loss: 0.0018037878908216953\n",
      "Epoch 2, Batch 67450, Loss: 0.0034342717844992876\n",
      "Epoch 2, Batch 67500, Loss: 0.002848383504897356\n",
      "Epoch 2, Batch 67550, Loss: 0.003204175503924489\n",
      "Epoch 2, Batch 67600, Loss: 0.00218675984069705\n",
      "Epoch 2, Batch 67650, Loss: 0.0018347343429923058\n",
      "Epoch 2, Batch 67700, Loss: 0.0017674750415608287\n",
      "Epoch 2, Batch 67750, Loss: 0.002477693371474743\n",
      "Epoch 2, Batch 67800, Loss: 0.0017443796386942267\n",
      "Epoch 2, Batch 67850, Loss: 0.0012526013888418674\n",
      "Epoch 2, Batch 67900, Loss: 0.0011215120321139693\n",
      "Epoch 2, Batch 67950, Loss: 0.00127139943651855\n",
      "Epoch 2, Batch 68000, Loss: 0.0018867745529860258\n",
      "Epoch 2, Batch 68050, Loss: 0.0018787516746670008\n",
      "Epoch 2, Batch 68100, Loss: 0.0017825273098424077\n",
      "Epoch 2, Batch 68150, Loss: 0.00187292427290231\n",
      "Epoch 2, Batch 68200, Loss: 0.0022337513510137796\n",
      "Epoch 2, Batch 68250, Loss: 0.0021970232482999563\n",
      "Epoch 2, Batch 68300, Loss: 0.0023399272467941046\n",
      "Epoch 2, Batch 68350, Loss: 0.002517053624615073\n",
      "Epoch 2, Batch 68400, Loss: 0.003104778239503503\n",
      "Epoch 2, Batch 68450, Loss: 0.0031539471819996834\n",
      "Epoch 2, Batch 68500, Loss: 0.0024999475572258234\n",
      "Epoch 2, Batch 68550, Loss: 0.002000117674469948\n",
      "Epoch 2, Batch 68600, Loss: 0.002565828850492835\n",
      "Epoch 2, Batch 68650, Loss: 0.0020054916385561228\n",
      "Epoch 2, Batch 68700, Loss: 0.0013667130842804909\n",
      "Epoch 2, Batch 68750, Loss: 0.0016606043791398406\n",
      "Epoch 2, Batch 68800, Loss: 0.0009491641540080309\n",
      "Epoch 2, Batch 68850, Loss: 0.0012030374491587281\n",
      "Epoch 2, Batch 68900, Loss: 0.0012937362771481276\n",
      "Epoch 2, Batch 68950, Loss: 0.0017819335917010903\n",
      "Epoch 2, Batch 69000, Loss: 0.0013381845783442259\n",
      "Epoch 2, Batch 69050, Loss: 0.0015673792222514749\n",
      "Epoch 2, Batch 69100, Loss: 0.0021242345683276653\n",
      "Epoch 2, Batch 69150, Loss: 0.001277135917916894\n",
      "Epoch 2, Batch 69200, Loss: 0.0014303512871265411\n",
      "Epoch 2, Batch 69250, Loss: 0.0009691810701042414\n",
      "Epoch 2, Batch 69300, Loss: 0.0010257416870445013\n",
      "Epoch 2, Batch 69350, Loss: 0.0012002548901364207\n",
      "Epoch 2, Batch 69400, Loss: 0.0012526233913376927\n",
      "Epoch 2, Batch 69450, Loss: 0.0010194024071097374\n",
      "Epoch 2, Batch 69500, Loss: 0.0014567435719072819\n",
      "Epoch 2, Batch 69550, Loss: 0.001272189780138433\n",
      "Epoch 2, Batch 69600, Loss: 0.0016051551792770624\n",
      "Epoch 2, Batch 69650, Loss: 0.0016189407324418426\n",
      "Epoch 2, Batch 69700, Loss: 0.0015270226867869496\n",
      "Epoch 2, Batch 69750, Loss: 0.0020702423062175512\n",
      "Epoch 2, Batch 69800, Loss: 0.0027352452743798494\n",
      "Epoch 2, Batch 69850, Loss: 0.002257898449897766\n",
      "Epoch 2, Batch 69900, Loss: 0.0017178482376039028\n",
      "Epoch 2, Batch 69950, Loss: 0.0018321460811421275\n",
      "Epoch 2, Batch 70000, Loss: 0.002095224568620324\n",
      "Epoch 2, Batch 70050, Loss: 0.002198506612330675\n",
      "Epoch 2, Batch 70100, Loss: 0.0035701938904821873\n",
      "Epoch 2, Batch 70150, Loss: 0.003625561948865652\n",
      "Epoch 2, Batch 70200, Loss: 0.002908236812800169\n",
      "Epoch 2, Batch 70250, Loss: 0.0029314609710127115\n",
      "Epoch 2, Batch 70300, Loss: 0.003092316910624504\n",
      "Epoch 2, Batch 70350, Loss: 0.002240558620542288\n",
      "Epoch 2, Batch 70400, Loss: 0.0023587236646562815\n",
      "Epoch 2, Batch 70450, Loss: 0.002224635798484087\n",
      "Epoch 2, Batch 70500, Loss: 0.001560512464493513\n",
      "Epoch 2, Batch 70550, Loss: 0.0012308238074183464\n",
      "Epoch 2, Batch 70600, Loss: 0.001743448548950255\n",
      "Epoch 2, Batch 70650, Loss: 0.0033337015192955732\n",
      "Epoch 2, Batch 70700, Loss: 0.0025207940489053726\n",
      "Epoch 2, Batch 70750, Loss: 0.002359566977247596\n",
      "Epoch 2, Batch 70800, Loss: 0.002824435941874981\n",
      "Epoch 2, Batch 70850, Loss: 0.001958114095032215\n",
      "Epoch 2, Batch 70900, Loss: 0.0025449965614825487\n",
      "Epoch 2, Batch 70950, Loss: 0.0032670581713318825\n",
      "Epoch 2, Batch 71000, Loss: 0.003659497480839491\n",
      "Epoch 2, Batch 71050, Loss: 0.39422407746315\n",
      "Epoch 2, Batch 71100, Loss: 0.0022501880303025246\n",
      "Epoch 2, Batch 71150, Loss: 0.0016931514255702496\n",
      "Epoch 2, Batch 71200, Loss: 0.002456508344039321\n",
      "Epoch 2, Batch 71250, Loss: 0.002440517535433173\n",
      "Epoch 2, Batch 71300, Loss: 0.0023873760364949703\n",
      "Epoch 2, Batch 71350, Loss: 0.002387627027928829\n",
      "Epoch 2, Batch 71400, Loss: 0.002296710852533579\n",
      "Epoch 2, Batch 71450, Loss: 0.0021998565644025803\n",
      "Epoch 2, Batch 71500, Loss: 0.0022076463792473078\n",
      "Epoch 2, Batch 71550, Loss: 0.0018526897765696049\n",
      "Epoch 2, Batch 71600, Loss: 0.0026769035030156374\n",
      "Epoch 2, Batch 71650, Loss: 0.002788655227050185\n",
      "Epoch 2, Batch 71700, Loss: 0.0028692791238427162\n",
      "Epoch 2, Batch 71750, Loss: 0.0022895652800798416\n",
      "Epoch 2, Batch 71800, Loss: 0.0030147498473525047\n",
      "Epoch 2, Batch 71850, Loss: 0.003012649482116103\n",
      "Epoch 2, Batch 71900, Loss: 0.002735488349571824\n",
      "Epoch 2, Batch 71950, Loss: 0.0027328107971698046\n",
      "Epoch 2, Batch 72000, Loss: 0.002412446541711688\n",
      "Epoch 2, Batch 72050, Loss: 0.0017421713564544916\n",
      "Epoch 2, Batch 72100, Loss: 0.0036347280256450176\n",
      "Epoch 2, Batch 72150, Loss: 0.0027475981041789055\n",
      "Epoch 2, Batch 72200, Loss: 0.0028463981579989195\n",
      "Epoch 2, Batch 72250, Loss: 0.002642677864059806\n",
      "Epoch 2, Batch 72300, Loss: 0.0019214519998058677\n",
      "Epoch 2, Batch 72350, Loss: 0.0017221596790477633\n",
      "Epoch 2, Batch 72400, Loss: 0.3855939507484436\n",
      "Epoch 2, Batch 72450, Loss: 0.00278741167858243\n",
      "Epoch 2, Batch 72500, Loss: 0.002928002504631877\n",
      "Epoch 2, Batch 72550, Loss: 0.0029714968986809254\n",
      "Epoch 2, Batch 72600, Loss: 0.0026840604841709137\n",
      "Epoch 2, Batch 72650, Loss: 0.002563673071563244\n",
      "Epoch 2, Batch 72700, Loss: 0.0019368580542504787\n",
      "Epoch 2, Batch 72750, Loss: 0.0025976658798754215\n",
      "Epoch 2, Batch 72800, Loss: 0.0023661176674067974\n",
      "Epoch 2, Batch 72850, Loss: 0.002180575393140316\n",
      "Epoch 2, Batch 72900, Loss: 0.002081702696159482\n",
      "Epoch 2, Batch 72950, Loss: 0.0015512574464082718\n",
      "Epoch 2, Batch 73000, Loss: 0.00149184325709939\n",
      "Epoch 2, Batch 73050, Loss: 0.4025972783565521\n",
      "Epoch 2, Batch 73100, Loss: 0.0013444878859445453\n",
      "Epoch 2, Batch 73150, Loss: 0.001675489591434598\n",
      "Epoch 2, Batch 73200, Loss: 0.001471910160034895\n",
      "Epoch 2, Batch 73250, Loss: 0.0014425277477130294\n",
      "Epoch 2, Batch 73300, Loss: 0.0013798093423247337\n",
      "Epoch 2, Batch 73350, Loss: 0.0017551780911162496\n",
      "Epoch 2, Batch 73400, Loss: 0.001584139303304255\n",
      "Epoch 2, Batch 73450, Loss: 0.00186390639282763\n",
      "Epoch 2, Batch 73500, Loss: 0.001769735594280064\n",
      "Epoch 2, Batch 73550, Loss: 0.0017145099118351936\n",
      "Epoch 2, Batch 73600, Loss: 0.0019409905653446913\n",
      "Epoch 2, Batch 73650, Loss: 0.001872535329312086\n",
      "Epoch 2, Batch 73700, Loss: 0.0015796165680512786\n",
      "Epoch 2, Batch 73750, Loss: 0.0014567796606570482\n",
      "Epoch 2, Batch 73800, Loss: 0.002046847017481923\n",
      "Epoch 2, Batch 73850, Loss: 0.0016207200242206454\n",
      "Epoch 2, Batch 73900, Loss: 0.0018827932653948665\n",
      "Epoch 2, Batch 73950, Loss: 0.0018944147741422057\n",
      "Epoch 2, Batch 74000, Loss: 0.0024285088293254375\n",
      "Epoch 2, Batch 74050, Loss: 0.0016390735981985927\n",
      "Epoch 2, Batch 74100, Loss: 0.0012920814333483577\n",
      "Epoch 2, Batch 74150, Loss: 0.001213313895277679\n",
      "Epoch 2, Batch 74200, Loss: 0.0010660234838724136\n",
      "Epoch 2, Batch 74250, Loss: 0.001186121255159378\n",
      "Epoch 2, Batch 74300, Loss: 0.0014271342661231756\n",
      "Epoch 2, Batch 74350, Loss: 0.0019645155407488346\n",
      "Epoch 2, Batch 74400, Loss: 0.0018405596492812037\n",
      "Epoch 2, Batch 74450, Loss: 0.0015183815266937017\n",
      "Epoch 2, Batch 74500, Loss: 0.0030894498340785503\n",
      "Epoch 2, Batch 74550, Loss: 0.0024590473622083664\n",
      "Epoch 2, Batch 74600, Loss: 0.002707409905269742\n",
      "Epoch 2, Batch 74650, Loss: 0.001936510088853538\n",
      "Epoch 2, Batch 74700, Loss: 0.0018431770149618387\n",
      "Epoch 2, Batch 74750, Loss: 0.0015674623427912593\n",
      "Epoch 2, Batch 74800, Loss: 0.0018074567196890712\n",
      "Epoch 2, Batch 74850, Loss: 0.0015942167956382036\n",
      "Epoch 2, Batch 74900, Loss: 0.0015173641731962562\n",
      "Epoch 2, Batch 74950, Loss: 0.0019538160413503647\n",
      "Epoch 2, Batch 75000, Loss: 0.001598283532075584\n",
      "Epoch 2, Batch 75050, Loss: 0.0016614096239209175\n",
      "Epoch 2, Batch 75100, Loss: 0.001732839155010879\n",
      "Epoch 2, Batch 75150, Loss: 0.002422603778541088\n",
      "Epoch 2, Batch 75200, Loss: 0.0016348289791494608\n",
      "Epoch 2, Batch 75250, Loss: 0.0013144892873242497\n",
      "Epoch 2, Batch 75300, Loss: 0.0016505821840837598\n",
      "Epoch 2, Batch 75350, Loss: 0.0015242000808939338\n",
      "Epoch 2, Batch 75400, Loss: 0.0015034620882943273\n",
      "Epoch 2, Batch 75450, Loss: 0.0016278381226584315\n",
      "Epoch 2, Batch 75500, Loss: 0.001156513229943812\n",
      "Epoch 2, Batch 75550, Loss: 0.3817562758922577\n",
      "Epoch 2, Batch 75600, Loss: 0.001986927818506956\n",
      "Epoch 2, Batch 75650, Loss: 0.002265052404254675\n",
      "Epoch 2, Batch 75700, Loss: 0.0020770186092704535\n",
      "Epoch 2, Batch 75750, Loss: 0.002531216712668538\n",
      "Epoch 2, Batch 75800, Loss: 0.0029802836943417788\n",
      "Epoch 2, Batch 75850, Loss: 0.0031009367667138577\n",
      "Epoch 2, Batch 75900, Loss: 0.002295625628903508\n",
      "Epoch 2, Batch 75950, Loss: 0.0022428492084145546\n",
      "Epoch 2, Batch 76000, Loss: 0.003226680215448141\n",
      "Epoch 2, Batch 76050, Loss: 0.002592376433312893\n",
      "Epoch 2, Batch 76100, Loss: 0.002138399053364992\n",
      "Epoch 2, Batch 76150, Loss: 0.00250058202072978\n",
      "Epoch 2, Batch 76200, Loss: 0.37797829508781433\n",
      "Epoch 2, Batch 76250, Loss: 0.0018845726735889912\n",
      "Epoch 2, Batch 76300, Loss: 0.0018005017191171646\n",
      "Epoch 2, Batch 76350, Loss: 0.39191877841949463\n",
      "Epoch 2, Batch 76400, Loss: 0.002458366332575679\n",
      "Epoch 2, Batch 76450, Loss: 0.002986241364851594\n",
      "Epoch 2, Batch 76500, Loss: 0.0023048168513923883\n",
      "Epoch 2, Batch 76550, Loss: 0.002155846217647195\n",
      "Epoch 2, Batch 76600, Loss: 0.0017325762892141938\n",
      "Epoch 2, Batch 76650, Loss: 0.0014146810863167048\n",
      "Epoch 2, Batch 76700, Loss: 0.0016594566404819489\n",
      "Epoch 2, Batch 76750, Loss: 0.0017183228628709912\n",
      "Epoch 2, Batch 76800, Loss: 0.00187901989556849\n",
      "Epoch 2, Batch 76850, Loss: 0.0026436459738761187\n",
      "Epoch 2, Batch 76900, Loss: 0.002660205354914069\n",
      "Epoch 2, Batch 76950, Loss: 0.3999973237514496\n",
      "Epoch 2, Batch 77000, Loss: 0.003044568235054612\n",
      "Epoch 2, Batch 77050, Loss: 0.002965218387544155\n",
      "Epoch 2, Batch 77100, Loss: 0.003047080710530281\n",
      "Epoch 2, Batch 77150, Loss: 0.002693506656214595\n",
      "Epoch 2, Batch 77200, Loss: 0.0020426560658961535\n",
      "Epoch 2, Batch 77250, Loss: 0.002647705841809511\n",
      "Epoch 2, Batch 77300, Loss: 0.003448601346462965\n",
      "Epoch 2, Batch 77350, Loss: 0.0027912696823477745\n",
      "Epoch 2, Batch 77400, Loss: 0.002748302184045315\n",
      "Epoch 2, Batch 77450, Loss: 0.003052846295759082\n",
      "Epoch 2, Batch 77500, Loss: 0.00329077010974288\n",
      "Epoch 2, Batch 77550, Loss: 0.0032525055576115847\n",
      "Epoch 2, Batch 77600, Loss: 0.002774153370410204\n",
      "Epoch 2, Batch 77650, Loss: 0.0019367450149729848\n",
      "Epoch 2, Batch 77700, Loss: 0.001883792458102107\n",
      "Epoch 2, Batch 77750, Loss: 0.0013595495838671923\n",
      "Epoch 2, Batch 77800, Loss: 0.0011884381528943777\n",
      "Epoch 2, Batch 77850, Loss: 0.0012030522339046001\n",
      "Epoch 2, Batch 77900, Loss: 0.0012917830608785152\n",
      "Epoch 2, Batch 77950, Loss: 0.0017192753730341792\n",
      "Epoch 2, Batch 78000, Loss: 0.0016025872901082039\n",
      "Epoch 2, Batch 78050, Loss: 0.0022349415812641382\n",
      "Epoch 2, Batch 78100, Loss: 0.002133379690349102\n",
      "Epoch 2, Batch 78150, Loss: 0.001731464872136712\n",
      "Epoch 2, Batch 78200, Loss: 0.0016679109539836645\n",
      "Epoch 2, Batch 78250, Loss: 0.0016858676681295037\n",
      "Epoch 2, Batch 78300, Loss: 0.001441354164853692\n",
      "Epoch 2, Batch 78350, Loss: 0.0013357552234083414\n",
      "Epoch 2, Batch 78400, Loss: 0.002464035525918007\n",
      "Epoch 2, Batch 78450, Loss: 0.002102382481098175\n",
      "Epoch 2, Batch 78500, Loss: 0.002558523789048195\n",
      "Epoch 2, Batch 78550, Loss: 0.002678794553503394\n",
      "Epoch 2, Batch 78600, Loss: 0.0019332184456288815\n",
      "Epoch 2, Batch 78650, Loss: 0.0016370562370866537\n",
      "Epoch 2, Batch 78700, Loss: 0.0016451360424980521\n",
      "Epoch 2, Batch 78750, Loss: 0.001954092411324382\n",
      "Epoch 2, Batch 78800, Loss: 0.0014996773097664118\n",
      "Epoch 2, Batch 78850, Loss: 0.0014862364623695612\n",
      "Epoch 2, Batch 78900, Loss: 0.000991381355561316\n",
      "Epoch 2, Batch 78950, Loss: 0.0015574650606140494\n",
      "Epoch 2, Batch 79000, Loss: 0.0017023957334458828\n",
      "Epoch 2, Batch 79050, Loss: 0.0020486717112362385\n",
      "Epoch 2, Batch 79100, Loss: 0.002222527051344514\n",
      "Epoch 2, Batch 79150, Loss: 0.002927290741354227\n",
      "Epoch 2, Batch 79200, Loss: 0.3820897042751312\n",
      "Epoch 2, Batch 79250, Loss: 0.002840257016941905\n",
      "Epoch 2, Batch 79300, Loss: 0.0025567414704710245\n",
      "Epoch 2, Batch 79350, Loss: 0.0019917706958949566\n",
      "Epoch 2, Batch 79400, Loss: 0.0022612845059484243\n",
      "Epoch 2, Batch 79450, Loss: 0.0023791640996932983\n",
      "Epoch 2, Batch 79500, Loss: 0.003167717484757304\n",
      "Epoch 2, Batch 79550, Loss: 0.0034304724540561438\n",
      "Epoch 2, Batch 79600, Loss: 0.003155296901240945\n",
      "Epoch 2, Batch 79650, Loss: 0.00394105538725853\n",
      "Epoch 2, Batch 79700, Loss: 0.003069134894758463\n",
      "Epoch 2, Batch 79750, Loss: 0.00248944154009223\n",
      "Epoch 2, Batch 79800, Loss: 0.002249083947390318\n",
      "Epoch 2, Batch 79850, Loss: 0.0027349544689059258\n",
      "Epoch 2, Batch 79900, Loss: 0.0022979937493801117\n",
      "Epoch 2, Batch 79950, Loss: 0.0015253693563863635\n",
      "Epoch 2, Batch 80000, Loss: 0.0017467155121266842\n",
      "Epoch 2, Batch 80050, Loss: 0.002120150253176689\n",
      "Epoch 2, Batch 80100, Loss: 0.0018872199580073357\n",
      "Epoch 2, Batch 80150, Loss: 0.001522105187177658\n",
      "Epoch 2, Batch 80200, Loss: 0.0015915747499093413\n",
      "Epoch 2, Batch 80250, Loss: 0.0016396723221987486\n",
      "Epoch 2, Batch 80300, Loss: 0.0014346837997436523\n",
      "Epoch 2, Batch 80350, Loss: 0.0010025878436863422\n",
      "Epoch 2, Batch 80400, Loss: 0.001579397008754313\n",
      "Epoch 2, Batch 80450, Loss: 0.0017722150078043342\n",
      "Epoch 2, Batch 80500, Loss: 0.0014202233869582415\n",
      "Epoch 2, Batch 80550, Loss: 0.0011631695087999105\n",
      "Epoch 2, Batch 80600, Loss: 0.0016909418627619743\n",
      "Epoch 2, Batch 80650, Loss: 0.0016603476833552122\n",
      "Epoch 2, Batch 80700, Loss: 0.0018654495943337679\n",
      "Epoch 2, Batch 80750, Loss: 0.001929048215970397\n",
      "Epoch 2, Batch 80800, Loss: 0.002248386386781931\n",
      "Epoch 2, Batch 80850, Loss: 0.001953279133886099\n",
      "Epoch 2, Batch 80900, Loss: 0.00174894614610821\n",
      "Epoch 2, Batch 80950, Loss: 0.0017296829028055072\n",
      "Epoch 2, Batch 81000, Loss: 0.0017242772737517953\n",
      "Epoch 2, Batch 81050, Loss: 0.0020427845884114504\n",
      "Epoch 2, Batch 81100, Loss: 0.0020758581813424826\n",
      "Epoch 2, Batch 81150, Loss: 0.0020143589936196804\n",
      "Epoch 2, Batch 81200, Loss: 0.001519856508821249\n",
      "Epoch 2, Batch 81250, Loss: 0.0026547275483608246\n",
      "Epoch 2, Batch 81300, Loss: 0.0033031152561306953\n",
      "Epoch 2, Batch 81350, Loss: 0.0021385448053479195\n",
      "Epoch 2, Batch 81400, Loss: 0.002315729157999158\n",
      "Epoch 2, Batch 81450, Loss: 0.4127540588378906\n",
      "Epoch 2, Batch 81500, Loss: 0.0014406630070880055\n",
      "Epoch 2, Batch 81550, Loss: 0.002201280789449811\n",
      "Epoch 2, Batch 81600, Loss: 0.0017293916316702962\n",
      "Epoch 2, Batch 81650, Loss: 0.0033164701890200377\n",
      "Epoch 2, Batch 81700, Loss: 0.0037577722687274218\n",
      "Epoch 2, Batch 81750, Loss: 0.003173103788867593\n",
      "Epoch 2, Batch 81800, Loss: 0.00253507518209517\n",
      "Epoch 2, Batch 81850, Loss: 0.0021989645902067423\n",
      "Epoch 2, Batch 81900, Loss: 0.0022566085681319237\n",
      "Epoch 2, Batch 81950, Loss: 0.0020058827940374613\n",
      "Epoch 2, Batch 82000, Loss: 0.0017852429300546646\n",
      "Epoch 2, Batch 82050, Loss: 0.002962221158668399\n",
      "Epoch 2, Batch 82100, Loss: 0.002968913409858942\n",
      "Epoch 2, Batch 82150, Loss: 0.0032100556418299675\n",
      "Epoch 2, Batch 82200, Loss: 0.003112945007160306\n",
      "Epoch 2, Batch 82250, Loss: 0.0023043774999678135\n",
      "Epoch 2, Batch 82300, Loss: 0.0022934903390705585\n",
      "Epoch 2, Batch 82350, Loss: 0.0023158227559179068\n",
      "Epoch 2, Batch 82400, Loss: 0.0022965988609939814\n",
      "Epoch 2, Batch 82450, Loss: 0.0019542023073881865\n",
      "Epoch 2, Batch 82500, Loss: 0.0019459687173366547\n",
      "Epoch 2, Batch 82550, Loss: 0.002032819902524352\n",
      "Epoch 2, Batch 82600, Loss: 0.001558010233566165\n",
      "Epoch 2, Batch 82650, Loss: 0.001971540739759803\n",
      "Epoch 2, Batch 82700, Loss: 0.0022164974361658096\n",
      "Epoch 2, Batch 82750, Loss: 0.0022914642468094826\n",
      "Epoch 2, Batch 82800, Loss: 0.0016962966183200479\n",
      "Epoch 2, Batch 82850, Loss: 0.0027832682244479656\n",
      "Epoch 2, Batch 82900, Loss: 0.002124876482412219\n",
      "Epoch 2, Batch 82950, Loss: 0.002005915390327573\n",
      "Epoch 2, Batch 83000, Loss: 0.0020140139386057854\n",
      "Epoch 2, Batch 83050, Loss: 0.0017676149727776647\n",
      "Epoch 2, Batch 83100, Loss: 0.001625079894438386\n",
      "Epoch 2, Batch 83150, Loss: 0.36988118290901184\n",
      "Epoch 2, Batch 83200, Loss: 0.002312521915882826\n",
      "Epoch 2, Batch 83250, Loss: 0.003942886367440224\n",
      "Epoch 2, Batch 83300, Loss: 0.004171786829829216\n",
      "Epoch 2, Batch 83350, Loss: 0.003634367138147354\n",
      "Epoch 2, Batch 83400, Loss: 0.003126729978248477\n",
      "Epoch 2, Batch 83450, Loss: 0.0021217470057308674\n",
      "Epoch 2, Batch 83500, Loss: 0.001639982801862061\n",
      "Epoch 2, Batch 83550, Loss: 0.0015811396297067404\n",
      "Epoch 2, Batch 83600, Loss: 0.0016685461159795523\n",
      "Epoch 2, Batch 83650, Loss: 0.0015515791019424796\n",
      "Epoch 2, Batch 83700, Loss: 0.0017238648142665625\n",
      "Epoch 2, Batch 83750, Loss: 0.0012378236278891563\n",
      "Epoch 2, Batch 83800, Loss: 0.0021715688053518534\n",
      "Epoch 2, Batch 83850, Loss: 0.0029132948257029057\n",
      "Epoch 2, Batch 83900, Loss: 0.001923370291478932\n",
      "Epoch 2, Batch 83950, Loss: 0.001836062641814351\n",
      "Epoch 2, Batch 84000, Loss: 0.0019714341033250093\n",
      "Epoch 2, Batch 84050, Loss: 0.00269208662211895\n",
      "Epoch 2, Batch 84100, Loss: 0.0028197153005748987\n",
      "Epoch 2, Batch 84150, Loss: 0.00189230649266392\n",
      "Epoch 2, Batch 84200, Loss: 0.001929623307660222\n",
      "Epoch 2, Batch 84250, Loss: 0.0018888607155531645\n",
      "Epoch 2, Batch 84300, Loss: 0.0015672595473006368\n",
      "Epoch 2, Batch 84350, Loss: 0.001656108070164919\n",
      "Epoch 2, Batch 84400, Loss: 0.002145540900528431\n",
      "Epoch 2, Batch 84450, Loss: 0.002261931309476495\n",
      "Epoch 2, Batch 84500, Loss: 0.002000778913497925\n",
      "Epoch 2, Batch 84550, Loss: 0.002993512200191617\n",
      "Epoch 2, Batch 84600, Loss: 0.0037064191419631243\n",
      "Epoch 2, Batch 84650, Loss: 0.0032324555795639753\n",
      "Epoch 2, Batch 84700, Loss: 0.002113936236128211\n",
      "Epoch 2, Batch 84750, Loss: 0.0021489919163286686\n",
      "Epoch 2, Batch 84800, Loss: 0.0025510177947580814\n",
      "Epoch 2, Batch 84850, Loss: 0.00242829998023808\n",
      "Epoch 2, Batch 84900, Loss: 0.0016719006234779954\n",
      "Epoch 2, Batch 84950, Loss: 0.0018784417770802975\n",
      "Epoch 2, Batch 85000, Loss: 0.0015778378583490849\n",
      "Epoch 2, Batch 85050, Loss: 0.0016162409447133541\n",
      "Epoch 2, Batch 85100, Loss: 0.001517775934189558\n",
      "Epoch 2, Batch 85150, Loss: 0.002264590933918953\n",
      "Epoch 2, Batch 85200, Loss: 0.395852267742157\n",
      "Epoch 2, Batch 85250, Loss: 0.002049780683591962\n",
      "Epoch 2, Batch 85300, Loss: 0.002198245609179139\n",
      "Epoch 2, Batch 85350, Loss: 0.001510626170784235\n",
      "Epoch 2, Batch 85400, Loss: 0.0016086138784885406\n",
      "Epoch 2, Batch 85450, Loss: 0.004396443720906973\n",
      "Epoch 2, Batch 85500, Loss: 0.0036798943765461445\n",
      "Epoch 2, Batch 85550, Loss: 0.003256007330492139\n",
      "Epoch 2, Batch 85600, Loss: 0.003294565249234438\n",
      "Epoch 2, Batch 85650, Loss: 0.0031689233146607876\n",
      "Epoch 2, Batch 85700, Loss: 0.002438641618937254\n",
      "Epoch 2, Batch 85750, Loss: 0.0029690552037209272\n",
      "Epoch 2, Batch 85800, Loss: 0.003234283532947302\n",
      "Epoch 2, Batch 85850, Loss: 0.002845345763489604\n",
      "Epoch 2, Batch 85900, Loss: 0.002372139133512974\n",
      "Epoch 2, Batch 85950, Loss: 0.0023475114721804857\n",
      "Epoch 2, Batch 86000, Loss: 0.0021639682818204165\n",
      "Epoch 2, Batch 86050, Loss: 0.002022980712354183\n",
      "Epoch 2, Batch 86100, Loss: 0.0020290156826376915\n",
      "Epoch 2, Batch 86150, Loss: 0.0027429373003542423\n",
      "Epoch 2, Batch 86200, Loss: 0.0024831320624798536\n",
      "Epoch 2, Batch 86250, Loss: 0.0037895243149250746\n",
      "Epoch 2, Batch 86300, Loss: 0.35345372557640076\n",
      "Epoch 2, Batch 86350, Loss: 0.0031799497082829475\n",
      "Epoch 2, Batch 86400, Loss: 0.002938002347946167\n",
      "Epoch 2, Batch 86450, Loss: 0.0023725798819214106\n",
      "Epoch 2, Batch 86500, Loss: 0.0016533327288925648\n",
      "Epoch 2, Batch 86550, Loss: 0.39008885622024536\n",
      "Epoch 2, Batch 86600, Loss: 0.0018871151842176914\n",
      "Epoch 2, Batch 86650, Loss: 0.0021247006952762604\n",
      "Epoch 2, Batch 86700, Loss: 0.38623520731925964\n",
      "Epoch 2, Batch 86750, Loss: 0.0020743687637150288\n",
      "Epoch 2, Batch 86800, Loss: 0.00172279158141464\n",
      "Epoch 2, Batch 86850, Loss: 0.0012474801624193788\n",
      "Epoch 2, Batch 86900, Loss: 0.0013353938702493906\n",
      "Epoch 2, Batch 86950, Loss: 0.001955996034666896\n",
      "Epoch 2, Batch 87000, Loss: 0.001759174163453281\n",
      "Epoch 2, Batch 87050, Loss: 0.001463359803892672\n",
      "Epoch 2, Batch 87100, Loss: 0.002366831060498953\n",
      "Epoch 2, Batch 87150, Loss: 0.001820700941607356\n",
      "Epoch 2, Batch 87200, Loss: 0.001985027687624097\n",
      "Epoch 2, Batch 87250, Loss: 0.0015215567545965314\n",
      "Epoch 2, Batch 87300, Loss: 0.0011014895280823112\n",
      "Epoch 2, Batch 87350, Loss: 0.0013400445459410548\n",
      "Epoch 2, Batch 87400, Loss: 0.0016984076937660575\n",
      "Epoch 2, Batch 87450, Loss: 0.0013649377506226301\n",
      "Epoch 2, Batch 87500, Loss: 0.0017457358771935105\n",
      "Epoch 2, Batch 87550, Loss: 0.0013405124191194773\n",
      "Epoch 2, Batch 87600, Loss: 0.0021583919879049063\n",
      "Epoch 2, Batch 87650, Loss: 0.0017641297308728099\n",
      "Epoch 2, Batch 87700, Loss: 0.0016710313502699137\n",
      "Epoch 2, Batch 87750, Loss: 0.0018303905380889773\n",
      "Epoch 2, Batch 87800, Loss: 0.0015957269351929426\n",
      "Epoch 2, Batch 87850, Loss: 0.0016074078157544136\n",
      "Epoch 2, Batch 87900, Loss: 0.0014057097723707557\n",
      "Epoch 2, Batch 87950, Loss: 0.0019719507545232773\n",
      "Epoch 2, Batch 88000, Loss: 0.0020642310846596956\n",
      "Epoch 2, Batch 88050, Loss: 0.002340056002140045\n",
      "Epoch 2, Batch 88100, Loss: 0.0023685097694396973\n",
      "Epoch 2, Batch 88150, Loss: 0.0017792339203879237\n",
      "Epoch 2, Batch 88200, Loss: 0.0016462040366604924\n",
      "Epoch 2, Batch 88250, Loss: 0.0015450103674083948\n",
      "Epoch 2, Batch 88300, Loss: 0.0022533214651048183\n",
      "Epoch 2, Batch 88350, Loss: 0.0024663566146045923\n",
      "Epoch 2, Batch 88400, Loss: 0.0024477303959429264\n",
      "Epoch 2, Batch 88450, Loss: 0.0024515141267329454\n",
      "Epoch 2, Batch 88500, Loss: 0.002166240941733122\n",
      "Epoch 2, Batch 88550, Loss: 0.0022814052645117044\n",
      "Epoch 2, Batch 88600, Loss: 0.00235097948461771\n",
      "Epoch 2, Batch 88650, Loss: 0.0024075708352029324\n",
      "Epoch 2, Batch 88700, Loss: 0.0028660609386861324\n",
      "Epoch 2, Batch 88750, Loss: 0.0030796497594565153\n",
      "Epoch 2, Batch 88800, Loss: 0.0029722382314503193\n",
      "Epoch 2, Batch 88850, Loss: 0.001799663994461298\n",
      "Epoch 2, Batch 88900, Loss: 0.002056992379948497\n",
      "Epoch 2, Batch 88950, Loss: 0.0028001521714031696\n",
      "Epoch 2, Batch 89000, Loss: 0.0028830813243985176\n",
      "Epoch 2, Batch 89050, Loss: 0.002016685903072357\n",
      "Epoch 2, Batch 89100, Loss: 0.0014190789079293609\n",
      "Epoch 2, Batch 89150, Loss: 0.001963244518265128\n",
      "Epoch 2, Batch 89200, Loss: 0.0017815931933000684\n",
      "Epoch 2, Batch 89250, Loss: 0.0017436599591746926\n",
      "Epoch 2, Batch 89300, Loss: 0.002348850015550852\n",
      "Epoch 2, Batch 89350, Loss: 0.002865597838535905\n",
      "Epoch 2, Batch 89400, Loss: 0.0032172496430575848\n",
      "Epoch 2, Batch 89450, Loss: 0.3483986556529999\n",
      "Epoch 2, Batch 89500, Loss: 0.0026655932888388634\n",
      "Epoch 2, Batch 89550, Loss: 0.0026504509150981903\n",
      "Epoch 2, Batch 89600, Loss: 0.0024637505412101746\n",
      "Epoch 2, Batch 89650, Loss: 0.0026643783785402775\n",
      "Epoch 2, Batch 89700, Loss: 0.0020736195147037506\n",
      "Epoch 2, Batch 89750, Loss: 0.0019697402603924274\n",
      "Epoch 2, Batch 89800, Loss: 0.0021937808487564325\n",
      "Epoch 2, Batch 89850, Loss: 0.003070955630391836\n",
      "Epoch 2, Batch 89900, Loss: 0.0036380940582603216\n",
      "Epoch 2, Batch 89950, Loss: 0.002903991611674428\n",
      "Epoch 2, Batch 90000, Loss: 0.002142665907740593\n",
      "Epoch 2, Batch 90050, Loss: 0.0027240896597504616\n",
      "Epoch 2, Batch 90100, Loss: 0.002959348727017641\n",
      "Epoch 2, Batch 90150, Loss: 0.0028557884506881237\n",
      "Epoch 2, Batch 90200, Loss: 0.0018561020260676742\n",
      "Epoch 2, Batch 90250, Loss: 0.002273016609251499\n",
      "Epoch 2, Batch 90300, Loss: 0.0027781848330050707\n",
      "Epoch 2, Batch 90350, Loss: 0.002124181017279625\n",
      "Epoch 2, Batch 90400, Loss: 0.0020526975858956575\n",
      "Epoch 2, Batch 90450, Loss: 0.003165803151205182\n",
      "Epoch 2, Batch 90500, Loss: 0.002818905748426914\n",
      "Epoch 2, Batch 90550, Loss: 0.002025216817855835\n",
      "Epoch 2, Batch 90600, Loss: 0.0024399342946708202\n",
      "Epoch 2, Batch 90650, Loss: 0.002068272791802883\n",
      "Epoch 2, Batch 90700, Loss: 0.0019140617223456502\n",
      "Epoch 2, Batch 90750, Loss: 0.001576286624185741\n",
      "Epoch 2, Batch 90800, Loss: 0.00206918572075665\n",
      "Epoch 2, Batch 90850, Loss: 0.001901634386740625\n",
      "Epoch 2, Batch 90900, Loss: 0.0023356182500720024\n",
      "Epoch 2, Batch 90950, Loss: 0.0023811846040189266\n",
      "Epoch 2, Batch 91000, Loss: 0.0020992225036025047\n",
      "Epoch 2, Batch 91050, Loss: 0.001948320074006915\n",
      "Epoch 2, Batch 91100, Loss: 0.001674938714131713\n",
      "Epoch 2, Batch 91150, Loss: 0.0014740180922672153\n",
      "Epoch 2, Batch 91200, Loss: 0.0014339624904096127\n",
      "Epoch 2, Batch 91250, Loss: 0.0017202869057655334\n",
      "Epoch 2, Batch 91300, Loss: 0.0034873110707849264\n",
      "Epoch 2, Batch 91350, Loss: 0.002723106648772955\n",
      "Epoch 2, Batch 91400, Loss: 0.002908760216087103\n",
      "Epoch 2, Batch 91450, Loss: 0.0021700961515307426\n",
      "Epoch 2, Batch 91500, Loss: 0.0017220053123310208\n",
      "Epoch 2, Batch 91550, Loss: 0.0017754044383764267\n",
      "Epoch 2, Batch 91600, Loss: 0.002008943585678935\n",
      "Epoch 2, Batch 91650, Loss: 0.0016439736355096102\n",
      "Epoch 2, Batch 91700, Loss: 0.001781960716471076\n",
      "Epoch 2, Batch 91750, Loss: 0.0017898741643875837\n",
      "Epoch 2, Batch 91800, Loss: 0.0013703912263736129\n",
      "Epoch 2, Batch 91850, Loss: 0.0016661176923662424\n",
      "Epoch 2, Batch 91900, Loss: 0.0013812275137752295\n",
      "Epoch 2, Batch 91950, Loss: 0.0016305246390402317\n",
      "Epoch 2, Batch 92000, Loss: 0.0016770731890574098\n",
      "Epoch 2, Batch 92050, Loss: 0.0015526787610724568\n",
      "Epoch 2, Batch 92100, Loss: 0.0013478955952450633\n",
      "Epoch 2, Batch 92150, Loss: 0.0017062417464330792\n",
      "Epoch 2, Batch 92200, Loss: 0.0023888240102678537\n",
      "Epoch 2, Batch 92250, Loss: 0.0034066312946379185\n",
      "Epoch 2, Batch 92300, Loss: 0.003045034362003207\n",
      "Epoch 2, Batch 92350, Loss: 0.0032396120950579643\n",
      "Epoch 2, Batch 92400, Loss: 0.002794265281409025\n",
      "Epoch 2, Batch 92450, Loss: 0.3700256645679474\n",
      "Epoch 2, Batch 92500, Loss: 0.002268262440338731\n",
      "Epoch 2, Batch 92550, Loss: 0.003880769480019808\n",
      "Epoch 2, Batch 92600, Loss: 0.0026483081746846437\n",
      "Epoch 2, Batch 92650, Loss: 0.002220768015831709\n",
      "Epoch 2, Batch 92700, Loss: 0.0023000920191407204\n",
      "Epoch 2, Batch 92750, Loss: 0.0018909912323579192\n",
      "Epoch 2, Batch 92800, Loss: 0.001777581637725234\n",
      "Epoch 2, Batch 92850, Loss: 0.0013483832590281963\n",
      "Epoch 2, Batch 92900, Loss: 0.0011477296939119697\n",
      "Epoch 2, Batch 92950, Loss: 0.0014123620931059122\n",
      "Epoch 2, Batch 93000, Loss: 0.001933146733790636\n",
      "Epoch 2, Batch 93050, Loss: 0.001494481461122632\n",
      "Epoch 2, Batch 93100, Loss: 0.0014289587270468473\n",
      "Epoch 2, Batch 93150, Loss: 0.0013976404443383217\n",
      "Epoch 2, Batch 93200, Loss: 0.0014546586899086833\n",
      "Epoch 2, Batch 93250, Loss: 0.00160972960293293\n",
      "Epoch 2, Batch 93300, Loss: 0.004371102433651686\n",
      "Epoch 2, Batch 93350, Loss: 0.004296079743653536\n",
      "Epoch 2, Batch 93400, Loss: 0.004881607834249735\n",
      "Epoch 2, Batch 93450, Loss: 0.003240913152694702\n",
      "Epoch 2, Batch 93500, Loss: 0.0030133111868053675\n",
      "Epoch 2, Batch 93550, Loss: 0.0037459649611264467\n",
      "Epoch 2, Batch 93600, Loss: 0.002676671836525202\n",
      "Epoch 2, Batch 93650, Loss: 0.002157670445740223\n",
      "Epoch 2, Batch 93700, Loss: 0.0019608044531196356\n",
      "Epoch 2, Batch 93750, Loss: 0.0016221626428887248\n",
      "Epoch 2, Batch 93800, Loss: 0.0013859642203897238\n",
      "Epoch 2, Batch 93850, Loss: 0.0017127336468547583\n",
      "Epoch 2, Batch 93900, Loss: 0.0016259500989690423\n",
      "Epoch 2, Batch 93950, Loss: 0.002601937623694539\n",
      "Epoch 2, Batch 94000, Loss: 0.0024605095386505127\n",
      "Epoch 2, Batch 94050, Loss: 0.002561782719567418\n",
      "Epoch 2, Batch 94100, Loss: 0.0021283256355673075\n",
      "Epoch 2, Batch 94150, Loss: 0.0022811084054410458\n",
      "Epoch 2, Batch 94200, Loss: 0.001835173461586237\n",
      "Epoch 2, Batch 94250, Loss: 0.0017546690069139004\n",
      "Epoch 2, Batch 94300, Loss: 0.002699165139347315\n",
      "Epoch 2, Batch 94350, Loss: 0.0026930246967822313\n",
      "Epoch 2, Batch 94400, Loss: 0.002426393795758486\n",
      "Epoch 2, Batch 94450, Loss: 0.002661106875166297\n",
      "Epoch 2, Batch 94500, Loss: 0.0016418338054791093\n",
      "Epoch 2, Batch 94550, Loss: 0.3926345407962799\n",
      "Epoch 2, Batch 94600, Loss: 0.002098187804222107\n",
      "Epoch 2, Batch 94650, Loss: 0.0026043218094855547\n",
      "Epoch 2, Batch 94700, Loss: 0.0032421848736703396\n",
      "Epoch 2, Batch 94750, Loss: 0.7079879641532898\n",
      "Epoch 2, Batch 94800, Loss: 0.0036734810564666986\n",
      "Epoch 2, Batch 94850, Loss: 0.0025112666189670563\n",
      "Epoch 2, Batch 94900, Loss: 0.003201226005330682\n",
      "Epoch 2, Batch 94950, Loss: 0.002792738378047943\n",
      "Epoch 2, Batch 95000, Loss: 0.002550109289586544\n",
      "Epoch 2, Batch 95050, Loss: 0.0027544975746423006\n",
      "Epoch 2, Batch 95100, Loss: 0.0029142547864466906\n",
      "Epoch 2, Batch 95150, Loss: 0.003424505004659295\n",
      "Epoch 2, Batch 95200, Loss: 0.0039807213470339775\n",
      "Epoch 2, Batch 95250, Loss: 0.0035173832438886166\n",
      "Epoch 2, Batch 95300, Loss: 0.003483792766928673\n",
      "Epoch 2, Batch 95350, Loss: 0.0031159145291894674\n",
      "Epoch 2, Batch 95400, Loss: 0.0029238685965538025\n",
      "Epoch 2, Batch 95450, Loss: 0.002871984615921974\n",
      "Epoch 2, Batch 95500, Loss: 0.002320597879588604\n",
      "Epoch 2, Batch 95550, Loss: 0.002504390897229314\n",
      "Epoch 2, Batch 95600, Loss: 0.0019556956831365824\n",
      "Epoch 2, Batch 95650, Loss: 0.0024740437511354685\n",
      "Epoch 2, Batch 95700, Loss: 0.0033865785226225853\n",
      "Epoch 2, Batch 95750, Loss: 0.002707552397623658\n",
      "Epoch 2, Batch 95800, Loss: 0.00330333155579865\n",
      "Epoch 2, Batch 95850, Loss: 0.002212570048868656\n",
      "Epoch 2, Batch 95900, Loss: 0.0015233245212584734\n",
      "Epoch 2, Batch 95950, Loss: 0.0020099503453820944\n",
      "Epoch 2, Batch 96000, Loss: 0.0019024059874936938\n",
      "Epoch 2, Batch 96050, Loss: 0.001418032217770815\n",
      "Epoch 2, Batch 96100, Loss: 0.39621278643608093\n",
      "Epoch 2, Batch 96150, Loss: 0.0022085027303546667\n",
      "Epoch 2, Batch 96200, Loss: 0.002189221326261759\n",
      "Epoch 2, Batch 96250, Loss: 0.0018197136232629418\n",
      "Epoch 2, Batch 96300, Loss: 0.0016110584838315845\n",
      "Epoch 2, Batch 96350, Loss: 0.0014599189162254333\n",
      "Epoch 2, Batch 96400, Loss: 0.0015039556892588735\n",
      "Epoch 2, Batch 96450, Loss: 0.0015161450719460845\n",
      "Epoch 2, Batch 96500, Loss: 0.0016531600849702954\n",
      "Epoch 2, Batch 96550, Loss: 0.002178734401240945\n",
      "Epoch 2, Batch 96600, Loss: 0.0017987804021686316\n",
      "Epoch 2, Batch 96650, Loss: 0.0017887079156935215\n",
      "Epoch 2, Batch 96700, Loss: 0.0015871381619945168\n",
      "Epoch 2, Batch 96750, Loss: 0.0022103809751570225\n",
      "Epoch 2, Batch 96800, Loss: 0.0020057884976267815\n",
      "Epoch 2, Batch 96850, Loss: 0.0020316727459430695\n",
      "Epoch 2, Batch 96900, Loss: 0.001857179100625217\n",
      "Epoch 2, Batch 96950, Loss: 0.0017474779160693288\n",
      "Epoch 2, Batch 97000, Loss: 0.001467820256948471\n",
      "Epoch 2, Batch 97050, Loss: 0.0013256390811875463\n",
      "Epoch 2, Batch 97100, Loss: 0.39241641759872437\n",
      "Epoch 2, Batch 97150, Loss: 0.00246084644459188\n",
      "Epoch 2, Batch 97200, Loss: 0.0028304317966103554\n",
      "Epoch 2, Batch 97250, Loss: 0.0018801717087626457\n",
      "Epoch 2, Batch 97300, Loss: 0.0017409151187166572\n",
      "Epoch 2, Batch 97350, Loss: 0.0017176547553390265\n",
      "Epoch 2, Batch 97400, Loss: 0.00233934517018497\n",
      "Epoch 2, Batch 97450, Loss: 0.00235399859957397\n",
      "Epoch 2, Batch 97500, Loss: 0.0019705649465322495\n",
      "Epoch 2, Batch 97550, Loss: 0.001536369090899825\n",
      "Epoch 2, Batch 97600, Loss: 0.0014543727738782763\n",
      "Epoch 2, Batch 97650, Loss: 0.0020671896636486053\n",
      "Epoch 2, Batch 97700, Loss: 0.0018492027884349227\n",
      "Epoch 2, Batch 97750, Loss: 0.002097772667184472\n",
      "Epoch 2, Batch 97800, Loss: 0.0020997077226638794\n",
      "Epoch 2, Batch 97850, Loss: 0.0017029867740347981\n",
      "Epoch 2, Batch 97900, Loss: 0.0014595165848731995\n",
      "Epoch 2, Batch 97950, Loss: 0.0011731573613360524\n",
      "Epoch 2, Batch 98000, Loss: 0.0011762467911466956\n",
      "Epoch 2, Batch 98050, Loss: 0.0011809560237452388\n",
      "Epoch 2, Batch 98100, Loss: 0.0011498337844386697\n",
      "Epoch 2, Batch 98150, Loss: 0.0023047677241265774\n",
      "Epoch 2, Batch 98200, Loss: 0.0031411617528647184\n",
      "Epoch 2, Batch 98250, Loss: 0.0038577045779675245\n",
      "Epoch 2, Batch 98300, Loss: 0.003711005439981818\n",
      "Epoch 2, Batch 98350, Loss: 0.0038475021719932556\n",
      "Epoch 2, Batch 98400, Loss: 0.0025172375608235598\n",
      "Epoch 2, Batch 98450, Loss: 0.0017870382871478796\n",
      "Epoch 2, Batch 98500, Loss: 0.0025525258388370275\n",
      "Epoch 2, Batch 98550, Loss: 0.0018914053216576576\n",
      "Epoch 2, Batch 98600, Loss: 0.0021025820169597864\n",
      "Epoch 2, Batch 98650, Loss: 0.0020427373237907887\n",
      "Epoch 2, Batch 98700, Loss: 0.0015291913878172636\n",
      "Epoch 2, Batch 98750, Loss: 0.0021760750096291304\n",
      "Epoch 2, Batch 98800, Loss: 0.003111886326223612\n",
      "Epoch 2, Batch 98850, Loss: 0.0025947822723537683\n",
      "Epoch 2, Batch 98900, Loss: 0.002409176668152213\n",
      "Epoch 2, Batch 98950, Loss: 0.002197534777224064\n",
      "Epoch 2, Batch 99000, Loss: 0.0015272466698661447\n",
      "Epoch 2, Batch 99050, Loss: 0.0014623422175645828\n",
      "Epoch 2, Batch 99100, Loss: 0.0018301644595339894\n",
      "Epoch 2, Batch 99150, Loss: 0.0021041398867964745\n",
      "Epoch 2, Batch 99200, Loss: 0.0015958357835188508\n",
      "Epoch 2, Batch 99250, Loss: 0.0016997051425278187\n",
      "Epoch 2, Batch 99300, Loss: 0.0014860080555081367\n",
      "Epoch 2, Batch 99350, Loss: 0.0018375994404777884\n",
      "Epoch 2, Batch 99400, Loss: 0.001496229670010507\n",
      "Epoch 2, Batch 99450, Loss: 0.0013898994075134397\n",
      "Epoch 2, Batch 99500, Loss: 0.001730902586132288\n",
      "Epoch 2, Batch 99550, Loss: 0.0015683986712247133\n",
      "Epoch 2, Batch 99600, Loss: 0.002114388393238187\n",
      "Epoch 2, Batch 99650, Loss: 0.002200252376496792\n",
      "Epoch 2, Batch 99700, Loss: 0.0031770835630595684\n",
      "Epoch 2, Batch 99750, Loss: 0.002981999423354864\n",
      "Epoch 2, Batch 99800, Loss: 0.0019222961273044348\n",
      "Epoch 2, Batch 99850, Loss: 0.0020667139906436205\n",
      "Epoch 2, Batch 99900, Loss: 0.003288918174803257\n",
      "Epoch 2, Batch 99950, Loss: 0.0028378311544656754\n",
      "Epoch 2, Batch 100000, Loss: 0.0022898316383361816\n",
      "Epoch 2, Batch 100050, Loss: 0.001668551703915\n",
      "Epoch 2, Batch 100100, Loss: 0.0026505719870328903\n",
      "Epoch 2, Batch 100150, Loss: 0.0028819467406719923\n",
      "Epoch 2, Batch 100200, Loss: 0.0024564145132899284\n",
      "Epoch 2, Batch 100250, Loss: 0.002295294078066945\n",
      "Epoch 2, Batch 100300, Loss: 0.0036028395406901836\n",
      "Epoch 2, Batch 100350, Loss: 0.003477885387837887\n",
      "Epoch 2, Batch 100400, Loss: 0.0035532712936401367\n",
      "Epoch 2, Batch 100450, Loss: 0.002568732248619199\n",
      "Epoch 2, Batch 100500, Loss: 0.002642870182171464\n",
      "Epoch 2, Batch 100550, Loss: 0.0022043546196073294\n",
      "Epoch 2, Batch 100600, Loss: 0.0017961065750569105\n",
      "Epoch 2, Batch 100650, Loss: 0.0012993811396881938\n",
      "Epoch 2, Batch 100700, Loss: 0.0014821760123595595\n",
      "Epoch 2, Batch 100750, Loss: 0.002036654157564044\n",
      "Epoch 2, Batch 100800, Loss: 0.001423560781404376\n",
      "Epoch 2, Batch 100850, Loss: 0.0015891804359853268\n",
      "Epoch 2, Batch 100900, Loss: 0.0015326901338994503\n",
      "Epoch 2, Batch 100950, Loss: 0.0016884849173948169\n",
      "Epoch 2, Batch 101000, Loss: 0.00109724176581949\n",
      "Epoch 2, Batch 101050, Loss: 0.0009194570011459291\n",
      "Epoch 2, Batch 101100, Loss: 0.0008680695318616927\n",
      "Epoch 2, Batch 101150, Loss: 0.0011462436523288488\n",
      "Epoch 2, Batch 101200, Loss: 0.0009664259268902242\n",
      "Epoch 2, Batch 101250, Loss: 0.0013550888979807496\n",
      "Epoch 2, Batch 101300, Loss: 0.0011853594332933426\n",
      "Epoch 2, Batch 101350, Loss: 0.0009637995390221477\n",
      "Epoch 2, Batch 101400, Loss: 0.0012584306532517076\n",
      "Epoch 2, Batch 101450, Loss: 0.0015055701369419694\n",
      "Epoch 2, Batch 101500, Loss: 0.0014149727066978812\n",
      "Epoch 2, Batch 101550, Loss: 0.0011797640472650528\n",
      "Epoch 2, Batch 101600, Loss: 0.0012585516087710857\n",
      "Epoch 2, Batch 101650, Loss: 0.0014400091022253036\n",
      "Epoch 2, Batch 101700, Loss: 0.3936895430088043\n",
      "Epoch 2, Batch 101750, Loss: 0.0023455736227333546\n",
      "Epoch 2, Batch 101800, Loss: 0.0026305182836949825\n",
      "Epoch 2, Batch 101850, Loss: 0.002210071310400963\n",
      "Epoch 2, Batch 101900, Loss: 0.002826581010594964\n",
      "Epoch 2, Batch 101950, Loss: 0.00257226824760437\n",
      "Epoch 2, Batch 102000, Loss: 0.002585344249382615\n",
      "Epoch 2, Batch 102050, Loss: 0.0029797174502164125\n",
      "Epoch 2, Batch 102100, Loss: 0.00200430559925735\n",
      "Epoch 2, Batch 102150, Loss: 0.001476656412705779\n",
      "Epoch 2, Batch 102200, Loss: 0.0017755143344402313\n",
      "Epoch 2, Batch 102250, Loss: 0.0017209042562171817\n",
      "Epoch 2, Batch 102300, Loss: 0.0019665840081870556\n",
      "Epoch 2, Batch 102350, Loss: 0.0016412055119872093\n",
      "Epoch 2, Batch 102400, Loss: 0.002014657249674201\n",
      "Epoch 2, Batch 102450, Loss: 0.002180982381105423\n",
      "Epoch 2, Batch 102500, Loss: 0.002222358947619796\n",
      "Epoch 2, Batch 102550, Loss: 0.0018378352979198098\n",
      "Epoch 2, Batch 102600, Loss: 0.0012759004021063447\n",
      "Epoch 2, Batch 102650, Loss: 0.002099280711263418\n",
      "Epoch 2, Batch 102700, Loss: 0.004890395328402519\n",
      "Epoch 2, Batch 102750, Loss: 0.003934231586754322\n",
      "Epoch 2, Batch 102800, Loss: 0.0028695333749055862\n",
      "Epoch 2, Batch 102850, Loss: 0.0029056579805910587\n",
      "Epoch 2, Batch 102900, Loss: 0.0023077696096152067\n",
      "Epoch 2, Batch 102950, Loss: 0.0016254710499197245\n",
      "Epoch 2, Batch 103000, Loss: 0.003018587362021208\n",
      "Epoch 2, Batch 103050, Loss: 0.41371220350265503\n",
      "Epoch 2, Batch 103100, Loss: 0.002814303617924452\n",
      "Epoch 2, Batch 103150, Loss: 0.0017887512221932411\n",
      "Epoch 2, Batch 103200, Loss: 0.001851558336056769\n",
      "Epoch 2, Batch 103250, Loss: 0.0018249333370476961\n",
      "Epoch 2, Batch 103300, Loss: 0.0017540075350552797\n",
      "Epoch 2, Batch 103350, Loss: 0.0017400417709723115\n",
      "Epoch 2, Batch 103400, Loss: 0.0012701511150225997\n",
      "Epoch 2, Batch 103450, Loss: 0.001186241046525538\n",
      "Epoch 2, Batch 103500, Loss: 0.0012702607782557607\n",
      "Epoch 2, Batch 103550, Loss: 0.0014018561923876405\n",
      "Epoch 2, Batch 103600, Loss: 0.00154039915651083\n",
      "Epoch 2, Batch 103650, Loss: 0.0018774832133203745\n",
      "Epoch 2, Batch 103700, Loss: 0.0019234349019825459\n",
      "Epoch 2, Batch 103750, Loss: 0.0018573710694909096\n",
      "Epoch 2, Batch 103800, Loss: 0.001244633225724101\n",
      "Epoch 2, Batch 103850, Loss: 0.002066743327304721\n",
      "Epoch 2, Batch 103900, Loss: 0.0020366115495562553\n",
      "Epoch 2, Batch 103950, Loss: 0.0019701907876878977\n",
      "Epoch 2, Batch 104000, Loss: 0.0024078579153865576\n",
      "Epoch 2, Batch 104050, Loss: 0.0023370820563286543\n",
      "Epoch 2, Batch 104100, Loss: 0.0025215239729732275\n",
      "Epoch 2, Batch 104150, Loss: 0.002144530415534973\n",
      "Epoch 2, Batch 104200, Loss: 0.0024582489859312773\n",
      "Epoch 2, Batch 104250, Loss: 0.002181075979024172\n",
      "Epoch 2, Batch 104300, Loss: 0.002282294910401106\n",
      "Epoch 2, Batch 104350, Loss: 0.0029743555933237076\n",
      "Epoch 2, Batch 104400, Loss: 0.0029903557151556015\n",
      "Epoch 2, Batch 104450, Loss: 0.0020870899315923452\n",
      "Epoch 2, Batch 104500, Loss: 0.002162364311516285\n",
      "Epoch 2, Batch 104550, Loss: 0.0025316316168755293\n",
      "Epoch 2, Batch 104600, Loss: 0.0018702051602303982\n",
      "Epoch 2, Batch 104650, Loss: 0.3668152987957001\n",
      "Epoch 2, Batch 104700, Loss: 0.0022460445761680603\n",
      "Epoch 2, Batch 104750, Loss: 0.002701058052480221\n",
      "Epoch 2, Batch 104800, Loss: 0.0028446002397686243\n",
      "Epoch 2, Batch 104850, Loss: 0.002592829056084156\n",
      "Epoch 2, Batch 104900, Loss: 0.0018635890446603298\n",
      "Epoch 2, Batch 104950, Loss: 0.0025553125888109207\n",
      "Epoch 2, Batch 105000, Loss: 0.37836912274360657\n",
      "Epoch 2, Batch 105050, Loss: 0.00238726194947958\n",
      "Epoch 2, Batch 105100, Loss: 0.002466428093612194\n",
      "Epoch 2, Batch 105150, Loss: 0.0025922455824911594\n",
      "Epoch 2, Batch 105200, Loss: 0.0028567237313836813\n",
      "Epoch 2, Batch 105250, Loss: 0.0024547686334699392\n",
      "Epoch 2, Batch 105300, Loss: 0.0025224736891686916\n",
      "Epoch 2, Batch 105350, Loss: 0.0024848193861544132\n",
      "Epoch 2, Batch 105400, Loss: 0.0029940942768007517\n",
      "Epoch 2, Batch 105450, Loss: 0.0024294820614159107\n",
      "Epoch 2, Batch 105500, Loss: 0.0018428087932989001\n",
      "Epoch 2, Batch 105550, Loss: 0.0030807815492153168\n",
      "Epoch 2, Batch 105600, Loss: 0.002439048606902361\n",
      "Epoch 2, Batch 105650, Loss: 0.0017803710652515292\n",
      "Epoch 2, Batch 105700, Loss: 0.0022849119268357754\n",
      "Epoch 2, Batch 105750, Loss: 0.0022251163609325886\n",
      "Epoch 2, Batch 105800, Loss: 0.0017226337222382426\n",
      "Epoch 2, Batch 105850, Loss: 0.0015751798637211323\n",
      "Epoch 2, Batch 105900, Loss: 0.0014975088415667415\n",
      "Epoch 2, Batch 105950, Loss: 0.0016679733525961637\n",
      "Epoch 2, Batch 106000, Loss: 0.0016742327716201544\n",
      "Epoch 2, Batch 106050, Loss: 0.0017377955373376608\n",
      "Epoch 2, Batch 106100, Loss: 0.0014542280696332455\n",
      "Epoch 2, Batch 106150, Loss: 0.0011660715099424124\n",
      "Epoch 2, Batch 106200, Loss: 0.0009195558959618211\n",
      "Epoch 2, Batch 106250, Loss: 0.4105890095233917\n",
      "Epoch 2, Batch 106300, Loss: 0.002860619220882654\n",
      "Epoch 2, Batch 106350, Loss: 0.002688976936042309\n",
      "Epoch 2, Batch 106400, Loss: 0.0019434564746916294\n",
      "Epoch 2, Batch 106450, Loss: 0.0025906285736709833\n",
      "Epoch 2, Batch 106500, Loss: 0.002214126754552126\n",
      "Epoch 2, Batch 106550, Loss: 0.0017545341979712248\n",
      "Epoch 2, Batch 106600, Loss: 0.0026317418087273836\n",
      "Epoch 2, Batch 106650, Loss: 0.002500922651961446\n",
      "Epoch 2, Batch 106700, Loss: 0.0023605970200151205\n",
      "Epoch 2, Batch 106750, Loss: 0.002176550216972828\n",
      "Epoch 2, Batch 106800, Loss: 0.0019500325433909893\n",
      "Epoch 2, Batch 106850, Loss: 0.0024501264560967684\n",
      "Epoch 2, Batch 106900, Loss: 0.0019249432953074574\n",
      "Epoch 2, Batch 106950, Loss: 0.0014854955952614546\n",
      "Epoch 2, Batch 107000, Loss: 0.002338199410587549\n",
      "Epoch 2, Batch 107050, Loss: 0.0022363527677953243\n",
      "Epoch 2, Batch 107100, Loss: 0.35884037613868713\n",
      "Epoch 2, Batch 107150, Loss: 0.003531234571710229\n",
      "Epoch 2, Batch 107200, Loss: 0.002806341042742133\n",
      "Epoch 2, Batch 107250, Loss: 0.0022810979280620813\n",
      "Epoch 2, Batch 107300, Loss: 0.002806888660416007\n",
      "Epoch 2, Batch 107350, Loss: 0.0029425628017634153\n",
      "Epoch 2, Batch 107400, Loss: 0.0023284321650862694\n",
      "Epoch 2, Batch 107450, Loss: 0.0018936707638204098\n",
      "Epoch 2, Batch 107500, Loss: 0.0025551195722073317\n",
      "Epoch 2, Batch 107550, Loss: 0.003583501558750868\n",
      "Epoch 2, Batch 107600, Loss: 0.002374549861997366\n",
      "Epoch 2, Batch 107650, Loss: 0.3740890324115753\n",
      "Epoch 2, Batch 107700, Loss: 0.0027074129320681095\n",
      "Epoch 2, Batch 107750, Loss: 0.002673262497410178\n",
      "Epoch 2, Batch 107800, Loss: 0.002086954191327095\n",
      "Epoch 2, Batch 107850, Loss: 0.001784760970622301\n",
      "Epoch 2, Batch 107900, Loss: 0.0018555918941274285\n",
      "Epoch 2, Batch 107950, Loss: 0.001844923011958599\n",
      "Epoch 2, Batch 108000, Loss: 0.0015404606238007545\n",
      "Epoch 2, Batch 108050, Loss: 0.0018520749872550368\n",
      "Epoch 2, Batch 108100, Loss: 0.0024862089194357395\n",
      "Epoch 2, Batch 108150, Loss: 0.32834112644195557\n",
      "Epoch 2, Batch 108200, Loss: 0.005205849651247263\n",
      "Epoch 2, Batch 108250, Loss: 0.003222045721486211\n",
      "Epoch 2, Batch 108300, Loss: 0.003171544522047043\n",
      "Epoch 2, Batch 108350, Loss: 0.0035507555585354567\n",
      "Epoch 2, Batch 108400, Loss: 0.0024200621992349625\n",
      "Epoch 2, Batch 108450, Loss: 0.0022894348949193954\n",
      "Epoch 2, Batch 108500, Loss: 0.0017276040744036436\n",
      "Epoch 2, Batch 108550, Loss: 0.001429299940355122\n",
      "Epoch 2, Batch 108600, Loss: 0.0018509682267904282\n",
      "Epoch 2, Batch 108650, Loss: 0.0015872134827077389\n",
      "Epoch 2, Batch 108700, Loss: 0.0015372586203739047\n",
      "Epoch 2, Batch 108750, Loss: 0.002149977721273899\n",
      "Epoch 2, Batch 108800, Loss: 0.002007195260375738\n",
      "Epoch 2, Batch 108850, Loss: 0.0018064012983813882\n",
      "Epoch 2, Batch 108900, Loss: 0.0015836218371987343\n",
      "Epoch 2, Batch 108950, Loss: 0.0012604080839082599\n",
      "Epoch 2, Batch 109000, Loss: 0.0014004739932715893\n",
      "Epoch 2, Batch 109050, Loss: 0.0019470389233902097\n",
      "Epoch 2, Batch 109100, Loss: 0.0016693659126758575\n",
      "Epoch 2, Batch 109150, Loss: 0.002168322214856744\n",
      "Epoch 2, Batch 109200, Loss: 0.0016144394176080823\n",
      "Epoch 2, Batch 109250, Loss: 0.0019265592563897371\n",
      "Epoch 2, Batch 109300, Loss: 0.0036807728465646505\n",
      "Epoch 2, Batch 109350, Loss: 0.0029333471320569515\n",
      "Epoch 2, Batch 109400, Loss: 0.0022857768926769495\n",
      "Epoch 2, Batch 109450, Loss: 0.39960798621177673\n",
      "Epoch 2, Batch 109500, Loss: 0.0022018435411155224\n",
      "Epoch 2, Batch 109550, Loss: 0.0018181935884058475\n",
      "Epoch 2, Batch 109600, Loss: 0.0022815812844783068\n",
      "Epoch 2, Batch 109650, Loss: 0.001836984301917255\n",
      "Epoch 2, Batch 109700, Loss: 0.0015116790309548378\n",
      "Epoch 2, Batch 109750, Loss: 0.0019329002825543284\n",
      "Epoch 2, Batch 109800, Loss: 0.0033224273938685656\n",
      "Epoch 2, Batch 109850, Loss: 0.0032219046261161566\n",
      "Epoch 2, Batch 109900, Loss: 0.0034390115179121494\n",
      "Epoch 2, Batch 109950, Loss: 0.003786081448197365\n",
      "Epoch 2, Batch 110000, Loss: 0.00356350583024323\n",
      "Epoch 2, Batch 110050, Loss: 0.002641834784299135\n",
      "Epoch 2, Batch 110100, Loss: 0.002220849273726344\n",
      "Epoch 2, Batch 110150, Loss: 0.0024240135680884123\n",
      "Epoch 2, Batch 110200, Loss: 0.0025512445718050003\n",
      "Epoch 2, Batch 110250, Loss: 0.002509342972189188\n",
      "Epoch 2, Batch 110300, Loss: 0.0019002110930159688\n",
      "Epoch 2, Batch 110350, Loss: 0.002095987321808934\n",
      "Epoch 2, Batch 110400, Loss: 0.0027342336252331734\n",
      "Epoch 2, Batch 110450, Loss: 0.002742342883720994\n",
      "Epoch 2, Batch 110500, Loss: 0.0033542332239449024\n",
      "Epoch 2, Batch 110550, Loss: 0.0026602784637361765\n",
      "Epoch 2, Batch 110600, Loss: 0.0018593615386635065\n",
      "Epoch 2, Batch 110650, Loss: 0.0016989343566820025\n",
      "Epoch 2, Batch 110700, Loss: 0.001548627158626914\n",
      "Epoch 2, Batch 110750, Loss: 0.001325032440945506\n",
      "Epoch 2, Batch 110800, Loss: 0.0014197924174368382\n",
      "Epoch 2, Batch 110850, Loss: 0.0013503609225153923\n",
      "Epoch 2, Batch 110900, Loss: 0.0015432812506332994\n",
      "Epoch 2, Batch 110950, Loss: 0.001818937249481678\n",
      "Epoch 2, Batch 111000, Loss: 0.0022897240705788136\n",
      "Epoch 2, Batch 111050, Loss: 0.0018435826059430838\n",
      "Epoch 2, Batch 111100, Loss: 0.0022209298331290483\n",
      "Epoch 2, Batch 111150, Loss: 0.0025552648585289717\n",
      "Epoch 2, Batch 111200, Loss: 0.0026544989086687565\n",
      "Epoch 2, Batch 111250, Loss: 0.003945027943700552\n",
      "Epoch 2, Batch 111300, Loss: 0.00382672599516809\n",
      "Epoch 2, Batch 111350, Loss: 0.001966840587556362\n",
      "Epoch 2, Batch 111400, Loss: 0.002229866571724415\n",
      "Epoch 2, Batch 111450, Loss: 0.0019163060933351517\n",
      "Epoch 2, Batch 111500, Loss: 0.002410952467471361\n",
      "Epoch 2, Batch 111550, Loss: 0.0016170330345630646\n",
      "Epoch 2, Batch 111600, Loss: 0.0015806907322257757\n",
      "Epoch 2, Batch 111650, Loss: 0.4143607020378113\n",
      "Epoch 2, Batch 111700, Loss: 0.002177733462303877\n",
      "Epoch 2, Batch 111750, Loss: 0.0022402992472052574\n",
      "Epoch 2, Batch 111800, Loss: 0.002057786099612713\n",
      "Epoch 2, Batch 111850, Loss: 0.001946294098161161\n",
      "Epoch 2, Batch 111900, Loss: 0.0013493839651346207\n",
      "Epoch 2, Batch 111950, Loss: 0.0016397443832829595\n",
      "Epoch 2, Batch 112000, Loss: 0.0016432672273367643\n",
      "Epoch 2, Batch 112050, Loss: 0.002613696502521634\n",
      "Epoch 2, Batch 112100, Loss: 0.0027464376762509346\n",
      "Epoch 2, Batch 112150, Loss: 0.0020851995795965195\n",
      "Epoch 2, Batch 112200, Loss: 0.002045700326561928\n",
      "Epoch 2, Batch 112250, Loss: 0.0016094340244308114\n",
      "Epoch 2, Batch 112300, Loss: 0.0014025645796209574\n",
      "Epoch 2, Batch 112350, Loss: 0.0027543306350708008\n",
      "Epoch 2, Batch 112400, Loss: 0.0021412719506770372\n",
      "Epoch 2, Batch 112450, Loss: 0.0019287405302748084\n",
      "Epoch 2, Batch 112500, Loss: 0.002102850005030632\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Assuming the model, dataset, and device setup\n",
    "model = model.to(device)  # Ensure model is on the correct device\n",
    "optimizer = Adam(model.parameters(), lr=5e-5)  # Define optimizer\n",
    "\n",
    "# Define DataLoader for both training and validation datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=16)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 3  # Define the number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        # Ensure all data in the batch is moved to the correct device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=batch['input_ids'],\n",
    "                        attention_mask=batch['attention_mask'],\n",
    "                        protein_features=batch['protein_encodings'])\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = F.cross_entropy(outputs, batch['labels'])  # Assuming your model outputs raw logits\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print loss every 50 batches\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f\"Epoch {epoch}, Batch {i + 1}, Loss: {loss.item()}\")  # Output the loss\n",
    "\n",
    "    # Validation loop (optional, for model evaluation during training)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(input_ids=batch['input_ids'],\n",
    "                            attention_mask=batch['attention_mask'],\n",
    "                            protein_features=batch['protein_encodings'])\n",
    "            loss = F.cross_entropy(outputs, batch['labels'])\n",
    "            # Add additional code to track validation loss, accuracy, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84f2ee97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T01:25:01.305188Z",
     "iopub.status.busy": "2024-05-07T01:25:01.304275Z",
     "iopub.status.idle": "2024-05-07T01:25:01.954254Z",
     "shell.execute_reply": "2024-05-07T01:25:01.953275Z"
    },
    "papermill": {
     "duration": 1.445907,
     "end_time": "2024-05-07T01:25:01.957003",
     "exception": false,
     "start_time": "2024-05-07T01:25:00.511096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save only the state dict\n",
    "torch.save(model.state_dict(), 'model_state_dict.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb2096e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T01:25:03.223294Z",
     "iopub.status.busy": "2024-05-07T01:25:03.222595Z",
     "iopub.status.idle": "2024-05-07T01:25:06.733856Z",
     "shell.execute_reply": "2024-05-07T01:25:06.732585Z"
    },
    "papermill": {
     "duration": 4.150754,
     "end_time": "2024-05-07T01:25:06.736533",
     "exception": false,
     "start_time": "2024-05-07T01:25:02.585779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Save the entire model\n",
    "torch.save(model, 'entire_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f6bb34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T18:59:35.122901Z",
     "iopub.status.busy": "2024-05-05T18:59:35.122561Z",
     "iopub.status.idle": "2024-05-05T18:59:35.257471Z",
     "shell.execute_reply": "2024-05-05T18:59:35.256563Z",
     "shell.execute_reply.started": "2024-05-05T18:59:35.122877Z"
    },
    "papermill": {
     "duration": 0.627678,
     "end_time": "2024-05-07T01:25:08.002369",
     "exception": false,
     "start_time": "2024-05-07T01:25:07.374691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c0ca62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:01:24.693101Z",
     "iopub.status.busy": "2024-05-05T19:01:24.692167Z",
     "iopub.status.idle": "2024-05-05T19:01:24.700407Z",
     "shell.execute_reply": "2024-05-05T19:01:24.699470Z",
     "shell.execute_reply.started": "2024-05-05T19:01:24.693069Z"
    },
    "papermill": {
     "duration": 0.620261,
     "end_time": "2024-05-07T01:25:09.255559",
     "exception": false,
     "start_time": "2024-05-07T01:25:08.635298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fe18638",
   "metadata": {
    "papermill": {
     "duration": 0.624449,
     "end_time": "2024-05-07T01:25:10.510743",
     "exception": false,
     "start_time": "2024-05-07T01:25:09.886294",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695764c4",
   "metadata": {
    "papermill": {
     "duration": 0.762467,
     "end_time": "2024-05-07T01:25:11.917397",
     "exception": false,
     "start_time": "2024-05-07T01:25:11.154930",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "LOading and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8cbf55c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T01:25:13.174974Z",
     "iopub.status.busy": "2024-05-07T01:25:13.174547Z",
     "iopub.status.idle": "2024-05-07T01:25:13.179300Z",
     "shell.execute_reply": "2024-05-07T01:25:13.178259Z"
    },
    "papermill": {
     "duration": 0.622632,
     "end_time": "2024-05-07T01:25:13.181662",
     "exception": false,
     "start_time": "2024-05-07T01:25:12.559030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_test = pd.read_csv('/kaggle/input/leash-BELKA/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab79bab3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T01:25:14.412071Z",
     "iopub.status.busy": "2024-05-07T01:25:14.411655Z",
     "iopub.status.idle": "2024-05-07T01:25:14.416494Z",
     "shell.execute_reply": "2024-05-07T01:25:14.415525Z"
    },
    "papermill": {
     "duration": 0.619611,
     "end_time": "2024-05-07T01:25:14.418645",
     "exception": false,
     "start_time": "2024-05-07T01:25:13.799034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0caf36a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T01:25:15.648311Z",
     "iopub.status.busy": "2024-05-07T01:25:15.647904Z",
     "iopub.status.idle": "2024-05-07T01:25:15.652524Z",
     "shell.execute_reply": "2024-05-07T01:25:15.651471Z"
    },
    "papermill": {
     "duration": 0.621728,
     "end_time": "2024-05-07T01:25:15.654777",
     "exception": false,
     "start_time": "2024-05-07T01:25:15.033049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Assuming df_test is your test DataFrame with similar columns as df_train except 'binds'\n",
    "# test_encodings = tokenizer(df_test['molecule_smiles'].tolist(), truncation=True, padding=True, max_length=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9dd087ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T01:25:16.893739Z",
     "iopub.status.busy": "2024-05-07T01:25:16.893207Z",
     "iopub.status.idle": "2024-05-07T01:25:16.898090Z",
     "shell.execute_reply": "2024-05-07T01:25:16.897044Z"
    },
    "papermill": {
     "duration": 0.626594,
     "end_time": "2024-05-07T01:25:16.900209",
     "exception": false,
     "start_time": "2024-05-07T01:25:16.273615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_dataset = SMILESTestDataset(test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ee97839",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T01:25:18.288926Z",
     "iopub.status.busy": "2024-05-07T01:25:18.288143Z",
     "iopub.status.idle": "2024-05-07T01:25:18.292881Z",
     "shell.execute_reply": "2024-05-07T01:25:18.291928Z"
    },
    "papermill": {
     "duration": 0.762889,
     "end_time": "2024-05-07T01:25:18.295050",
     "exception": false,
     "start_time": "2024-05-07T01:25:17.532161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Predict\n",
    "# predictions = trainer.predict(test_dataset)\n",
    "\n",
    "# # The predictions object includes a predictions array, label_ids array (if available), and metrics (if labels provided during prediction)\n",
    "# pred_labels = predictions.predictions.argmax(-1)  # We use argmax to convert from logits to class labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ddd7b9eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T01:25:19.526170Z",
     "iopub.status.busy": "2024-05-07T01:25:19.525800Z",
     "iopub.status.idle": "2024-05-07T01:25:19.530285Z",
     "shell.execute_reply": "2024-05-07T01:25:19.529309Z"
    },
    "papermill": {
     "duration": 0.620854,
     "end_time": "2024-05-07T01:25:19.532491",
     "exception": false,
     "start_time": "2024-05-07T01:25:18.911637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_test['predicted_binds'] = pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d4ae3c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T01:25:20.792495Z",
     "iopub.status.busy": "2024-05-07T01:25:20.791646Z",
     "iopub.status.idle": "2024-05-07T01:25:20.796344Z",
     "shell.execute_reply": "2024-05-07T01:25:20.795242Z"
    },
    "papermill": {
     "duration": 0.655052,
     "end_time": "2024-05-07T01:25:20.798564",
     "exception": false,
     "start_time": "2024-05-07T01:25:20.143512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Saving the DataFrame with predictions to a new CSV file\n",
    "# df_test.to_csv('test_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbb99a6",
   "metadata": {
    "papermill": {
     "duration": 0.623388,
     "end_time": "2024-05-07T01:25:22.049341",
     "exception": false,
     "start_time": "2024-05-07T01:25:21.425953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8006601,
     "sourceId": 67356,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29923.876343,
   "end_time": "2024-05-07T01:25:27.295096",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-06T17:06:43.418753",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "08f340b446a04552b168fce99459010e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0d1e5cdb9f194a2986c7d73dcf33eb3f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2739b2a48a9043c48587080e7c57359b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2a505d00fa8e4dacadbce1ce3cb2398a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3334f459a3cf41be85b257a60a31a86c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "337ed9fc5b354f0683c7b03b8911b834": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e7a3859f885d443a8358dc87314d69f1",
       "placeholder": "",
       "style": "IPY_MODEL_70f73b33d47945dfb834488c7a5a90f0",
       "value": " 101k/101k [00:00&lt;00:00, 7.35MB/s]"
      }
     },
     "35659d6d4ffc420ea6918f2b7bb8fb27": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "385d3a8790214f4d8dab6b9dd72af85d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4039aaac8d774677bf57dc0c349fd20c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "465792570b3945a9a8467606dee706f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_687ce2b3b196459caced53a4bb6cf3cb",
       "max": 101307.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_628a3b76dc1b4ddeb52672ae6ff7517a",
       "value": 101307.0
      }
     },
     "4a0293189fe241ff829fd8f27d961a9f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8e536210131b42efba8bb893df84fd6a",
       "placeholder": "",
       "style": "IPY_MODEL_910b491e8d5d4a6d89a8fde494372fa6",
       "value": "vocab.json: 100%"
      }
     },
     "4fa3983ba00b4770b26aee81cdef1f6c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "50093cc1788e4405b0a93f22bf986015": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5b8dbb66923d4bdd9a7c1d4e1611b6b9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5f6a48b520284a438501784a23acb0d9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5f6a76895b144889bc8bf1961ccb41fb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "61ea63985f854fa4a17af7224b33b665": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6267dc85aafa4974a80ece5bdc828947": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "628a3b76dc1b4ddeb52672ae6ff7517a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "67427283336849b68c1befcb376531f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5b8dbb66923d4bdd9a7c1d4e1611b6b9",
       "max": 515.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_bfe33dbd7fc847959ab75b5cac1ca274",
       "value": 515.0
      }
     },
     "687ce2b3b196459caced53a4bb6cf3cb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6af19a6a648c4528aca54d56595dee0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6fb338fa482c440285448425ace72cde": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6267dc85aafa4974a80ece5bdc828947",
       "max": 336422980.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f0054824fb464d048ff9fa81464bb735",
       "value": 336422980.0
      }
     },
     "70f73b33d47945dfb834488c7a5a90f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "725e19250df94511b5bde6764a417388": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7322cc63539e4f6ab01adddf36c6e07f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b7b4832b4b4749c9bbebc54ffbe68cf2",
       "placeholder": "",
       "style": "IPY_MODEL_4039aaac8d774677bf57dc0c349fd20c",
       "value": " 772/772 [00:00&lt;00:00, 62.7kB/s]"
      }
     },
     "7a7743124aaa43c19d04686f40266329": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7df505afb3594a318854e86bf5557fc2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_725e19250df94511b5bde6764a417388",
       "max": 62.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a47a215556004fceab5b4178c5139b7c",
       "value": 62.0
      }
     },
     "88920c04f4184c2cb142b0b1ca326a7f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e37724988c15445693a8982234d46738",
        "IPY_MODEL_67427283336849b68c1befcb376531f8",
        "IPY_MODEL_dc58d31d9038405b91fc94b2792fdb2e"
       ],
       "layout": "IPY_MODEL_da04baee7a9145eb87ab519be9e31aed"
      }
     },
     "8d66cac0774241b69d71df44e129cfc3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a476dcbe2dbb488bba2ee0c02d1926ae",
       "placeholder": "",
       "style": "IPY_MODEL_c926008cc3f24b499853f03eb49d105d",
       "value": "pytorch_model.bin: 100%"
      }
     },
     "8e536210131b42efba8bb893df84fd6a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8ecbe77baadf49839ea6b0cd4199a383": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0d1e5cdb9f194a2986c7d73dcf33eb3f",
       "placeholder": "",
       "style": "IPY_MODEL_61ea63985f854fa4a17af7224b33b665",
       "value": "merges.txt: 100%"
      }
     },
     "8eeaecdb7e1a4eab910acdbc2e9f4a15": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8f3c6ec2e2074faeaf8c97063681741c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8f5322c70d4342ff92d7e0d7d06000e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8ecbe77baadf49839ea6b0cd4199a383",
        "IPY_MODEL_465792570b3945a9a8467606dee706f9",
        "IPY_MODEL_337ed9fc5b354f0683c7b03b8911b834"
       ],
       "layout": "IPY_MODEL_5f6a76895b144889bc8bf1961ccb41fb"
      }
     },
     "910b491e8d5d4a6d89a8fde494372fa6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "915f723103624187ae026dc5e4e03b95": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9a197e4dd67244729ddbc687c5e09513": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8eeaecdb7e1a4eab910acdbc2e9f4a15",
       "placeholder": "",
       "style": "IPY_MODEL_6af19a6a648c4528aca54d56595dee0d",
       "value": "tokenizer_config.json: 100%"
      }
     },
     "9d92e590b55d4ceaad69468121b93274": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a2d50101b3044455a6369f5c1e3b7533": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a476dcbe2dbb488bba2ee0c02d1926ae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a47a215556004fceab5b4178c5139b7c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b7b4832b4b4749c9bbebc54ffbe68cf2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b7f9f96f1ecb4fd9823804a2b23ee4da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a2d50101b3044455a6369f5c1e3b7533",
       "placeholder": "",
       "style": "IPY_MODEL_385d3a8790214f4d8dab6b9dd72af85d",
       "value": " 62.0/62.0 [00:00&lt;00:00, 4.02kB/s]"
      }
     },
     "bfe33dbd7fc847959ab75b5cac1ca274": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c00b48042256455eb25de23191edbe00": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f1a8f39355694ea4a8a77a2ee08aa6fc",
       "max": 164540.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_915f723103624187ae026dc5e4e03b95",
       "value": 164540.0
      }
     },
     "c8c3cb37ac2f43fa8518579fef3e3c71": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8f3c6ec2e2074faeaf8c97063681741c",
       "placeholder": "",
       "style": "IPY_MODEL_4fa3983ba00b4770b26aee81cdef1f6c",
       "value": " 165k/165k [00:00&lt;00:00, 5.82MB/s]"
      }
     },
     "c926008cc3f24b499853f03eb49d105d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "cd80d165abd24086881cc1d70ea598f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4a0293189fe241ff829fd8f27d961a9f",
        "IPY_MODEL_c00b48042256455eb25de23191edbe00",
        "IPY_MODEL_c8c3cb37ac2f43fa8518579fef3e3c71"
       ],
       "layout": "IPY_MODEL_2a505d00fa8e4dacadbce1ce3cb2398a"
      }
     },
     "d5030df112ee439b8460b310d6ce1258": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d7c8118c6e0a4aaf8b40c9204f40e7b0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d86a8c7902394d929af7c86e67a94acb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f91b8d8386e549daa9906979b5bd2920",
       "max": 772.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2739b2a48a9043c48587080e7c57359b",
       "value": 772.0
      }
     },
     "da04baee7a9145eb87ab519be9e31aed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "da6ee7be9b344d6a874c7b4a206c9009": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fb63d9bccf274b9abc0eaaf145370c16",
       "placeholder": "",
       "style": "IPY_MODEL_ddc88b5fad1e4b40b07edb956c92873b",
       "value": "special_tokens_map.json: 100%"
      }
     },
     "dc58d31d9038405b91fc94b2792fdb2e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_08f340b446a04552b168fce99459010e",
       "placeholder": "",
       "style": "IPY_MODEL_9d92e590b55d4ceaad69468121b93274",
       "value": " 515/515 [00:00&lt;00:00, 41.2kB/s]"
      }
     },
     "ddc88b5fad1e4b40b07edb956c92873b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e37724988c15445693a8982234d46738": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3334f459a3cf41be85b257a60a31a86c",
       "placeholder": "",
       "style": "IPY_MODEL_d5030df112ee439b8460b310d6ce1258",
       "value": "config.json: 100%"
      }
     },
     "e7a3859f885d443a8358dc87314d69f1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e953e9d3150e48ed9399d000276ec073": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8d66cac0774241b69d71df44e129cfc3",
        "IPY_MODEL_6fb338fa482c440285448425ace72cde",
        "IPY_MODEL_f7fcd2a967fe4da4b93aa510f3d46c97"
       ],
       "layout": "IPY_MODEL_50093cc1788e4405b0a93f22bf986015"
      }
     },
     "f0054824fb464d048ff9fa81464bb735": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f1a8f39355694ea4a8a77a2ee08aa6fc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f1cce9c92079452691eae126d5ac5f47": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9a197e4dd67244729ddbc687c5e09513",
        "IPY_MODEL_7df505afb3594a318854e86bf5557fc2",
        "IPY_MODEL_b7f9f96f1ecb4fd9823804a2b23ee4da"
       ],
       "layout": "IPY_MODEL_5f6a48b520284a438501784a23acb0d9"
      }
     },
     "f1eb0ad4d24249efb0222efe59ba2729": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_da6ee7be9b344d6a874c7b4a206c9009",
        "IPY_MODEL_d86a8c7902394d929af7c86e67a94acb",
        "IPY_MODEL_7322cc63539e4f6ab01adddf36c6e07f"
       ],
       "layout": "IPY_MODEL_d7c8118c6e0a4aaf8b40c9204f40e7b0"
      }
     },
     "f7fcd2a967fe4da4b93aa510f3d46c97": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7a7743124aaa43c19d04686f40266329",
       "placeholder": "",
       "style": "IPY_MODEL_35659d6d4ffc420ea6918f2b7bb8fb27",
       "value": " 336M/336M [00:05&lt;00:00, 136MB/s]"
      }
     },
     "f91b8d8386e549daa9906979b5bd2920": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fb63d9bccf274b9abc0eaaf145370c16": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
