{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "843d7c94",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-05T19:47:02.648225Z",
     "iopub.status.busy": "2024-05-05T19:47:02.647927Z",
     "iopub.status.idle": "2024-05-05T19:47:03.343861Z",
     "shell.execute_reply": "2024-05-05T19:47:03.342515Z"
    },
    "papermill": {
     "duration": 0.711878,
     "end_time": "2024-05-05T19:47:03.346123",
     "exception": false,
     "start_time": "2024-05-05T19:47:02.634245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/leash-BELKA/sample_submission.csv\n",
      "/kaggle/input/leash-BELKA/train.parquet\n",
      "/kaggle/input/leash-BELKA/test.parquet\n",
      "/kaggle/input/leash-BELKA/train.csv\n",
      "/kaggle/input/leash-BELKA/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under theinput directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4337692a",
   "metadata": {
    "papermill": {
     "duration": 0.011961,
     "end_time": "2024-05-05T19:47:03.370804",
     "exception": false,
     "start_time": "2024-05-05T19:47:03.358843",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LB Competition:\n",
    "\n",
    "## 1. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ade3db7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:47:03.396213Z",
     "iopub.status.busy": "2024-05-05T19:47:03.395840Z",
     "iopub.status.idle": "2024-05-05T19:47:03.399710Z",
     "shell.execute_reply": "2024-05-05T19:47:03.398939Z"
    },
    "papermill": {
     "duration": 0.018784,
     "end_time": "2024-05-05T19:47:03.401651",
     "exception": false,
     "start_time": "2024-05-05T19:47:03.382867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## Loading The Data\n",
    "\n",
    "# # Change to full Dataseet  for Massive Training and for testing\n",
    "# df_train = pd.read_csv('/kaggle/input/leash-BELKA/train.csv', nrows=1000)\n",
    "# df_test = pd.read_csv('/kaggle/input/leash-BELKA/test.csv', nrows=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e87423c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:47:03.427671Z",
     "iopub.status.busy": "2024-05-05T19:47:03.427391Z",
     "iopub.status.idle": "2024-05-05T19:47:03.430918Z",
     "shell.execute_reply": "2024-05-05T19:47:03.430060Z"
    },
    "papermill": {
     "duration": 0.018857,
     "end_time": "2024-05-05T19:47:03.432649",
     "exception": false,
     "start_time": "2024-05-05T19:47:03.413792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a40008ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:47:03.458302Z",
     "iopub.status.busy": "2024-05-05T19:47:03.457647Z",
     "iopub.status.idle": "2024-05-05T19:47:03.461197Z",
     "shell.execute_reply": "2024-05-05T19:47:03.460428Z"
    },
    "papermill": {
     "duration": 0.018085,
     "end_time": "2024-05-05T19:47:03.462999",
     "exception": false,
     "start_time": "2024-05-05T19:47:03.444914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install rdkit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799fccdb",
   "metadata": {
    "papermill": {
     "duration": 0.011733,
     "end_time": "2024-05-05T19:47:03.486685",
     "exception": false,
     "start_time": "2024-05-05T19:47:03.474952",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Plotting 2d Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "790cb54f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:47:03.511853Z",
     "iopub.status.busy": "2024-05-05T19:47:03.511597Z",
     "iopub.status.idle": "2024-05-05T19:47:03.515570Z",
     "shell.execute_reply": "2024-05-05T19:47:03.514778Z"
    },
    "papermill": {
     "duration": 0.018744,
     "end_time": "2024-05-05T19:47:03.517495",
     "exception": false,
     "start_time": "2024-05-05T19:47:03.498751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from rdkit import Chem\n",
    "# from rdkit.Chem import Draw\n",
    "\n",
    "# def plot_2d_molecule(df, molecule_id):\n",
    "#     # Filter the DataFrame for the given id\n",
    "#     row = df[df['id'] == molecule_id]\n",
    "#     # Get the SMILES string for the molecule\n",
    "#     smiles_string = row['molecule_smiles'].values[0]\n",
    "#     # Generate an RDKit molecule object\n",
    "#     mol = Chem.MolFromSmiles(smiles_string)\n",
    "#     # Use RDKit to draw the molecule\n",
    "#     img = Draw.MolToImage(mol)\n",
    "#     # Display the image\n",
    "#     return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fe55411",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:47:03.542435Z",
     "iopub.status.busy": "2024-05-05T19:47:03.542185Z",
     "iopub.status.idle": "2024-05-05T19:47:03.545753Z",
     "shell.execute_reply": "2024-05-05T19:47:03.544943Z"
    },
    "papermill": {
     "duration": 0.018148,
     "end_time": "2024-05-05T19:47:03.547708",
     "exception": false,
     "start_time": "2024-05-05T19:47:03.529560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #Example usage:\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mpimg\n",
    "\n",
    "# img = plot_2d_molecule(df_train, 1)\n",
    "# plt.imshow(img)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cae14fb",
   "metadata": {
    "papermill": {
     "duration": 0.011752,
     "end_time": "2024-05-05T19:47:03.572521",
     "exception": false,
     "start_time": "2024-05-05T19:47:03.560769",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Plotting 3d Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5edc659e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:47:03.597418Z",
     "iopub.status.busy": "2024-05-05T19:47:03.597161Z",
     "iopub.status.idle": "2024-05-05T19:47:03.600561Z",
     "shell.execute_reply": "2024-05-05T19:47:03.599779Z"
    },
    "papermill": {
     "duration": 0.018066,
     "end_time": "2024-05-05T19:47:03.602514",
     "exception": false,
     "start_time": "2024-05-05T19:47:03.584448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install py3Dmol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69543072",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:47:03.630301Z",
     "iopub.status.busy": "2024-05-05T19:47:03.630025Z",
     "iopub.status.idle": "2024-05-05T19:47:03.634589Z",
     "shell.execute_reply": "2024-05-05T19:47:03.633781Z"
    },
    "papermill": {
     "duration": 0.021937,
     "end_time": "2024-05-05T19:47:03.636377",
     "exception": false,
     "start_time": "2024-05-05T19:47:03.614440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# from rdkit.Chem import AllChem\n",
    "# import py3Dmol\n",
    "\n",
    "# def plot_3d_molecule_by_id(df, molecule_id):\n",
    "#     # Filter the DataFrame for the given id\n",
    "#     row = df[df['id'] == molecule_id]\n",
    "#     if row.empty:\n",
    "#         return \"No entry with the given ID.\"\n",
    "\n",
    "#     # Get the SMILES string for the molecule\n",
    "#     smiles_string = row['molecule_smiles'].values[0]\n",
    "#     if not smiles_string:\n",
    "#         return \"No SMILES string found for the given ID.\"\n",
    "    \n",
    "#     # Create a molecule from a SMILES string\n",
    "#     mol = Chem.MolFromSmiles(smiles_string)\n",
    "#     if mol is None:\n",
    "#         return \"Invalid SMILES string.\"\n",
    "    \n",
    "#     # Generate 3D coordinates\n",
    "#     mol = Chem.AddHs(mol)  # Add hydrogens\n",
    "#     AllChem.EmbedMolecule(mol, AllChem.ETKDG())  # Embed molecule in 3D space using ETKDG methodology\n",
    "#     AllChem.UFFOptimizeMolecule(mol)  # Optimize the geometry\n",
    "\n",
    "#     # Use py3Dmol for visualization\n",
    "#     mb = Chem.MolToMolBlock(mol)\n",
    "#     viewer = py3Dmol.view(width=800, height=400)\n",
    "#     viewer.addModel(mb, \"mol\")\n",
    "#     viewer.setStyle({'stick': {}})\n",
    "#     viewer.zoomTo()\n",
    "#     return viewer.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c499e23b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:47:03.661082Z",
     "iopub.status.busy": "2024-05-05T19:47:03.660845Z",
     "iopub.status.idle": "2024-05-05T19:47:03.664379Z",
     "shell.execute_reply": "2024-05-05T19:47:03.663531Z"
    },
    "papermill": {
     "duration": 0.017996,
     "end_time": "2024-05-05T19:47:03.666324",
     "exception": false,
     "start_time": "2024-05-05T19:47:03.648328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Example usage:\n",
    "# plot_3d_molecule_by_id(df_train, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a928265",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:47:03.691126Z",
     "iopub.status.busy": "2024-05-05T19:47:03.690858Z",
     "iopub.status.idle": "2024-05-05T19:47:03.694420Z",
     "shell.execute_reply": "2024-05-05T19:47:03.693585Z"
    },
    "papermill": {
     "duration": 0.018146,
     "end_time": "2024-05-05T19:47:03.696319",
     "exception": false,
     "start_time": "2024-05-05T19:47:03.678173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install rdkit-pypi networkx matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "707e7851",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:47:03.721541Z",
     "iopub.status.busy": "2024-05-05T19:47:03.721303Z",
     "iopub.status.idle": "2024-05-05T19:47:03.725888Z",
     "shell.execute_reply": "2024-05-05T19:47:03.725042Z"
    },
    "papermill": {
     "duration": 0.019619,
     "end_time": "2024-05-05T19:47:03.727915",
     "exception": false,
     "start_time": "2024-05-05T19:47:03.708296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# import pandas as pd\n",
    "# import networkx as nx\n",
    "# import matplotlib.pyplot as plt\n",
    "# from rdkit import Chem\n",
    "# from rdkit.Chem import Draw\n",
    "# from rdkit.Chem.rdmolops import GetAdjacencyMatrix\n",
    "\n",
    "# def plot_molecule_graph(df, molecule_id):\n",
    "#     # Find the molecule by ID\n",
    "#     row = df[df['id'] == molecule_id]\n",
    "#     if row.empty:\n",
    "#         print(\"No entry with the given ID.\")\n",
    "#         return\n",
    "\n",
    "#     # Extract the SMILES string\n",
    "#     smiles = row['molecule_smiles'].values[0]\n",
    "#     mol = Chem.MolFromSmiles(smiles)\n",
    "#     if mol is None:\n",
    "#         print(\"Invalid SMILES string.\")\n",
    "#         return\n",
    "\n",
    "#     # Create a graph from the molecule\n",
    "#     G = nx.Graph(Chem.rdmolops.GetAdjacencyMatrix(mol))\n",
    "#     labels = {}\n",
    "#     for idx, atom in enumerate(mol.GetAtoms()):\n",
    "#         G.nodes[idx]['label'] = atom.GetSymbol()\n",
    "#         labels[idx] = atom.GetSymbol()\n",
    "\n",
    "#     # Draw the graph\n",
    "#     pos = nx.spring_layout(G)  # positions for all nodes\n",
    "#     nx.draw(G, pos, with_labels=True, labels=labels, node_size=700, node_color='skyblue', font_size=16, font_weight='bold', edge_color='gray')\n",
    "#     plt.title(f'Molecular graph of ID {molecule_id}')\n",
    "#     plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cf55954",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:47:03.752701Z",
     "iopub.status.busy": "2024-05-05T19:47:03.752438Z",
     "iopub.status.idle": "2024-05-05T19:47:03.755974Z",
     "shell.execute_reply": "2024-05-05T19:47:03.755267Z"
    },
    "papermill": {
     "duration": 0.018121,
     "end_time": "2024-05-05T19:47:03.757921",
     "exception": false,
     "start_time": "2024-05-05T19:47:03.739800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Example usage:\n",
    "# plot_molecule_graph(df_train, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fe174c",
   "metadata": {
    "papermill": {
     "duration": 0.01172,
     "end_time": "2024-05-05T19:47:03.781384",
     "exception": false,
     "start_time": "2024-05-05T19:47:03.769664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33ba6e44",
   "metadata": {
    "papermill": {
     "duration": 0.011805,
     "end_time": "2024-05-05T19:47:03.805088",
     "exception": false,
     "start_time": "2024-05-05T19:47:03.793283",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model 1 - SMILESBerth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bd2ed34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:47:03.829960Z",
     "iopub.status.busy": "2024-05-05T19:47:03.829704Z",
     "iopub.status.idle": "2024-05-05T19:47:07.034872Z",
     "shell.execute_reply": "2024-05-05T19:47:07.033860Z"
    },
    "papermill": {
     "duration": 3.22015,
     "end_time": "2024-05-05T19:47:07.037207",
     "exception": false,
     "start_time": "2024-05-05T19:47:03.817057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Path to the Parquet file\n",
    "# Change to full Dataseet  for Massive Training and for testing\n",
    "df = pd.read_csv('/kaggle/input/leash-BELKA/train.csv', nrows=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fafbf5c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:47:07.062978Z",
     "iopub.status.busy": "2024-05-05T19:47:07.062652Z",
     "iopub.status.idle": "2024-05-05T19:47:08.395198Z",
     "shell.execute_reply": "2024-05-05T19:47:08.394133Z"
    },
    "papermill": {
     "duration": 1.348132,
     "end_time": "2024-05-05T19:47:08.397814",
     "exception": false,
     "start_time": "2024-05-05T19:47:07.049682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split df_train to create a new training set and an evaluation set\n",
    "df_train, df_eval = train_test_split(df, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0d8864f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:47:08.423421Z",
     "iopub.status.busy": "2024-05-05T19:47:08.423106Z",
     "iopub.status.idle": "2024-05-05T19:47:08.431117Z",
     "shell.execute_reply": "2024-05-05T19:47:08.430292Z"
    },
    "papermill": {
     "duration": 0.022898,
     "end_time": "2024-05-05T19:47:08.433117",
     "exception": false,
     "start_time": "2024-05-05T19:47:08.410219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'buildingblock1_smiles', 'buildingblock2_smiles',\n",
       "       'buildingblock3_smiles', 'molecule_smiles', 'protein_name', 'binds'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f67ab1f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:47:08.458959Z",
     "iopub.status.busy": "2024-05-05T19:47:08.458269Z",
     "iopub.status.idle": "2024-05-05T19:47:08.472483Z",
     "shell.execute_reply": "2024-05-05T19:47:08.471642Z"
    },
    "papermill": {
     "duration": 0.028898,
     "end_time": "2024-05-05T19:47:08.474338",
     "exception": false,
     "start_time": "2024-05-05T19:47:08.445440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>buildingblock1_smiles</th>\n",
       "      <th>buildingblock2_smiles</th>\n",
       "      <th>buildingblock3_smiles</th>\n",
       "      <th>molecule_smiles</th>\n",
       "      <th>protein_name</th>\n",
       "      <th>binds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>987231</th>\n",
       "      <td>987231</td>\n",
       "      <td>C#CC[C@@H](CC(=O)O)NC(=O)OCC1c2ccccc2-c2ccccc21</td>\n",
       "      <td>Nc1cccc(OC(F)F)c1</td>\n",
       "      <td>Nc1ccnc(-c2ccccc2)c1</td>\n",
       "      <td>C#CC[C@@H](CC(=O)N[Dy])Nc1nc(Nc2cccc(OC(F)F)c2...</td>\n",
       "      <td>BRD4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79954</th>\n",
       "      <td>79954</td>\n",
       "      <td>C#CC[C@@H](CC(=O)O)NC(=O)OCC1c2ccccc2-c2ccccc21</td>\n",
       "      <td>CC1(F)CCN(CCN)C1.Cl.Cl</td>\n",
       "      <td>Cl.Cl.NCc1cc(Br)cc2cccnc12</td>\n",
       "      <td>C#CC[C@@H](CC(=O)N[Dy])Nc1nc(NCCN2CCC(C)(F)C2)...</td>\n",
       "      <td>HSA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567130</th>\n",
       "      <td>567130</td>\n",
       "      <td>C#CC[C@@H](CC(=O)O)NC(=O)OCC1c2ccccc2-c2ccccc21</td>\n",
       "      <td>Cl.NCC1CC2CC1C1CC21</td>\n",
       "      <td>COc1cc2nc(Cl)nc(N)c2cc1OC</td>\n",
       "      <td>C#CC[C@@H](CC(=O)N[Dy])Nc1nc(NCC2CC3CC2C2CC32)...</td>\n",
       "      <td>HSA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500891</th>\n",
       "      <td>500891</td>\n",
       "      <td>C#CC[C@@H](CC(=O)O)NC(=O)OCC1c2ccccc2-c2ccccc21</td>\n",
       "      <td>Cl.Cl.NCc1ccc[n+]([O-])c1</td>\n",
       "      <td>CC1(C)OB(c2ccc(N)cc2)OC1(C)C</td>\n",
       "      <td>C#CC[C@@H](CC(=O)N[Dy])Nc1nc(NCc2ccc[n+]([O-])...</td>\n",
       "      <td>sEH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55399</th>\n",
       "      <td>55399</td>\n",
       "      <td>C#CC[C@@H](CC(=O)O)NC(=O)OCC1c2ccccc2-c2ccccc21</td>\n",
       "      <td>CC(CN)OC(C)(C)C.Cl</td>\n",
       "      <td>Cl.NCc1cnc(Cl)s1</td>\n",
       "      <td>C#CC[C@@H](CC(=O)N[Dy])Nc1nc(NCc2cnc(Cl)s2)nc(...</td>\n",
       "      <td>HSA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                            buildingblock1_smiles  \\\n",
       "987231  987231  C#CC[C@@H](CC(=O)O)NC(=O)OCC1c2ccccc2-c2ccccc21   \n",
       "79954    79954  C#CC[C@@H](CC(=O)O)NC(=O)OCC1c2ccccc2-c2ccccc21   \n",
       "567130  567130  C#CC[C@@H](CC(=O)O)NC(=O)OCC1c2ccccc2-c2ccccc21   \n",
       "500891  500891  C#CC[C@@H](CC(=O)O)NC(=O)OCC1c2ccccc2-c2ccccc21   \n",
       "55399    55399  C#CC[C@@H](CC(=O)O)NC(=O)OCC1c2ccccc2-c2ccccc21   \n",
       "\n",
       "            buildingblock2_smiles         buildingblock3_smiles  \\\n",
       "987231          Nc1cccc(OC(F)F)c1          Nc1ccnc(-c2ccccc2)c1   \n",
       "79954      CC1(F)CCN(CCN)C1.Cl.Cl    Cl.Cl.NCc1cc(Br)cc2cccnc12   \n",
       "567130        Cl.NCC1CC2CC1C1CC21     COc1cc2nc(Cl)nc(N)c2cc1OC   \n",
       "500891  Cl.Cl.NCc1ccc[n+]([O-])c1  CC1(C)OB(c2ccc(N)cc2)OC1(C)C   \n",
       "55399          CC(CN)OC(C)(C)C.Cl              Cl.NCc1cnc(Cl)s1   \n",
       "\n",
       "                                          molecule_smiles protein_name  binds  \n",
       "987231  C#CC[C@@H](CC(=O)N[Dy])Nc1nc(Nc2cccc(OC(F)F)c2...         BRD4      0  \n",
       "79954   C#CC[C@@H](CC(=O)N[Dy])Nc1nc(NCCN2CCC(C)(F)C2)...          HSA      0  \n",
       "567130  C#CC[C@@H](CC(=O)N[Dy])Nc1nc(NCC2CC3CC2C2CC32)...          HSA      0  \n",
       "500891  C#CC[C@@H](CC(=O)N[Dy])Nc1nc(NCc2ccc[n+]([O-])...          sEH      0  \n",
       "55399   C#CC[C@@H](CC(=O)N[Dy])Nc1nc(NCc2cnc(Cl)s2)nc(...          HSA      0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b72ff2d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:47:08.500775Z",
     "iopub.status.busy": "2024-05-05T19:47:08.499978Z",
     "iopub.status.idle": "2024-05-05T19:47:21.573017Z",
     "shell.execute_reply": "2024-05-05T19:47:21.571807Z"
    },
    "papermill": {
     "duration": 13.088879,
     "end_time": "2024-05-05T19:47:21.575536",
     "exception": false,
     "start_time": "2024-05-05T19:47:08.486657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.2.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd90d595",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:47:21.644795Z",
     "iopub.status.busy": "2024-05-05T19:47:21.643976Z",
     "iopub.status.idle": "2024-05-05T19:47:30.624291Z",
     "shell.execute_reply": "2024-05-05T19:47:30.623348Z"
    },
    "papermill": {
     "duration": 8.997189,
     "end_time": "2024-05-05T19:47:30.626380",
     "exception": false,
     "start_time": "2024-05-05T19:47:21.629191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3584db61af7c454eb23db05abf14eb52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/62.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a19cd88885474fa098ec9d967841e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/515 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c62c50c1ac54865a3461917e02cb34e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/165k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38f538f52a0441f79f570622221aaf95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/101k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8837800f5545406a9b3f1dff34db4697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_name = \"seyonec/PubChem10M_SMILES_BPE_450k\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8988faac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:47:30.655713Z",
     "iopub.status.busy": "2024-05-05T19:47:30.655289Z",
     "iopub.status.idle": "2024-05-05T19:48:55.756354Z",
     "shell.execute_reply": "2024-05-05T19:48:55.755473Z"
    },
    "papermill": {
     "duration": 85.118309,
     "end_time": "2024-05-05T19:48:55.758954",
     "exception": false,
     "start_time": "2024-05-05T19:47:30.640645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 19:47:33.116982: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-05 19:47:33.117085: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-05 19:47:33.220647: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "# Tokenizing the SMILES strings\n",
    "\n",
    "train_encodings = tokenizer(df_train['molecule_smiles'].tolist(), truncation=True, padding=True, max_length=512)\n",
    "eval_encodings = tokenizer(df_eval['molecule_smiles'].tolist(), truncation=True, padding=True, max_length=512)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "824ef467",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:48:55.789710Z",
     "iopub.status.busy": "2024-05-05T19:48:55.789075Z",
     "iopub.status.idle": "2024-05-05T19:48:56.166016Z",
     "shell.execute_reply": "2024-05-05T19:48:56.165197Z"
    },
    "papermill": {
     "duration": 0.395375,
     "end_time": "2024-05-05T19:48:56.168708",
     "exception": false,
     "start_time": "2024-05-05T19:48:55.773333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Encode protein names\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "train_proteins = encoder.fit_transform(df_train['protein_name'].values.reshape(-1, 1))\n",
    "eval_proteins = encoder.transform(df_eval['protein_name'].values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4a1dc2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:48:56.198294Z",
     "iopub.status.busy": "2024-05-05T19:48:56.197937Z",
     "iopub.status.idle": "2024-05-05T19:48:56.204944Z",
     "shell.execute_reply": "2024-05-05T19:48:56.204116Z"
    },
    "papermill": {
     "duration": 0.023919,
     "end_time": "2024-05-05T19:48:56.206874",
     "exception": false,
     "start_time": "2024-05-05T19:48:56.182955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Creating a Dataset object for Hugging Face\n",
    "import torch\n",
    "\n",
    "class SMILESDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels, protein_encodings):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.protein_encodings = protein_encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        item['protein_encodings'] = torch.tensor(self.protein_encodings[idx], dtype=torch.float32)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94d23f78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:48:56.235981Z",
     "iopub.status.busy": "2024-05-05T19:48:56.235635Z",
     "iopub.status.idle": "2024-05-05T19:48:56.243262Z",
     "shell.execute_reply": "2024-05-05T19:48:56.242361Z"
    },
    "papermill": {
     "duration": 0.024431,
     "end_time": "2024-05-05T19:48:56.245158",
     "exception": false,
     "start_time": "2024-05-05T19:48:56.220727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ProteinBindingModel(nn.Module):\n",
    "    def __init__(self, transformer_model, num_protein_features):\n",
    "        super(ProteinBindingModel, self).__init__()\n",
    "        self.transformer = transformer_model\n",
    "        self.protein_features = nn.Linear(num_protein_features, 256)\n",
    "        self.classifier = nn.Linear(768 + 256, 2)  # Adjust sizes accordingly if using a different model\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, protein_features):\n",
    "        # Obtain the outputs from the transformer model\n",
    "        outputs = self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Use the last hidden state\n",
    "        last_hidden_state = outputs.last_hidden_state  # This is generally [batch size, sequence length, hidden size]\n",
    "        pooled_output = last_hidden_state[:, 0, :]  # Take the first token's embeddings across all batches\n",
    "        \n",
    "        # Process protein features\n",
    "        protein_features = self.protein_features(protein_features)\n",
    "        \n",
    "        # Concatenate pooled output and protein features\n",
    "        combined_features = torch.cat((pooled_output, protein_features), dim=1)\n",
    "        output = self.classifier(combined_features)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c552aded",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:48:56.274564Z",
     "iopub.status.busy": "2024-05-05T19:48:56.274292Z",
     "iopub.status.idle": "2024-05-05T19:48:56.297766Z",
     "shell.execute_reply": "2024-05-05T19:48:56.296935Z"
    },
    "papermill": {
     "duration": 0.040524,
     "end_time": "2024-05-05T19:48:56.299796",
     "exception": false,
     "start_time": "2024-05-05T19:48:56.259272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create Dataset\n",
    "train_dataset = SMILESDataset(train_encodings, df_train['binds'].tolist(), train_proteins)\n",
    "eval_dataset = SMILESDataset(eval_encodings, df_eval['binds'].tolist(), eval_proteins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79ff070a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:48:56.329267Z",
     "iopub.status.busy": "2024-05-05T19:48:56.328967Z",
     "iopub.status.idle": "2024-05-05T19:49:01.364507Z",
     "shell.execute_reply": "2024-05-05T19:49:01.363622Z"
    },
    "papermill": {
     "duration": 5.052733,
     "end_time": "2024-05-05T19:49:01.366811",
     "exception": false,
     "start_time": "2024-05-05T19:48:56.314078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2438645c600147788a9a4361961bd817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/336M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at seyonec/PubChem10M_SMILES_BPE_450k and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the base transformer model without the classification head\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2).base_model\n",
    "model = ProteinBindingModel(base_model, train_proteins.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf585090",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:49:01.400286Z",
     "iopub.status.busy": "2024-05-05T19:49:01.399960Z",
     "iopub.status.idle": "2024-05-05T19:49:01.503598Z",
     "shell.execute_reply": "2024-05-05T19:49:01.502789Z"
    },
    "papermill": {
     "duration": 0.122697,
     "end_time": "2024-05-05T19:49:01.505925",
     "exception": false,
     "start_time": "2024-05-05T19:49:01.383228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='/kaggle/working/',           # output directory\n",
    "    num_train_epochs=3,                      # number of training epochs\n",
    "    per_device_train_batch_size=16,          # batch size for training\n",
    "    per_device_eval_batch_size=64,           # batch size for evaluation\n",
    "    warmup_steps=500,                        # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,                       # strength of weight decay\n",
    "    logging_dir='/kaggle/working/logs',      # directory for storing logs\n",
    "    logging_steps=1000,\n",
    "    report_to=\"none\",                        # suppress logging to WANDB\n",
    "    save_steps=10000,                        # save model every 10000 steps\n",
    "    evaluation_strategy='steps',             # evaluate each `eval_steps`\n",
    "    eval_steps=5000,                         # evaluation every 5000 steps\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a502c47e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:49:01.538877Z",
     "iopub.status.busy": "2024-05-05T19:49:01.538261Z",
     "iopub.status.idle": "2024-05-05T19:49:03.706894Z",
     "shell.execute_reply": "2024-05-05T19:49:03.706006Z"
    },
    "papermill": {
     "duration": 2.187373,
     "end_time": "2024-05-05T19:49:03.708943",
     "exception": false,
     "start_time": "2024-05-05T19:49:01.521570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75b23aaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:49:03.739937Z",
     "iopub.status.busy": "2024-05-05T19:49:03.739355Z",
     "iopub.status.idle": "2024-05-05T19:49:03.746478Z",
     "shell.execute_reply": "2024-05-05T19:49:03.745613Z"
    },
    "papermill": {
     "duration": 0.025012,
     "end_time": "2024-05-05T19:49:03.748664",
     "exception": false,
     "start_time": "2024-05-05T19:49:03.723652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ProteinBindingTrainer(Trainer):\n",
    "    def _prepare_inputs(self, inputs):\n",
    "        # Instead of modifying inputs, just pass them through.\n",
    "        return inputs\n",
    "\n",
    "    def training_step(self, model, batch):\n",
    "        # Move batch to device\n",
    "        batch = {k: v.to(self.args.device) for k, v in batch.items() if hasattr(v, 'to')}\n",
    "\n",
    "        # Extract inputs from batch\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        protein_features = batch['protein_encodings']\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, protein_features=protein_features)\n",
    "        logits = outputs.logits if hasattr(outputs, 'logits') else outputs[0]\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = self.compute_loss(logits, labels)\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78f3d989",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:49:03.779770Z",
     "iopub.status.busy": "2024-05-05T19:49:03.779041Z",
     "iopub.status.idle": "2024-05-05T19:49:03.899923Z",
     "shell.execute_reply": "2024-05-05T19:49:03.898790Z"
    },
    "papermill": {
     "duration": 0.138786,
     "end_time": "2024-05-05T19:49:03.902033",
     "exception": false,
     "start_time": "2024-05-05T19:49:03.763247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels', 'protein_encodings'])\n"
     ]
    }
   ],
   "source": [
    "test_loader = torch.utils.data.DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "test_batch = next(iter(test_loader))\n",
    "print(test_batch.keys())  # This should include 'labels' and 'protein_encodings'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1d6b625",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:49:03.934031Z",
     "iopub.status.busy": "2024-05-05T19:49:03.933117Z",
     "iopub.status.idle": "2024-05-05T19:49:03.937588Z",
     "shell.execute_reply": "2024-05-05T19:49:03.936779Z"
    },
    "papermill": {
     "duration": 0.022553,
     "end_time": "2024-05-05T19:49:03.939626",
     "exception": false,
     "start_time": "2024-05-05T19:49:03.917073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Ensure the model is on the correct device\n",
    "# model.to(device)\n",
    "\n",
    "#THIS TRAINER IS NOT WORKING... SOMEHOW THE FUNCTION IS NOT GETTNG THE KEYS PROPERLY\n",
    "\n",
    "# # Initialize the trainer with all settings\n",
    "# trainer = ProteinBindingTrainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_dataset,  # Ensure this is your dataset, not DataLoader\n",
    "#     eval_dataset=eval_dataset     # Ensure this is your dataset, not DataLoader\n",
    "# )\n",
    "\n",
    "# # Start training\n",
    "# trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ca6fbb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:49:03.972087Z",
     "iopub.status.busy": "2024-05-05T19:49:03.971321Z",
     "iopub.status.idle": "2024-05-05T19:49:03.976625Z",
     "shell.execute_reply": "2024-05-05T19:49:03.975729Z"
    },
    "papermill": {
     "duration": 0.023836,
     "end_time": "2024-05-05T19:49:03.978692",
     "exception": false,
     "start_time": "2024-05-05T19:49:03.954856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set the device to GPU if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15073ba6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:49:04.010434Z",
     "iopub.status.busy": "2024-05-05T19:49:04.009926Z",
     "iopub.status.idle": "2024-05-05T23:54:24.427175Z",
     "shell.execute_reply": "2024-05-05T23:54:24.425982Z"
    },
    "papermill": {
     "duration": 14720.436524,
     "end_time": "2024-05-05T23:54:24.430007",
     "exception": false,
     "start_time": "2024-05-05T19:49:03.993483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch 50, Loss: 0.003011100459843874\n",
      "Epoch 0, Batch 100, Loss: 0.003960413858294487\n",
      "Epoch 0, Batch 150, Loss: 0.000303868786431849\n",
      "Epoch 0, Batch 200, Loss: 0.0011192959500476718\n",
      "Epoch 0, Batch 250, Loss: 0.009093795903027058\n",
      "Epoch 0, Batch 300, Loss: 0.00026848865672945976\n",
      "Epoch 0, Batch 350, Loss: 0.0011966925812885165\n",
      "Epoch 0, Batch 400, Loss: 0.004300858359783888\n",
      "Epoch 0, Batch 450, Loss: 0.001480689737945795\n",
      "Epoch 0, Batch 500, Loss: 0.002336540026590228\n",
      "Epoch 0, Batch 550, Loss: 0.001975973369553685\n",
      "Epoch 0, Batch 600, Loss: 0.0012676059268414974\n",
      "Epoch 0, Batch 650, Loss: 0.002383419079706073\n",
      "Epoch 0, Batch 700, Loss: 0.3907552659511566\n",
      "Epoch 0, Batch 750, Loss: 0.004538297653198242\n",
      "Epoch 0, Batch 800, Loss: 0.003043226432055235\n",
      "Epoch 0, Batch 850, Loss: 0.004021947737783194\n",
      "Epoch 0, Batch 900, Loss: 0.0005200065206736326\n",
      "Epoch 0, Batch 950, Loss: 0.00533688860014081\n",
      "Epoch 0, Batch 1000, Loss: 0.008402034640312195\n",
      "Epoch 0, Batch 1050, Loss: 0.0012753763003274798\n",
      "Epoch 0, Batch 1100, Loss: 0.0054648579098284245\n",
      "Epoch 0, Batch 1150, Loss: 0.0006041669403202832\n",
      "Epoch 0, Batch 1200, Loss: 0.0013920078054070473\n",
      "Epoch 0, Batch 1250, Loss: 0.003079743590205908\n",
      "Epoch 0, Batch 1300, Loss: 0.0038301669992506504\n",
      "Epoch 0, Batch 1350, Loss: 0.0007651748019270599\n",
      "Epoch 0, Batch 1400, Loss: 0.001001782133243978\n",
      "Epoch 0, Batch 1450, Loss: 0.0007930491119623184\n",
      "Epoch 0, Batch 1500, Loss: 0.48748597502708435\n",
      "Epoch 0, Batch 1550, Loss: 0.0023978373501449823\n",
      "Epoch 0, Batch 1600, Loss: 0.0014976880047470331\n",
      "Epoch 0, Batch 1650, Loss: 0.0007728891796432436\n",
      "Epoch 0, Batch 1700, Loss: 0.01038362830877304\n",
      "Epoch 0, Batch 1750, Loss: 0.003164109541103244\n",
      "Epoch 0, Batch 1800, Loss: 0.001646455843001604\n",
      "Epoch 0, Batch 1850, Loss: 0.001642903545871377\n",
      "Epoch 0, Batch 1900, Loss: 0.00044985595741309226\n",
      "Epoch 0, Batch 1950, Loss: 0.0025769679341465235\n",
      "Epoch 0, Batch 2000, Loss: 0.0014996351674199104\n",
      "Epoch 0, Batch 2050, Loss: 0.002646565670147538\n",
      "Epoch 0, Batch 2100, Loss: 0.0018985067727044225\n",
      "Epoch 0, Batch 2150, Loss: 0.0008526385063305497\n",
      "Epoch 0, Batch 2200, Loss: 0.0008244760683737695\n",
      "Epoch 0, Batch 2250, Loss: 0.0019417509902268648\n",
      "Epoch 0, Batch 2300, Loss: 0.0005501488340087235\n",
      "Epoch 0, Batch 2350, Loss: 0.003696630010381341\n",
      "Epoch 0, Batch 2400, Loss: 0.001731468248181045\n",
      "Epoch 0, Batch 2450, Loss: 0.0058309645392000675\n",
      "Epoch 0, Batch 2500, Loss: 0.002663737628608942\n",
      "Epoch 0, Batch 2550, Loss: 0.004202738869935274\n",
      "Epoch 0, Batch 2600, Loss: 0.002163763390854001\n",
      "Epoch 0, Batch 2650, Loss: 0.0012538701994344592\n",
      "Epoch 0, Batch 2700, Loss: 0.0039657107554376125\n",
      "Epoch 0, Batch 2750, Loss: 0.0010548713617026806\n",
      "Epoch 0, Batch 2800, Loss: 0.0035925237461924553\n",
      "Epoch 0, Batch 2850, Loss: 0.007947606965899467\n",
      "Epoch 0, Batch 2900, Loss: 0.32560738921165466\n",
      "Epoch 0, Batch 2950, Loss: 0.002743953140452504\n",
      "Epoch 0, Batch 3000, Loss: 0.0031718092504888773\n",
      "Epoch 0, Batch 3050, Loss: 0.0012611665297299623\n",
      "Epoch 0, Batch 3100, Loss: 0.00047532105236314237\n",
      "Epoch 0, Batch 3150, Loss: 0.0007855122094042599\n",
      "Epoch 0, Batch 3200, Loss: 0.0007604380953125656\n",
      "Epoch 0, Batch 3250, Loss: 0.001181898289360106\n",
      "Epoch 0, Batch 3300, Loss: 0.0029167337343096733\n",
      "Epoch 0, Batch 3350, Loss: 0.0014079991960898042\n",
      "Epoch 0, Batch 3400, Loss: 0.0035028301645070314\n",
      "Epoch 0, Batch 3450, Loss: 0.003935066983103752\n",
      "Epoch 0, Batch 3500, Loss: 0.001589665887877345\n",
      "Epoch 0, Batch 3550, Loss: 0.0023758518509566784\n",
      "Epoch 0, Batch 3600, Loss: 0.0022474348079413176\n",
      "Epoch 0, Batch 3650, Loss: 0.0007563013350591063\n",
      "Epoch 0, Batch 3700, Loss: 0.0013947786064818501\n",
      "Epoch 0, Batch 3750, Loss: 0.0015338819939643145\n",
      "Epoch 0, Batch 3800, Loss: 0.0012260330840945244\n",
      "Epoch 0, Batch 3850, Loss: 0.0018555495189502835\n",
      "Epoch 0, Batch 3900, Loss: 0.004565386101603508\n",
      "Epoch 0, Batch 3950, Loss: 0.39395204186439514\n",
      "Epoch 0, Batch 4000, Loss: 0.0041967518627643585\n",
      "Epoch 0, Batch 4050, Loss: 0.0023040049709379673\n",
      "Epoch 0, Batch 4100, Loss: 0.0021325121633708477\n",
      "Epoch 0, Batch 4150, Loss: 0.3744639456272125\n",
      "Epoch 0, Batch 4200, Loss: 0.0028655712958425283\n",
      "Epoch 0, Batch 4250, Loss: 0.0007643135613761842\n",
      "Epoch 0, Batch 4300, Loss: 0.0016492517897859216\n",
      "Epoch 0, Batch 4350, Loss: 0.0018556793220341206\n",
      "Epoch 0, Batch 4400, Loss: 0.0005943446303717792\n",
      "Epoch 0, Batch 4450, Loss: 0.40645405650138855\n",
      "Epoch 0, Batch 4500, Loss: 0.0011087440652772784\n",
      "Epoch 0, Batch 4550, Loss: 0.010076203383505344\n",
      "Epoch 0, Batch 4600, Loss: 0.0019216600339859724\n",
      "Epoch 0, Batch 4650, Loss: 0.0007171248435042799\n",
      "Epoch 0, Batch 4700, Loss: 0.0020495534408837557\n",
      "Epoch 0, Batch 4750, Loss: 0.001573303947225213\n",
      "Epoch 0, Batch 4800, Loss: 0.0018437226535752416\n",
      "Epoch 0, Batch 4850, Loss: 0.008405660279095173\n",
      "Epoch 0, Batch 4900, Loss: 0.0015075849369168282\n",
      "Epoch 0, Batch 4950, Loss: 0.002562685636803508\n",
      "Epoch 0, Batch 5000, Loss: 0.004555167630314827\n",
      "Epoch 0, Batch 5050, Loss: 0.38717710971832275\n",
      "Epoch 0, Batch 5100, Loss: 0.0023079426027834415\n",
      "Epoch 0, Batch 5150, Loss: 0.0012817634269595146\n",
      "Epoch 0, Batch 5200, Loss: 0.0012523012701421976\n",
      "Epoch 0, Batch 5250, Loss: 0.0023854493629187346\n",
      "Epoch 0, Batch 5300, Loss: 0.005163038149476051\n",
      "Epoch 0, Batch 5350, Loss: 0.009265598841011524\n",
      "Epoch 0, Batch 5400, Loss: 0.0014285646611824632\n",
      "Epoch 0, Batch 5450, Loss: 0.0006561651243828237\n",
      "Epoch 0, Batch 5500, Loss: 0.0026519636157900095\n",
      "Epoch 0, Batch 5550, Loss: 0.0020404313690960407\n",
      "Epoch 0, Batch 5600, Loss: 0.0020128122996538877\n",
      "Epoch 0, Batch 5650, Loss: 0.003216648008674383\n",
      "Epoch 0, Batch 5700, Loss: 0.0016485725063830614\n",
      "Epoch 0, Batch 5750, Loss: 0.001917039044201374\n",
      "Epoch 0, Batch 5800, Loss: 0.0013733383966609836\n",
      "Epoch 0, Batch 5850, Loss: 0.0033184417989104986\n",
      "Epoch 0, Batch 5900, Loss: 0.002770882798358798\n",
      "Epoch 0, Batch 5950, Loss: 0.0015596015146002173\n",
      "Epoch 0, Batch 6000, Loss: 0.0012898611603304744\n",
      "Epoch 0, Batch 6050, Loss: 0.0009705110569484532\n",
      "Epoch 0, Batch 6100, Loss: 0.0015712145250290632\n",
      "Epoch 0, Batch 6150, Loss: 0.0020803241059184074\n",
      "Epoch 0, Batch 6200, Loss: 0.0008142144652083516\n",
      "Epoch 0, Batch 6250, Loss: 0.38338473439216614\n",
      "Epoch 0, Batch 6300, Loss: 0.002286288421601057\n",
      "Epoch 0, Batch 6350, Loss: 0.001153772696852684\n",
      "Epoch 0, Batch 6400, Loss: 0.002818114124238491\n",
      "Epoch 0, Batch 6450, Loss: 0.0023220099974423647\n",
      "Epoch 0, Batch 6500, Loss: 0.0026361229829490185\n",
      "Epoch 0, Batch 6550, Loss: 0.00148914591409266\n",
      "Epoch 0, Batch 6600, Loss: 0.0012085246853530407\n",
      "Epoch 0, Batch 6650, Loss: 0.4399244785308838\n",
      "Epoch 0, Batch 6700, Loss: 0.0011755896266549826\n",
      "Epoch 0, Batch 6750, Loss: 0.44629141688346863\n",
      "Epoch 0, Batch 6800, Loss: 0.31863999366760254\n",
      "Epoch 0, Batch 6850, Loss: 0.003837126772850752\n",
      "Epoch 0, Batch 6900, Loss: 0.0021061766892671585\n",
      "Epoch 0, Batch 6950, Loss: 0.001917694928124547\n",
      "Epoch 0, Batch 7000, Loss: 0.0016053055878728628\n",
      "Epoch 0, Batch 7050, Loss: 0.0015633399598300457\n",
      "Epoch 0, Batch 7100, Loss: 0.0012933476828038692\n",
      "Epoch 0, Batch 7150, Loss: 0.0008099291007965803\n",
      "Epoch 0, Batch 7200, Loss: 0.0031255120411515236\n",
      "Epoch 0, Batch 7250, Loss: 0.003967995755374432\n",
      "Epoch 0, Batch 7300, Loss: 0.004093590658158064\n",
      "Epoch 0, Batch 7350, Loss: 0.004423632752150297\n",
      "Epoch 0, Batch 7400, Loss: 0.0026885014958679676\n",
      "Epoch 0, Batch 7450, Loss: 0.0018409586045891047\n",
      "Epoch 0, Batch 7500, Loss: 0.0018747418653219938\n",
      "Epoch 0, Batch 7550, Loss: 0.0012985788052901626\n",
      "Epoch 0, Batch 7600, Loss: 0.003102269722148776\n",
      "Epoch 0, Batch 7650, Loss: 0.002375347539782524\n",
      "Epoch 0, Batch 7700, Loss: 0.0019768031779676676\n",
      "Epoch 0, Batch 7750, Loss: 0.002937071491032839\n",
      "Epoch 0, Batch 7800, Loss: 0.0030572013929486275\n",
      "Epoch 0, Batch 7850, Loss: 0.0017543249996379018\n",
      "Epoch 0, Batch 7900, Loss: 0.000913335126824677\n",
      "Epoch 0, Batch 7950, Loss: 0.001010192441754043\n",
      "Epoch 0, Batch 8000, Loss: 0.4293591380119324\n",
      "Epoch 0, Batch 8050, Loss: 0.0038300775922834873\n",
      "Epoch 0, Batch 8100, Loss: 0.0015917980344966054\n",
      "Epoch 0, Batch 8150, Loss: 0.0018793671624734998\n",
      "Epoch 0, Batch 8200, Loss: 0.003725360380485654\n",
      "Epoch 0, Batch 8250, Loss: 0.004168574698269367\n",
      "Epoch 0, Batch 8300, Loss: 0.002165808342397213\n",
      "Epoch 0, Batch 8350, Loss: 0.002661011414602399\n",
      "Epoch 0, Batch 8400, Loss: 0.002377644879743457\n",
      "Epoch 0, Batch 8450, Loss: 0.0025495807640254498\n",
      "Epoch 0, Batch 8500, Loss: 0.003998124971985817\n",
      "Epoch 0, Batch 8550, Loss: 0.0014887206489220262\n",
      "Epoch 0, Batch 8600, Loss: 0.0012263900134712458\n",
      "Epoch 0, Batch 8650, Loss: 0.0019579429645091295\n",
      "Epoch 0, Batch 8700, Loss: 0.0024375629145652056\n",
      "Epoch 0, Batch 8750, Loss: 0.0023187482729554176\n",
      "Epoch 0, Batch 8800, Loss: 0.0013487269170582294\n",
      "Epoch 0, Batch 8850, Loss: 0.0023566922172904015\n",
      "Epoch 0, Batch 8900, Loss: 0.003627330996096134\n",
      "Epoch 0, Batch 8950, Loss: 0.0009927379433065653\n",
      "Epoch 0, Batch 9000, Loss: 0.0013348711654543877\n",
      "Epoch 0, Batch 9050, Loss: 0.004221784416586161\n",
      "Epoch 0, Batch 9100, Loss: 0.0035480260848999023\n",
      "Epoch 0, Batch 9150, Loss: 0.002993121277540922\n",
      "Epoch 0, Batch 9200, Loss: 0.004966808948665857\n",
      "Epoch 0, Batch 9250, Loss: 0.00971725769340992\n",
      "Epoch 0, Batch 9300, Loss: 0.0026708818040788174\n",
      "Epoch 0, Batch 9350, Loss: 0.0009974539279937744\n",
      "Epoch 0, Batch 9400, Loss: 0.001379908062517643\n",
      "Epoch 0, Batch 9450, Loss: 0.0009132470586337149\n",
      "Epoch 0, Batch 9500, Loss: 0.0014389295829460025\n",
      "Epoch 0, Batch 9550, Loss: 0.0015475250547751784\n",
      "Epoch 0, Batch 9600, Loss: 0.0030311085283756256\n",
      "Epoch 0, Batch 9650, Loss: 0.0020580096170306206\n",
      "Epoch 0, Batch 9700, Loss: 0.003008441533893347\n",
      "Epoch 0, Batch 9750, Loss: 0.0020527213346213102\n",
      "Epoch 0, Batch 9800, Loss: 0.00481976056471467\n",
      "Epoch 0, Batch 9850, Loss: 0.0023232754319906235\n",
      "Epoch 0, Batch 9900, Loss: 0.0011475288774818182\n",
      "Epoch 0, Batch 9950, Loss: 0.0008578510023653507\n",
      "Epoch 0, Batch 10000, Loss: 0.00027472784859128296\n",
      "Epoch 0, Batch 10050, Loss: 0.001719190739095211\n",
      "Epoch 0, Batch 10100, Loss: 0.0011767094256356359\n",
      "Epoch 0, Batch 10150, Loss: 0.0021107331849634647\n",
      "Epoch 0, Batch 10200, Loss: 0.0009633137960918248\n",
      "Epoch 0, Batch 10250, Loss: 0.002413794631138444\n",
      "Epoch 0, Batch 10300, Loss: 0.001198024139739573\n",
      "Epoch 0, Batch 10350, Loss: 0.0011463438859209418\n",
      "Epoch 0, Batch 10400, Loss: 0.00668139336630702\n",
      "Epoch 0, Batch 10450, Loss: 0.0011667656945064664\n",
      "Epoch 0, Batch 10500, Loss: 0.43169569969177246\n",
      "Epoch 0, Batch 10550, Loss: 0.002414776710793376\n",
      "Epoch 0, Batch 10600, Loss: 0.0030336480122059584\n",
      "Epoch 0, Batch 10650, Loss: 0.002522093243896961\n",
      "Epoch 0, Batch 10700, Loss: 0.3601628839969635\n",
      "Epoch 0, Batch 10750, Loss: 0.000736914633307606\n",
      "Epoch 0, Batch 10800, Loss: 0.0027136660646647215\n",
      "Epoch 0, Batch 10850, Loss: 0.3395361006259918\n",
      "Epoch 0, Batch 10900, Loss: 0.0017936070216819644\n",
      "Epoch 0, Batch 10950, Loss: 0.002019675448536873\n",
      "Epoch 0, Batch 11000, Loss: 0.003657127497717738\n",
      "Epoch 0, Batch 11050, Loss: 0.002075646072626114\n",
      "Epoch 0, Batch 11100, Loss: 0.0024812251795083284\n",
      "Epoch 0, Batch 11150, Loss: 0.0023867550771683455\n",
      "Epoch 0, Batch 11200, Loss: 0.0014364310773089528\n",
      "Epoch 0, Batch 11250, Loss: 0.0038822232745587826\n",
      "Epoch 0, Batch 11300, Loss: 0.0025085315573960543\n",
      "Epoch 0, Batch 11350, Loss: 0.0024736218620091677\n",
      "Epoch 0, Batch 11400, Loss: 0.0034242882393300533\n",
      "Epoch 0, Batch 11450, Loss: 0.0024206892121583223\n",
      "Epoch 0, Batch 11500, Loss: 0.0028510447591543198\n",
      "Epoch 0, Batch 11550, Loss: 0.002417226554825902\n",
      "Epoch 0, Batch 11600, Loss: 0.0019240776309743524\n",
      "Epoch 0, Batch 11650, Loss: 0.0031172295566648245\n",
      "Epoch 0, Batch 11700, Loss: 0.001883145421743393\n",
      "Epoch 0, Batch 11750, Loss: 0.0024014844093471766\n",
      "Epoch 0, Batch 11800, Loss: 0.0028996143955737352\n",
      "Epoch 0, Batch 11850, Loss: 0.0041068485006690025\n",
      "Epoch 0, Batch 11900, Loss: 0.003502287669107318\n",
      "Epoch 0, Batch 11950, Loss: 0.006966089829802513\n",
      "Epoch 0, Batch 12000, Loss: 0.0012942756293341517\n",
      "Epoch 0, Batch 12050, Loss: 0.0022822776809334755\n",
      "Epoch 0, Batch 12100, Loss: 0.0039337328635156155\n",
      "Epoch 0, Batch 12150, Loss: 0.003612195374444127\n",
      "Epoch 0, Batch 12200, Loss: 0.0012167238164693117\n",
      "Epoch 0, Batch 12250, Loss: 0.0016192472539842129\n",
      "Epoch 0, Batch 12300, Loss: 0.0009545179782435298\n",
      "Epoch 0, Batch 12350, Loss: 0.0023136206436902285\n",
      "Epoch 0, Batch 12400, Loss: 0.001996644539758563\n",
      "Epoch 0, Batch 12450, Loss: 0.0012240023352205753\n",
      "Epoch 0, Batch 12500, Loss: 0.00143352709710598\n",
      "Epoch 0, Batch 12550, Loss: 0.00342342141084373\n",
      "Epoch 0, Batch 12600, Loss: 0.001939347479492426\n",
      "Epoch 0, Batch 12650, Loss: 0.00411032373085618\n",
      "Epoch 0, Batch 12700, Loss: 0.0028870166279375553\n",
      "Epoch 0, Batch 12750, Loss: 0.0022508057300001383\n",
      "Epoch 0, Batch 12800, Loss: 0.0011148309567943215\n",
      "Epoch 0, Batch 12850, Loss: 0.0017201547743752599\n",
      "Epoch 0, Batch 12900, Loss: 0.0015931820962578058\n",
      "Epoch 0, Batch 12950, Loss: 0.002744340803474188\n",
      "Epoch 0, Batch 13000, Loss: 0.3963102400302887\n",
      "Epoch 0, Batch 13050, Loss: 0.002424439648166299\n",
      "Epoch 0, Batch 13100, Loss: 0.002230511512607336\n",
      "Epoch 0, Batch 13150, Loss: 0.001982895890250802\n",
      "Epoch 0, Batch 13200, Loss: 0.00462035508826375\n",
      "Epoch 0, Batch 13250, Loss: 0.0014622650342062116\n",
      "Epoch 0, Batch 13300, Loss: 0.0024567879736423492\n",
      "Epoch 0, Batch 13350, Loss: 0.002799162408336997\n",
      "Epoch 0, Batch 13400, Loss: 0.001674192608334124\n",
      "Epoch 0, Batch 13450, Loss: 0.4012262523174286\n",
      "Epoch 0, Batch 13500, Loss: 0.003935949876904488\n",
      "Epoch 0, Batch 13550, Loss: 0.0031041554175317287\n",
      "Epoch 0, Batch 13600, Loss: 0.0010896463645622134\n",
      "Epoch 0, Batch 13650, Loss: 0.0021367836743593216\n",
      "Epoch 0, Batch 13700, Loss: 0.0018205061787739396\n",
      "Epoch 0, Batch 13750, Loss: 0.009116937406361103\n",
      "Epoch 0, Batch 13800, Loss: 0.314130961894989\n",
      "Epoch 0, Batch 13850, Loss: 0.0036905270535498857\n",
      "Epoch 0, Batch 13900, Loss: 0.0032483648974448442\n",
      "Epoch 0, Batch 13950, Loss: 0.0024672471918165684\n",
      "Epoch 0, Batch 14000, Loss: 0.0030240630730986595\n",
      "Epoch 0, Batch 14050, Loss: 0.0033067367039620876\n",
      "Epoch 0, Batch 14100, Loss: 0.0020280275493860245\n",
      "Epoch 0, Batch 14150, Loss: 0.0028629396110773087\n",
      "Epoch 0, Batch 14200, Loss: 0.0018171363044530153\n",
      "Epoch 0, Batch 14250, Loss: 0.001667918637394905\n",
      "Epoch 0, Batch 14300, Loss: 0.0023392995353788137\n",
      "Epoch 0, Batch 14350, Loss: 0.005025854799896479\n",
      "Epoch 0, Batch 14400, Loss: 0.002751759486272931\n",
      "Epoch 0, Batch 14450, Loss: 0.004963313229382038\n",
      "Epoch 0, Batch 14500, Loss: 0.0023496218491345644\n",
      "Epoch 0, Batch 14550, Loss: 0.002046681474894285\n",
      "Epoch 0, Batch 14600, Loss: 0.0014269602252170444\n",
      "Epoch 0, Batch 14650, Loss: 0.0009038972784765065\n",
      "Epoch 0, Batch 14700, Loss: 0.0006893433746881783\n",
      "Epoch 0, Batch 14750, Loss: 0.0009870524518191814\n",
      "Epoch 0, Batch 14800, Loss: 0.0014404382091015577\n",
      "Epoch 0, Batch 14850, Loss: 0.0016259743133559823\n",
      "Epoch 0, Batch 14900, Loss: 0.0017253196565434337\n",
      "Epoch 0, Batch 14950, Loss: 0.0014244302874431014\n",
      "Epoch 0, Batch 15000, Loss: 0.0033779675140976906\n",
      "Epoch 0, Batch 15050, Loss: 0.0001142104811151512\n",
      "Epoch 0, Batch 15100, Loss: 0.0002763158699963242\n",
      "Epoch 0, Batch 15150, Loss: 0.0004873812140431255\n",
      "Epoch 0, Batch 15200, Loss: 0.0008311672718264163\n",
      "Epoch 0, Batch 15250, Loss: 0.00031679836683906615\n",
      "Epoch 0, Batch 15300, Loss: 0.0001585278077982366\n",
      "Epoch 0, Batch 15350, Loss: 0.002106728730723262\n",
      "Epoch 0, Batch 15400, Loss: 0.0006548791425302625\n",
      "Epoch 0, Batch 15450, Loss: 0.0007208173628896475\n",
      "Epoch 0, Batch 15500, Loss: 0.0027880226261913776\n",
      "Epoch 0, Batch 15550, Loss: 0.0013441354967653751\n",
      "Epoch 0, Batch 15600, Loss: 0.0008118359837681055\n",
      "Epoch 0, Batch 15650, Loss: 0.005307554733008146\n",
      "Epoch 0, Batch 15700, Loss: 0.0036319915670901537\n",
      "Epoch 0, Batch 15750, Loss: 0.0036739467177540064\n",
      "Epoch 0, Batch 15800, Loss: 0.0014496216317638755\n",
      "Epoch 0, Batch 15850, Loss: 0.0018879832932725549\n",
      "Epoch 0, Batch 15900, Loss: 0.001117040403187275\n",
      "Epoch 0, Batch 15950, Loss: 0.0024152793921530247\n",
      "Epoch 0, Batch 16000, Loss: 0.0019962857477366924\n",
      "Epoch 0, Batch 16050, Loss: 0.0007310748333111405\n",
      "Epoch 0, Batch 16100, Loss: 0.0041700997389853\n",
      "Epoch 0, Batch 16150, Loss: 0.0020522219128906727\n",
      "Epoch 0, Batch 16200, Loss: 0.0019546784460544586\n",
      "Epoch 0, Batch 16250, Loss: 0.001909542945213616\n",
      "Epoch 0, Batch 16300, Loss: 0.0024834207724779844\n",
      "Epoch 0, Batch 16350, Loss: 0.3437621593475342\n",
      "Epoch 0, Batch 16400, Loss: 0.0036013321951031685\n",
      "Epoch 0, Batch 16450, Loss: 0.003123899456113577\n",
      "Epoch 0, Batch 16500, Loss: 0.0020820440258830786\n",
      "Epoch 0, Batch 16550, Loss: 0.008111291565001011\n",
      "Epoch 0, Batch 16600, Loss: 0.0031501688063144684\n",
      "Epoch 0, Batch 16650, Loss: 0.002902141073718667\n",
      "Epoch 0, Batch 16700, Loss: 0.00129378167912364\n",
      "Epoch 0, Batch 16750, Loss: 0.0018491630908101797\n",
      "Epoch 0, Batch 16800, Loss: 0.001711689867079258\n",
      "Epoch 0, Batch 16850, Loss: 0.002215748652815819\n",
      "Epoch 0, Batch 16900, Loss: 0.005250441376119852\n",
      "Epoch 0, Batch 16950, Loss: 0.0026032899040728807\n",
      "Epoch 0, Batch 17000, Loss: 0.0015839553670957685\n",
      "Epoch 0, Batch 17050, Loss: 0.0014845236437395215\n",
      "Epoch 0, Batch 17100, Loss: 0.002682429738342762\n",
      "Epoch 0, Batch 17150, Loss: 0.0027170537505298853\n",
      "Epoch 0, Batch 17200, Loss: 0.0055150617845356464\n",
      "Epoch 0, Batch 17250, Loss: 0.0020634219981729984\n",
      "Epoch 0, Batch 17300, Loss: 0.0010263171279802918\n",
      "Epoch 0, Batch 17350, Loss: 0.005730301141738892\n",
      "Epoch 0, Batch 17400, Loss: 0.0026415728498250246\n",
      "Epoch 0, Batch 17450, Loss: 0.0016636466607451439\n",
      "Epoch 0, Batch 17500, Loss: 0.001441418076865375\n",
      "Epoch 0, Batch 17550, Loss: 0.0016488831024616957\n",
      "Epoch 0, Batch 17600, Loss: 0.0017308579990640283\n",
      "Epoch 0, Batch 17650, Loss: 0.003838373813778162\n",
      "Epoch 0, Batch 17700, Loss: 0.0032469078432768583\n",
      "Epoch 0, Batch 17750, Loss: 0.0029286760836839676\n",
      "Epoch 0, Batch 17800, Loss: 0.003035746980458498\n",
      "Epoch 0, Batch 17850, Loss: 0.002009747549891472\n",
      "Epoch 0, Batch 17900, Loss: 0.001382341724820435\n",
      "Epoch 0, Batch 17950, Loss: 0.0021070940420031548\n",
      "Epoch 0, Batch 18000, Loss: 0.00171804113779217\n",
      "Epoch 0, Batch 18050, Loss: 0.00204125652089715\n",
      "Epoch 0, Batch 18100, Loss: 0.003228698158636689\n",
      "Epoch 0, Batch 18150, Loss: 0.006052164826542139\n",
      "Epoch 0, Batch 18200, Loss: 0.001997901126742363\n",
      "Epoch 0, Batch 18250, Loss: 0.0061232284642755985\n",
      "Epoch 0, Batch 18300, Loss: 0.0014220550656318665\n",
      "Epoch 0, Batch 18350, Loss: 0.003679251065477729\n",
      "Epoch 0, Batch 18400, Loss: 0.003521521110087633\n",
      "Epoch 0, Batch 18450, Loss: 0.001263673068024218\n",
      "Epoch 0, Batch 18500, Loss: 0.002443106845021248\n",
      "Epoch 0, Batch 18550, Loss: 0.42578575015068054\n",
      "Epoch 0, Batch 18600, Loss: 0.002097571035847068\n",
      "Epoch 0, Batch 18650, Loss: 0.001093046274036169\n",
      "Epoch 0, Batch 18700, Loss: 0.0021592278499156237\n",
      "Epoch 0, Batch 18750, Loss: 0.001797103206627071\n",
      "Epoch 0, Batch 18800, Loss: 0.0021558315493166447\n",
      "Epoch 0, Batch 18850, Loss: 0.005045600235462189\n",
      "Epoch 0, Batch 18900, Loss: 0.001692191231995821\n",
      "Epoch 0, Batch 18950, Loss: 0.0022266965825110674\n",
      "Epoch 0, Batch 19000, Loss: 0.003022044664248824\n",
      "Epoch 0, Batch 19050, Loss: 0.001837456482462585\n",
      "Epoch 0, Batch 19100, Loss: 0.0010925822425633669\n",
      "Epoch 0, Batch 19150, Loss: 0.0019088503904640675\n",
      "Epoch 0, Batch 19200, Loss: 0.004335987381637096\n",
      "Epoch 0, Batch 19250, Loss: 0.0013214872451499104\n",
      "Epoch 0, Batch 19300, Loss: 0.0011660397285595536\n",
      "Epoch 0, Batch 19350, Loss: 0.0026885150000452995\n",
      "Epoch 0, Batch 19400, Loss: 0.3809407949447632\n",
      "Epoch 0, Batch 19450, Loss: 0.0024095075204968452\n",
      "Epoch 0, Batch 19500, Loss: 0.0011215890990570188\n",
      "Epoch 0, Batch 19550, Loss: 0.0011294452706351876\n",
      "Epoch 0, Batch 19600, Loss: 0.0008602188900113106\n",
      "Epoch 0, Batch 19650, Loss: 0.001059519941918552\n",
      "Epoch 0, Batch 19700, Loss: 0.0011707660742104053\n",
      "Epoch 0, Batch 19750, Loss: 0.3676433563232422\n",
      "Epoch 0, Batch 19800, Loss: 0.0019519998459145427\n",
      "Epoch 0, Batch 19850, Loss: 0.0017055710777640343\n",
      "Epoch 0, Batch 19900, Loss: 0.004153965972363949\n",
      "Epoch 0, Batch 19950, Loss: 0.003736993996426463\n",
      "Epoch 0, Batch 20000, Loss: 0.004330391529947519\n",
      "Epoch 0, Batch 20050, Loss: 0.0018566830549389124\n",
      "Epoch 0, Batch 20100, Loss: 0.0010183965787291527\n",
      "Epoch 0, Batch 20150, Loss: 0.001609333441592753\n",
      "Epoch 0, Batch 20200, Loss: 0.0011934455251321197\n",
      "Epoch 0, Batch 20250, Loss: 0.002545057563111186\n",
      "Epoch 0, Batch 20300, Loss: 0.0016416121507063508\n",
      "Epoch 0, Batch 20350, Loss: 0.0012853741645812988\n",
      "Epoch 0, Batch 20400, Loss: 0.0039895521476864815\n",
      "Epoch 0, Batch 20450, Loss: 0.002024631015956402\n",
      "Epoch 0, Batch 20500, Loss: 0.0027692068833857775\n",
      "Epoch 0, Batch 20550, Loss: 0.00286861858330667\n",
      "Epoch 0, Batch 20600, Loss: 0.0027502896264195442\n",
      "Epoch 0, Batch 20650, Loss: 0.0029870120342820883\n",
      "Epoch 0, Batch 20700, Loss: 0.002958753379061818\n",
      "Epoch 0, Batch 20750, Loss: 0.0016361218877136707\n",
      "Epoch 0, Batch 20800, Loss: 0.003324877005070448\n",
      "Epoch 0, Batch 20850, Loss: 0.002846956718713045\n",
      "Epoch 0, Batch 20900, Loss: 0.0030050347559154034\n",
      "Epoch 0, Batch 20950, Loss: 0.0020420269574970007\n",
      "Epoch 0, Batch 21000, Loss: 0.0016618482768535614\n",
      "Epoch 0, Batch 21050, Loss: 0.34331682324409485\n",
      "Epoch 0, Batch 21100, Loss: 0.003639945527538657\n",
      "Epoch 0, Batch 21150, Loss: 0.003479213686659932\n",
      "Epoch 0, Batch 21200, Loss: 0.0027091733645647764\n",
      "Epoch 0, Batch 21250, Loss: 0.0019237046362832189\n",
      "Epoch 0, Batch 21300, Loss: 0.0015491824597120285\n",
      "Epoch 0, Batch 21350, Loss: 0.001440088963136077\n",
      "Epoch 0, Batch 21400, Loss: 0.0009506744099780917\n",
      "Epoch 0, Batch 21450, Loss: 0.0016032912535592914\n",
      "Epoch 0, Batch 21500, Loss: 0.0016257436946034431\n",
      "Epoch 0, Batch 21550, Loss: 0.002277499297633767\n",
      "Epoch 0, Batch 21600, Loss: 0.0029014907777309418\n",
      "Epoch 0, Batch 21650, Loss: 0.0023072739131748676\n",
      "Epoch 0, Batch 21700, Loss: 0.001966162584722042\n",
      "Epoch 0, Batch 21750, Loss: 0.0027030371129512787\n",
      "Epoch 0, Batch 21800, Loss: 0.001477065496146679\n",
      "Epoch 0, Batch 21850, Loss: 0.40452995896339417\n",
      "Epoch 0, Batch 21900, Loss: 0.003033233107998967\n",
      "Epoch 0, Batch 21950, Loss: 0.0021348693408071995\n",
      "Epoch 0, Batch 22000, Loss: 0.003560698591172695\n",
      "Epoch 0, Batch 22050, Loss: 0.0029531128238886595\n",
      "Epoch 0, Batch 22100, Loss: 0.0028623947873711586\n",
      "Epoch 0, Batch 22150, Loss: 0.0024808619637042284\n",
      "Epoch 0, Batch 22200, Loss: 0.002610074356198311\n",
      "Epoch 0, Batch 22250, Loss: 0.005750406999140978\n",
      "Epoch 0, Batch 22300, Loss: 0.002247533295303583\n",
      "Epoch 0, Batch 22350, Loss: 0.00466966861858964\n",
      "Epoch 0, Batch 22400, Loss: 0.002708235988393426\n",
      "Epoch 0, Batch 22450, Loss: 0.0013119931099936366\n",
      "Epoch 0, Batch 22500, Loss: 0.0012082000030204654\n",
      "Epoch 0, Batch 22550, Loss: 0.001287171384319663\n",
      "Epoch 0, Batch 22600, Loss: 0.0024168144445866346\n",
      "Epoch 0, Batch 22650, Loss: 0.0023848542477935553\n",
      "Epoch 0, Batch 22700, Loss: 0.0018715233309194446\n",
      "Epoch 0, Batch 22750, Loss: 0.0016571106389164925\n",
      "Epoch 0, Batch 22800, Loss: 0.0013128442224115133\n",
      "Epoch 0, Batch 22850, Loss: 0.0013266130117699504\n",
      "Epoch 0, Batch 22900, Loss: 0.002825232921168208\n",
      "Epoch 0, Batch 22950, Loss: 0.004633848089724779\n",
      "Epoch 0, Batch 23000, Loss: 0.0026347809471189976\n",
      "Epoch 0, Batch 23050, Loss: 0.0038426369428634644\n",
      "Epoch 0, Batch 23100, Loss: 0.0027770204469561577\n",
      "Epoch 0, Batch 23150, Loss: 0.0018183605279773474\n",
      "Epoch 0, Batch 23200, Loss: 0.0021848513279110193\n",
      "Epoch 0, Batch 23250, Loss: 0.0021908108610659838\n",
      "Epoch 0, Batch 23300, Loss: 0.0022616421338170767\n",
      "Epoch 0, Batch 23350, Loss: 0.003315679496154189\n",
      "Epoch 0, Batch 23400, Loss: 0.0030641304329037666\n",
      "Epoch 0, Batch 23450, Loss: 0.0035756449215114117\n",
      "Epoch 0, Batch 23500, Loss: 0.0026697402354329824\n",
      "Epoch 0, Batch 23550, Loss: 0.0016550037544220686\n",
      "Epoch 0, Batch 23600, Loss: 0.0015009684721007943\n",
      "Epoch 0, Batch 23650, Loss: 0.0018977614818140864\n",
      "Epoch 0, Batch 23700, Loss: 0.001899627037346363\n",
      "Epoch 0, Batch 23750, Loss: 0.0013155365595594049\n",
      "Epoch 0, Batch 23800, Loss: 0.003987720236182213\n",
      "Epoch 0, Batch 23850, Loss: 0.0032588497269898653\n",
      "Epoch 0, Batch 23900, Loss: 0.0032880837097764015\n",
      "Epoch 0, Batch 23950, Loss: 0.00427493080496788\n",
      "Epoch 0, Batch 24000, Loss: 0.004131875466555357\n",
      "Epoch 0, Batch 24050, Loss: 0.0016685605514794588\n",
      "Epoch 0, Batch 24100, Loss: 0.001455799676477909\n",
      "Epoch 0, Batch 24150, Loss: 0.0013806064380332828\n",
      "Epoch 0, Batch 24200, Loss: 0.0038965940475463867\n",
      "Epoch 0, Batch 24250, Loss: 0.00391294714063406\n",
      "Epoch 0, Batch 24300, Loss: 0.005011354107409716\n",
      "Epoch 0, Batch 24350, Loss: 0.3573334515094757\n",
      "Epoch 0, Batch 24400, Loss: 0.002961300779134035\n",
      "Epoch 0, Batch 24450, Loss: 0.004131976515054703\n",
      "Epoch 0, Batch 24500, Loss: 0.0020204901229590178\n",
      "Epoch 0, Batch 24550, Loss: 0.0018633237341418862\n",
      "Epoch 0, Batch 24600, Loss: 0.0019924622029066086\n",
      "Epoch 0, Batch 24650, Loss: 0.0021231230348348618\n",
      "Epoch 0, Batch 24700, Loss: 0.003853938542306423\n",
      "Epoch 0, Batch 24750, Loss: 0.3761180639266968\n",
      "Epoch 0, Batch 24800, Loss: 0.0028943046927452087\n",
      "Epoch 0, Batch 24850, Loss: 0.002019705716520548\n",
      "Epoch 0, Batch 24900, Loss: 0.001833867165260017\n",
      "Epoch 0, Batch 24950, Loss: 0.0025232243351638317\n",
      "Epoch 0, Batch 25000, Loss: 0.0024411443155258894\n",
      "Epoch 0, Batch 25050, Loss: 0.0033822839614003897\n",
      "Epoch 0, Batch 25100, Loss: 0.002024414949119091\n",
      "Epoch 0, Batch 25150, Loss: 0.001769073773175478\n",
      "Epoch 0, Batch 25200, Loss: 0.0014775707386434078\n",
      "Epoch 0, Batch 25250, Loss: 0.002508995123207569\n",
      "Epoch 0, Batch 25300, Loss: 0.002453293651342392\n",
      "Epoch 0, Batch 25350, Loss: 0.00209509558044374\n",
      "Epoch 0, Batch 25400, Loss: 0.35885027050971985\n",
      "Epoch 0, Batch 25450, Loss: 0.005876040086150169\n",
      "Epoch 0, Batch 25500, Loss: 0.003527567721903324\n",
      "Epoch 0, Batch 25550, Loss: 0.0021417303942143917\n",
      "Epoch 0, Batch 25600, Loss: 0.0023619101848453283\n",
      "Epoch 0, Batch 25650, Loss: 0.004043161403387785\n",
      "Epoch 0, Batch 25700, Loss: 0.005723596550524235\n",
      "Epoch 0, Batch 25750, Loss: 0.0021465709432959557\n",
      "Epoch 0, Batch 25800, Loss: 0.002336422447115183\n",
      "Epoch 0, Batch 25850, Loss: 0.001365580246783793\n",
      "Epoch 0, Batch 25900, Loss: 0.00485676946118474\n",
      "Epoch 0, Batch 25950, Loss: 0.0068901656195521355\n",
      "Epoch 0, Batch 26000, Loss: 0.005605394020676613\n",
      "Epoch 0, Batch 26050, Loss: 0.00468001514673233\n",
      "Epoch 0, Batch 26100, Loss: 0.0027288172859698534\n",
      "Epoch 0, Batch 26150, Loss: 0.0038062252569943666\n",
      "Epoch 0, Batch 26200, Loss: 0.0029978991951793432\n",
      "Epoch 0, Batch 26250, Loss: 0.0020346809178590775\n",
      "Epoch 0, Batch 26300, Loss: 0.001660963986068964\n",
      "Epoch 0, Batch 26350, Loss: 0.001160782645456493\n",
      "Epoch 0, Batch 26400, Loss: 0.00174537708517164\n",
      "Epoch 0, Batch 26450, Loss: 0.003085132222622633\n",
      "Epoch 0, Batch 26500, Loss: 0.0029974565841257572\n",
      "Epoch 0, Batch 26550, Loss: 0.0028719212859869003\n",
      "Epoch 0, Batch 26600, Loss: 0.002835961291566491\n",
      "Epoch 0, Batch 26650, Loss: 0.0031345183961093426\n",
      "Epoch 0, Batch 26700, Loss: 0.0036270159762352705\n",
      "Epoch 0, Batch 26750, Loss: 0.002685367362573743\n",
      "Epoch 0, Batch 26800, Loss: 0.0029235705733299255\n",
      "Epoch 0, Batch 26850, Loss: 0.002491557504981756\n",
      "Epoch 0, Batch 26900, Loss: 0.004447131883352995\n",
      "Epoch 0, Batch 26950, Loss: 0.002588390139862895\n",
      "Epoch 0, Batch 27000, Loss: 0.004589451011270285\n",
      "Epoch 0, Batch 27050, Loss: 0.005488908849656582\n",
      "Epoch 0, Batch 27100, Loss: 0.002937447279691696\n",
      "Epoch 0, Batch 27150, Loss: 0.002962626749649644\n",
      "Epoch 0, Batch 27200, Loss: 0.0023800237104296684\n",
      "Epoch 0, Batch 27250, Loss: 0.001412950805388391\n",
      "Epoch 0, Batch 27300, Loss: 0.0010166961001232266\n",
      "Epoch 0, Batch 27350, Loss: 0.0012478235876187682\n",
      "Epoch 0, Batch 27400, Loss: 0.4153865873813629\n",
      "Epoch 0, Batch 27450, Loss: 0.0022881790064275265\n",
      "Epoch 0, Batch 27500, Loss: 0.0018196695018559694\n",
      "Epoch 0, Batch 27550, Loss: 0.004016547463834286\n",
      "Epoch 0, Batch 27600, Loss: 0.0034792418591678143\n",
      "Epoch 0, Batch 27650, Loss: 0.0027630256954580545\n",
      "Epoch 0, Batch 27700, Loss: 0.003083600429818034\n",
      "Epoch 0, Batch 27750, Loss: 0.002571952296420932\n",
      "Epoch 0, Batch 27800, Loss: 0.0026627269107848406\n",
      "Epoch 0, Batch 27850, Loss: 0.0031548631377518177\n",
      "Epoch 0, Batch 27900, Loss: 0.004100027959793806\n",
      "Epoch 0, Batch 27950, Loss: 0.003826037747785449\n",
      "Epoch 0, Batch 28000, Loss: 0.003283149329945445\n",
      "Epoch 0, Batch 28050, Loss: 0.0036246017552912235\n",
      "Epoch 0, Batch 28100, Loss: 0.005516484379768372\n",
      "Epoch 0, Batch 28150, Loss: 0.003301183693110943\n",
      "Epoch 0, Batch 28200, Loss: 0.0022986780386418104\n",
      "Epoch 0, Batch 28250, Loss: 0.001792663591913879\n",
      "Epoch 0, Batch 28300, Loss: 0.0011926022125408053\n",
      "Epoch 0, Batch 28350, Loss: 0.0014368382981047034\n",
      "Epoch 0, Batch 28400, Loss: 0.0017643517348915339\n",
      "Epoch 0, Batch 28450, Loss: 0.001864332822151482\n",
      "Epoch 0, Batch 28500, Loss: 0.003017331473529339\n",
      "Epoch 0, Batch 28550, Loss: 0.003978650085628033\n",
      "Epoch 0, Batch 28600, Loss: 0.004998939111828804\n",
      "Epoch 0, Batch 28650, Loss: 0.0028314257506281137\n",
      "Epoch 0, Batch 28700, Loss: 0.0017776573076844215\n",
      "Epoch 0, Batch 28750, Loss: 0.0017615207470953465\n",
      "Epoch 0, Batch 28800, Loss: 0.0012083639157935977\n",
      "Epoch 0, Batch 28850, Loss: 0.0022659527603536844\n",
      "Epoch 0, Batch 28900, Loss: 0.003793340642005205\n",
      "Epoch 0, Batch 28950, Loss: 0.00242100958712399\n",
      "Epoch 0, Batch 29000, Loss: 0.0024639139883220196\n",
      "Epoch 0, Batch 29050, Loss: 0.001726865186356008\n",
      "Epoch 0, Batch 29100, Loss: 0.004020664840936661\n",
      "Epoch 0, Batch 29150, Loss: 0.0021101729944348335\n",
      "Epoch 0, Batch 29200, Loss: 0.005749886389821768\n",
      "Epoch 0, Batch 29250, Loss: 0.004212964791804552\n",
      "Epoch 0, Batch 29300, Loss: 0.00581258675083518\n",
      "Epoch 0, Batch 29350, Loss: 0.004164932761341333\n",
      "Epoch 0, Batch 29400, Loss: 0.002505510114133358\n",
      "Epoch 0, Batch 29450, Loss: 0.0026947411242872477\n",
      "Epoch 0, Batch 29500, Loss: 0.0017945053987205029\n",
      "Epoch 0, Batch 29550, Loss: 0.0014700187603011727\n",
      "Epoch 0, Batch 29600, Loss: 0.001444866182282567\n",
      "Epoch 0, Batch 29650, Loss: 0.0010113660246133804\n",
      "Epoch 0, Batch 29700, Loss: 0.0016411717515438795\n",
      "Epoch 0, Batch 29750, Loss: 0.001481881714425981\n",
      "Epoch 0, Batch 29800, Loss: 0.0013409792445600033\n",
      "Epoch 0, Batch 29850, Loss: 0.0012847239850088954\n",
      "Epoch 0, Batch 29900, Loss: 0.001285964623093605\n",
      "Epoch 0, Batch 29950, Loss: 0.0014172443188726902\n",
      "Epoch 0, Batch 30000, Loss: 0.40203407406806946\n",
      "Epoch 0, Batch 30050, Loss: 0.0014833142049610615\n",
      "Epoch 0, Batch 30100, Loss: 0.002517329528927803\n",
      "Epoch 0, Batch 30150, Loss: 0.0020815450698137283\n",
      "Epoch 0, Batch 30200, Loss: 0.002494222717359662\n",
      "Epoch 0, Batch 30250, Loss: 0.3612052798271179\n",
      "Epoch 0, Batch 30300, Loss: 0.0035816552117466927\n",
      "Epoch 0, Batch 30350, Loss: 0.0043633366003632545\n",
      "Epoch 0, Batch 30400, Loss: 0.33368322253227234\n",
      "Epoch 0, Batch 30450, Loss: 0.003363946685567498\n",
      "Epoch 0, Batch 30500, Loss: 0.0014574297238141298\n",
      "Epoch 0, Batch 30550, Loss: 0.0016359584406018257\n",
      "Epoch 0, Batch 30600, Loss: 0.0030637069139629602\n",
      "Epoch 0, Batch 30650, Loss: 0.0026012612506747246\n",
      "Epoch 0, Batch 30700, Loss: 0.0023079777602106333\n",
      "Epoch 0, Batch 30750, Loss: 0.0015956951538100839\n",
      "Epoch 0, Batch 30800, Loss: 0.00104024528991431\n",
      "Epoch 0, Batch 30850, Loss: 0.0008974281372502446\n",
      "Epoch 0, Batch 30900, Loss: 0.0009196190512739122\n",
      "Epoch 0, Batch 30950, Loss: 0.001989120850339532\n",
      "Epoch 0, Batch 31000, Loss: 0.0024267127737402916\n",
      "Epoch 0, Batch 31050, Loss: 0.0027038236148655415\n",
      "Epoch 0, Batch 31100, Loss: 0.401719331741333\n",
      "Epoch 0, Batch 31150, Loss: 0.0037294568028301\n",
      "Epoch 0, Batch 31200, Loss: 0.0018858928233385086\n",
      "Epoch 0, Batch 31250, Loss: 0.002555730752646923\n",
      "Epoch 0, Batch 31300, Loss: 0.00207794108428061\n",
      "Epoch 0, Batch 31350, Loss: 0.001859581097960472\n",
      "Epoch 0, Batch 31400, Loss: 0.0018555338028818369\n",
      "Epoch 0, Batch 31450, Loss: 0.001544956467114389\n",
      "Epoch 0, Batch 31500, Loss: 0.0012298653600737453\n",
      "Epoch 0, Batch 31550, Loss: 0.0021141499746590853\n",
      "Epoch 0, Batch 31600, Loss: 0.001887666410766542\n",
      "Epoch 0, Batch 31650, Loss: 0.002898608334362507\n",
      "Epoch 0, Batch 31700, Loss: 0.002033916302025318\n",
      "Epoch 0, Batch 31750, Loss: 0.002253584796562791\n",
      "Epoch 0, Batch 31800, Loss: 0.0019965986721217632\n",
      "Epoch 0, Batch 31850, Loss: 0.0016075499588623643\n",
      "Epoch 0, Batch 31900, Loss: 0.0017213558312505484\n",
      "Epoch 0, Batch 31950, Loss: 0.0012136357836425304\n",
      "Epoch 0, Batch 32000, Loss: 0.0020747166126966476\n",
      "Epoch 0, Batch 32050, Loss: 0.0018184160580858588\n",
      "Epoch 0, Batch 32100, Loss: 0.0018090828089043498\n",
      "Epoch 0, Batch 32150, Loss: 0.0009854750242084265\n",
      "Epoch 0, Batch 32200, Loss: 0.0013904315419495106\n",
      "Epoch 0, Batch 32250, Loss: 0.0012059403816238046\n",
      "Epoch 0, Batch 32300, Loss: 0.0030574488919228315\n",
      "Epoch 0, Batch 32350, Loss: 0.0040358747355639935\n",
      "Epoch 0, Batch 32400, Loss: 0.0021734104957431555\n",
      "Epoch 0, Batch 32450, Loss: 0.0020710525568574667\n",
      "Epoch 0, Batch 32500, Loss: 0.002306290902197361\n",
      "Epoch 0, Batch 32550, Loss: 0.0020604366436600685\n",
      "Epoch 0, Batch 32600, Loss: 0.0019433124689385295\n",
      "Epoch 0, Batch 32650, Loss: 0.3762607276439667\n",
      "Epoch 0, Batch 32700, Loss: 0.0033752210438251495\n",
      "Epoch 0, Batch 32750, Loss: 0.0025281214620918036\n",
      "Epoch 0, Batch 32800, Loss: 0.0019116748590022326\n",
      "Epoch 0, Batch 32850, Loss: 0.0014648112701252103\n",
      "Epoch 0, Batch 32900, Loss: 0.0025472640991210938\n",
      "Epoch 0, Batch 32950, Loss: 0.001615526620298624\n",
      "Epoch 0, Batch 33000, Loss: 0.0035454577300697565\n",
      "Epoch 0, Batch 33050, Loss: 0.0024386548902839422\n",
      "Epoch 0, Batch 33100, Loss: 0.0020026282873004675\n",
      "Epoch 0, Batch 33150, Loss: 0.0012692274758592248\n",
      "Epoch 0, Batch 33200, Loss: 0.0008663715561851859\n",
      "Epoch 0, Batch 33250, Loss: 0.0015210865531116724\n",
      "Epoch 0, Batch 33300, Loss: 0.001773117808625102\n",
      "Epoch 0, Batch 33350, Loss: 0.37844592332839966\n",
      "Epoch 0, Batch 33400, Loss: 0.002034589648246765\n",
      "Epoch 0, Batch 33450, Loss: 0.0018530444940552115\n",
      "Epoch 0, Batch 33500, Loss: 0.0017157337861135602\n",
      "Epoch 0, Batch 33550, Loss: 0.003006146289408207\n",
      "Epoch 0, Batch 33600, Loss: 0.0025106389075517654\n",
      "Epoch 0, Batch 33650, Loss: 0.002339365892112255\n",
      "Epoch 0, Batch 33700, Loss: 0.00241677719168365\n",
      "Epoch 0, Batch 33750, Loss: 0.35986459255218506\n",
      "Epoch 0, Batch 33800, Loss: 0.0027218395844101906\n",
      "Epoch 0, Batch 33850, Loss: 0.002751958090811968\n",
      "Epoch 0, Batch 33900, Loss: 0.0020050019957125187\n",
      "Epoch 0, Batch 33950, Loss: 0.0016958198975771666\n",
      "Epoch 0, Batch 34000, Loss: 0.37596067786216736\n",
      "Epoch 0, Batch 34050, Loss: 0.0029384815134108067\n",
      "Epoch 0, Batch 34100, Loss: 0.002985251136124134\n",
      "Epoch 0, Batch 34150, Loss: 0.002157803624868393\n",
      "Epoch 0, Batch 34200, Loss: 0.0013973411405459046\n",
      "Epoch 0, Batch 34250, Loss: 0.0010346838971599936\n",
      "Epoch 0, Batch 34300, Loss: 0.0006713070906698704\n",
      "Epoch 0, Batch 34350, Loss: 0.4009041488170624\n",
      "Epoch 0, Batch 34400, Loss: 0.0027117424178868532\n",
      "Epoch 0, Batch 34450, Loss: 0.002378061879426241\n",
      "Epoch 0, Batch 34500, Loss: 0.002340678358450532\n",
      "Epoch 0, Batch 34550, Loss: 0.0016299559501931071\n",
      "Epoch 0, Batch 34600, Loss: 0.001094040460884571\n",
      "Epoch 0, Batch 34650, Loss: 0.0025185563135892153\n",
      "Epoch 0, Batch 34700, Loss: 0.0021672556176781654\n",
      "Epoch 0, Batch 34750, Loss: 0.005718572065234184\n",
      "Epoch 0, Batch 34800, Loss: 0.0026549564208835363\n",
      "Epoch 0, Batch 34850, Loss: 0.001948147197254002\n",
      "Epoch 0, Batch 34900, Loss: 0.00275660352781415\n",
      "Epoch 0, Batch 34950, Loss: 0.0014769055414944887\n",
      "Epoch 0, Batch 35000, Loss: 0.0018949077930301428\n",
      "Epoch 0, Batch 35050, Loss: 0.41786694526672363\n",
      "Epoch 0, Batch 35100, Loss: 0.0019791629165410995\n",
      "Epoch 0, Batch 35150, Loss: 0.0021136151626706123\n",
      "Epoch 0, Batch 35200, Loss: 0.0017400243086740375\n",
      "Epoch 0, Batch 35250, Loss: 0.001592117128893733\n",
      "Epoch 0, Batch 35300, Loss: 0.0012534414418041706\n",
      "Epoch 0, Batch 35350, Loss: 0.0017097803065553308\n",
      "Epoch 0, Batch 35400, Loss: 0.0030960149597376585\n",
      "Epoch 0, Batch 35450, Loss: 0.00403478741645813\n",
      "Epoch 0, Batch 35500, Loss: 0.005251023918390274\n",
      "Epoch 0, Batch 35550, Loss: 0.0026568330358713865\n",
      "Epoch 0, Batch 35600, Loss: 0.0034828020725399256\n",
      "Epoch 0, Batch 35650, Loss: 0.00273752654902637\n",
      "Epoch 0, Batch 35700, Loss: 0.001969248754903674\n",
      "Epoch 0, Batch 35750, Loss: 0.0013657662784680724\n",
      "Epoch 0, Batch 35800, Loss: 0.002447039121761918\n",
      "Epoch 0, Batch 35850, Loss: 0.005923479795455933\n",
      "Epoch 0, Batch 35900, Loss: 0.003587170038372278\n",
      "Epoch 0, Batch 35950, Loss: 0.002491176128387451\n",
      "Epoch 0, Batch 36000, Loss: 0.0022405555937439203\n",
      "Epoch 0, Batch 36050, Loss: 0.0023834770545363426\n",
      "Epoch 0, Batch 36100, Loss: 0.0033745330292731524\n",
      "Epoch 0, Batch 36150, Loss: 0.0024071326479315758\n",
      "Epoch 0, Batch 36200, Loss: 0.001577485934831202\n",
      "Epoch 0, Batch 36250, Loss: 0.0036939862184226513\n",
      "Epoch 0, Batch 36300, Loss: 0.35815441608428955\n",
      "Epoch 0, Batch 36350, Loss: 0.001736887264996767\n",
      "Epoch 0, Batch 36400, Loss: 0.0018367102602496743\n",
      "Epoch 0, Batch 36450, Loss: 0.003084928961470723\n",
      "Epoch 0, Batch 36500, Loss: 0.0033451574854552746\n",
      "Epoch 0, Batch 36550, Loss: 0.003134789876639843\n",
      "Epoch 0, Batch 36600, Loss: 0.002015859354287386\n",
      "Epoch 0, Batch 36650, Loss: 0.0026405162643641233\n",
      "Epoch 0, Batch 36700, Loss: 0.002859927248209715\n",
      "Epoch 0, Batch 36750, Loss: 0.0021313356701284647\n",
      "Epoch 0, Batch 36800, Loss: 0.0031740840058773756\n",
      "Epoch 0, Batch 36850, Loss: 0.002647332614287734\n",
      "Epoch 0, Batch 36900, Loss: 0.003724690293893218\n",
      "Epoch 0, Batch 36950, Loss: 0.34211236238479614\n",
      "Epoch 0, Batch 37000, Loss: 0.002402659971266985\n",
      "Epoch 0, Batch 37050, Loss: 0.4038962125778198\n",
      "Epoch 0, Batch 37100, Loss: 0.001958490815013647\n",
      "Epoch 0, Batch 37150, Loss: 0.0021838066168129444\n",
      "Epoch 0, Batch 37200, Loss: 0.0027282466180622578\n",
      "Epoch 0, Batch 37250, Loss: 0.0021288974676281214\n",
      "Epoch 0, Batch 37300, Loss: 0.0025677597150206566\n",
      "Epoch 0, Batch 37350, Loss: 0.002878534607589245\n",
      "Epoch 0, Batch 37400, Loss: 0.0030122778844088316\n",
      "Epoch 0, Batch 37450, Loss: 0.0032715382985770702\n",
      "Epoch 0, Batch 37500, Loss: 0.00261605903506279\n",
      "Epoch 0, Batch 37550, Loss: 0.001759320730343461\n",
      "Epoch 0, Batch 37600, Loss: 0.0023232484236359596\n",
      "Epoch 0, Batch 37650, Loss: 0.0023092946503311396\n",
      "Epoch 0, Batch 37700, Loss: 0.0028262839186936617\n",
      "Epoch 0, Batch 37750, Loss: 0.002183412667363882\n",
      "Epoch 0, Batch 37800, Loss: 0.003102207090705633\n",
      "Epoch 0, Batch 37850, Loss: 0.003122840542346239\n",
      "Epoch 0, Batch 37900, Loss: 0.003617042675614357\n",
      "Epoch 0, Batch 37950, Loss: 0.004100702237337828\n",
      "Epoch 0, Batch 38000, Loss: 0.004479893017560244\n",
      "Epoch 0, Batch 38050, Loss: 0.0043260278180241585\n",
      "Epoch 0, Batch 38100, Loss: 0.0033274583984166384\n",
      "Epoch 0, Batch 38150, Loss: 0.0046065147034823895\n",
      "Epoch 0, Batch 38200, Loss: 0.005147870164364576\n",
      "Epoch 0, Batch 38250, Loss: 0.004481710493564606\n",
      "Epoch 0, Batch 38300, Loss: 0.37656834721565247\n",
      "Epoch 0, Batch 38350, Loss: 0.0042596617713570595\n",
      "Epoch 0, Batch 38400, Loss: 0.3547990024089813\n",
      "Epoch 0, Batch 38450, Loss: 0.002497175708413124\n",
      "Epoch 0, Batch 38500, Loss: 0.003412781748920679\n",
      "Epoch 0, Batch 38550, Loss: 0.003645894816145301\n",
      "Epoch 0, Batch 38600, Loss: 0.003067342098802328\n",
      "Epoch 0, Batch 38650, Loss: 0.002856219420209527\n",
      "Epoch 0, Batch 38700, Loss: 0.3535357713699341\n",
      "Epoch 0, Batch 38750, Loss: 0.0030422059353441\n",
      "Epoch 0, Batch 38800, Loss: 0.002376758959144354\n",
      "Epoch 0, Batch 38850, Loss: 0.0014742588391527534\n",
      "Epoch 0, Batch 38900, Loss: 0.0009671961888670921\n",
      "Epoch 0, Batch 38950, Loss: 0.002365991473197937\n",
      "Epoch 0, Batch 39000, Loss: 0.38060352206230164\n",
      "Epoch 0, Batch 39050, Loss: 0.0024096432607620955\n",
      "Epoch 0, Batch 39100, Loss: 0.0019826653879135847\n",
      "Epoch 0, Batch 39150, Loss: 0.0020497916266322136\n",
      "Epoch 0, Batch 39200, Loss: 0.0022144154645502567\n",
      "Epoch 0, Batch 39250, Loss: 0.0019503760850057006\n",
      "Epoch 0, Batch 39300, Loss: 0.002180323237553239\n",
      "Epoch 0, Batch 39350, Loss: 0.0030388496816158295\n",
      "Epoch 0, Batch 39400, Loss: 0.005318145267665386\n",
      "Epoch 0, Batch 39450, Loss: 0.003779669990763068\n",
      "Epoch 0, Batch 39500, Loss: 0.003468494163826108\n",
      "Epoch 0, Batch 39550, Loss: 0.004792383871972561\n",
      "Epoch 0, Batch 39600, Loss: 0.0028314217925071716\n",
      "Epoch 0, Batch 39650, Loss: 0.00183728092815727\n",
      "Epoch 0, Batch 39700, Loss: 0.0026890693698078394\n",
      "Epoch 0, Batch 39750, Loss: 0.003334257286041975\n",
      "Epoch 0, Batch 39800, Loss: 0.0029855750035494566\n",
      "Epoch 0, Batch 39850, Loss: 0.0019370135851204395\n",
      "Epoch 0, Batch 39900, Loss: 0.0012981934705749154\n",
      "Epoch 0, Batch 39950, Loss: 0.001541247358545661\n",
      "Epoch 0, Batch 40000, Loss: 0.0011926826555281878\n",
      "Epoch 0, Batch 40050, Loss: 0.0017725445795804262\n",
      "Epoch 0, Batch 40100, Loss: 0.004964874591678381\n",
      "Epoch 0, Batch 40150, Loss: 0.004120765719562769\n",
      "Epoch 0, Batch 40200, Loss: 0.0030803345143795013\n",
      "Epoch 0, Batch 40250, Loss: 0.003564526094123721\n",
      "Epoch 0, Batch 40300, Loss: 0.0026823014486581087\n",
      "Epoch 0, Batch 40350, Loss: 0.002144013997167349\n",
      "Epoch 0, Batch 40400, Loss: 0.0037781749852001667\n",
      "Epoch 0, Batch 40450, Loss: 0.00288296677172184\n",
      "Epoch 0, Batch 40500, Loss: 0.3783037066459656\n",
      "Epoch 0, Batch 40550, Loss: 0.3556625247001648\n",
      "Epoch 0, Batch 40600, Loss: 0.002655480522662401\n",
      "Epoch 0, Batch 40650, Loss: 0.002138058887794614\n",
      "Epoch 0, Batch 40700, Loss: 0.0016201932448893785\n",
      "Epoch 0, Batch 40750, Loss: 0.0011496883817017078\n",
      "Epoch 0, Batch 40800, Loss: 0.0015676525654271245\n",
      "Epoch 0, Batch 40850, Loss: 0.38993605971336365\n",
      "Epoch 0, Batch 40900, Loss: 0.002130244392901659\n",
      "Epoch 0, Batch 40950, Loss: 0.37833264470100403\n",
      "Epoch 0, Batch 41000, Loss: 0.0016825809143483639\n",
      "Epoch 0, Batch 41050, Loss: 0.00234969612210989\n",
      "Epoch 0, Batch 41100, Loss: 0.002291143871843815\n",
      "Epoch 0, Batch 41150, Loss: 0.0017258739098906517\n",
      "Epoch 0, Batch 41200, Loss: 0.002896784106269479\n",
      "Epoch 0, Batch 41250, Loss: 0.0029263566248118877\n",
      "Epoch 0, Batch 41300, Loss: 0.003257538890466094\n",
      "Epoch 0, Batch 41350, Loss: 0.00455159367993474\n",
      "Epoch 0, Batch 41400, Loss: 0.0029220138676464558\n",
      "Epoch 0, Batch 41450, Loss: 0.0030919325072318316\n",
      "Epoch 0, Batch 41500, Loss: 0.0019710143096745014\n",
      "Epoch 0, Batch 41550, Loss: 0.00195456575602293\n",
      "Epoch 0, Batch 41600, Loss: 0.001516225514933467\n",
      "Epoch 0, Batch 41650, Loss: 0.0012969245435670018\n",
      "Epoch 0, Batch 41700, Loss: 0.001413127058185637\n",
      "Epoch 0, Batch 41750, Loss: 0.0010957386111840606\n",
      "Epoch 0, Batch 41800, Loss: 0.0010801020544022322\n",
      "Epoch 0, Batch 41850, Loss: 0.0018319481750950217\n",
      "Epoch 0, Batch 41900, Loss: 0.003054627450183034\n",
      "Epoch 0, Batch 41950, Loss: 0.002504562260583043\n",
      "Epoch 0, Batch 42000, Loss: 0.0031184821855276823\n",
      "Epoch 0, Batch 42050, Loss: 0.0032294976990669966\n",
      "Epoch 0, Batch 42100, Loss: 0.0028951598796993494\n",
      "Epoch 0, Batch 42150, Loss: 0.0028976351022720337\n",
      "Epoch 0, Batch 42200, Loss: 0.0037812141235917807\n",
      "Epoch 0, Batch 42250, Loss: 0.003109755227342248\n",
      "Epoch 0, Batch 42300, Loss: 0.003071642480790615\n",
      "Epoch 0, Batch 42350, Loss: 0.005455055274069309\n",
      "Epoch 0, Batch 42400, Loss: 0.003721070708706975\n",
      "Epoch 0, Batch 42450, Loss: 0.3458794951438904\n",
      "Epoch 0, Batch 42500, Loss: 0.003025843994691968\n",
      "Epoch 0, Batch 42550, Loss: 0.0022335583344101906\n",
      "Epoch 0, Batch 42600, Loss: 0.0024303318932652473\n",
      "Epoch 0, Batch 42650, Loss: 0.00317158130928874\n",
      "Epoch 0, Batch 42700, Loss: 0.003901480929926038\n",
      "Epoch 0, Batch 42750, Loss: 0.0027069072239100933\n",
      "Epoch 0, Batch 42800, Loss: 0.004965983331203461\n",
      "Epoch 0, Batch 42850, Loss: 0.0021802117116749287\n",
      "Epoch 0, Batch 42900, Loss: 0.0016310017090290785\n",
      "Epoch 0, Batch 42950, Loss: 0.0030930149368941784\n",
      "Epoch 0, Batch 43000, Loss: 0.0014735902659595013\n",
      "Epoch 0, Batch 43050, Loss: 0.0019843047484755516\n",
      "Epoch 0, Batch 43100, Loss: 0.0015620484482496977\n",
      "Epoch 0, Batch 43150, Loss: 0.0038225785829126835\n",
      "Epoch 0, Batch 43200, Loss: 0.00297129200771451\n",
      "Epoch 0, Batch 43250, Loss: 0.0034990867134183645\n",
      "Epoch 0, Batch 43300, Loss: 0.0017688272055238485\n",
      "Epoch 0, Batch 43350, Loss: 0.0030168062075972557\n",
      "Epoch 0, Batch 43400, Loss: 0.002055754652246833\n",
      "Epoch 0, Batch 43450, Loss: 0.0029220744036138058\n",
      "Epoch 0, Batch 43500, Loss: 0.001577581511810422\n",
      "Epoch 0, Batch 43550, Loss: 0.001923342584632337\n",
      "Epoch 0, Batch 43600, Loss: 0.002105848165228963\n",
      "Epoch 0, Batch 43650, Loss: 0.00640719011425972\n",
      "Epoch 0, Batch 43700, Loss: 0.0039017200469970703\n",
      "Epoch 0, Batch 43750, Loss: 0.0021418912801891565\n",
      "Epoch 0, Batch 43800, Loss: 0.002420613542199135\n",
      "Epoch 0, Batch 43850, Loss: 0.0029523796401917934\n",
      "Epoch 0, Batch 43900, Loss: 0.0055420720018446445\n",
      "Epoch 0, Batch 43950, Loss: 0.004209169186651707\n",
      "Epoch 0, Batch 44000, Loss: 0.0028556569013744593\n",
      "Epoch 0, Batch 44050, Loss: 0.001679238979704678\n",
      "Epoch 0, Batch 44100, Loss: 0.3771422207355499\n",
      "Epoch 0, Batch 44150, Loss: 0.005608850624412298\n",
      "Epoch 0, Batch 44200, Loss: 0.003231699811294675\n",
      "Epoch 0, Batch 44250, Loss: 0.0015175261069089174\n",
      "Epoch 0, Batch 44300, Loss: 0.0020357035100460052\n",
      "Epoch 0, Batch 44350, Loss: 0.0017546439776197076\n",
      "Epoch 0, Batch 44400, Loss: 0.0015253190649673343\n",
      "Epoch 0, Batch 44450, Loss: 0.0013821105239912868\n",
      "Epoch 0, Batch 44500, Loss: 0.0009590715053491294\n",
      "Epoch 0, Batch 44550, Loss: 0.0009854960953816772\n",
      "Epoch 0, Batch 44600, Loss: 0.0010894305305555463\n",
      "Epoch 0, Batch 44650, Loss: 0.000782931107096374\n",
      "Epoch 0, Batch 44700, Loss: 0.0012348133604973555\n",
      "Epoch 0, Batch 44750, Loss: 0.0011311565758660436\n",
      "Epoch 0, Batch 44800, Loss: 0.0014116282109171152\n",
      "Epoch 0, Batch 44850, Loss: 0.001214676769450307\n",
      "Epoch 0, Batch 44900, Loss: 0.001767484936863184\n",
      "Epoch 0, Batch 44950, Loss: 0.0016067003598436713\n",
      "Epoch 0, Batch 45000, Loss: 0.0024898285046219826\n",
      "Epoch 0, Batch 45050, Loss: 0.0023898084182292223\n",
      "Epoch 0, Batch 45100, Loss: 0.002069012261927128\n",
      "Epoch 0, Batch 45150, Loss: 0.0022680088877677917\n",
      "Epoch 0, Batch 45200, Loss: 0.002735967980697751\n",
      "Epoch 0, Batch 45250, Loss: 0.0023883008398115635\n",
      "Epoch 0, Batch 45300, Loss: 0.4189523458480835\n",
      "Epoch 0, Batch 45350, Loss: 0.0019572358578443527\n",
      "Epoch 0, Batch 45400, Loss: 0.001917451387271285\n",
      "Epoch 0, Batch 45450, Loss: 0.001951917540282011\n",
      "Epoch 0, Batch 45500, Loss: 0.0030129437800496817\n",
      "Epoch 0, Batch 45550, Loss: 0.0035158107057213783\n",
      "Epoch 0, Batch 45600, Loss: 0.003896199632436037\n",
      "Epoch 0, Batch 45650, Loss: 0.0030235261656343937\n",
      "Epoch 0, Batch 45700, Loss: 0.002472678665071726\n",
      "Epoch 0, Batch 45750, Loss: 0.003734949044883251\n",
      "Epoch 0, Batch 45800, Loss: 0.0024627165403217077\n",
      "Epoch 0, Batch 45850, Loss: 0.0025035336147993803\n",
      "Epoch 0, Batch 45900, Loss: 0.0020342059433460236\n",
      "Epoch 0, Batch 45950, Loss: 0.003980616107583046\n",
      "Epoch 0, Batch 46000, Loss: 0.003685561241582036\n",
      "Epoch 0, Batch 46050, Loss: 0.002898839768022299\n",
      "Epoch 0, Batch 46100, Loss: 0.002131412271410227\n",
      "Epoch 0, Batch 46150, Loss: 0.002762196585536003\n",
      "Epoch 0, Batch 46200, Loss: 0.002736693248152733\n",
      "Epoch 0, Batch 46250, Loss: 0.0027461799327284098\n",
      "Epoch 0, Batch 46300, Loss: 0.0015282281674444675\n",
      "Epoch 0, Batch 46350, Loss: 0.0011354235466569662\n",
      "Epoch 0, Batch 46400, Loss: 0.0018238421762362123\n",
      "Epoch 0, Batch 46450, Loss: 0.4080972373485565\n",
      "Epoch 0, Batch 46500, Loss: 0.001966804964467883\n",
      "Epoch 0, Batch 46550, Loss: 0.0015936193522065878\n",
      "Epoch 0, Batch 46600, Loss: 0.0019812954124063253\n",
      "Epoch 0, Batch 46650, Loss: 0.0034171210136264563\n",
      "Epoch 0, Batch 46700, Loss: 0.0024327929131686687\n",
      "Epoch 0, Batch 46750, Loss: 0.0038951418828219175\n",
      "Epoch 0, Batch 46800, Loss: 0.0036201600451022387\n",
      "Epoch 0, Batch 46850, Loss: 0.0017853338504210114\n",
      "Epoch 0, Batch 46900, Loss: 0.0011593346716836095\n",
      "Epoch 0, Batch 46950, Loss: 0.0015315227210521698\n",
      "Epoch 0, Batch 47000, Loss: 0.0019351557129994035\n",
      "Epoch 0, Batch 47050, Loss: 0.0016596923815086484\n",
      "Epoch 0, Batch 47100, Loss: 0.0013155663618817925\n",
      "Epoch 0, Batch 47150, Loss: 0.003317806636914611\n",
      "Epoch 0, Batch 47200, Loss: 0.001463075284846127\n",
      "Epoch 0, Batch 47250, Loss: 0.0011052070185542107\n",
      "Epoch 0, Batch 47300, Loss: 0.0013869514223188162\n",
      "Epoch 0, Batch 47350, Loss: 0.0017103468999266624\n",
      "Epoch 0, Batch 47400, Loss: 0.002517763525247574\n",
      "Epoch 0, Batch 47450, Loss: 0.003916097339242697\n",
      "Epoch 0, Batch 47500, Loss: 0.002026282250881195\n",
      "Epoch 0, Batch 47550, Loss: 0.001981270033866167\n",
      "Epoch 0, Batch 47600, Loss: 0.0019215572392567992\n",
      "Epoch 0, Batch 47650, Loss: 0.0012480488512665033\n",
      "Epoch 0, Batch 47700, Loss: 0.0020016334019601345\n",
      "Epoch 0, Batch 47750, Loss: 0.0024925970938056707\n",
      "Epoch 0, Batch 47800, Loss: 0.0025441909674555063\n",
      "Epoch 0, Batch 47850, Loss: 0.003248383291065693\n",
      "Epoch 0, Batch 47900, Loss: 0.0032104221172630787\n",
      "Epoch 0, Batch 47950, Loss: 0.001732945442199707\n",
      "Epoch 0, Batch 48000, Loss: 0.004063370171934366\n",
      "Epoch 0, Batch 48050, Loss: 0.002165466081351042\n",
      "Epoch 0, Batch 48100, Loss: 0.0022300705313682556\n",
      "Epoch 0, Batch 48150, Loss: 0.0026575473602861166\n",
      "Epoch 0, Batch 48200, Loss: 0.0019930852577090263\n",
      "Epoch 0, Batch 48250, Loss: 0.0017967664171010256\n",
      "Epoch 0, Batch 48300, Loss: 0.0023894361220300198\n",
      "Epoch 0, Batch 48350, Loss: 0.0031564137898385525\n",
      "Epoch 0, Batch 48400, Loss: 0.002222836948931217\n",
      "Epoch 0, Batch 48450, Loss: 0.0024394504725933075\n",
      "Epoch 0, Batch 48500, Loss: 0.0031105470843613148\n",
      "Epoch 0, Batch 48550, Loss: 0.00174275366589427\n",
      "Epoch 0, Batch 48600, Loss: 0.0018924077739939094\n",
      "Epoch 0, Batch 48650, Loss: 0.001951370621100068\n",
      "Epoch 0, Batch 48700, Loss: 0.0015136887086555362\n",
      "Epoch 0, Batch 48750, Loss: 0.002054627286270261\n",
      "Epoch 0, Batch 48800, Loss: 0.001948768738657236\n",
      "Epoch 0, Batch 48850, Loss: 0.0013853999553248286\n",
      "Epoch 0, Batch 48900, Loss: 0.001757597434334457\n",
      "Epoch 0, Batch 48950, Loss: 0.001962440088391304\n",
      "Epoch 0, Batch 49000, Loss: 0.0012996083823964\n",
      "Epoch 0, Batch 49050, Loss: 0.0019459971226751804\n",
      "Epoch 0, Batch 49100, Loss: 0.001918121357448399\n",
      "Epoch 0, Batch 49150, Loss: 0.0034580621868371964\n",
      "Epoch 0, Batch 49200, Loss: 0.002021417487412691\n",
      "Epoch 0, Batch 49250, Loss: 0.002757259411737323\n",
      "Epoch 0, Batch 49300, Loss: 0.0040932269766926765\n",
      "Epoch 0, Batch 49350, Loss: 0.0037013106048107147\n",
      "Epoch 0, Batch 49400, Loss: 0.0035283139441162348\n",
      "Epoch 0, Batch 49450, Loss: 0.002780716633424163\n",
      "Epoch 0, Batch 49500, Loss: 0.002135008107870817\n",
      "Epoch 0, Batch 49550, Loss: 0.7124624252319336\n",
      "Epoch 0, Batch 49600, Loss: 0.002978031523525715\n",
      "Epoch 0, Batch 49650, Loss: 0.002525344491004944\n",
      "Epoch 0, Batch 49700, Loss: 0.0025632688775658607\n",
      "Epoch 0, Batch 49750, Loss: 0.003460998646914959\n",
      "Epoch 0, Batch 49800, Loss: 0.0030575250275433064\n",
      "Epoch 0, Batch 49850, Loss: 0.00203083548694849\n",
      "Epoch 0, Batch 49900, Loss: 0.0023940287064760923\n",
      "Epoch 0, Batch 49950, Loss: 0.0025028374511748552\n",
      "Epoch 0, Batch 50000, Loss: 0.00198492337949574\n",
      "Epoch 0, Batch 50050, Loss: 0.0029197426047176123\n",
      "Epoch 0, Batch 50100, Loss: 0.0018409896874800324\n",
      "Epoch 0, Batch 50150, Loss: 0.002435927512124181\n",
      "Epoch 0, Batch 50200, Loss: 0.0021159721072763205\n",
      "Epoch 0, Batch 50250, Loss: 0.003992412704974413\n",
      "Epoch 0, Batch 50300, Loss: 0.0022846872452646494\n",
      "Epoch 0, Batch 50350, Loss: 0.0014190638903528452\n",
      "Epoch 0, Batch 50400, Loss: 0.004043248947709799\n",
      "Epoch 0, Batch 50450, Loss: 0.0031417361460626125\n",
      "Epoch 0, Batch 50500, Loss: 0.0020214214455336332\n",
      "Epoch 0, Batch 50550, Loss: 0.0019622864201664925\n",
      "Epoch 0, Batch 50600, Loss: 0.001970273442566395\n",
      "Epoch 0, Batch 50650, Loss: 0.00260732090100646\n",
      "Epoch 0, Batch 50700, Loss: 0.0017010372830554843\n",
      "Epoch 0, Batch 50750, Loss: 0.002555130049586296\n",
      "Epoch 0, Batch 50800, Loss: 0.004549842793494463\n",
      "Epoch 0, Batch 50850, Loss: 0.002364850603044033\n",
      "Epoch 0, Batch 50900, Loss: 0.001924182754009962\n",
      "Epoch 0, Batch 50950, Loss: 0.002304808935150504\n",
      "Epoch 0, Batch 51000, Loss: 0.002108396729454398\n",
      "Epoch 0, Batch 51050, Loss: 0.002865477930754423\n",
      "Epoch 0, Batch 51100, Loss: 0.004895995371043682\n",
      "Epoch 0, Batch 51150, Loss: 0.004360460210591555\n",
      "Epoch 0, Batch 51200, Loss: 0.003402743488550186\n",
      "Epoch 0, Batch 51250, Loss: 0.004003613255918026\n",
      "Epoch 0, Batch 51300, Loss: 0.0021595205180346966\n",
      "Epoch 0, Batch 51350, Loss: 0.0029920064844191074\n",
      "Epoch 0, Batch 51400, Loss: 0.003171595511958003\n",
      "Epoch 0, Batch 51450, Loss: 0.0025112684816122055\n",
      "Epoch 0, Batch 51500, Loss: 0.002333654323592782\n",
      "Epoch 0, Batch 51550, Loss: 0.002614186378195882\n",
      "Epoch 0, Batch 51600, Loss: 0.0019063146319240332\n",
      "Epoch 0, Batch 51650, Loss: 0.0015206836396828294\n",
      "Epoch 0, Batch 51700, Loss: 0.0015782425180077553\n",
      "Epoch 0, Batch 51750, Loss: 0.001743859495036304\n",
      "Epoch 0, Batch 51800, Loss: 0.002247539348900318\n",
      "Epoch 0, Batch 51850, Loss: 0.00308379833586514\n",
      "Epoch 0, Batch 51900, Loss: 0.0019143135286867619\n",
      "Epoch 0, Batch 51950, Loss: 0.0019294163212180138\n",
      "Epoch 0, Batch 52000, Loss: 0.003888644278049469\n",
      "Epoch 0, Batch 52050, Loss: 0.004724833648651838\n",
      "Epoch 0, Batch 52100, Loss: 0.004645087756216526\n",
      "Epoch 0, Batch 52150, Loss: 0.0031641621608287096\n",
      "Epoch 0, Batch 52200, Loss: 0.003331788582727313\n",
      "Epoch 0, Batch 52250, Loss: 0.00368521804921329\n",
      "Epoch 0, Batch 52300, Loss: 0.0029990728944540024\n",
      "Epoch 0, Batch 52350, Loss: 0.002165525918826461\n",
      "Epoch 0, Batch 52400, Loss: 0.0035057449713349342\n",
      "Epoch 0, Batch 52450, Loss: 0.0027912345249205828\n",
      "Epoch 0, Batch 52500, Loss: 0.002275730250403285\n",
      "Epoch 0, Batch 52550, Loss: 0.0060586342588067055\n",
      "Epoch 0, Batch 52600, Loss: 0.0031676385551691055\n",
      "Epoch 0, Batch 52650, Loss: 0.0029612560756504536\n",
      "Epoch 0, Batch 52700, Loss: 0.0021433685906231403\n",
      "Epoch 0, Batch 52750, Loss: 0.0018134877318516374\n",
      "Epoch 0, Batch 52800, Loss: 0.002274011494591832\n",
      "Epoch 0, Batch 52850, Loss: 0.0017687168437987566\n",
      "Epoch 0, Batch 52900, Loss: 0.0012337418738752604\n",
      "Epoch 0, Batch 52950, Loss: 0.0008777498733252287\n",
      "Epoch 0, Batch 53000, Loss: 0.0015740913804620504\n",
      "Epoch 0, Batch 53050, Loss: 0.0015464338939636946\n",
      "Epoch 0, Batch 53100, Loss: 0.001798161305487156\n",
      "Epoch 0, Batch 53150, Loss: 0.00516464002430439\n",
      "Epoch 0, Batch 53200, Loss: 0.003544786712154746\n",
      "Epoch 0, Batch 53250, Loss: 0.0034266088623553514\n",
      "Epoch 0, Batch 53300, Loss: 0.3667163848876953\n",
      "Epoch 0, Batch 53350, Loss: 0.0028993512969464064\n",
      "Epoch 0, Batch 53400, Loss: 0.0022895734291523695\n",
      "Epoch 0, Batch 53450, Loss: 0.0016802138416096568\n",
      "Epoch 0, Batch 53500, Loss: 0.0026570395566523075\n",
      "Epoch 0, Batch 53550, Loss: 0.0020512209739536047\n",
      "Epoch 0, Batch 53600, Loss: 0.0018686604453250766\n",
      "Epoch 0, Batch 53650, Loss: 0.002012497279793024\n",
      "Epoch 0, Batch 53700, Loss: 0.0020622287411242723\n",
      "Epoch 0, Batch 53750, Loss: 0.0024426719173789024\n",
      "Epoch 0, Batch 53800, Loss: 0.002057239878922701\n",
      "Epoch 0, Batch 53850, Loss: 0.35013145208358765\n",
      "Epoch 0, Batch 53900, Loss: 0.0032261412125080824\n",
      "Epoch 0, Batch 53950, Loss: 0.0017822490772232413\n",
      "Epoch 0, Batch 54000, Loss: 0.0028595442418009043\n",
      "Epoch 0, Batch 54050, Loss: 0.0025921619962900877\n",
      "Epoch 0, Batch 54100, Loss: 0.0022730212658643723\n",
      "Epoch 0, Batch 54150, Loss: 0.0025102023500949144\n",
      "Epoch 0, Batch 54200, Loss: 0.36034655570983887\n",
      "Epoch 0, Batch 54250, Loss: 0.002310811774805188\n",
      "Epoch 0, Batch 54300, Loss: 0.002024488989263773\n",
      "Epoch 0, Batch 54350, Loss: 0.002063238527625799\n",
      "Epoch 0, Batch 54400, Loss: 0.0021988798398524523\n",
      "Epoch 0, Batch 54450, Loss: 0.00187784805893898\n",
      "Epoch 0, Batch 54500, Loss: 0.0024552103132009506\n",
      "Epoch 0, Batch 54550, Loss: 0.0027445789892226458\n",
      "Epoch 0, Batch 54600, Loss: 0.0029888246208429337\n",
      "Epoch 0, Batch 54650, Loss: 0.0026651890948414803\n",
      "Epoch 0, Batch 54700, Loss: 0.0035738134756684303\n",
      "Epoch 0, Batch 54750, Loss: 0.00213422579690814\n",
      "Epoch 0, Batch 54800, Loss: 0.004048832692205906\n",
      "Epoch 0, Batch 54850, Loss: 0.003442137036472559\n",
      "Epoch 0, Batch 54900, Loss: 0.003092342521995306\n",
      "Epoch 0, Batch 54950, Loss: 0.0030886325985193253\n",
      "Epoch 0, Batch 55000, Loss: 0.39132794737815857\n",
      "Epoch 0, Batch 55050, Loss: 0.002278748666867614\n",
      "Epoch 0, Batch 55100, Loss: 0.0016207222361117601\n",
      "Epoch 0, Batch 55150, Loss: 0.0017354900483042002\n",
      "Epoch 0, Batch 55200, Loss: 0.0014512515626847744\n",
      "Epoch 0, Batch 55250, Loss: 0.0015383976278826594\n",
      "Epoch 0, Batch 55300, Loss: 0.0015385907609015703\n",
      "Epoch 0, Batch 55350, Loss: 0.4220542013645172\n",
      "Epoch 0, Batch 55400, Loss: 0.0027206630911678076\n",
      "Epoch 0, Batch 55450, Loss: 0.0022519526537507772\n",
      "Epoch 0, Batch 55500, Loss: 0.7948465943336487\n",
      "Epoch 0, Batch 55550, Loss: 0.0033182036131620407\n",
      "Epoch 0, Batch 55600, Loss: 0.0021901524160057306\n",
      "Epoch 0, Batch 55650, Loss: 0.0028970087878406048\n",
      "Epoch 0, Batch 55700, Loss: 0.0026010589208453894\n",
      "Epoch 0, Batch 55750, Loss: 0.0020694839768111706\n",
      "Epoch 0, Batch 55800, Loss: 0.0017496435903012753\n",
      "Epoch 0, Batch 55850, Loss: 0.0011061651166528463\n",
      "Epoch 0, Batch 55900, Loss: 0.0011852167081087828\n",
      "Epoch 0, Batch 55950, Loss: 0.0014878477668389678\n",
      "Epoch 0, Batch 56000, Loss: 0.0012543810298666358\n",
      "Epoch 0, Batch 56050, Loss: 0.0009328277665190399\n",
      "Epoch 0, Batch 56100, Loss: 0.4355185329914093\n",
      "Epoch 0, Batch 56150, Loss: 0.41070112586021423\n",
      "Epoch 0, Batch 56200, Loss: 0.0013883148785680532\n",
      "Epoch 0, Batch 56250, Loss: 0.0019964922685176134\n",
      "Epoch 1, Batch 50, Loss: 0.003164480673149228\n",
      "Epoch 1, Batch 100, Loss: 0.004613542463630438\n",
      "Epoch 1, Batch 150, Loss: 0.0021926029585301876\n",
      "Epoch 1, Batch 200, Loss: 0.0021764046978205442\n",
      "Epoch 1, Batch 250, Loss: 0.0016921358183026314\n",
      "Epoch 1, Batch 300, Loss: 0.0011330182896927\n",
      "Epoch 1, Batch 350, Loss: 0.0015831628115847707\n",
      "Epoch 1, Batch 400, Loss: 0.0015503213508054614\n",
      "Epoch 1, Batch 450, Loss: 0.0023209471255540848\n",
      "Epoch 1, Batch 500, Loss: 0.001799589954316616\n",
      "Epoch 1, Batch 550, Loss: 0.0024869218468666077\n",
      "Epoch 1, Batch 600, Loss: 0.0021777597721666098\n",
      "Epoch 1, Batch 650, Loss: 0.003519389545544982\n",
      "Epoch 1, Batch 700, Loss: 0.005411739461123943\n",
      "Epoch 1, Batch 750, Loss: 0.0028158307541161776\n",
      "Epoch 1, Batch 800, Loss: 0.0038695570547133684\n",
      "Epoch 1, Batch 850, Loss: 0.0034337118268013\n",
      "Epoch 1, Batch 900, Loss: 0.003373522777110338\n",
      "Epoch 1, Batch 950, Loss: 0.002848335076123476\n",
      "Epoch 1, Batch 1000, Loss: 0.002817881992086768\n",
      "Epoch 1, Batch 1050, Loss: 0.002024895278736949\n",
      "Epoch 1, Batch 1100, Loss: 0.0025051599368453026\n",
      "Epoch 1, Batch 1150, Loss: 0.0018453603843227029\n",
      "Epoch 1, Batch 1200, Loss: 0.0015932341339066625\n",
      "Epoch 1, Batch 1250, Loss: 0.0018504478503018618\n",
      "Epoch 1, Batch 1300, Loss: 0.0015100784366950393\n",
      "Epoch 1, Batch 1350, Loss: 0.0019926531240344048\n",
      "Epoch 1, Batch 1400, Loss: 0.0020715692080557346\n",
      "Epoch 1, Batch 1450, Loss: 0.377310574054718\n",
      "Epoch 1, Batch 1500, Loss: 0.0036878110840916634\n",
      "Epoch 1, Batch 1550, Loss: 0.004422851372510195\n",
      "Epoch 1, Batch 1600, Loss: 0.0038750246167182922\n",
      "Epoch 1, Batch 1650, Loss: 0.007462139241397381\n",
      "Epoch 1, Batch 1700, Loss: 0.004180137068033218\n",
      "Epoch 1, Batch 1750, Loss: 0.0034016037825495005\n",
      "Epoch 1, Batch 1800, Loss: 0.39158323407173157\n",
      "Epoch 1, Batch 1850, Loss: 0.0017517019296064973\n",
      "Epoch 1, Batch 1900, Loss: 0.0011013092007488012\n",
      "Epoch 1, Batch 1950, Loss: 0.001148246694356203\n",
      "Epoch 1, Batch 2000, Loss: 0.0019453419372439384\n",
      "Epoch 1, Batch 2050, Loss: 0.002755639376118779\n",
      "Epoch 1, Batch 2100, Loss: 0.003120986744761467\n",
      "Epoch 1, Batch 2150, Loss: 0.0020617851987481117\n",
      "Epoch 1, Batch 2200, Loss: 0.00198168377391994\n",
      "Epoch 1, Batch 2250, Loss: 0.0017552307108417153\n",
      "Epoch 1, Batch 2300, Loss: 0.3756084144115448\n",
      "Epoch 1, Batch 2350, Loss: 0.0022214045748114586\n",
      "Epoch 1, Batch 2400, Loss: 0.0018283093813806772\n",
      "Epoch 1, Batch 2450, Loss: 0.0012617335887625813\n",
      "Epoch 1, Batch 2500, Loss: 0.0012060777517035604\n",
      "Epoch 1, Batch 2550, Loss: 0.002125269267708063\n",
      "Epoch 1, Batch 2600, Loss: 0.0024691540747880936\n",
      "Epoch 1, Batch 2650, Loss: 0.0016952415462583303\n",
      "Epoch 1, Batch 2700, Loss: 0.3754950761795044\n",
      "Epoch 1, Batch 2750, Loss: 0.002252815058454871\n",
      "Epoch 1, Batch 2800, Loss: 0.40739837288856506\n",
      "Epoch 1, Batch 2850, Loss: 0.0018755648052319884\n",
      "Epoch 1, Batch 2900, Loss: 0.0023532493505626917\n",
      "Epoch 1, Batch 2950, Loss: 0.005410303361713886\n",
      "Epoch 1, Batch 3000, Loss: 0.00389179983176291\n",
      "Epoch 1, Batch 3050, Loss: 0.003958103246986866\n",
      "Epoch 1, Batch 3100, Loss: 0.0027097100391983986\n",
      "Epoch 1, Batch 3150, Loss: 0.002105316612869501\n",
      "Epoch 1, Batch 3200, Loss: 0.0018420348642393947\n",
      "Epoch 1, Batch 3250, Loss: 0.0017571699572727084\n",
      "Epoch 1, Batch 3300, Loss: 0.002510152757167816\n",
      "Epoch 1, Batch 3350, Loss: 0.002399232005700469\n",
      "Epoch 1, Batch 3400, Loss: 0.003415547078475356\n",
      "Epoch 1, Batch 3450, Loss: 0.0034736348316073418\n",
      "Epoch 1, Batch 3500, Loss: 0.002808212535455823\n",
      "Epoch 1, Batch 3550, Loss: 0.002796218963339925\n",
      "Epoch 1, Batch 3600, Loss: 0.0030659628100693226\n",
      "Epoch 1, Batch 3650, Loss: 0.003098313696682453\n",
      "Epoch 1, Batch 3700, Loss: 0.005049197468906641\n",
      "Epoch 1, Batch 3750, Loss: 0.0034360771533101797\n",
      "Epoch 1, Batch 3800, Loss: 0.004442933946847916\n",
      "Epoch 1, Batch 3850, Loss: 0.003666139207780361\n",
      "Epoch 1, Batch 3900, Loss: 0.0049941749311983585\n",
      "Epoch 1, Batch 3950, Loss: 0.002402271842584014\n",
      "Epoch 1, Batch 4000, Loss: 0.0018216446042060852\n",
      "Epoch 1, Batch 4050, Loss: 0.001928454264998436\n",
      "Epoch 1, Batch 4100, Loss: 0.002286872360855341\n",
      "Epoch 1, Batch 4150, Loss: 0.0019255452789366245\n",
      "Epoch 1, Batch 4200, Loss: 0.004336675629019737\n",
      "Epoch 1, Batch 4250, Loss: 0.35942402482032776\n",
      "Epoch 1, Batch 4300, Loss: 0.003404569812119007\n",
      "Epoch 1, Batch 4350, Loss: 0.0034892300609499216\n",
      "Epoch 1, Batch 4400, Loss: 0.002453693188726902\n",
      "Epoch 1, Batch 4450, Loss: 0.002007715404033661\n",
      "Epoch 1, Batch 4500, Loss: 0.0022026486694812775\n",
      "Epoch 1, Batch 4550, Loss: 0.0019964417442679405\n",
      "Epoch 1, Batch 4600, Loss: 0.00241105817258358\n",
      "Epoch 1, Batch 4650, Loss: 0.0022729267366230488\n",
      "Epoch 1, Batch 4700, Loss: 0.002867035800591111\n",
      "Epoch 1, Batch 4750, Loss: 0.002935959491878748\n",
      "Epoch 1, Batch 4800, Loss: 0.002283649519085884\n",
      "Epoch 1, Batch 4850, Loss: 0.001795510877855122\n",
      "Epoch 1, Batch 4900, Loss: 0.0016071608988568187\n",
      "Epoch 1, Batch 4950, Loss: 0.001115248305723071\n",
      "Epoch 1, Batch 5000, Loss: 0.0010051187127828598\n",
      "Epoch 1, Batch 5050, Loss: 0.0019312850199639797\n",
      "Epoch 1, Batch 5100, Loss: 0.001828456181101501\n",
      "Epoch 1, Batch 5150, Loss: 0.0017036624485626817\n",
      "Epoch 1, Batch 5200, Loss: 0.0028045729268342257\n",
      "Epoch 1, Batch 5250, Loss: 0.002866168739274144\n",
      "Epoch 1, Batch 5300, Loss: 0.0026958251837641\n",
      "Epoch 1, Batch 5350, Loss: 0.002105741761624813\n",
      "Epoch 1, Batch 5400, Loss: 0.001876250607892871\n",
      "Epoch 1, Batch 5450, Loss: 0.00208882219158113\n",
      "Epoch 1, Batch 5500, Loss: 0.002533178310841322\n",
      "Epoch 1, Batch 5550, Loss: 0.0021805609576404095\n",
      "Epoch 1, Batch 5600, Loss: 0.00220143492333591\n",
      "Epoch 1, Batch 5650, Loss: 0.0014679263113066554\n",
      "Epoch 1, Batch 5700, Loss: 0.0019859136082232\n",
      "Epoch 1, Batch 5750, Loss: 0.002114460803568363\n",
      "Epoch 1, Batch 5800, Loss: 0.0025591778103262186\n",
      "Epoch 1, Batch 5850, Loss: 0.002665351377800107\n",
      "Epoch 1, Batch 5900, Loss: 0.0050533972680568695\n",
      "Epoch 1, Batch 5950, Loss: 0.003123314818367362\n",
      "Epoch 1, Batch 6000, Loss: 0.008759785443544388\n",
      "Epoch 1, Batch 6050, Loss: 0.004541434347629547\n",
      "Epoch 1, Batch 6100, Loss: 0.0033222686033695936\n",
      "Epoch 1, Batch 6150, Loss: 0.002933232579380274\n",
      "Epoch 1, Batch 6200, Loss: 0.0023587278556078672\n",
      "Epoch 1, Batch 6250, Loss: 0.002353773219510913\n",
      "Epoch 1, Batch 6300, Loss: 0.002174107823520899\n",
      "Epoch 1, Batch 6350, Loss: 0.002332407748326659\n",
      "Epoch 1, Batch 6400, Loss: 0.0031663100235164165\n",
      "Epoch 1, Batch 6450, Loss: 0.0032286327332258224\n",
      "Epoch 1, Batch 6500, Loss: 0.0018457778496667743\n",
      "Epoch 1, Batch 6550, Loss: 0.001521785743534565\n",
      "Epoch 1, Batch 6600, Loss: 0.001634244224987924\n",
      "Epoch 1, Batch 6650, Loss: 0.0015479131834581494\n",
      "Epoch 1, Batch 6700, Loss: 0.0016490808920934796\n",
      "Epoch 1, Batch 6750, Loss: 0.0018910533981397748\n",
      "Epoch 1, Batch 6800, Loss: 0.0017067862208932638\n",
      "Epoch 1, Batch 6850, Loss: 0.0020027917344123125\n",
      "Epoch 1, Batch 6900, Loss: 0.0022252127528190613\n",
      "Epoch 1, Batch 6950, Loss: 0.0020181366708129644\n",
      "Epoch 1, Batch 7000, Loss: 0.002125481842085719\n",
      "Epoch 1, Batch 7050, Loss: 0.0023460572119802237\n",
      "Epoch 1, Batch 7100, Loss: 0.002115151146426797\n",
      "Epoch 1, Batch 7150, Loss: 0.0038902866654098034\n",
      "Epoch 1, Batch 7200, Loss: 0.003936076071113348\n",
      "Epoch 1, Batch 7250, Loss: 0.0027359433006495237\n",
      "Epoch 1, Batch 7300, Loss: 0.0016963481903076172\n",
      "Epoch 1, Batch 7350, Loss: 0.002612314186990261\n",
      "Epoch 1, Batch 7400, Loss: 0.0041507538408041\n",
      "Epoch 1, Batch 7450, Loss: 0.004214840941131115\n",
      "Epoch 1, Batch 7500, Loss: 0.006826087366789579\n",
      "Epoch 1, Batch 7550, Loss: 0.004175650887191296\n",
      "Epoch 1, Batch 7600, Loss: 0.0029764650389552116\n",
      "Epoch 1, Batch 7650, Loss: 0.002665705746039748\n",
      "Epoch 1, Batch 7700, Loss: 0.003140151035040617\n",
      "Epoch 1, Batch 7750, Loss: 0.003206146415323019\n",
      "Epoch 1, Batch 7800, Loss: 0.003122471971437335\n",
      "Epoch 1, Batch 7850, Loss: 0.0029702570755034685\n",
      "Epoch 1, Batch 7900, Loss: 0.0035325083881616592\n",
      "Epoch 1, Batch 7950, Loss: 0.0034058145247399807\n",
      "Epoch 1, Batch 8000, Loss: 0.0037517219316214323\n",
      "Epoch 1, Batch 8050, Loss: 0.0026507778093218803\n",
      "Epoch 1, Batch 8100, Loss: 0.003303028177469969\n",
      "Epoch 1, Batch 8150, Loss: 0.003864840604364872\n",
      "Epoch 1, Batch 8200, Loss: 0.002324500121176243\n",
      "Epoch 1, Batch 8250, Loss: 0.0023673376999795437\n",
      "Epoch 1, Batch 8300, Loss: 0.0024161157198250294\n",
      "Epoch 1, Batch 8350, Loss: 0.0016499565681442618\n",
      "Epoch 1, Batch 8400, Loss: 0.0023351761046797037\n",
      "Epoch 1, Batch 8450, Loss: 0.002118804957717657\n",
      "Epoch 1, Batch 8500, Loss: 0.0022041737101972103\n",
      "Epoch 1, Batch 8550, Loss: 0.0039037978276610374\n",
      "Epoch 1, Batch 8600, Loss: 0.0027367458678781986\n",
      "Epoch 1, Batch 8650, Loss: 0.001766257337294519\n",
      "Epoch 1, Batch 8700, Loss: 0.0011290977708995342\n",
      "Epoch 1, Batch 8750, Loss: 0.0009406089666299522\n",
      "Epoch 1, Batch 8800, Loss: 0.001760060666128993\n",
      "Epoch 1, Batch 8850, Loss: 0.0020768980029970407\n",
      "Epoch 1, Batch 8900, Loss: 0.0016852169064804912\n",
      "Epoch 1, Batch 8950, Loss: 0.0029042940586805344\n",
      "Epoch 1, Batch 9000, Loss: 0.0024874580558389425\n",
      "Epoch 1, Batch 9050, Loss: 0.0020029968582093716\n",
      "Epoch 1, Batch 9100, Loss: 0.0016157424543052912\n",
      "Epoch 1, Batch 9150, Loss: 0.002094891155138612\n",
      "Epoch 1, Batch 9200, Loss: 0.0021671014837920666\n",
      "Epoch 1, Batch 9250, Loss: 0.0023845641408115625\n",
      "Epoch 1, Batch 9300, Loss: 0.0019084438681602478\n",
      "Epoch 1, Batch 9350, Loss: 0.002112750895321369\n",
      "Epoch 1, Batch 9400, Loss: 0.0016376249259337783\n",
      "Epoch 1, Batch 9450, Loss: 0.001716583501547575\n",
      "Epoch 1, Batch 9500, Loss: 0.0024496521800756454\n",
      "Epoch 1, Batch 9550, Loss: 0.003838918637484312\n",
      "Epoch 1, Batch 9600, Loss: 0.003286876482889056\n",
      "Epoch 1, Batch 9650, Loss: 0.005814112722873688\n",
      "Epoch 1, Batch 9700, Loss: 0.0033175661228597164\n",
      "Epoch 1, Batch 9750, Loss: 0.004285799339413643\n",
      "Epoch 1, Batch 9800, Loss: 0.003943281713873148\n",
      "Epoch 1, Batch 9850, Loss: 0.003972291015088558\n",
      "Epoch 1, Batch 9900, Loss: 0.002271021483466029\n",
      "Epoch 1, Batch 9950, Loss: 0.002228889614343643\n",
      "Epoch 1, Batch 10000, Loss: 0.002445557154715061\n",
      "Epoch 1, Batch 10050, Loss: 0.002807296346873045\n",
      "Epoch 1, Batch 10100, Loss: 0.0023849536664783955\n",
      "Epoch 1, Batch 10150, Loss: 0.002228331519290805\n",
      "Epoch 1, Batch 10200, Loss: 0.0016385589260607958\n",
      "Epoch 1, Batch 10250, Loss: 0.0013652709312736988\n",
      "Epoch 1, Batch 10300, Loss: 0.0014735792065039277\n",
      "Epoch 1, Batch 10350, Loss: 0.002902585780248046\n",
      "Epoch 1, Batch 10400, Loss: 0.003062949515879154\n",
      "Epoch 1, Batch 10450, Loss: 0.004109112545847893\n",
      "Epoch 1, Batch 10500, Loss: 0.0031208498403429985\n",
      "Epoch 1, Batch 10550, Loss: 0.003142652567476034\n",
      "Epoch 1, Batch 10600, Loss: 0.002984185703098774\n",
      "Epoch 1, Batch 10650, Loss: 0.001931329257786274\n",
      "Epoch 1, Batch 10700, Loss: 0.002175280824303627\n",
      "Epoch 1, Batch 10750, Loss: 0.002585986629128456\n",
      "Epoch 1, Batch 10800, Loss: 0.3947329521179199\n",
      "Epoch 1, Batch 10850, Loss: 0.003307765582576394\n",
      "Epoch 1, Batch 10900, Loss: 0.0044296314008533955\n",
      "Epoch 1, Batch 10950, Loss: 0.0038047642447054386\n",
      "Epoch 1, Batch 11000, Loss: 0.0028675564099103212\n",
      "Epoch 1, Batch 11050, Loss: 0.002982881385833025\n",
      "Epoch 1, Batch 11100, Loss: 0.002396177966147661\n",
      "Epoch 1, Batch 11150, Loss: 0.0022510371636599302\n",
      "Epoch 1, Batch 11200, Loss: 0.001623974647372961\n",
      "Epoch 1, Batch 11250, Loss: 0.001501315156929195\n",
      "Epoch 1, Batch 11300, Loss: 0.00185198534745723\n",
      "Epoch 1, Batch 11350, Loss: 0.0015860504936426878\n",
      "Epoch 1, Batch 11400, Loss: 0.0017064422136172652\n",
      "Epoch 1, Batch 11450, Loss: 0.0029919345397502184\n",
      "Epoch 1, Batch 11500, Loss: 0.003297280753031373\n",
      "Epoch 1, Batch 11550, Loss: 0.0024100157897919416\n",
      "Epoch 1, Batch 11600, Loss: 0.0014440953964367509\n",
      "Epoch 1, Batch 11650, Loss: 0.0013962493976578116\n",
      "Epoch 1, Batch 11700, Loss: 0.0012014501262456179\n",
      "Epoch 1, Batch 11750, Loss: 0.0014167808694764972\n",
      "Epoch 1, Batch 11800, Loss: 0.0018424252048134804\n",
      "Epoch 1, Batch 11850, Loss: 0.0017813971498981118\n",
      "Epoch 1, Batch 11900, Loss: 0.002029248047620058\n",
      "Epoch 1, Batch 11950, Loss: 0.0018037569243460894\n",
      "Epoch 1, Batch 12000, Loss: 0.0014758214820176363\n",
      "Epoch 1, Batch 12050, Loss: 0.0021018085535615683\n",
      "Epoch 1, Batch 12100, Loss: 0.004162828903645277\n",
      "Epoch 1, Batch 12150, Loss: 0.0031186682172119617\n",
      "Epoch 1, Batch 12200, Loss: 0.003923794720321894\n",
      "Epoch 1, Batch 12250, Loss: 0.0038425298407673836\n",
      "Epoch 1, Batch 12300, Loss: 0.003356632776558399\n",
      "Epoch 1, Batch 12350, Loss: 0.004513485822826624\n",
      "Epoch 1, Batch 12400, Loss: 0.0033047443721443415\n",
      "Epoch 1, Batch 12450, Loss: 0.00291274837218225\n",
      "Epoch 1, Batch 12500, Loss: 0.0019944836385548115\n",
      "Epoch 1, Batch 12550, Loss: 0.0020535048097372055\n",
      "Epoch 1, Batch 12600, Loss: 0.0017941338010132313\n",
      "Epoch 1, Batch 12650, Loss: 0.0017525687580928206\n",
      "Epoch 1, Batch 12700, Loss: 0.37300539016723633\n",
      "Epoch 1, Batch 12750, Loss: 0.0045010861940681934\n",
      "Epoch 1, Batch 12800, Loss: 0.0029232099186629057\n",
      "Epoch 1, Batch 12850, Loss: 0.0031904755160212517\n",
      "Epoch 1, Batch 12900, Loss: 0.004068970214575529\n",
      "Epoch 1, Batch 12950, Loss: 0.004237465560436249\n",
      "Epoch 1, Batch 13000, Loss: 0.0027266168035566807\n",
      "Epoch 1, Batch 13050, Loss: 0.002758679911494255\n",
      "Epoch 1, Batch 13100, Loss: 0.002627414185553789\n",
      "Epoch 1, Batch 13150, Loss: 0.003844968043267727\n",
      "Epoch 1, Batch 13200, Loss: 0.003862838027998805\n",
      "Epoch 1, Batch 13250, Loss: 0.004066359717398882\n",
      "Epoch 1, Batch 13300, Loss: 0.0033662880305200815\n",
      "Epoch 1, Batch 13350, Loss: 0.003710623364895582\n",
      "Epoch 1, Batch 13400, Loss: 0.002777906134724617\n",
      "Epoch 1, Batch 13450, Loss: 0.0026821771170943975\n",
      "Epoch 1, Batch 13500, Loss: 0.002292133867740631\n",
      "Epoch 1, Batch 13550, Loss: 0.0015807683812454343\n",
      "Epoch 1, Batch 13600, Loss: 0.0011746938107535243\n",
      "Epoch 1, Batch 13650, Loss: 0.0013129410799592733\n",
      "Epoch 1, Batch 13700, Loss: 0.001131017692387104\n",
      "Epoch 1, Batch 13750, Loss: 0.0009335410431958735\n",
      "Epoch 1, Batch 13800, Loss: 0.0007018171017989516\n",
      "Epoch 1, Batch 13850, Loss: 0.0010099217761307955\n",
      "Epoch 1, Batch 13900, Loss: 0.0018750111339613795\n",
      "Epoch 1, Batch 13950, Loss: 0.003468882292509079\n",
      "Epoch 1, Batch 14000, Loss: 0.0020883497782051563\n",
      "Epoch 1, Batch 14050, Loss: 0.0020123946014791727\n",
      "Epoch 1, Batch 14100, Loss: 0.0020448139403015375\n",
      "Epoch 1, Batch 14150, Loss: 0.0019367343047633767\n",
      "Epoch 1, Batch 14200, Loss: 0.0011851046001538634\n",
      "Epoch 1, Batch 14250, Loss: 0.0017287593800574541\n",
      "Epoch 1, Batch 14300, Loss: 0.0017680423334240913\n",
      "Epoch 1, Batch 14350, Loss: 0.0014603047166019678\n",
      "Epoch 1, Batch 14400, Loss: 0.001629686332307756\n",
      "Epoch 1, Batch 14450, Loss: 0.002298763021826744\n",
      "Epoch 1, Batch 14500, Loss: 0.0032910839654505253\n",
      "Epoch 1, Batch 14550, Loss: 0.002844856120646\n",
      "Epoch 1, Batch 14600, Loss: 0.0021202005445957184\n",
      "Epoch 1, Batch 14650, Loss: 0.0015261289663612843\n",
      "Epoch 1, Batch 14700, Loss: 0.0028336134273558855\n",
      "Epoch 1, Batch 14750, Loss: 0.0022822662722319365\n",
      "Epoch 1, Batch 14800, Loss: 0.002589496783912182\n",
      "Epoch 1, Batch 14850, Loss: 0.0026999397668987513\n",
      "Epoch 1, Batch 14900, Loss: 0.003086706157773733\n",
      "Epoch 1, Batch 14950, Loss: 0.0039494032971560955\n",
      "Epoch 1, Batch 15000, Loss: 0.0026282304897904396\n",
      "Epoch 1, Batch 15050, Loss: 0.003102172166109085\n",
      "Epoch 1, Batch 15100, Loss: 0.004256275948137045\n",
      "Epoch 1, Batch 15150, Loss: 0.0028940849006175995\n",
      "Epoch 1, Batch 15200, Loss: 0.0028887176886200905\n",
      "Epoch 1, Batch 15250, Loss: 0.002156819449737668\n",
      "Epoch 1, Batch 15300, Loss: 0.40576377511024475\n",
      "Epoch 1, Batch 15350, Loss: 0.0026961599942296743\n",
      "Epoch 1, Batch 15400, Loss: 0.0046810582280159\n",
      "Epoch 1, Batch 15450, Loss: 0.0031882827170193195\n",
      "Epoch 1, Batch 15500, Loss: 0.0040659657679498196\n",
      "Epoch 1, Batch 15550, Loss: 0.004580139182507992\n",
      "Epoch 1, Batch 15600, Loss: 0.0024099466390907764\n",
      "Epoch 1, Batch 15650, Loss: 0.002435691189020872\n",
      "Epoch 1, Batch 15700, Loss: 0.002620853018015623\n",
      "Epoch 1, Batch 15750, Loss: 0.0028407752979546785\n",
      "Epoch 1, Batch 15800, Loss: 0.0019754255190491676\n",
      "Epoch 1, Batch 15850, Loss: 0.0014030709862709045\n",
      "Epoch 1, Batch 15900, Loss: 0.0012271861778572202\n",
      "Epoch 1, Batch 15950, Loss: 0.002158741233870387\n",
      "Epoch 1, Batch 16000, Loss: 0.0018159712199121714\n",
      "Epoch 1, Batch 16050, Loss: 0.0020332231651991606\n",
      "Epoch 1, Batch 16100, Loss: 0.002162685850635171\n",
      "Epoch 1, Batch 16150, Loss: 0.0038411999121308327\n",
      "Epoch 1, Batch 16200, Loss: 0.0026604468002915382\n",
      "Epoch 1, Batch 16250, Loss: 0.3529939651489258\n",
      "Epoch 1, Batch 16300, Loss: 0.003122620517387986\n",
      "Epoch 1, Batch 16350, Loss: 0.002175841946154833\n",
      "Epoch 1, Batch 16400, Loss: 0.34569594264030457\n",
      "Epoch 1, Batch 16450, Loss: 0.003237383905798197\n",
      "Epoch 1, Batch 16500, Loss: 0.0031788856722414494\n",
      "Epoch 1, Batch 16550, Loss: 0.002659437246620655\n",
      "Epoch 1, Batch 16600, Loss: 0.0030141735915094614\n",
      "Epoch 1, Batch 16650, Loss: 0.0025235405191779137\n",
      "Epoch 1, Batch 16700, Loss: 0.0021187730599194765\n",
      "Epoch 1, Batch 16750, Loss: 0.0028337170369923115\n",
      "Epoch 1, Batch 16800, Loss: 0.005770692601799965\n",
      "Epoch 1, Batch 16850, Loss: 0.00413158442825079\n",
      "Epoch 1, Batch 16900, Loss: 0.004652643576264381\n",
      "Epoch 1, Batch 16950, Loss: 0.005163373425602913\n",
      "Epoch 1, Batch 17000, Loss: 0.005636760964989662\n",
      "Epoch 1, Batch 17050, Loss: 0.004222763702273369\n",
      "Epoch 1, Batch 17100, Loss: 0.35595425963401794\n",
      "Epoch 1, Batch 17150, Loss: 0.0026396471075713634\n",
      "Epoch 1, Batch 17200, Loss: 0.0017549436306580901\n",
      "Epoch 1, Batch 17250, Loss: 0.0014542751014232635\n",
      "Epoch 1, Batch 17300, Loss: 0.0014054067432880402\n",
      "Epoch 1, Batch 17350, Loss: 0.0018329989397898316\n",
      "Epoch 1, Batch 17400, Loss: 0.00266586453653872\n",
      "Epoch 1, Batch 17450, Loss: 0.0025199628435075283\n",
      "Epoch 1, Batch 17500, Loss: 0.002070372924208641\n",
      "Epoch 1, Batch 17550, Loss: 0.0015321056125685573\n",
      "Epoch 1, Batch 17600, Loss: 0.001747269183397293\n",
      "Epoch 1, Batch 17650, Loss: 0.0017640553414821625\n",
      "Epoch 1, Batch 17700, Loss: 0.0017700549215078354\n",
      "Epoch 1, Batch 17750, Loss: 0.004413926973938942\n",
      "Epoch 1, Batch 17800, Loss: 0.003616148140281439\n",
      "Epoch 1, Batch 17850, Loss: 0.0030399926472455263\n",
      "Epoch 1, Batch 17900, Loss: 0.002800720278173685\n",
      "Epoch 1, Batch 17950, Loss: 0.004547761287540197\n",
      "Epoch 1, Batch 18000, Loss: 0.004336121492087841\n",
      "Epoch 1, Batch 18050, Loss: 0.00542679475620389\n",
      "Epoch 1, Batch 18100, Loss: 0.003887421451508999\n",
      "Epoch 1, Batch 18150, Loss: 0.0029746084474027157\n",
      "Epoch 1, Batch 18200, Loss: 0.004254304803907871\n",
      "Epoch 1, Batch 18250, Loss: 0.0041040899232029915\n",
      "Epoch 1, Batch 18300, Loss: 0.0029296784196048975\n",
      "Epoch 1, Batch 18350, Loss: 0.0022589333821088076\n",
      "Epoch 1, Batch 18400, Loss: 0.0019910968840122223\n",
      "Epoch 1, Batch 18450, Loss: 0.0017602832522243261\n",
      "Epoch 1, Batch 18500, Loss: 0.001986292889341712\n",
      "Epoch 1, Batch 18550, Loss: 0.002588021568953991\n",
      "Epoch 1, Batch 18600, Loss: 0.001901695504784584\n",
      "Epoch 1, Batch 18650, Loss: 0.0019660054240375757\n",
      "Epoch 1, Batch 18700, Loss: 0.0016107303090393543\n",
      "Epoch 1, Batch 18750, Loss: 0.0015903498278930783\n",
      "Epoch 1, Batch 18800, Loss: 0.0012366537703201175\n",
      "Epoch 1, Batch 18850, Loss: 0.0018302708631381392\n",
      "Epoch 1, Batch 18900, Loss: 0.0018434959929436445\n",
      "Epoch 1, Batch 18950, Loss: 0.001891601481474936\n",
      "Epoch 1, Batch 19000, Loss: 0.0019349390640854836\n",
      "Epoch 1, Batch 19050, Loss: 0.0016035886947065592\n",
      "Epoch 1, Batch 19100, Loss: 0.0012781866826117039\n",
      "Epoch 1, Batch 19150, Loss: 0.0012172461720183492\n",
      "Epoch 1, Batch 19200, Loss: 0.0014606888871639967\n",
      "Epoch 1, Batch 19250, Loss: 0.0017542884452268481\n",
      "Epoch 1, Batch 19300, Loss: 0.0020069065503776073\n",
      "Epoch 1, Batch 19350, Loss: 0.001864536781795323\n",
      "Epoch 1, Batch 19400, Loss: 0.0035971258766949177\n",
      "Epoch 1, Batch 19450, Loss: 0.002948604989796877\n",
      "Epoch 1, Batch 19500, Loss: 0.0019931511487811804\n",
      "Epoch 1, Batch 19550, Loss: 0.43612754344940186\n",
      "Epoch 1, Batch 19600, Loss: 0.0016721482388675213\n",
      "Epoch 1, Batch 19650, Loss: 0.0012519024312496185\n",
      "Epoch 1, Batch 19700, Loss: 0.001920573296956718\n",
      "Epoch 1, Batch 19750, Loss: 0.0015360722318291664\n",
      "Epoch 1, Batch 19800, Loss: 0.0020991626661270857\n",
      "Epoch 1, Batch 19850, Loss: 0.00512398686259985\n",
      "Epoch 1, Batch 19900, Loss: 0.003016455564647913\n",
      "Epoch 1, Batch 19950, Loss: 0.0022924095392227173\n",
      "Epoch 1, Batch 20000, Loss: 0.00403989851474762\n",
      "Epoch 1, Batch 20050, Loss: 0.004354384262114763\n",
      "Epoch 1, Batch 20100, Loss: 0.002516765845939517\n",
      "Epoch 1, Batch 20150, Loss: 0.0020031288731843233\n",
      "Epoch 1, Batch 20200, Loss: 0.004236553329974413\n",
      "Epoch 1, Batch 20250, Loss: 0.006632907781749964\n",
      "Epoch 1, Batch 20300, Loss: 0.003084513358771801\n",
      "Epoch 1, Batch 20350, Loss: 0.0021946835331618786\n",
      "Epoch 1, Batch 20400, Loss: 0.004204826429486275\n",
      "Epoch 1, Batch 20450, Loss: 0.0036264683585613966\n",
      "Epoch 1, Batch 20500, Loss: 0.00272208359092474\n",
      "Epoch 1, Batch 20550, Loss: 0.003129854565486312\n",
      "Epoch 1, Batch 20600, Loss: 0.001987220486626029\n",
      "Epoch 1, Batch 20650, Loss: 0.002294614678248763\n",
      "Epoch 1, Batch 20700, Loss: 0.0020944823045283556\n",
      "Epoch 1, Batch 20750, Loss: 0.0026647979393601418\n",
      "Epoch 1, Batch 20800, Loss: 0.0029818005859851837\n",
      "Epoch 1, Batch 20850, Loss: 0.003424891037866473\n",
      "Epoch 1, Batch 20900, Loss: 0.0022826637141406536\n",
      "Epoch 1, Batch 20950, Loss: 0.0022193514741957188\n",
      "Epoch 1, Batch 21000, Loss: 0.002893623895943165\n",
      "Epoch 1, Batch 21050, Loss: 0.0036967014893889427\n",
      "Epoch 1, Batch 21100, Loss: 0.0029526969883590937\n",
      "Epoch 1, Batch 21150, Loss: 0.002882289933040738\n",
      "Epoch 1, Batch 21200, Loss: 0.0026723076589405537\n",
      "Epoch 1, Batch 21250, Loss: 0.0028626136481761932\n",
      "Epoch 1, Batch 21300, Loss: 0.0028371631633490324\n",
      "Epoch 1, Batch 21350, Loss: 0.0033902907744050026\n",
      "Epoch 1, Batch 21400, Loss: 0.004141935147345066\n",
      "Epoch 1, Batch 21450, Loss: 0.0034347258042544127\n",
      "Epoch 1, Batch 21500, Loss: 0.0028065377846360207\n",
      "Epoch 1, Batch 21550, Loss: 0.002687355736270547\n",
      "Epoch 1, Batch 21600, Loss: 0.0022408526856452227\n",
      "Epoch 1, Batch 21650, Loss: 0.0018634609878063202\n",
      "Epoch 1, Batch 21700, Loss: 0.407668799161911\n",
      "Epoch 1, Batch 21750, Loss: 0.00211096229031682\n",
      "Epoch 1, Batch 21800, Loss: 0.002406089333817363\n",
      "Epoch 1, Batch 21850, Loss: 0.0017670453526079655\n",
      "Epoch 1, Batch 21900, Loss: 0.0016861110925674438\n",
      "Epoch 1, Batch 21950, Loss: 0.002529282821342349\n",
      "Epoch 1, Batch 22000, Loss: 0.0038041763473302126\n",
      "Epoch 1, Batch 22050, Loss: 0.0029167579486966133\n",
      "Epoch 1, Batch 22100, Loss: 0.0018232202855870128\n",
      "Epoch 1, Batch 22150, Loss: 0.0030024275183677673\n",
      "Epoch 1, Batch 22200, Loss: 0.0023173345252871513\n",
      "Epoch 1, Batch 22250, Loss: 0.0017945055151358247\n",
      "Epoch 1, Batch 22300, Loss: 0.0016435970319435\n",
      "Epoch 1, Batch 22350, Loss: 0.0018920741276815534\n",
      "Epoch 1, Batch 22400, Loss: 0.0019046401139348745\n",
      "Epoch 1, Batch 22450, Loss: 0.0020891556050628424\n",
      "Epoch 1, Batch 22500, Loss: 0.0023163144942373037\n",
      "Epoch 1, Batch 22550, Loss: 0.0033770918380469084\n",
      "Epoch 1, Batch 22600, Loss: 0.0032713240943849087\n",
      "Epoch 1, Batch 22650, Loss: 0.0043252441100776196\n",
      "Epoch 1, Batch 22700, Loss: 0.002979966579005122\n",
      "Epoch 1, Batch 22750, Loss: 0.002788628451526165\n",
      "Epoch 1, Batch 22800, Loss: 0.0024711403530091047\n",
      "Epoch 1, Batch 22850, Loss: 0.002336333505809307\n",
      "Epoch 1, Batch 22900, Loss: 0.0017499217065051198\n",
      "Epoch 1, Batch 22950, Loss: 0.0018364317947998643\n",
      "Epoch 1, Batch 23000, Loss: 0.0018796399235725403\n",
      "Epoch 1, Batch 23050, Loss: 0.0017348566325381398\n",
      "Epoch 1, Batch 23100, Loss: 0.0024905658792704344\n",
      "Epoch 1, Batch 23150, Loss: 0.0017665086779743433\n",
      "Epoch 1, Batch 23200, Loss: 0.0012598216999322176\n",
      "Epoch 1, Batch 23250, Loss: 0.0021702139638364315\n",
      "Epoch 1, Batch 23300, Loss: 0.0018116465071216226\n",
      "Epoch 1, Batch 23350, Loss: 0.00194217124953866\n",
      "Epoch 1, Batch 23400, Loss: 0.002057356061413884\n",
      "Epoch 1, Batch 23450, Loss: 0.0030890696216374636\n",
      "Epoch 1, Batch 23500, Loss: 0.0028476433362811804\n",
      "Epoch 1, Batch 23550, Loss: 0.0021614450961351395\n",
      "Epoch 1, Batch 23600, Loss: 0.0017256459686905146\n",
      "Epoch 1, Batch 23650, Loss: 0.001891933847218752\n",
      "Epoch 1, Batch 23700, Loss: 0.0021056998521089554\n",
      "Epoch 1, Batch 23750, Loss: 0.0020589723717421293\n",
      "Epoch 1, Batch 23800, Loss: 0.002067198511213064\n",
      "Epoch 1, Batch 23850, Loss: 0.002249683951959014\n",
      "Epoch 1, Batch 23900, Loss: 0.0029612346552312374\n",
      "Epoch 1, Batch 23950, Loss: 0.0037397455889731646\n",
      "Epoch 1, Batch 24000, Loss: 0.002781118731945753\n",
      "Epoch 1, Batch 24050, Loss: 0.0022591298911720514\n",
      "Epoch 1, Batch 24100, Loss: 0.003585584694519639\n",
      "Epoch 1, Batch 24150, Loss: 0.003997631836682558\n",
      "Epoch 1, Batch 24200, Loss: 0.004284212831407785\n",
      "Epoch 1, Batch 24250, Loss: 0.004107441287487745\n",
      "Epoch 1, Batch 24300, Loss: 0.0035149825271219015\n",
      "Epoch 1, Batch 24350, Loss: 0.0024937151465564966\n",
      "Epoch 1, Batch 24400, Loss: 0.00230208458378911\n",
      "Epoch 1, Batch 24450, Loss: 0.0019398363074287772\n",
      "Epoch 1, Batch 24500, Loss: 0.0015711126616224647\n",
      "Epoch 1, Batch 24550, Loss: 0.0009306228021159768\n",
      "Epoch 1, Batch 24600, Loss: 0.001361658563837409\n",
      "Epoch 1, Batch 24650, Loss: 0.0015384053112939\n",
      "Epoch 1, Batch 24700, Loss: 0.0022801996674388647\n",
      "Epoch 1, Batch 24750, Loss: 0.0014249311061576009\n",
      "Epoch 1, Batch 24800, Loss: 0.0016130361473187804\n",
      "Epoch 1, Batch 24850, Loss: 0.0013001469196751714\n",
      "Epoch 1, Batch 24900, Loss: 0.0012016566470265388\n",
      "Epoch 1, Batch 24950, Loss: 0.0015209784032776952\n",
      "Epoch 1, Batch 25000, Loss: 0.0023361968342214823\n",
      "Epoch 1, Batch 25050, Loss: 0.0028800652362406254\n",
      "Epoch 1, Batch 25100, Loss: 0.00343003636226058\n",
      "Epoch 1, Batch 25150, Loss: 0.003038102528080344\n",
      "Epoch 1, Batch 25200, Loss: 0.0027437210083007812\n",
      "Epoch 1, Batch 25250, Loss: 0.002099808771163225\n",
      "Epoch 1, Batch 25300, Loss: 0.0016253131907433271\n",
      "Epoch 1, Batch 25350, Loss: 0.001419746084138751\n",
      "Epoch 1, Batch 25400, Loss: 0.001903948956169188\n",
      "Epoch 1, Batch 25450, Loss: 0.0014778893673792481\n",
      "Epoch 1, Batch 25500, Loss: 0.0018660319037735462\n",
      "Epoch 1, Batch 25550, Loss: 0.002143572550266981\n",
      "Epoch 1, Batch 25600, Loss: 0.0037058102898299694\n",
      "Epoch 1, Batch 25650, Loss: 0.002763215685263276\n",
      "Epoch 1, Batch 25700, Loss: 0.0028334411326795816\n",
      "Epoch 1, Batch 25750, Loss: 0.004513897467404604\n",
      "Epoch 1, Batch 25800, Loss: 0.005499324295669794\n",
      "Epoch 1, Batch 25850, Loss: 0.0030583515763282776\n",
      "Epoch 1, Batch 25900, Loss: 0.0034340207930654287\n",
      "Epoch 1, Batch 25950, Loss: 0.0037672286853194237\n",
      "Epoch 1, Batch 26000, Loss: 0.00397524842992425\n",
      "Epoch 1, Batch 26050, Loss: 0.004431391134858131\n",
      "Epoch 1, Batch 26100, Loss: 0.0028803523164242506\n",
      "Epoch 1, Batch 26150, Loss: 0.002182773081585765\n",
      "Epoch 1, Batch 26200, Loss: 0.0024973175022751093\n",
      "Epoch 1, Batch 26250, Loss: 0.0037362282164394855\n",
      "Epoch 1, Batch 26300, Loss: 0.002986524486914277\n",
      "Epoch 1, Batch 26350, Loss: 0.004132316447794437\n",
      "Epoch 1, Batch 26400, Loss: 0.004248459357768297\n",
      "Epoch 1, Batch 26450, Loss: 0.0028210615273565054\n",
      "Epoch 1, Batch 26500, Loss: 0.0029971394687891006\n",
      "Epoch 1, Batch 26550, Loss: 0.002560979686677456\n",
      "Epoch 1, Batch 26600, Loss: 0.00273236446082592\n",
      "Epoch 1, Batch 26650, Loss: 0.0019892980344593525\n",
      "Epoch 1, Batch 26700, Loss: 0.001965159550309181\n",
      "Epoch 1, Batch 26750, Loss: 0.0019606424029916525\n",
      "Epoch 1, Batch 26800, Loss: 0.002645733067765832\n",
      "Epoch 1, Batch 26850, Loss: 0.002459623385220766\n",
      "Epoch 1, Batch 26900, Loss: 0.0035501630045473576\n",
      "Epoch 1, Batch 26950, Loss: 0.0040055448189377785\n",
      "Epoch 1, Batch 27000, Loss: 0.0028191448654979467\n",
      "Epoch 1, Batch 27050, Loss: 0.0021727446001023054\n",
      "Epoch 1, Batch 27100, Loss: 0.0020467257127165794\n",
      "Epoch 1, Batch 27150, Loss: 0.0015710177831351757\n",
      "Epoch 1, Batch 27200, Loss: 0.0017732731066644192\n",
      "Epoch 1, Batch 27250, Loss: 0.0021842217538505793\n",
      "Epoch 1, Batch 27300, Loss: 0.0029211610089987516\n",
      "Epoch 1, Batch 27350, Loss: 0.0038138744421303272\n",
      "Epoch 1, Batch 27400, Loss: 0.002095970558002591\n",
      "Epoch 1, Batch 27450, Loss: 0.0019189006416127086\n",
      "Epoch 1, Batch 27500, Loss: 0.0021524119656533003\n",
      "Epoch 1, Batch 27550, Loss: 0.0017030120361596346\n",
      "Epoch 1, Batch 27600, Loss: 0.0017731644911691546\n",
      "Epoch 1, Batch 27650, Loss: 0.0022681939881294966\n",
      "Epoch 1, Batch 27700, Loss: 0.0025078742764890194\n",
      "Epoch 1, Batch 27750, Loss: 0.002014512661844492\n",
      "Epoch 1, Batch 27800, Loss: 0.0029046782292425632\n",
      "Epoch 1, Batch 27850, Loss: 0.35300213098526\n",
      "Epoch 1, Batch 27900, Loss: 0.003833737690001726\n",
      "Epoch 1, Batch 27950, Loss: 0.0037236253265291452\n",
      "Epoch 1, Batch 28000, Loss: 0.00377454049885273\n",
      "Epoch 1, Batch 28050, Loss: 0.003776454832404852\n",
      "Epoch 1, Batch 28100, Loss: 0.0036287857219576836\n",
      "Epoch 1, Batch 28150, Loss: 0.0030229059047997\n",
      "Epoch 1, Batch 28200, Loss: 0.0022109299898147583\n",
      "Epoch 1, Batch 28250, Loss: 0.0023559576366096735\n",
      "Epoch 1, Batch 28300, Loss: 0.0034870298113673925\n",
      "Epoch 1, Batch 28350, Loss: 0.004562672693282366\n",
      "Epoch 1, Batch 28400, Loss: 0.004946786444634199\n",
      "Epoch 1, Batch 28450, Loss: 0.004257158376276493\n",
      "Epoch 1, Batch 28500, Loss: 0.003180611412972212\n",
      "Epoch 1, Batch 28550, Loss: 0.003427869873121381\n",
      "Epoch 1, Batch 28600, Loss: 0.0029934952035546303\n",
      "Epoch 1, Batch 28650, Loss: 0.002725329715758562\n",
      "Epoch 1, Batch 28700, Loss: 0.003885833779349923\n",
      "Epoch 1, Batch 28750, Loss: 0.00319449114613235\n",
      "Epoch 1, Batch 28800, Loss: 0.0030770194716751575\n",
      "Epoch 1, Batch 28850, Loss: 0.003061802126467228\n",
      "Epoch 1, Batch 28900, Loss: 0.0022342796437442303\n",
      "Epoch 1, Batch 28950, Loss: 0.003598216688260436\n",
      "Epoch 1, Batch 29000, Loss: 0.0023251737002283335\n",
      "Epoch 1, Batch 29050, Loss: 0.0020427715498954058\n",
      "Epoch 1, Batch 29100, Loss: 0.0025483558420091867\n",
      "Epoch 1, Batch 29150, Loss: 0.0017896766075864434\n",
      "Epoch 1, Batch 29200, Loss: 0.00200434448197484\n",
      "Epoch 1, Batch 29250, Loss: 0.0020516719669103622\n",
      "Epoch 1, Batch 29300, Loss: 0.0021958937868475914\n",
      "Epoch 1, Batch 29350, Loss: 0.002286150585860014\n",
      "Epoch 1, Batch 29400, Loss: 0.0027136916760355234\n",
      "Epoch 1, Batch 29450, Loss: 0.0026934724301099777\n",
      "Epoch 1, Batch 29500, Loss: 0.0021297840867191553\n",
      "Epoch 1, Batch 29550, Loss: 0.4061100482940674\n",
      "Epoch 1, Batch 29600, Loss: 0.001558659947477281\n",
      "Epoch 1, Batch 29650, Loss: 0.0014013180043548346\n",
      "Epoch 1, Batch 29700, Loss: 0.0025739113334566355\n",
      "Epoch 1, Batch 29750, Loss: 0.004129133652895689\n",
      "Epoch 1, Batch 29800, Loss: 0.003077790839597583\n",
      "Epoch 1, Batch 29850, Loss: 0.0032485511619597673\n",
      "Epoch 1, Batch 29900, Loss: 0.3664817214012146\n",
      "Epoch 1, Batch 29950, Loss: 0.0025992959272116423\n",
      "Epoch 1, Batch 30000, Loss: 0.002500722650438547\n",
      "Epoch 1, Batch 30050, Loss: 0.002291115466505289\n",
      "Epoch 1, Batch 30100, Loss: 0.002627848880365491\n",
      "Epoch 1, Batch 30150, Loss: 0.0028383575845509768\n",
      "Epoch 1, Batch 30200, Loss: 0.0026738583110272884\n",
      "Epoch 1, Batch 30250, Loss: 0.003169842530041933\n",
      "Epoch 1, Batch 30300, Loss: 0.0022250935435295105\n",
      "Epoch 1, Batch 30350, Loss: 0.001986379036679864\n",
      "Epoch 1, Batch 30400, Loss: 0.002141798846423626\n",
      "Epoch 1, Batch 30450, Loss: 0.0018523982726037502\n",
      "Epoch 1, Batch 30500, Loss: 0.0018875107634812593\n",
      "Epoch 1, Batch 30550, Loss: 0.0032944793347269297\n",
      "Epoch 1, Batch 30600, Loss: 0.0029784992802888155\n",
      "Epoch 1, Batch 30650, Loss: 0.0032932437025010586\n",
      "Epoch 1, Batch 30700, Loss: 0.0030407030135393143\n",
      "Epoch 1, Batch 30750, Loss: 0.002587056951597333\n",
      "Epoch 1, Batch 30800, Loss: 0.0019546528346836567\n",
      "Epoch 1, Batch 30850, Loss: 0.002720271935686469\n",
      "Epoch 1, Batch 30900, Loss: 0.002094901166856289\n",
      "Epoch 1, Batch 30950, Loss: 0.002450720639899373\n",
      "Epoch 1, Batch 31000, Loss: 0.3988543152809143\n",
      "Epoch 1, Batch 31050, Loss: 0.001796562341041863\n",
      "Epoch 1, Batch 31100, Loss: 0.0017601762665435672\n",
      "Epoch 1, Batch 31150, Loss: 0.0019507992547005415\n",
      "Epoch 1, Batch 31200, Loss: 0.0024370565079152584\n",
      "Epoch 1, Batch 31250, Loss: 0.002272252459079027\n",
      "Epoch 1, Batch 31300, Loss: 0.0019768555648624897\n",
      "Epoch 1, Batch 31350, Loss: 0.0021988367661833763\n",
      "Epoch 1, Batch 31400, Loss: 0.0016522626392543316\n",
      "Epoch 1, Batch 31450, Loss: 0.0018380177207291126\n",
      "Epoch 1, Batch 31500, Loss: 0.0026334114372730255\n",
      "Epoch 1, Batch 31550, Loss: 0.002835768973454833\n",
      "Epoch 1, Batch 31600, Loss: 0.0020327449310570955\n",
      "Epoch 1, Batch 31650, Loss: 0.002163992729038\n",
      "Epoch 1, Batch 31700, Loss: 0.0015869205817580223\n",
      "Epoch 1, Batch 31750, Loss: 0.0016373505350202322\n",
      "Epoch 1, Batch 31800, Loss: 0.0011499135289341211\n",
      "Epoch 1, Batch 31850, Loss: 0.0013878867030143738\n",
      "Epoch 1, Batch 31900, Loss: 0.0015411353670060635\n",
      "Epoch 1, Batch 31950, Loss: 0.001993609359487891\n",
      "Epoch 1, Batch 32000, Loss: 0.00188135402277112\n",
      "Epoch 1, Batch 32050, Loss: 0.0026821596547961235\n",
      "Epoch 1, Batch 32100, Loss: 0.0025150454603135586\n",
      "Epoch 1, Batch 32150, Loss: 0.0024742521345615387\n",
      "Epoch 1, Batch 32200, Loss: 0.0023292647674679756\n",
      "Epoch 1, Batch 32250, Loss: 0.0015388785395771265\n",
      "Epoch 1, Batch 32300, Loss: 0.001302745076827705\n",
      "Epoch 1, Batch 32350, Loss: 0.0020932997576892376\n",
      "Epoch 1, Batch 32400, Loss: 0.003099423833191395\n",
      "Epoch 1, Batch 32450, Loss: 0.0032969447784125805\n",
      "Epoch 1, Batch 32500, Loss: 0.003128635697066784\n",
      "Epoch 1, Batch 32550, Loss: 0.3380734324455261\n",
      "Epoch 1, Batch 32600, Loss: 0.0034095339942723513\n",
      "Epoch 1, Batch 32650, Loss: 0.0025850185193121433\n",
      "Epoch 1, Batch 32700, Loss: 0.002561653032898903\n",
      "Epoch 1, Batch 32750, Loss: 0.0023248412180691957\n",
      "Epoch 1, Batch 32800, Loss: 0.004528115503489971\n",
      "Epoch 1, Batch 32850, Loss: 0.0025650691241025925\n",
      "Epoch 1, Batch 32900, Loss: 0.003024221630766988\n",
      "Epoch 1, Batch 32950, Loss: 0.0022560223005712032\n",
      "Epoch 1, Batch 33000, Loss: 0.001898093381896615\n",
      "Epoch 1, Batch 33050, Loss: 0.002474531065672636\n",
      "Epoch 1, Batch 33100, Loss: 0.0023379381746053696\n",
      "Epoch 1, Batch 33150, Loss: 0.0031592233572155237\n",
      "Epoch 1, Batch 33200, Loss: 0.0020325887016952038\n",
      "Epoch 1, Batch 33250, Loss: 0.002096609678119421\n",
      "Epoch 1, Batch 33300, Loss: 0.003309906693175435\n",
      "Epoch 1, Batch 33350, Loss: 0.0021749394945800304\n",
      "Epoch 1, Batch 33400, Loss: 0.0017994181253015995\n",
      "Epoch 1, Batch 33450, Loss: 0.001766291563399136\n",
      "Epoch 1, Batch 33500, Loss: 0.002384333172813058\n",
      "Epoch 1, Batch 33550, Loss: 0.002559054410085082\n",
      "Epoch 1, Batch 33600, Loss: 0.0020096355583518744\n",
      "Epoch 1, Batch 33650, Loss: 0.0021257977932691574\n",
      "Epoch 1, Batch 33700, Loss: 0.0020857357885688543\n",
      "Epoch 1, Batch 33750, Loss: 0.002044483320787549\n",
      "Epoch 1, Batch 33800, Loss: 0.3619031310081482\n",
      "Epoch 1, Batch 33850, Loss: 0.0027842968702316284\n",
      "Epoch 1, Batch 33900, Loss: 0.002783443545922637\n",
      "Epoch 1, Batch 33950, Loss: 0.0025588495191186666\n",
      "Epoch 1, Batch 34000, Loss: 0.0023626310285180807\n",
      "Epoch 1, Batch 34050, Loss: 0.002366362838074565\n",
      "Epoch 1, Batch 34100, Loss: 0.0028847893700003624\n",
      "Epoch 1, Batch 34150, Loss: 0.003071933751925826\n",
      "Epoch 1, Batch 34200, Loss: 0.0033212928101420403\n",
      "Epoch 1, Batch 34250, Loss: 0.003982055466622114\n",
      "Epoch 1, Batch 34300, Loss: 0.00263318233191967\n",
      "Epoch 1, Batch 34350, Loss: 0.002640264108777046\n",
      "Epoch 1, Batch 34400, Loss: 0.0019020114559680223\n",
      "Epoch 1, Batch 34450, Loss: 0.0026875329203903675\n",
      "Epoch 1, Batch 34500, Loss: 0.002864325186237693\n",
      "Epoch 1, Batch 34550, Loss: 0.0028955265879631042\n",
      "Epoch 1, Batch 34600, Loss: 0.0024241814389824867\n",
      "Epoch 1, Batch 34650, Loss: 0.001867546234279871\n",
      "Epoch 1, Batch 34700, Loss: 0.0019356985576450825\n",
      "Epoch 1, Batch 34750, Loss: 0.0029999669641256332\n",
      "Epoch 1, Batch 34800, Loss: 0.0030788674484938383\n",
      "Epoch 1, Batch 34850, Loss: 0.002188998507335782\n",
      "Epoch 1, Batch 34900, Loss: 0.0017092899652197957\n",
      "Epoch 1, Batch 34950, Loss: 0.001874949666671455\n",
      "Epoch 1, Batch 35000, Loss: 0.001865335856564343\n",
      "Epoch 1, Batch 35050, Loss: 0.002867081668227911\n",
      "Epoch 1, Batch 35100, Loss: 0.003683388466015458\n",
      "Epoch 1, Batch 35150, Loss: 0.38673362135887146\n",
      "Epoch 1, Batch 35200, Loss: 0.002706432482227683\n",
      "Epoch 1, Batch 35250, Loss: 0.00288168853148818\n",
      "Epoch 1, Batch 35300, Loss: 0.0021629470866173506\n",
      "Epoch 1, Batch 35350, Loss: 0.002623508684337139\n",
      "Epoch 1, Batch 35400, Loss: 0.0021164310164749622\n",
      "Epoch 1, Batch 35450, Loss: 0.0021667100954800844\n",
      "Epoch 1, Batch 35500, Loss: 0.002724127843976021\n",
      "Epoch 1, Batch 35550, Loss: 0.004025756381452084\n",
      "Epoch 1, Batch 35600, Loss: 0.0022854297421872616\n",
      "Epoch 1, Batch 35650, Loss: 0.0023208381608128548\n",
      "Epoch 1, Batch 35700, Loss: 0.0023557995446026325\n",
      "Epoch 1, Batch 35750, Loss: 0.0033073683734983206\n",
      "Epoch 1, Batch 35800, Loss: 0.0021844536531716585\n",
      "Epoch 1, Batch 35850, Loss: 0.0015144881326705217\n",
      "Epoch 1, Batch 35900, Loss: 0.0013682247372344136\n",
      "Epoch 1, Batch 35950, Loss: 0.0016089963028207421\n",
      "Epoch 1, Batch 36000, Loss: 0.002641883213073015\n",
      "Epoch 1, Batch 36050, Loss: 0.0027157324366271496\n",
      "Epoch 1, Batch 36100, Loss: 0.002371017588302493\n",
      "Epoch 1, Batch 36150, Loss: 0.00172864377964288\n",
      "Epoch 1, Batch 36200, Loss: 0.0017108122119680047\n",
      "Epoch 1, Batch 36250, Loss: 0.0018970182863995433\n",
      "Epoch 1, Batch 36300, Loss: 0.001991095719859004\n",
      "Epoch 1, Batch 36350, Loss: 0.0027668813709169626\n",
      "Epoch 1, Batch 36400, Loss: 0.00411260686814785\n",
      "Epoch 1, Batch 36450, Loss: 0.003631370607763529\n",
      "Epoch 1, Batch 36500, Loss: 0.003494903678074479\n",
      "Epoch 1, Batch 36550, Loss: 0.0039513022638857365\n",
      "Epoch 1, Batch 36600, Loss: 0.004041639156639576\n",
      "Epoch 1, Batch 36650, Loss: 0.0026103206910192966\n",
      "Epoch 1, Batch 36700, Loss: 0.0027187305968254805\n",
      "Epoch 1, Batch 36750, Loss: 0.0024778624065220356\n",
      "Epoch 1, Batch 36800, Loss: 0.0016681875567883253\n",
      "Epoch 1, Batch 36850, Loss: 0.0018773050978779793\n",
      "Epoch 1, Batch 36900, Loss: 0.0017999483970925212\n",
      "Epoch 1, Batch 36950, Loss: 0.0022053502034395933\n",
      "Epoch 1, Batch 37000, Loss: 0.003228976856917143\n",
      "Epoch 1, Batch 37050, Loss: 0.003447585739195347\n",
      "Epoch 1, Batch 37100, Loss: 0.0032711150124669075\n",
      "Epoch 1, Batch 37150, Loss: 0.002028822433203459\n",
      "Epoch 1, Batch 37200, Loss: 0.0032634350936859846\n",
      "Epoch 1, Batch 37250, Loss: 0.0022339867427945137\n",
      "Epoch 1, Batch 37300, Loss: 0.001696949708275497\n",
      "Epoch 1, Batch 37350, Loss: 0.0025662616826593876\n",
      "Epoch 1, Batch 37400, Loss: 0.0027626599185168743\n",
      "Epoch 1, Batch 37450, Loss: 0.007582372520118952\n",
      "Epoch 1, Batch 37500, Loss: 0.0046618301421403885\n",
      "Epoch 1, Batch 37550, Loss: 0.003260113997384906\n",
      "Epoch 1, Batch 37600, Loss: 0.0024369100574404\n",
      "Epoch 1, Batch 37650, Loss: 0.002651067916303873\n",
      "Epoch 1, Batch 37700, Loss: 0.0023753729183226824\n",
      "Epoch 1, Batch 37750, Loss: 0.37708669900894165\n",
      "Epoch 1, Batch 37800, Loss: 0.0027186591178178787\n",
      "Epoch 1, Batch 37850, Loss: 0.0021926932968199253\n",
      "Epoch 1, Batch 37900, Loss: 0.002140113851055503\n",
      "Epoch 1, Batch 37950, Loss: 0.002395300893113017\n",
      "Epoch 1, Batch 38000, Loss: 0.0031166565604507923\n",
      "Epoch 1, Batch 38050, Loss: 0.004253408405929804\n",
      "Epoch 1, Batch 38100, Loss: 0.0029537780210375786\n",
      "Epoch 1, Batch 38150, Loss: 0.002387861954048276\n",
      "Epoch 1, Batch 38200, Loss: 0.0017245685448870063\n",
      "Epoch 1, Batch 38250, Loss: 0.00198926217854023\n",
      "Epoch 1, Batch 38300, Loss: 0.0018076738342642784\n",
      "Epoch 1, Batch 38350, Loss: 0.0015078800497576594\n",
      "Epoch 1, Batch 38400, Loss: 0.0016554518369957805\n",
      "Epoch 1, Batch 38450, Loss: 0.001312900334596634\n",
      "Epoch 1, Batch 38500, Loss: 0.0012935071717947721\n",
      "Epoch 1, Batch 38550, Loss: 0.001292802975513041\n",
      "Epoch 1, Batch 38600, Loss: 0.0019031414994969964\n",
      "Epoch 1, Batch 38650, Loss: 0.002029363065958023\n",
      "Epoch 1, Batch 38700, Loss: 0.001721548498608172\n",
      "Epoch 1, Batch 38750, Loss: 0.0026426950935274363\n",
      "Epoch 1, Batch 38800, Loss: 0.0024051745422184467\n",
      "Epoch 1, Batch 38850, Loss: 0.0020934257190674543\n",
      "Epoch 1, Batch 38900, Loss: 0.0021471052896231413\n",
      "Epoch 1, Batch 38950, Loss: 0.002610432216897607\n",
      "Epoch 1, Batch 39000, Loss: 0.0025810166262090206\n",
      "Epoch 1, Batch 39050, Loss: 0.002402368700131774\n",
      "Epoch 1, Batch 39100, Loss: 0.0021922271698713303\n",
      "Epoch 1, Batch 39150, Loss: 0.002080803969874978\n",
      "Epoch 1, Batch 39200, Loss: 0.0029673450626432896\n",
      "Epoch 1, Batch 39250, Loss: 0.0022360756993293762\n",
      "Epoch 1, Batch 39300, Loss: 0.3518407344818115\n",
      "Epoch 1, Batch 39350, Loss: 0.003277487587183714\n",
      "Epoch 1, Batch 39400, Loss: 0.003116643987596035\n",
      "Epoch 1, Batch 39450, Loss: 0.0026081502437591553\n",
      "Epoch 1, Batch 39500, Loss: 0.0022959343623369932\n",
      "Epoch 1, Batch 39550, Loss: 0.001882052281871438\n",
      "Epoch 1, Batch 39600, Loss: 0.0029679008293896914\n",
      "Epoch 1, Batch 39650, Loss: 0.002722067292779684\n",
      "Epoch 1, Batch 39700, Loss: 0.002823324641212821\n",
      "Epoch 1, Batch 39750, Loss: 0.0032382369972765446\n",
      "Epoch 1, Batch 39800, Loss: 0.002150546992197633\n",
      "Epoch 1, Batch 39850, Loss: 0.0014651953242719173\n",
      "Epoch 1, Batch 39900, Loss: 0.0014432462630793452\n",
      "Epoch 1, Batch 39950, Loss: 0.001425302354618907\n",
      "Epoch 1, Batch 40000, Loss: 0.00132776889950037\n",
      "Epoch 1, Batch 40050, Loss: 0.0019700266420841217\n",
      "Epoch 1, Batch 40100, Loss: 0.002433781512081623\n",
      "Epoch 1, Batch 40150, Loss: 0.002444207202643156\n",
      "Epoch 1, Batch 40200, Loss: 0.0025217393413186073\n",
      "Epoch 1, Batch 40250, Loss: 0.0022186548449099064\n",
      "Epoch 1, Batch 40300, Loss: 0.0014871960738673806\n",
      "Epoch 1, Batch 40350, Loss: 0.001376302563585341\n",
      "Epoch 1, Batch 40400, Loss: 0.0021250720601528883\n",
      "Epoch 1, Batch 40450, Loss: 0.002398477168753743\n",
      "Epoch 1, Batch 40500, Loss: 0.002274971455335617\n",
      "Epoch 1, Batch 40550, Loss: 0.002198020927608013\n",
      "Epoch 1, Batch 40600, Loss: 0.0016581275267526507\n",
      "Epoch 1, Batch 40650, Loss: 0.001731688273139298\n",
      "Epoch 1, Batch 40700, Loss: 0.0029891696758568287\n",
      "Epoch 1, Batch 40750, Loss: 0.0020014443434774876\n",
      "Epoch 1, Batch 40800, Loss: 0.0015975097194314003\n",
      "Epoch 1, Batch 40850, Loss: 0.0015563851920887828\n",
      "Epoch 1, Batch 40900, Loss: 0.002612243639305234\n",
      "Epoch 1, Batch 40950, Loss: 0.002139054937288165\n",
      "Epoch 1, Batch 41000, Loss: 0.0023325225338339806\n",
      "Epoch 1, Batch 41050, Loss: 0.0028527944814413786\n",
      "Epoch 1, Batch 41100, Loss: 0.0019599669612944126\n",
      "Epoch 1, Batch 41150, Loss: 0.0015992897097021341\n",
      "Epoch 1, Batch 41200, Loss: 0.0014023511903360486\n",
      "Epoch 1, Batch 41250, Loss: 0.001171040697954595\n",
      "Epoch 1, Batch 41300, Loss: 0.0014798687770962715\n",
      "Epoch 1, Batch 41350, Loss: 0.004392990842461586\n",
      "Epoch 1, Batch 41400, Loss: 0.0038302778266370296\n",
      "Epoch 1, Batch 41450, Loss: 0.0026277811266481876\n",
      "Epoch 1, Batch 41500, Loss: 0.002179546747356653\n",
      "Epoch 1, Batch 41550, Loss: 0.0018883816665038466\n",
      "Epoch 1, Batch 41600, Loss: 0.00274155056104064\n",
      "Epoch 1, Batch 41650, Loss: 0.003798465710133314\n",
      "Epoch 1, Batch 41700, Loss: 0.002972250571474433\n",
      "Epoch 1, Batch 41750, Loss: 0.002806355943903327\n",
      "Epoch 1, Batch 41800, Loss: 0.003053512889891863\n",
      "Epoch 1, Batch 41850, Loss: 0.0025057687889784575\n",
      "Epoch 1, Batch 41900, Loss: 0.0022415518760681152\n",
      "Epoch 1, Batch 41950, Loss: 0.0028831646777689457\n",
      "Epoch 1, Batch 42000, Loss: 0.0017649638466536999\n",
      "Epoch 1, Batch 42050, Loss: 0.002303409855812788\n",
      "Epoch 1, Batch 42100, Loss: 0.002493611304089427\n",
      "Epoch 1, Batch 42150, Loss: 0.002665164414793253\n",
      "Epoch 1, Batch 42200, Loss: 0.002500564092770219\n",
      "Epoch 1, Batch 42250, Loss: 0.0024686858523637056\n",
      "Epoch 1, Batch 42300, Loss: 0.002286589238792658\n",
      "Epoch 1, Batch 42350, Loss: 0.0015504135517403483\n",
      "Epoch 1, Batch 42400, Loss: 0.002043574582785368\n",
      "Epoch 1, Batch 42450, Loss: 0.0015510031953454018\n",
      "Epoch 1, Batch 42500, Loss: 0.0017675117123872042\n",
      "Epoch 1, Batch 42550, Loss: 0.0013316506519913673\n",
      "Epoch 1, Batch 42600, Loss: 0.001412029261700809\n",
      "Epoch 1, Batch 42650, Loss: 0.0015421591233462095\n",
      "Epoch 1, Batch 42700, Loss: 0.0014560180716216564\n",
      "Epoch 1, Batch 42750, Loss: 0.001719313790090382\n",
      "Epoch 1, Batch 42800, Loss: 0.3808509111404419\n",
      "Epoch 1, Batch 42850, Loss: 0.002007287461310625\n",
      "Epoch 1, Batch 42900, Loss: 0.0020228999201208353\n",
      "Epoch 1, Batch 42950, Loss: 0.001646646996960044\n",
      "Epoch 1, Batch 43000, Loss: 0.0033028789330273867\n",
      "Epoch 1, Batch 43050, Loss: 0.002691148081794381\n",
      "Epoch 1, Batch 43100, Loss: 0.002802028553560376\n",
      "Epoch 1, Batch 43150, Loss: 0.0027960401494055986\n",
      "Epoch 1, Batch 43200, Loss: 0.002030900912359357\n",
      "Epoch 1, Batch 43250, Loss: 0.37147775292396545\n",
      "Epoch 1, Batch 43300, Loss: 0.0024309654254466295\n",
      "Epoch 1, Batch 43350, Loss: 0.0019464724464341998\n",
      "Epoch 1, Batch 43400, Loss: 0.0021159634925425053\n",
      "Epoch 1, Batch 43450, Loss: 0.0016089919954538345\n",
      "Epoch 1, Batch 43500, Loss: 0.3650026023387909\n",
      "Epoch 1, Batch 43550, Loss: 0.0029882430098950863\n",
      "Epoch 1, Batch 43600, Loss: 0.0027370662428438663\n",
      "Epoch 1, Batch 43650, Loss: 0.0023258645087480545\n",
      "Epoch 1, Batch 43700, Loss: 0.001976791536435485\n",
      "Epoch 1, Batch 43750, Loss: 0.0015536494320258498\n",
      "Epoch 1, Batch 43800, Loss: 0.0028278206009417772\n",
      "Epoch 1, Batch 43850, Loss: 0.0021973438560962677\n",
      "Epoch 1, Batch 43900, Loss: 0.002692037494853139\n",
      "Epoch 1, Batch 43950, Loss: 0.0027945858892053366\n",
      "Epoch 1, Batch 44000, Loss: 0.002410551765933633\n",
      "Epoch 1, Batch 44050, Loss: 0.0018066171323880553\n",
      "Epoch 1, Batch 44100, Loss: 0.0027338387444615364\n",
      "Epoch 1, Batch 44150, Loss: 0.0020600827410817146\n",
      "Epoch 1, Batch 44200, Loss: 0.0023236689157783985\n",
      "Epoch 1, Batch 44250, Loss: 0.00198208331130445\n",
      "Epoch 1, Batch 44300, Loss: 0.0017290714895352721\n",
      "Epoch 1, Batch 44350, Loss: 0.0011740175541490316\n",
      "Epoch 1, Batch 44400, Loss: 0.0017343800282105803\n",
      "Epoch 1, Batch 44450, Loss: 0.0032369252294301987\n",
      "Epoch 1, Batch 44500, Loss: 0.0021598823368549347\n",
      "Epoch 1, Batch 44550, Loss: 0.0028424784541130066\n",
      "Epoch 1, Batch 44600, Loss: 0.0024487681221216917\n",
      "Epoch 1, Batch 44650, Loss: 0.002393190748989582\n",
      "Epoch 1, Batch 44700, Loss: 0.0020426902920007706\n",
      "Epoch 1, Batch 44750, Loss: 0.0029488226864486933\n",
      "Epoch 1, Batch 44800, Loss: 0.0029286083299666643\n",
      "Epoch 1, Batch 44850, Loss: 0.003458344377577305\n",
      "Epoch 1, Batch 44900, Loss: 0.002283661626279354\n",
      "Epoch 1, Batch 44950, Loss: 0.0022279806435108185\n",
      "Epoch 1, Batch 45000, Loss: 0.0023132688365876675\n",
      "Epoch 1, Batch 45050, Loss: 0.002509450074285269\n",
      "Epoch 1, Batch 45100, Loss: 0.0025442338082939386\n",
      "Epoch 1, Batch 45150, Loss: 0.002279173582792282\n",
      "Epoch 1, Batch 45200, Loss: 0.002576875500380993\n",
      "Epoch 1, Batch 45250, Loss: 0.003298782743513584\n",
      "Epoch 1, Batch 45300, Loss: 0.0038873173762112856\n",
      "Epoch 1, Batch 45350, Loss: 0.003934802021831274\n",
      "Epoch 1, Batch 45400, Loss: 0.002846157643944025\n",
      "Epoch 1, Batch 45450, Loss: 0.0017693080008029938\n",
      "Epoch 1, Batch 45500, Loss: 0.0011897464282810688\n",
      "Epoch 1, Batch 45550, Loss: 0.0013199923560023308\n",
      "Epoch 1, Batch 45600, Loss: 0.001708089024759829\n",
      "Epoch 1, Batch 45650, Loss: 0.0030331388115882874\n",
      "Epoch 1, Batch 45700, Loss: 0.0022330235224217176\n",
      "Epoch 1, Batch 45750, Loss: 0.0014586936449632049\n",
      "Epoch 1, Batch 45800, Loss: 0.0015135717112571\n",
      "Epoch 1, Batch 45850, Loss: 0.4536987543106079\n",
      "Epoch 1, Batch 45900, Loss: 0.001521293306723237\n",
      "Epoch 1, Batch 45950, Loss: 0.0014863727847114205\n",
      "Epoch 1, Batch 46000, Loss: 0.40270212292671204\n",
      "Epoch 1, Batch 46050, Loss: 0.3258773982524872\n",
      "Epoch 1, Batch 46100, Loss: 0.003317300695925951\n",
      "Epoch 1, Batch 46150, Loss: 0.0024316394701600075\n",
      "Epoch 1, Batch 46200, Loss: 0.0021951845847070217\n",
      "Epoch 1, Batch 46250, Loss: 0.0020847669802606106\n",
      "Epoch 1, Batch 46300, Loss: 0.002046058187261224\n",
      "Epoch 1, Batch 46350, Loss: 0.0032585894223302603\n",
      "Epoch 1, Batch 46400, Loss: 0.002710306318476796\n",
      "Epoch 1, Batch 46450, Loss: 0.002989287953823805\n",
      "Epoch 1, Batch 46500, Loss: 0.0017694287234917283\n",
      "Epoch 1, Batch 46550, Loss: 0.0014908617595210671\n",
      "Epoch 1, Batch 46600, Loss: 0.0020499106030911207\n",
      "Epoch 1, Batch 46650, Loss: 0.002429057378321886\n",
      "Epoch 1, Batch 46700, Loss: 0.002060989150777459\n",
      "Epoch 1, Batch 46750, Loss: 0.0023331954143941402\n",
      "Epoch 1, Batch 46800, Loss: 0.0036937599070370197\n",
      "Epoch 1, Batch 46850, Loss: 0.004126939922571182\n",
      "Epoch 1, Batch 46900, Loss: 0.0030984727200120687\n",
      "Epoch 1, Batch 46950, Loss: 0.002000190783292055\n",
      "Epoch 1, Batch 47000, Loss: 0.002020953455939889\n",
      "Epoch 1, Batch 47050, Loss: 0.002123206853866577\n",
      "Epoch 1, Batch 47100, Loss: 0.0036907691974192858\n",
      "Epoch 1, Batch 47150, Loss: 0.002554642967879772\n",
      "Epoch 1, Batch 47200, Loss: 0.00328909233212471\n",
      "Epoch 1, Batch 47250, Loss: 0.002177248941734433\n",
      "Epoch 1, Batch 47300, Loss: 0.0028210387099534273\n",
      "Epoch 1, Batch 47350, Loss: 0.003266639309003949\n",
      "Epoch 1, Batch 47400, Loss: 0.0026265361811965704\n",
      "Epoch 1, Batch 47450, Loss: 0.0026836951728910208\n",
      "Epoch 1, Batch 47500, Loss: 0.0022018421441316605\n",
      "Epoch 1, Batch 47550, Loss: 0.002850254764780402\n",
      "Epoch 1, Batch 47600, Loss: 0.0024655060842633247\n",
      "Epoch 1, Batch 47650, Loss: 0.3757912516593933\n",
      "Epoch 1, Batch 47700, Loss: 0.002124709775671363\n",
      "Epoch 1, Batch 47750, Loss: 0.0018976028077304363\n",
      "Epoch 1, Batch 47800, Loss: 0.0019344465108588338\n",
      "Epoch 1, Batch 47850, Loss: 0.002473081462085247\n",
      "Epoch 1, Batch 47900, Loss: 0.002490551909431815\n",
      "Epoch 1, Batch 47950, Loss: 0.0016702228458598256\n",
      "Epoch 1, Batch 48000, Loss: 0.002266816096380353\n",
      "Epoch 1, Batch 48050, Loss: 0.00353568559512496\n",
      "Epoch 1, Batch 48100, Loss: 0.0029173342045396566\n",
      "Epoch 1, Batch 48150, Loss: 0.0028531523421406746\n",
      "Epoch 1, Batch 48200, Loss: 0.0033570546656847\n",
      "Epoch 1, Batch 48250, Loss: 0.0025732037611305714\n",
      "Epoch 1, Batch 48300, Loss: 0.0020789525005966425\n",
      "Epoch 1, Batch 48350, Loss: 0.002426520921289921\n",
      "Epoch 1, Batch 48400, Loss: 0.3716927766799927\n",
      "Epoch 1, Batch 48450, Loss: 0.002378153847530484\n",
      "Epoch 1, Batch 48500, Loss: 0.002334783785045147\n",
      "Epoch 1, Batch 48550, Loss: 0.0033770916052162647\n",
      "Epoch 1, Batch 48600, Loss: 0.002909907605499029\n",
      "Epoch 1, Batch 48650, Loss: 0.003116006962954998\n",
      "Epoch 1, Batch 48700, Loss: 0.0023947274312376976\n",
      "Epoch 1, Batch 48750, Loss: 0.0037289559841156006\n",
      "Epoch 1, Batch 48800, Loss: 0.003851962508633733\n",
      "Epoch 1, Batch 48850, Loss: 0.0022631369065493345\n",
      "Epoch 1, Batch 48900, Loss: 0.00263702729716897\n",
      "Epoch 1, Batch 48950, Loss: 0.004849044606089592\n",
      "Epoch 1, Batch 49000, Loss: 0.005869834218174219\n",
      "Epoch 1, Batch 49050, Loss: 0.002739905845373869\n",
      "Epoch 1, Batch 49100, Loss: 0.0021811737678945065\n",
      "Epoch 1, Batch 49150, Loss: 0.0024885383900254965\n",
      "Epoch 1, Batch 49200, Loss: 0.0020910450257360935\n",
      "Epoch 1, Batch 49250, Loss: 0.0019862744957208633\n",
      "Epoch 1, Batch 49300, Loss: 0.0017834302270784974\n",
      "Epoch 1, Batch 49350, Loss: 0.0013451447011902928\n",
      "Epoch 1, Batch 49400, Loss: 0.0011767816031351686\n",
      "Epoch 1, Batch 49450, Loss: 0.0010892493883147836\n",
      "Epoch 1, Batch 49500, Loss: 0.0007966280682012439\n",
      "Epoch 1, Batch 49550, Loss: 0.0014079365646466613\n",
      "Epoch 1, Batch 49600, Loss: 0.001892830478027463\n",
      "Epoch 1, Batch 49650, Loss: 0.00201980653218925\n",
      "Epoch 1, Batch 49700, Loss: 0.0013062449870631099\n",
      "Epoch 1, Batch 49750, Loss: 0.0017780194757506251\n",
      "Epoch 1, Batch 49800, Loss: 0.0019338816637173295\n",
      "Epoch 1, Batch 49850, Loss: 0.002185173099860549\n",
      "Epoch 1, Batch 49900, Loss: 0.0018580751493573189\n",
      "Epoch 1, Batch 49950, Loss: 0.0018969017546623945\n",
      "Epoch 1, Batch 50000, Loss: 0.001595978974364698\n",
      "Epoch 1, Batch 50050, Loss: 0.0019084124360233545\n",
      "Epoch 1, Batch 50100, Loss: 0.0025072835851460695\n",
      "Epoch 1, Batch 50150, Loss: 0.001441851374693215\n",
      "Epoch 1, Batch 50200, Loss: 0.001536648254841566\n",
      "Epoch 1, Batch 50250, Loss: 0.001918287598527968\n",
      "Epoch 1, Batch 50300, Loss: 0.002061303937807679\n",
      "Epoch 1, Batch 50350, Loss: 0.002051937161013484\n",
      "Epoch 1, Batch 50400, Loss: 0.002334544900804758\n",
      "Epoch 1, Batch 50450, Loss: 0.003125075250864029\n",
      "Epoch 1, Batch 50500, Loss: 0.0026619501877576113\n",
      "Epoch 1, Batch 50550, Loss: 0.002099735662341118\n",
      "Epoch 1, Batch 50600, Loss: 0.001648966339416802\n",
      "Epoch 1, Batch 50650, Loss: 0.002864454872906208\n",
      "Epoch 1, Batch 50700, Loss: 0.0024861132260411978\n",
      "Epoch 1, Batch 50750, Loss: 0.004313833545893431\n",
      "Epoch 1, Batch 50800, Loss: 0.0037621748633682728\n",
      "Epoch 1, Batch 50850, Loss: 0.002837212523445487\n",
      "Epoch 1, Batch 50900, Loss: 0.0026555012445896864\n",
      "Epoch 1, Batch 50950, Loss: 0.0016796966083347797\n",
      "Epoch 1, Batch 51000, Loss: 0.002410624176263809\n",
      "Epoch 1, Batch 51050, Loss: 0.3620885908603668\n",
      "Epoch 1, Batch 51100, Loss: 0.0024069654755294323\n",
      "Epoch 1, Batch 51150, Loss: 0.002046487294137478\n",
      "Epoch 1, Batch 51200, Loss: 0.0023886184208095074\n",
      "Epoch 1, Batch 51250, Loss: 0.004731375724077225\n",
      "Epoch 1, Batch 51300, Loss: 0.0042596235871315\n",
      "Epoch 1, Batch 51350, Loss: 0.002418265212327242\n",
      "Epoch 1, Batch 51400, Loss: 0.0019511388381943107\n",
      "Epoch 1, Batch 51450, Loss: 0.0016795983538031578\n",
      "Epoch 1, Batch 51500, Loss: 0.0022146785631775856\n",
      "Epoch 1, Batch 51550, Loss: 0.002725779777392745\n",
      "Epoch 1, Batch 51600, Loss: 0.002297467552125454\n",
      "Epoch 1, Batch 51650, Loss: 0.0021789888851344585\n",
      "Epoch 1, Batch 51700, Loss: 0.002879004692658782\n",
      "Epoch 1, Batch 51750, Loss: 0.00238655973225832\n",
      "Epoch 1, Batch 51800, Loss: 0.0022949385456740856\n",
      "Epoch 1, Batch 51850, Loss: 0.0029094747733324766\n",
      "Epoch 1, Batch 51900, Loss: 0.0036899952683597803\n",
      "Epoch 1, Batch 51950, Loss: 0.002834357786923647\n",
      "Epoch 1, Batch 52000, Loss: 0.0020841872319579124\n",
      "Epoch 1, Batch 52050, Loss: 0.0018094193655997515\n",
      "Epoch 1, Batch 52100, Loss: 0.0018395964289084077\n",
      "Epoch 1, Batch 52150, Loss: 0.002803526818752289\n",
      "Epoch 1, Batch 52200, Loss: 0.0018839798867702484\n",
      "Epoch 1, Batch 52250, Loss: 0.3932012915611267\n",
      "Epoch 1, Batch 52300, Loss: 0.0024950660299509764\n",
      "Epoch 1, Batch 52350, Loss: 0.0037932980339974165\n",
      "Epoch 1, Batch 52400, Loss: 0.0022915424779057503\n",
      "Epoch 1, Batch 52450, Loss: 0.003128188196569681\n",
      "Epoch 1, Batch 52500, Loss: 0.0031586778350174427\n",
      "Epoch 1, Batch 52550, Loss: 0.002351907780393958\n",
      "Epoch 1, Batch 52600, Loss: 0.00438427459448576\n",
      "Epoch 1, Batch 52650, Loss: 0.004224286414682865\n",
      "Epoch 1, Batch 52700, Loss: 0.0028022248297929764\n",
      "Epoch 1, Batch 52750, Loss: 0.0024823907297104597\n",
      "Epoch 1, Batch 52800, Loss: 0.3519389033317566\n",
      "Epoch 1, Batch 52850, Loss: 0.004973041359335184\n",
      "Epoch 1, Batch 52900, Loss: 0.005657344590872526\n",
      "Epoch 1, Batch 52950, Loss: 0.003841700730845332\n",
      "Epoch 1, Batch 53000, Loss: 0.003471347503364086\n",
      "Epoch 1, Batch 53050, Loss: 0.003001135541126132\n",
      "Epoch 1, Batch 53100, Loss: 0.0029939301311969757\n",
      "Epoch 1, Batch 53150, Loss: 0.0029809935949742794\n",
      "Epoch 1, Batch 53200, Loss: 0.0022741251159459352\n",
      "Epoch 1, Batch 53250, Loss: 0.0019902477506548166\n",
      "Epoch 1, Batch 53300, Loss: 0.0015038272831588984\n",
      "Epoch 1, Batch 53350, Loss: 0.002255156869068742\n",
      "Epoch 1, Batch 53400, Loss: 0.003110297955572605\n",
      "Epoch 1, Batch 53450, Loss: 0.001998489024117589\n",
      "Epoch 1, Batch 53500, Loss: 0.0025924923829734325\n",
      "Epoch 1, Batch 53550, Loss: 0.002644738182425499\n",
      "Epoch 1, Batch 53600, Loss: 0.003487973241135478\n",
      "Epoch 1, Batch 53650, Loss: 0.003391456324607134\n",
      "Epoch 1, Batch 53700, Loss: 0.0033118566498160362\n",
      "Epoch 1, Batch 53750, Loss: 0.003609929932281375\n",
      "Epoch 1, Batch 53800, Loss: 0.00317266583442688\n",
      "Epoch 1, Batch 53850, Loss: 0.0022625362034887075\n",
      "Epoch 1, Batch 53900, Loss: 0.001975748687982559\n",
      "Epoch 1, Batch 53950, Loss: 0.0018167149974033237\n",
      "Epoch 1, Batch 54000, Loss: 0.002396141644567251\n",
      "Epoch 1, Batch 54050, Loss: 0.0019438095623627305\n",
      "Epoch 1, Batch 54100, Loss: 0.002514356980100274\n",
      "Epoch 1, Batch 54150, Loss: 0.0021555041894316673\n",
      "Epoch 1, Batch 54200, Loss: 0.0024536363780498505\n",
      "Epoch 1, Batch 54250, Loss: 0.0016816692659631371\n",
      "Epoch 1, Batch 54300, Loss: 0.0018878106493502855\n",
      "Epoch 1, Batch 54350, Loss: 0.002437383169308305\n",
      "Epoch 1, Batch 54400, Loss: 0.0014505869476124644\n",
      "Epoch 1, Batch 54450, Loss: 0.0018097287975251675\n",
      "Epoch 1, Batch 54500, Loss: 0.00178628193680197\n",
      "Epoch 1, Batch 54550, Loss: 0.002971822861582041\n",
      "Epoch 1, Batch 54600, Loss: 0.002643476938828826\n",
      "Epoch 1, Batch 54650, Loss: 0.002693577902391553\n",
      "Epoch 1, Batch 54700, Loss: 0.0015862100990489125\n",
      "Epoch 1, Batch 54750, Loss: 0.002201433526352048\n",
      "Epoch 1, Batch 54800, Loss: 0.002637762576341629\n",
      "Epoch 1, Batch 54850, Loss: 0.0033567738719284534\n",
      "Epoch 1, Batch 54900, Loss: 0.38596946001052856\n",
      "Epoch 1, Batch 54950, Loss: 0.003984465263783932\n",
      "Epoch 1, Batch 55000, Loss: 0.004573306068778038\n",
      "Epoch 1, Batch 55050, Loss: 0.0026224427856504917\n",
      "Epoch 1, Batch 55100, Loss: 0.0022173007018864155\n",
      "Epoch 1, Batch 55150, Loss: 0.002616588259115815\n",
      "Epoch 1, Batch 55200, Loss: 0.0029198136180639267\n",
      "Epoch 1, Batch 55250, Loss: 0.0034524535294622183\n",
      "Epoch 1, Batch 55300, Loss: 0.0037756357342004776\n",
      "Epoch 1, Batch 55350, Loss: 0.006123744882643223\n",
      "Epoch 1, Batch 55400, Loss: 0.004149348009377718\n",
      "Epoch 1, Batch 55450, Loss: 0.0029657420236617327\n",
      "Epoch 1, Batch 55500, Loss: 0.0031995102763175964\n",
      "Epoch 1, Batch 55550, Loss: 0.002516739768907428\n",
      "Epoch 1, Batch 55600, Loss: 0.0030738292261958122\n",
      "Epoch 1, Batch 55650, Loss: 0.0025388228241354227\n",
      "Epoch 1, Batch 55700, Loss: 0.005001059267669916\n",
      "Epoch 1, Batch 55750, Loss: 0.0035168929025530815\n",
      "Epoch 1, Batch 55800, Loss: 0.002317931968718767\n",
      "Epoch 1, Batch 55850, Loss: 0.0022141793742775917\n",
      "Epoch 1, Batch 55900, Loss: 0.0026613124646246433\n",
      "Epoch 1, Batch 55950, Loss: 0.385302871465683\n",
      "Epoch 1, Batch 56000, Loss: 0.004111702553927898\n",
      "Epoch 1, Batch 56050, Loss: 0.003581403288990259\n",
      "Epoch 1, Batch 56100, Loss: 0.0026704552583396435\n",
      "Epoch 1, Batch 56150, Loss: 0.0018976079300045967\n",
      "Epoch 1, Batch 56200, Loss: 0.00182332971598953\n",
      "Epoch 1, Batch 56250, Loss: 0.002612927695736289\n",
      "Epoch 2, Batch 50, Loss: 0.002734127454459667\n",
      "Epoch 2, Batch 100, Loss: 0.0018556423019617796\n",
      "Epoch 2, Batch 150, Loss: 0.00130429957062006\n",
      "Epoch 2, Batch 200, Loss: 0.00170027872081846\n",
      "Epoch 2, Batch 250, Loss: 0.0015944739570841193\n",
      "Epoch 2, Batch 300, Loss: 0.0024202463682740927\n",
      "Epoch 2, Batch 350, Loss: 0.004360813647508621\n",
      "Epoch 2, Batch 400, Loss: 0.0034089612308889627\n",
      "Epoch 2, Batch 450, Loss: 0.0031637707725167274\n",
      "Epoch 2, Batch 500, Loss: 0.0027992278337478638\n",
      "Epoch 2, Batch 550, Loss: 0.002588770817965269\n",
      "Epoch 2, Batch 600, Loss: 0.00225464696995914\n",
      "Epoch 2, Batch 650, Loss: 0.0018277402268722653\n",
      "Epoch 2, Batch 700, Loss: 0.0017223815666511655\n",
      "Epoch 2, Batch 750, Loss: 0.002480260096490383\n",
      "Epoch 2, Batch 800, Loss: 0.0025739576667547226\n",
      "Epoch 2, Batch 850, Loss: 0.0028040322940796614\n",
      "Epoch 2, Batch 900, Loss: 0.0018372641643509269\n",
      "Epoch 2, Batch 950, Loss: 0.0015925118932500482\n",
      "Epoch 2, Batch 1000, Loss: 0.0014585251919925213\n",
      "Epoch 2, Batch 1050, Loss: 0.001198908081278205\n",
      "Epoch 2, Batch 1100, Loss: 0.002369249938055873\n",
      "Epoch 2, Batch 1150, Loss: 0.0027617665473371744\n",
      "Epoch 2, Batch 1200, Loss: 0.0027588605880737305\n",
      "Epoch 2, Batch 1250, Loss: 0.0019940687343478203\n",
      "Epoch 2, Batch 1300, Loss: 0.002009698888286948\n",
      "Epoch 2, Batch 1350, Loss: 0.3946916162967682\n",
      "Epoch 2, Batch 1400, Loss: 0.0020210188813507557\n",
      "Epoch 2, Batch 1450, Loss: 0.002129777567461133\n",
      "Epoch 2, Batch 1500, Loss: 0.0019524109084159136\n",
      "Epoch 2, Batch 1550, Loss: 0.002291338052600622\n",
      "Epoch 2, Batch 1600, Loss: 0.0022043257486075163\n",
      "Epoch 2, Batch 1650, Loss: 0.002475120360031724\n",
      "Epoch 2, Batch 1700, Loss: 0.002173176035284996\n",
      "Epoch 2, Batch 1750, Loss: 0.0020323465578258038\n",
      "Epoch 2, Batch 1800, Loss: 0.0028493006248027086\n",
      "Epoch 2, Batch 1850, Loss: 0.0047839004546403885\n",
      "Epoch 2, Batch 1900, Loss: 0.002818418201059103\n",
      "Epoch 2, Batch 1950, Loss: 0.0022580239456146955\n",
      "Epoch 2, Batch 2000, Loss: 0.002734446432441473\n",
      "Epoch 2, Batch 2050, Loss: 0.0026233240496367216\n",
      "Epoch 2, Batch 2100, Loss: 0.0023509999737143517\n",
      "Epoch 2, Batch 2150, Loss: 0.0020865369588136673\n",
      "Epoch 2, Batch 2200, Loss: 0.004089738242328167\n",
      "Epoch 2, Batch 2250, Loss: 0.0033512944355607033\n",
      "Epoch 2, Batch 2300, Loss: 0.004381941165775061\n",
      "Epoch 2, Batch 2350, Loss: 0.005390044767409563\n",
      "Epoch 2, Batch 2400, Loss: 0.0034361400175839663\n",
      "Epoch 2, Batch 2450, Loss: 0.003675332758575678\n",
      "Epoch 2, Batch 2500, Loss: 0.0028113964945077896\n",
      "Epoch 2, Batch 2550, Loss: 0.00198059668764472\n",
      "Epoch 2, Batch 2600, Loss: 0.0016826681094244123\n",
      "Epoch 2, Batch 2650, Loss: 0.0014188536442816257\n",
      "Epoch 2, Batch 2700, Loss: 0.0019158711656928062\n",
      "Epoch 2, Batch 2750, Loss: 0.0016512144356966019\n",
      "Epoch 2, Batch 2800, Loss: 0.0020492111798375845\n",
      "Epoch 2, Batch 2850, Loss: 0.0021723401732742786\n",
      "Epoch 2, Batch 2900, Loss: 0.0020657768473029137\n",
      "Epoch 2, Batch 2950, Loss: 0.0034605055116117\n",
      "Epoch 2, Batch 3000, Loss: 0.0027970520313829184\n",
      "Epoch 2, Batch 3050, Loss: 0.003574511967599392\n",
      "Epoch 2, Batch 3100, Loss: 0.0026014228351414204\n",
      "Epoch 2, Batch 3150, Loss: 0.0029888495337218046\n",
      "Epoch 2, Batch 3200, Loss: 0.0024114951957017183\n",
      "Epoch 2, Batch 3250, Loss: 0.0017872164025902748\n",
      "Epoch 2, Batch 3300, Loss: 0.0026631816290318966\n",
      "Epoch 2, Batch 3350, Loss: 0.0025042120832949877\n",
      "Epoch 2, Batch 3400, Loss: 0.0021882501896470785\n",
      "Epoch 2, Batch 3450, Loss: 0.0026831154245883226\n",
      "Epoch 2, Batch 3500, Loss: 0.003136466722935438\n",
      "Epoch 2, Batch 3550, Loss: 0.005676715634763241\n",
      "Epoch 2, Batch 3600, Loss: 0.004633477423340082\n",
      "Epoch 2, Batch 3650, Loss: 0.003102386137470603\n",
      "Epoch 2, Batch 3700, Loss: 0.0023567057214677334\n",
      "Epoch 2, Batch 3750, Loss: 0.0018257650081068277\n",
      "Epoch 2, Batch 3800, Loss: 0.0026015674229711294\n",
      "Epoch 2, Batch 3850, Loss: 0.001960989087820053\n",
      "Epoch 2, Batch 3900, Loss: 0.0023402187507599592\n",
      "Epoch 2, Batch 3950, Loss: 0.0018947531934827566\n",
      "Epoch 2, Batch 4000, Loss: 0.0012471320806071162\n",
      "Epoch 2, Batch 4050, Loss: 0.0013033525319769979\n",
      "Epoch 2, Batch 4100, Loss: 0.001126149669289589\n",
      "Epoch 2, Batch 4150, Loss: 0.001020470866933465\n",
      "Epoch 2, Batch 4200, Loss: 0.0023837764747440815\n",
      "Epoch 2, Batch 4250, Loss: 0.0031583313830196857\n",
      "Epoch 2, Batch 4300, Loss: 0.0021959857549518347\n",
      "Epoch 2, Batch 4350, Loss: 0.002686105202883482\n",
      "Epoch 2, Batch 4400, Loss: 0.004028197377920151\n",
      "Epoch 2, Batch 4450, Loss: 0.0028608478605747223\n",
      "Epoch 2, Batch 4500, Loss: 0.0022557945922017097\n",
      "Epoch 2, Batch 4550, Loss: 0.001697285333648324\n",
      "Epoch 2, Batch 4600, Loss: 0.0013948003761470318\n",
      "Epoch 2, Batch 4650, Loss: 0.0014738255413249135\n",
      "Epoch 2, Batch 4700, Loss: 0.0019076007883995771\n",
      "Epoch 2, Batch 4750, Loss: 0.0015707070706412196\n",
      "Epoch 2, Batch 4800, Loss: 0.0023887320421636105\n",
      "Epoch 2, Batch 4850, Loss: 0.003508137771859765\n",
      "Epoch 2, Batch 4900, Loss: 0.0034140092320740223\n",
      "Epoch 2, Batch 4950, Loss: 0.0021540855523198843\n",
      "Epoch 2, Batch 5000, Loss: 0.3930245637893677\n",
      "Epoch 2, Batch 5050, Loss: 0.0028499383479356766\n",
      "Epoch 2, Batch 5100, Loss: 0.001910346676595509\n",
      "Epoch 2, Batch 5150, Loss: 0.0016715603414922953\n",
      "Epoch 2, Batch 5200, Loss: 0.0025017510633915663\n",
      "Epoch 2, Batch 5250, Loss: 0.0021554362028837204\n",
      "Epoch 2, Batch 5300, Loss: 0.0025128424167633057\n",
      "Epoch 2, Batch 5350, Loss: 0.0025769344065338373\n",
      "Epoch 2, Batch 5400, Loss: 0.002944995416328311\n",
      "Epoch 2, Batch 5450, Loss: 0.0028683061245828867\n",
      "Epoch 2, Batch 5500, Loss: 0.002819431247189641\n",
      "Epoch 2, Batch 5550, Loss: 0.3699389398097992\n",
      "Epoch 2, Batch 5600, Loss: 0.0035367212258279324\n",
      "Epoch 2, Batch 5650, Loss: 0.003213123884052038\n",
      "Epoch 2, Batch 5700, Loss: 0.0024952066596597433\n",
      "Epoch 2, Batch 5750, Loss: 0.0021242962684482336\n",
      "Epoch 2, Batch 5800, Loss: 0.002538870321586728\n",
      "Epoch 2, Batch 5850, Loss: 0.0035778656601905823\n",
      "Epoch 2, Batch 5900, Loss: 0.003263142192736268\n",
      "Epoch 2, Batch 5950, Loss: 0.0019856300204992294\n",
      "Epoch 2, Batch 6000, Loss: 0.002674996852874756\n",
      "Epoch 2, Batch 6050, Loss: 0.3648320138454437\n",
      "Epoch 2, Batch 6100, Loss: 0.0023281890898942947\n",
      "Epoch 2, Batch 6150, Loss: 0.0019799573346972466\n",
      "Epoch 2, Batch 6200, Loss: 0.0022166981361806393\n",
      "Epoch 2, Batch 6250, Loss: 0.002597662853077054\n",
      "Epoch 2, Batch 6300, Loss: 0.002654358511790633\n",
      "Epoch 2, Batch 6350, Loss: 0.002142450539395213\n",
      "Epoch 2, Batch 6400, Loss: 0.0018083022441715002\n",
      "Epoch 2, Batch 6450, Loss: 0.002432764507830143\n",
      "Epoch 2, Batch 6500, Loss: 0.0030596598517149687\n",
      "Epoch 2, Batch 6550, Loss: 0.0029722501058131456\n",
      "Epoch 2, Batch 6600, Loss: 0.0019375013653188944\n",
      "Epoch 2, Batch 6650, Loss: 0.0016369214281439781\n",
      "Epoch 2, Batch 6700, Loss: 0.0021999862510710955\n",
      "Epoch 2, Batch 6750, Loss: 0.0015825987793505192\n",
      "Epoch 2, Batch 6800, Loss: 0.0016516235191375017\n",
      "Epoch 2, Batch 6850, Loss: 0.0017610871000215411\n",
      "Epoch 2, Batch 6900, Loss: 0.002704968210309744\n",
      "Epoch 2, Batch 6950, Loss: 0.002315412973985076\n",
      "Epoch 2, Batch 7000, Loss: 0.0018099689623340964\n",
      "Epoch 2, Batch 7050, Loss: 0.0018022592412307858\n",
      "Epoch 2, Batch 7100, Loss: 0.002620543586090207\n",
      "Epoch 2, Batch 7150, Loss: 0.002305180300027132\n",
      "Epoch 2, Batch 7200, Loss: 0.0032343873754143715\n",
      "Epoch 2, Batch 7250, Loss: 0.0030435980297625065\n",
      "Epoch 2, Batch 7300, Loss: 0.003053035121411085\n",
      "Epoch 2, Batch 7350, Loss: 0.0033381159882992506\n",
      "Epoch 2, Batch 7400, Loss: 0.0026310477405786514\n",
      "Epoch 2, Batch 7450, Loss: 0.002655028598383069\n",
      "Epoch 2, Batch 7500, Loss: 0.0034044424537569284\n",
      "Epoch 2, Batch 7550, Loss: 0.0022468869574368\n",
      "Epoch 2, Batch 7600, Loss: 0.0026659348513931036\n",
      "Epoch 2, Batch 7650, Loss: 0.004983748309314251\n",
      "Epoch 2, Batch 7700, Loss: 0.003531691851094365\n",
      "Epoch 2, Batch 7750, Loss: 0.0032744845375418663\n",
      "Epoch 2, Batch 7800, Loss: 0.007315094117075205\n",
      "Epoch 2, Batch 7850, Loss: 0.004640469327569008\n",
      "Epoch 2, Batch 7900, Loss: 0.0029491062741726637\n",
      "Epoch 2, Batch 7950, Loss: 0.003035839181393385\n",
      "Epoch 2, Batch 8000, Loss: 0.002199058188125491\n",
      "Epoch 2, Batch 8050, Loss: 0.002521228976547718\n",
      "Epoch 2, Batch 8100, Loss: 0.002295898739248514\n",
      "Epoch 2, Batch 8150, Loss: 0.0018287845887243748\n",
      "Epoch 2, Batch 8200, Loss: 0.0014763687504455447\n",
      "Epoch 2, Batch 8250, Loss: 0.0021743488032370806\n",
      "Epoch 2, Batch 8300, Loss: 0.0024855216033756733\n",
      "Epoch 2, Batch 8350, Loss: 0.0027157561853528023\n",
      "Epoch 2, Batch 8400, Loss: 0.004668073728680611\n",
      "Epoch 2, Batch 8450, Loss: 0.0032670162618160248\n",
      "Epoch 2, Batch 8500, Loss: 0.0028727941680699587\n",
      "Epoch 2, Batch 8550, Loss: 0.002503472613170743\n",
      "Epoch 2, Batch 8600, Loss: 0.002518284833058715\n",
      "Epoch 2, Batch 8650, Loss: 0.0020108220633119345\n",
      "Epoch 2, Batch 8700, Loss: 0.002125529106706381\n",
      "Epoch 2, Batch 8750, Loss: 0.0019181129755452275\n",
      "Epoch 2, Batch 8800, Loss: 0.002133564092218876\n",
      "Epoch 2, Batch 8850, Loss: 0.0018893604865297675\n",
      "Epoch 2, Batch 8900, Loss: 0.0022675064392387867\n",
      "Epoch 2, Batch 8950, Loss: 0.002364793326705694\n",
      "Epoch 2, Batch 9000, Loss: 0.0018318836810067296\n",
      "Epoch 2, Batch 9050, Loss: 0.38472065329551697\n",
      "Epoch 2, Batch 9100, Loss: 0.0013519618660211563\n",
      "Epoch 2, Batch 9150, Loss: 0.0013745857868343592\n",
      "Epoch 2, Batch 9200, Loss: 0.0012131575495004654\n",
      "Epoch 2, Batch 9250, Loss: 0.0012409474002197385\n",
      "Epoch 2, Batch 9300, Loss: 0.0021514417603611946\n",
      "Epoch 2, Batch 9350, Loss: 0.0018387895543128252\n",
      "Epoch 2, Batch 9400, Loss: 0.0020733699202537537\n",
      "Epoch 2, Batch 9450, Loss: 0.002658558078110218\n",
      "Epoch 2, Batch 9500, Loss: 0.002577277598902583\n",
      "Epoch 2, Batch 9550, Loss: 0.0024539281148463488\n",
      "Epoch 2, Batch 9600, Loss: 0.0024880855344235897\n",
      "Epoch 2, Batch 9650, Loss: 0.001662195660173893\n",
      "Epoch 2, Batch 9700, Loss: 0.0021392914932221174\n",
      "Epoch 2, Batch 9750, Loss: 0.002352283801883459\n",
      "Epoch 2, Batch 9800, Loss: 0.0016882999334484339\n",
      "Epoch 2, Batch 9850, Loss: 0.002400387078523636\n",
      "Epoch 2, Batch 9900, Loss: 0.002337739337235689\n",
      "Epoch 2, Batch 9950, Loss: 0.0026419919449836016\n",
      "Epoch 2, Batch 10000, Loss: 0.0016925281379371881\n",
      "Epoch 2, Batch 10050, Loss: 0.002297450555488467\n",
      "Epoch 2, Batch 10100, Loss: 0.0029127593152225018\n",
      "Epoch 2, Batch 10150, Loss: 0.0020976962987333536\n",
      "Epoch 2, Batch 10200, Loss: 0.0021567901130765676\n",
      "Epoch 2, Batch 10250, Loss: 0.0020097587257623672\n",
      "Epoch 2, Batch 10300, Loss: 0.0021968199871480465\n",
      "Epoch 2, Batch 10350, Loss: 0.0033412633929401636\n",
      "Epoch 2, Batch 10400, Loss: 0.002348535694181919\n",
      "Epoch 2, Batch 10450, Loss: 0.0038368862587958574\n",
      "Epoch 2, Batch 10500, Loss: 0.004539423622190952\n",
      "Epoch 2, Batch 10550, Loss: 0.0028321389108896255\n",
      "Epoch 2, Batch 10600, Loss: 0.0026328680105507374\n",
      "Epoch 2, Batch 10650, Loss: 0.001978525659069419\n",
      "Epoch 2, Batch 10700, Loss: 0.0041644880548119545\n",
      "Epoch 2, Batch 10750, Loss: 0.0038040566723793745\n",
      "Epoch 2, Batch 10800, Loss: 0.002780401613563299\n",
      "Epoch 2, Batch 10850, Loss: 0.0025094090960919857\n",
      "Epoch 2, Batch 10900, Loss: 0.002343592466786504\n",
      "Epoch 2, Batch 10950, Loss: 0.0020077480003237724\n",
      "Epoch 2, Batch 11000, Loss: 0.003060390008613467\n",
      "Epoch 2, Batch 11050, Loss: 0.001984282862395048\n",
      "Epoch 2, Batch 11100, Loss: 0.0018995332065969706\n",
      "Epoch 2, Batch 11150, Loss: 0.0016820365563035011\n",
      "Epoch 2, Batch 11200, Loss: 0.0024336872156709433\n",
      "Epoch 2, Batch 11250, Loss: 0.0025057026650756598\n",
      "Epoch 2, Batch 11300, Loss: 0.001716615166515112\n",
      "Epoch 2, Batch 11350, Loss: 0.0012664917157962918\n",
      "Epoch 2, Batch 11400, Loss: 0.0013013128191232681\n",
      "Epoch 2, Batch 11450, Loss: 0.0009712919127196074\n",
      "Epoch 2, Batch 11500, Loss: 0.0008326552924700081\n",
      "Epoch 2, Batch 11550, Loss: 0.0013583478284999728\n",
      "Epoch 2, Batch 11600, Loss: 0.001540647353976965\n",
      "Epoch 2, Batch 11650, Loss: 0.0017138756811618805\n",
      "Epoch 2, Batch 11700, Loss: 0.0012710654409602284\n",
      "Epoch 2, Batch 11750, Loss: 0.0023253685794770718\n",
      "Epoch 2, Batch 11800, Loss: 0.0021801264956593513\n",
      "Epoch 2, Batch 11850, Loss: 0.0029960181564092636\n",
      "Epoch 2, Batch 11900, Loss: 0.0022481828927993774\n",
      "Epoch 2, Batch 11950, Loss: 0.0013979630311951041\n",
      "Epoch 2, Batch 12000, Loss: 0.001224577659741044\n",
      "Epoch 2, Batch 12050, Loss: 0.0016398008447140455\n",
      "Epoch 2, Batch 12100, Loss: 0.0010675335070118308\n",
      "Epoch 2, Batch 12150, Loss: 0.001297515002079308\n",
      "Epoch 2, Batch 12200, Loss: 0.0012815621448680758\n",
      "Epoch 2, Batch 12250, Loss: 0.001990636344999075\n",
      "Epoch 2, Batch 12300, Loss: 0.0029688950162380934\n",
      "Epoch 2, Batch 12350, Loss: 0.0023658182471990585\n",
      "Epoch 2, Batch 12400, Loss: 0.002368602668866515\n",
      "Epoch 2, Batch 12450, Loss: 0.002064085565507412\n",
      "Epoch 2, Batch 12500, Loss: 0.002464406890794635\n",
      "Epoch 2, Batch 12550, Loss: 0.002310279058292508\n",
      "Epoch 2, Batch 12600, Loss: 0.0020238859578967094\n",
      "Epoch 2, Batch 12650, Loss: 0.0020968702156096697\n",
      "Epoch 2, Batch 12700, Loss: 0.0021462596487253904\n",
      "Epoch 2, Batch 12750, Loss: 0.003959516063332558\n",
      "Epoch 2, Batch 12800, Loss: 0.0038356769364327192\n",
      "Epoch 2, Batch 12850, Loss: 0.004861811641603708\n",
      "Epoch 2, Batch 12900, Loss: 0.0039263018406927586\n",
      "Epoch 2, Batch 12950, Loss: 0.005690236575901508\n",
      "Epoch 2, Batch 13000, Loss: 0.004388107918202877\n",
      "Epoch 2, Batch 13050, Loss: 0.0031230628956109285\n",
      "Epoch 2, Batch 13100, Loss: 0.0030889310874044895\n",
      "Epoch 2, Batch 13150, Loss: 0.0029693490359932184\n",
      "Epoch 2, Batch 13200, Loss: 0.004436070099473\n",
      "Epoch 2, Batch 13250, Loss: 0.002406707499176264\n",
      "Epoch 2, Batch 13300, Loss: 0.002457090187817812\n",
      "Epoch 2, Batch 13350, Loss: 0.002889912575483322\n",
      "Epoch 2, Batch 13400, Loss: 0.002334585413336754\n",
      "Epoch 2, Batch 13450, Loss: 0.0021563658956438303\n",
      "Epoch 2, Batch 13500, Loss: 0.002736293012276292\n",
      "Epoch 2, Batch 13550, Loss: 0.0020478733349591494\n",
      "Epoch 2, Batch 13600, Loss: 0.001581071293912828\n",
      "Epoch 2, Batch 13650, Loss: 0.002548657124862075\n",
      "Epoch 2, Batch 13700, Loss: 0.004441932309418917\n",
      "Epoch 2, Batch 13750, Loss: 0.004546368960291147\n",
      "Epoch 2, Batch 13800, Loss: 0.36880722641944885\n",
      "Epoch 2, Batch 13850, Loss: 0.004366988781839609\n",
      "Epoch 2, Batch 13900, Loss: 0.0028140340000391006\n",
      "Epoch 2, Batch 13950, Loss: 0.002187273232266307\n",
      "Epoch 2, Batch 14000, Loss: 0.0020636660046875477\n",
      "Epoch 2, Batch 14050, Loss: 0.0020073573105037212\n",
      "Epoch 2, Batch 14100, Loss: 0.0022307096514850855\n",
      "Epoch 2, Batch 14150, Loss: 0.002222091890871525\n",
      "Epoch 2, Batch 14200, Loss: 0.0033972139935940504\n",
      "Epoch 2, Batch 14250, Loss: 0.0027798733208328485\n",
      "Epoch 2, Batch 14300, Loss: 0.002027715789154172\n",
      "Epoch 2, Batch 14350, Loss: 0.0021706721745431423\n",
      "Epoch 2, Batch 14400, Loss: 0.0025433884002268314\n",
      "Epoch 2, Batch 14450, Loss: 0.00183633784763515\n",
      "Epoch 2, Batch 14500, Loss: 0.003099598689004779\n",
      "Epoch 2, Batch 14550, Loss: 0.0034106469247490168\n",
      "Epoch 2, Batch 14600, Loss: 0.002924218075349927\n",
      "Epoch 2, Batch 14650, Loss: 0.003150944598019123\n",
      "Epoch 2, Batch 14700, Loss: 0.0024797627702355385\n",
      "Epoch 2, Batch 14750, Loss: 0.002611196367070079\n",
      "Epoch 2, Batch 14800, Loss: 0.002977284835651517\n",
      "Epoch 2, Batch 14850, Loss: 0.0032937799114733934\n",
      "Epoch 2, Batch 14900, Loss: 0.0032891114242374897\n",
      "Epoch 2, Batch 14950, Loss: 0.002485420322045684\n",
      "Epoch 2, Batch 15000, Loss: 0.0025349778588861227\n",
      "Epoch 2, Batch 15050, Loss: 0.0021838608663529158\n",
      "Epoch 2, Batch 15100, Loss: 0.001947871409356594\n",
      "Epoch 2, Batch 15150, Loss: 0.0025730333290994167\n",
      "Epoch 2, Batch 15200, Loss: 0.002714127069339156\n",
      "Epoch 2, Batch 15250, Loss: 0.0034186081029474735\n",
      "Epoch 2, Batch 15300, Loss: 0.002887635724619031\n",
      "Epoch 2, Batch 15350, Loss: 0.0030915786046534777\n",
      "Epoch 2, Batch 15400, Loss: 0.0033910584170371294\n",
      "Epoch 2, Batch 15450, Loss: 0.0024211567360907793\n",
      "Epoch 2, Batch 15500, Loss: 0.0021743287798017263\n",
      "Epoch 2, Batch 15550, Loss: 0.0028172910679131746\n",
      "Epoch 2, Batch 15600, Loss: 0.003349907463416457\n",
      "Epoch 2, Batch 15650, Loss: 0.002891553333029151\n",
      "Epoch 2, Batch 15700, Loss: 0.002724839374423027\n",
      "Epoch 2, Batch 15750, Loss: 0.0020272727124392986\n",
      "Epoch 2, Batch 15800, Loss: 0.002264424692839384\n",
      "Epoch 2, Batch 15850, Loss: 0.0022694391664117575\n",
      "Epoch 2, Batch 15900, Loss: 0.0020760821644216776\n",
      "Epoch 2, Batch 15950, Loss: 0.002673801966011524\n",
      "Epoch 2, Batch 16000, Loss: 0.002145068719983101\n",
      "Epoch 2, Batch 16050, Loss: 0.0020797208417207003\n",
      "Epoch 2, Batch 16100, Loss: 0.001916425651870668\n",
      "Epoch 2, Batch 16150, Loss: 0.0033880879636853933\n",
      "Epoch 2, Batch 16200, Loss: 0.003710282500833273\n",
      "Epoch 2, Batch 16250, Loss: 0.0021776168141514063\n",
      "Epoch 2, Batch 16300, Loss: 0.001787157030776143\n",
      "Epoch 2, Batch 16350, Loss: 0.0017013081815093756\n",
      "Epoch 2, Batch 16400, Loss: 0.0019233082421123981\n",
      "Epoch 2, Batch 16450, Loss: 0.003094644518569112\n",
      "Epoch 2, Batch 16500, Loss: 0.0026839005295187235\n",
      "Epoch 2, Batch 16550, Loss: 0.0028828352224081755\n",
      "Epoch 2, Batch 16600, Loss: 0.0030545140616595745\n",
      "Epoch 2, Batch 16650, Loss: 0.0021332777105271816\n",
      "Epoch 2, Batch 16700, Loss: 0.003212088020518422\n",
      "Epoch 2, Batch 16750, Loss: 0.0030783950351178646\n",
      "Epoch 2, Batch 16800, Loss: 0.0031221448443830013\n",
      "Epoch 2, Batch 16850, Loss: 0.005141029134392738\n",
      "Epoch 2, Batch 16900, Loss: 0.0032031491864472628\n",
      "Epoch 2, Batch 16950, Loss: 0.002613362856209278\n",
      "Epoch 2, Batch 17000, Loss: 0.0020561155397444963\n",
      "Epoch 2, Batch 17050, Loss: 0.002488228725269437\n",
      "Epoch 2, Batch 17100, Loss: 0.0036092353984713554\n",
      "Epoch 2, Batch 17150, Loss: 0.003174371784552932\n",
      "Epoch 2, Batch 17200, Loss: 0.002757108537480235\n",
      "Epoch 2, Batch 17250, Loss: 0.002789359539747238\n",
      "Epoch 2, Batch 17300, Loss: 0.0024735103361308575\n",
      "Epoch 2, Batch 17350, Loss: 0.002778682392090559\n",
      "Epoch 2, Batch 17400, Loss: 0.0024322939570993185\n",
      "Epoch 2, Batch 17450, Loss: 0.002196815563365817\n",
      "Epoch 2, Batch 17500, Loss: 0.0017338807228952646\n",
      "Epoch 2, Batch 17550, Loss: 0.0018982106121256948\n",
      "Epoch 2, Batch 17600, Loss: 0.0020659405272454023\n",
      "Epoch 2, Batch 17650, Loss: 0.002208733931183815\n",
      "Epoch 2, Batch 17700, Loss: 0.002545573515817523\n",
      "Epoch 2, Batch 17750, Loss: 0.0021091760136187077\n",
      "Epoch 2, Batch 17800, Loss: 0.0020718902815133333\n",
      "Epoch 2, Batch 17850, Loss: 0.0020462817046791315\n",
      "Epoch 2, Batch 17900, Loss: 0.0015653807204216719\n",
      "Epoch 2, Batch 17950, Loss: 0.0020197664853185415\n",
      "Epoch 2, Batch 18000, Loss: 0.004280969966202974\n",
      "Epoch 2, Batch 18050, Loss: 0.003794532734900713\n",
      "Epoch 2, Batch 18100, Loss: 0.00705272052437067\n",
      "Epoch 2, Batch 18150, Loss: 0.00392163498327136\n",
      "Epoch 2, Batch 18200, Loss: 0.0024676865432411432\n",
      "Epoch 2, Batch 18250, Loss: 0.0029283296316862106\n",
      "Epoch 2, Batch 18300, Loss: 0.0036415550857782364\n",
      "Epoch 2, Batch 18350, Loss: 0.0028829858638346195\n",
      "Epoch 2, Batch 18400, Loss: 0.0023330997209995985\n",
      "Epoch 2, Batch 18450, Loss: 0.0018344264244660735\n",
      "Epoch 2, Batch 18500, Loss: 0.0018216983880847692\n",
      "Epoch 2, Batch 18550, Loss: 0.0015709672588855028\n",
      "Epoch 2, Batch 18600, Loss: 0.0015453119995072484\n",
      "Epoch 2, Batch 18650, Loss: 0.0030779133085161448\n",
      "Epoch 2, Batch 18700, Loss: 0.004044841509312391\n",
      "Epoch 2, Batch 18750, Loss: 0.0029108647722750902\n",
      "Epoch 2, Batch 18800, Loss: 0.0028730363119393587\n",
      "Epoch 2, Batch 18850, Loss: 0.0025618395302444696\n",
      "Epoch 2, Batch 18900, Loss: 0.0027158076409250498\n",
      "Epoch 2, Batch 18950, Loss: 0.002652293536812067\n",
      "Epoch 2, Batch 19000, Loss: 0.002531986916437745\n",
      "Epoch 2, Batch 19050, Loss: 0.001573165412992239\n",
      "Epoch 2, Batch 19100, Loss: 0.00195914413779974\n",
      "Epoch 2, Batch 19150, Loss: 0.002186062978580594\n",
      "Epoch 2, Batch 19200, Loss: 0.0021917331032454967\n",
      "Epoch 2, Batch 19250, Loss: 0.004055797588080168\n",
      "Epoch 2, Batch 19300, Loss: 0.003223370760679245\n",
      "Epoch 2, Batch 19350, Loss: 0.003227983135730028\n",
      "Epoch 2, Batch 19400, Loss: 0.0024785627610981464\n",
      "Epoch 2, Batch 19450, Loss: 0.0021790028549730778\n",
      "Epoch 2, Batch 19500, Loss: 0.0016884291544556618\n",
      "Epoch 2, Batch 19550, Loss: 0.0019672054331749678\n",
      "Epoch 2, Batch 19600, Loss: 0.0017056107753887773\n",
      "Epoch 2, Batch 19650, Loss: 0.0019573038443922997\n",
      "Epoch 2, Batch 19700, Loss: 0.40006008744239807\n",
      "Epoch 2, Batch 19750, Loss: 0.0019967013504356146\n",
      "Epoch 2, Batch 19800, Loss: 0.383060485124588\n",
      "Epoch 2, Batch 19850, Loss: 0.001871371758170426\n",
      "Epoch 2, Batch 19900, Loss: 0.0022473856806755066\n",
      "Epoch 2, Batch 19950, Loss: 0.0017396381590515375\n",
      "Epoch 2, Batch 20000, Loss: 0.00127613905351609\n",
      "Epoch 2, Batch 20050, Loss: 0.001538570853881538\n",
      "Epoch 2, Batch 20100, Loss: 0.0015836897073313594\n",
      "Epoch 2, Batch 20150, Loss: 0.002740818541496992\n",
      "Epoch 2, Batch 20200, Loss: 0.0018119905143976212\n",
      "Epoch 2, Batch 20250, Loss: 0.0016221863916143775\n",
      "Epoch 2, Batch 20300, Loss: 0.0016258651157841086\n",
      "Epoch 2, Batch 20350, Loss: 0.0013735981192439795\n",
      "Epoch 2, Batch 20400, Loss: 0.0020297879818826914\n",
      "Epoch 2, Batch 20450, Loss: 0.002353628631681204\n",
      "Epoch 2, Batch 20500, Loss: 0.001543720718473196\n",
      "Epoch 2, Batch 20550, Loss: 0.0015216669999063015\n",
      "Epoch 2, Batch 20600, Loss: 0.0017199632711708546\n",
      "Epoch 2, Batch 20650, Loss: 0.002362777478992939\n",
      "Epoch 2, Batch 20700, Loss: 0.0029654621612280607\n",
      "Epoch 2, Batch 20750, Loss: 0.004383416846394539\n",
      "Epoch 2, Batch 20800, Loss: 0.004627339541912079\n",
      "Epoch 2, Batch 20850, Loss: 0.0027484858874231577\n",
      "Epoch 2, Batch 20900, Loss: 0.0026670722290873528\n",
      "Epoch 2, Batch 20950, Loss: 0.0026920035015791655\n",
      "Epoch 2, Batch 21000, Loss: 0.002743343124166131\n",
      "Epoch 2, Batch 21050, Loss: 0.002024005400016904\n",
      "Epoch 2, Batch 21100, Loss: 0.0015779485693201423\n",
      "Epoch 2, Batch 21150, Loss: 0.0024512875825166702\n",
      "Epoch 2, Batch 21200, Loss: 0.0033626218792051077\n",
      "Epoch 2, Batch 21250, Loss: 0.0028529802802950144\n",
      "Epoch 2, Batch 21300, Loss: 0.0024348944425582886\n",
      "Epoch 2, Batch 21350, Loss: 0.0035928008146584034\n",
      "Epoch 2, Batch 21400, Loss: 0.003422859124839306\n",
      "Epoch 2, Batch 21450, Loss: 0.0028672590851783752\n",
      "Epoch 2, Batch 21500, Loss: 0.0023428513668477535\n",
      "Epoch 2, Batch 21550, Loss: 0.002867439528927207\n",
      "Epoch 2, Batch 21600, Loss: 0.004032427910715342\n",
      "Epoch 2, Batch 21650, Loss: 0.003597706090658903\n",
      "Epoch 2, Batch 21700, Loss: 0.0028729718178510666\n",
      "Epoch 2, Batch 21750, Loss: 0.0023619914427399635\n",
      "Epoch 2, Batch 21800, Loss: 0.0030250269919633865\n",
      "Epoch 2, Batch 21850, Loss: 0.0026798220351338387\n",
      "Epoch 2, Batch 21900, Loss: 0.0022872125264257193\n",
      "Epoch 2, Batch 21950, Loss: 0.0020863618701696396\n",
      "Epoch 2, Batch 22000, Loss: 0.0025113995652645826\n",
      "Epoch 2, Batch 22050, Loss: 0.0022761686705052853\n",
      "Epoch 2, Batch 22100, Loss: 0.0017076741205528378\n",
      "Epoch 2, Batch 22150, Loss: 0.0015184379881247878\n",
      "Epoch 2, Batch 22200, Loss: 0.0013885146472603083\n",
      "Epoch 2, Batch 22250, Loss: 0.001462576910853386\n",
      "Epoch 2, Batch 22300, Loss: 0.0017044155392795801\n",
      "Epoch 2, Batch 22350, Loss: 0.0013176053762435913\n",
      "Epoch 2, Batch 22400, Loss: 0.4128202199935913\n",
      "Epoch 2, Batch 22450, Loss: 0.002567589981481433\n",
      "Epoch 2, Batch 22500, Loss: 0.36954841017723083\n",
      "Epoch 2, Batch 22550, Loss: 0.0026249191723763943\n",
      "Epoch 2, Batch 22600, Loss: 0.0032687855418771505\n",
      "Epoch 2, Batch 22650, Loss: 0.002766435034573078\n",
      "Epoch 2, Batch 22700, Loss: 0.0018173838034272194\n",
      "Epoch 2, Batch 22750, Loss: 0.0021630669943988323\n",
      "Epoch 2, Batch 22800, Loss: 0.0026660305447876453\n",
      "Epoch 2, Batch 22850, Loss: 0.002442755503579974\n",
      "Epoch 2, Batch 22900, Loss: 0.0020764670334756374\n",
      "Epoch 2, Batch 22950, Loss: 0.0020329535473138094\n",
      "Epoch 2, Batch 23000, Loss: 0.0023283816408365965\n",
      "Epoch 2, Batch 23050, Loss: 0.001764195505529642\n",
      "Epoch 2, Batch 23100, Loss: 0.0011350924614816904\n",
      "Epoch 2, Batch 23150, Loss: 0.0013607661239802837\n",
      "Epoch 2, Batch 23200, Loss: 0.001648035948164761\n",
      "Epoch 2, Batch 23250, Loss: 0.001853537280112505\n",
      "Epoch 2, Batch 23300, Loss: 0.0015637153992429376\n",
      "Epoch 2, Batch 23350, Loss: 0.0014288719976320863\n",
      "Epoch 2, Batch 23400, Loss: 0.0017745511140674353\n",
      "Epoch 2, Batch 23450, Loss: 0.0021582753397524357\n",
      "Epoch 2, Batch 23500, Loss: 0.0026630007196217775\n",
      "Epoch 2, Batch 23550, Loss: 0.0016256580129265785\n",
      "Epoch 2, Batch 23600, Loss: 0.001556497416459024\n",
      "Epoch 2, Batch 23650, Loss: 0.001856395392678678\n",
      "Epoch 2, Batch 23700, Loss: 0.002064706524834037\n",
      "Epoch 2, Batch 23750, Loss: 0.0023067165166139603\n",
      "Epoch 2, Batch 23800, Loss: 0.002065354259684682\n",
      "Epoch 2, Batch 23850, Loss: 0.00228496384806931\n",
      "Epoch 2, Batch 23900, Loss: 0.0019376687705516815\n",
      "Epoch 2, Batch 23950, Loss: 0.0022255375515669584\n",
      "Epoch 2, Batch 24000, Loss: 0.0020648918580263853\n",
      "Epoch 2, Batch 24050, Loss: 0.0030597567092627287\n",
      "Epoch 2, Batch 24100, Loss: 0.0022727232426404953\n",
      "Epoch 2, Batch 24150, Loss: 0.0020931244362145662\n",
      "Epoch 2, Batch 24200, Loss: 0.002240849193185568\n",
      "Epoch 2, Batch 24250, Loss: 0.0018394701182842255\n",
      "Epoch 2, Batch 24300, Loss: 0.002113289199769497\n",
      "Epoch 2, Batch 24350, Loss: 0.002054880140349269\n",
      "Epoch 2, Batch 24400, Loss: 0.001878029783256352\n",
      "Epoch 2, Batch 24450, Loss: 0.0019555119797587395\n",
      "Epoch 2, Batch 24500, Loss: 0.004040200263261795\n",
      "Epoch 2, Batch 24550, Loss: 0.002991273533552885\n",
      "Epoch 2, Batch 24600, Loss: 0.002101072808727622\n",
      "Epoch 2, Batch 24650, Loss: 0.002006514696404338\n",
      "Epoch 2, Batch 24700, Loss: 0.0026015855837613344\n",
      "Epoch 2, Batch 24750, Loss: 0.002134858863428235\n",
      "Epoch 2, Batch 24800, Loss: 0.002442525466904044\n",
      "Epoch 2, Batch 24850, Loss: 0.004188568331301212\n",
      "Epoch 2, Batch 24900, Loss: 0.0029922095127403736\n",
      "Epoch 2, Batch 24950, Loss: 0.002071634866297245\n",
      "Epoch 2, Batch 25000, Loss: 0.0018293897155672312\n",
      "Epoch 2, Batch 25050, Loss: 0.0017064758576452732\n",
      "Epoch 2, Batch 25100, Loss: 0.0022322239819914103\n",
      "Epoch 2, Batch 25150, Loss: 0.0021392113994807005\n",
      "Epoch 2, Batch 25200, Loss: 0.0017619681311771274\n",
      "Epoch 2, Batch 25250, Loss: 0.0015440761344507337\n",
      "Epoch 2, Batch 25300, Loss: 0.001417417312040925\n",
      "Epoch 2, Batch 25350, Loss: 0.0013581633102148771\n",
      "Epoch 2, Batch 25400, Loss: 0.0018895610701292753\n",
      "Epoch 2, Batch 25450, Loss: 0.0017587603069841862\n",
      "Epoch 2, Batch 25500, Loss: 0.002242721850052476\n",
      "Epoch 2, Batch 25550, Loss: 0.0015869387425482273\n",
      "Epoch 2, Batch 25600, Loss: 0.0029533475171774626\n",
      "Epoch 2, Batch 25650, Loss: 0.0035037712659686804\n",
      "Epoch 2, Batch 25700, Loss: 0.0026234774850308895\n",
      "Epoch 2, Batch 25750, Loss: 0.002664948580786586\n",
      "Epoch 2, Batch 25800, Loss: 0.0021106936037540436\n",
      "Epoch 2, Batch 25850, Loss: 0.0028578301426023245\n",
      "Epoch 2, Batch 25900, Loss: 0.001853696652688086\n",
      "Epoch 2, Batch 25950, Loss: 0.0020714455749839544\n",
      "Epoch 2, Batch 26000, Loss: 0.0021421262063086033\n",
      "Epoch 2, Batch 26050, Loss: 0.002159520285204053\n",
      "Epoch 2, Batch 26100, Loss: 0.0019400289747864008\n",
      "Epoch 2, Batch 26150, Loss: 0.0017735654255375266\n",
      "Epoch 2, Batch 26200, Loss: 0.0018419603584334254\n",
      "Epoch 2, Batch 26250, Loss: 0.001967570511624217\n",
      "Epoch 2, Batch 26300, Loss: 0.0024313577450811863\n",
      "Epoch 2, Batch 26350, Loss: 0.0022538439370691776\n",
      "Epoch 2, Batch 26400, Loss: 0.002458395902067423\n",
      "Epoch 2, Batch 26450, Loss: 0.001925242249853909\n",
      "Epoch 2, Batch 26500, Loss: 0.0021390668116509914\n",
      "Epoch 2, Batch 26550, Loss: 0.0026301206089556217\n",
      "Epoch 2, Batch 26600, Loss: 0.0019050099654123187\n",
      "Epoch 2, Batch 26650, Loss: 0.3830239772796631\n",
      "Epoch 2, Batch 26700, Loss: 0.0023578430991619825\n",
      "Epoch 2, Batch 26750, Loss: 0.0021261293441057205\n",
      "Epoch 2, Batch 26800, Loss: 0.3608897626399994\n",
      "Epoch 2, Batch 26850, Loss: 0.0018048726487904787\n",
      "Epoch 2, Batch 26900, Loss: 0.0021375049836933613\n",
      "Epoch 2, Batch 26950, Loss: 0.0027642310597002506\n",
      "Epoch 2, Batch 27000, Loss: 0.0038749980740249157\n",
      "Epoch 2, Batch 27050, Loss: 0.004119258839637041\n",
      "Epoch 2, Batch 27100, Loss: 0.0032656043767929077\n",
      "Epoch 2, Batch 27150, Loss: 0.0024034359958022833\n",
      "Epoch 2, Batch 27200, Loss: 0.001752871903590858\n",
      "Epoch 2, Batch 27250, Loss: 0.0013524467358365655\n",
      "Epoch 2, Batch 27300, Loss: 0.35673987865448\n",
      "Epoch 2, Batch 27350, Loss: 0.0037364037707448006\n",
      "Epoch 2, Batch 27400, Loss: 0.0026774671860039234\n",
      "Epoch 2, Batch 27450, Loss: 0.0032177288085222244\n",
      "Epoch 2, Batch 27500, Loss: 0.002991926157847047\n",
      "Epoch 2, Batch 27550, Loss: 0.0047556450590491295\n",
      "Epoch 2, Batch 27600, Loss: 0.0045328037813305855\n",
      "Epoch 2, Batch 27650, Loss: 0.003319269511848688\n",
      "Epoch 2, Batch 27700, Loss: 0.002606898546218872\n",
      "Epoch 2, Batch 27750, Loss: 0.0022705739829689264\n",
      "Epoch 2, Batch 27800, Loss: 0.0020525390282273293\n",
      "Epoch 2, Batch 27850, Loss: 0.36594364047050476\n",
      "Epoch 2, Batch 27900, Loss: 0.0030974294058978558\n",
      "Epoch 2, Batch 27950, Loss: 0.002772450679913163\n",
      "Epoch 2, Batch 28000, Loss: 0.002628121292218566\n",
      "Epoch 2, Batch 28050, Loss: 0.002086550695821643\n",
      "Epoch 2, Batch 28100, Loss: 0.002428058534860611\n",
      "Epoch 2, Batch 28150, Loss: 0.0024116304703056812\n",
      "Epoch 2, Batch 28200, Loss: 0.00230794632807374\n",
      "Epoch 2, Batch 28250, Loss: 0.0026583056896924973\n",
      "Epoch 2, Batch 28300, Loss: 0.0024079831782728434\n",
      "Epoch 2, Batch 28350, Loss: 0.002250263001769781\n",
      "Epoch 2, Batch 28400, Loss: 0.003076559863984585\n",
      "Epoch 2, Batch 28450, Loss: 0.002520541427657008\n",
      "Epoch 2, Batch 28500, Loss: 0.003609566017985344\n",
      "Epoch 2, Batch 28550, Loss: 0.003277331590652466\n",
      "Epoch 2, Batch 28600, Loss: 0.002935427241027355\n",
      "Epoch 2, Batch 28650, Loss: 0.0028890841640532017\n",
      "Epoch 2, Batch 28700, Loss: 0.0022707702592015266\n",
      "Epoch 2, Batch 28750, Loss: 0.002036732155829668\n",
      "Epoch 2, Batch 28800, Loss: 0.0018206597305834293\n",
      "Epoch 2, Batch 28850, Loss: 0.0016061211936175823\n",
      "Epoch 2, Batch 28900, Loss: 0.0017211447702720761\n",
      "Epoch 2, Batch 28950, Loss: 0.0023188074119389057\n",
      "Epoch 2, Batch 29000, Loss: 0.002995401155203581\n",
      "Epoch 2, Batch 29050, Loss: 0.003582552308216691\n",
      "Epoch 2, Batch 29100, Loss: 0.0029901068191975355\n",
      "Epoch 2, Batch 29150, Loss: 0.0018812627531588078\n",
      "Epoch 2, Batch 29200, Loss: 0.001985212555155158\n",
      "Epoch 2, Batch 29250, Loss: 0.0025758296251296997\n",
      "Epoch 2, Batch 29300, Loss: 0.00355184031650424\n",
      "Epoch 2, Batch 29350, Loss: 0.003461160697042942\n",
      "Epoch 2, Batch 29400, Loss: 0.0026826816610991955\n",
      "Epoch 2, Batch 29450, Loss: 0.002555654151365161\n",
      "Epoch 2, Batch 29500, Loss: 0.002329555107280612\n",
      "Epoch 2, Batch 29550, Loss: 0.0023185897152870893\n",
      "Epoch 2, Batch 29600, Loss: 0.002048976719379425\n",
      "Epoch 2, Batch 29650, Loss: 0.001592983608134091\n",
      "Epoch 2, Batch 29700, Loss: 0.0018354663625359535\n",
      "Epoch 2, Batch 29750, Loss: 0.0017417275812476873\n",
      "Epoch 2, Batch 29800, Loss: 0.0019149626605212688\n",
      "Epoch 2, Batch 29850, Loss: 0.0016672033816576004\n",
      "Epoch 2, Batch 29900, Loss: 0.0015088343061506748\n",
      "Epoch 2, Batch 29950, Loss: 0.0027809462044388056\n",
      "Epoch 2, Batch 30000, Loss: 0.0023200020659714937\n",
      "Epoch 2, Batch 30050, Loss: 0.0022812874522060156\n",
      "Epoch 2, Batch 30100, Loss: 0.0026240693405270576\n",
      "Epoch 2, Batch 30150, Loss: 0.0044039711356163025\n",
      "Epoch 2, Batch 30200, Loss: 0.004029171075671911\n",
      "Epoch 2, Batch 30250, Loss: 0.0026231901720166206\n",
      "Epoch 2, Batch 30300, Loss: 0.0019489884143695235\n",
      "Epoch 2, Batch 30350, Loss: 0.0021458365954458714\n",
      "Epoch 2, Batch 30400, Loss: 0.0020075866486877203\n",
      "Epoch 2, Batch 30450, Loss: 0.002801380818709731\n",
      "Epoch 2, Batch 30500, Loss: 0.0021226077806204557\n",
      "Epoch 2, Batch 30550, Loss: 0.00205404544249177\n",
      "Epoch 2, Batch 30600, Loss: 0.0015932840760797262\n",
      "Epoch 2, Batch 30650, Loss: 0.0015407729661092162\n",
      "Epoch 2, Batch 30700, Loss: 0.002512534847483039\n",
      "Epoch 2, Batch 30750, Loss: 0.38715943694114685\n",
      "Epoch 2, Batch 30800, Loss: 0.004282827954739332\n",
      "Epoch 2, Batch 30850, Loss: 0.0030903462320566177\n",
      "Epoch 2, Batch 30900, Loss: 0.0027173308189958334\n",
      "Epoch 2, Batch 30950, Loss: 0.0024565376807004213\n",
      "Epoch 2, Batch 31000, Loss: 0.0024536610580980778\n",
      "Epoch 2, Batch 31050, Loss: 0.002486187731847167\n",
      "Epoch 2, Batch 31100, Loss: 0.37453997135162354\n",
      "Epoch 2, Batch 31150, Loss: 0.003927037585526705\n",
      "Epoch 2, Batch 31200, Loss: 0.0040504285134375095\n",
      "Epoch 2, Batch 31250, Loss: 0.0034883879125118256\n",
      "Epoch 2, Batch 31300, Loss: 0.0028178864158689976\n",
      "Epoch 2, Batch 31350, Loss: 0.002735407557338476\n",
      "Epoch 2, Batch 31400, Loss: 0.002530759898945689\n",
      "Epoch 2, Batch 31450, Loss: 0.0031998667400330305\n",
      "Epoch 2, Batch 31500, Loss: 0.00316437054425478\n",
      "Epoch 2, Batch 31550, Loss: 0.002706858329474926\n",
      "Epoch 2, Batch 31600, Loss: 0.3554134666919708\n",
      "Epoch 2, Batch 31650, Loss: 0.002677720505744219\n",
      "Epoch 2, Batch 31700, Loss: 0.0018998117884621024\n",
      "Epoch 2, Batch 31750, Loss: 0.002140820724889636\n",
      "Epoch 2, Batch 31800, Loss: 0.0016883682692423463\n",
      "Epoch 2, Batch 31850, Loss: 0.001621429342776537\n",
      "Epoch 2, Batch 31900, Loss: 0.0030249713454395533\n",
      "Epoch 2, Batch 31950, Loss: 0.002442079596221447\n",
      "Epoch 2, Batch 32000, Loss: 0.002895006211474538\n",
      "Epoch 2, Batch 32050, Loss: 0.002913416363298893\n",
      "Epoch 2, Batch 32100, Loss: 0.0027495333924889565\n",
      "Epoch 2, Batch 32150, Loss: 0.0020483785774558783\n",
      "Epoch 2, Batch 32200, Loss: 0.0025030681863427162\n",
      "Epoch 2, Batch 32250, Loss: 0.004382212646305561\n",
      "Epoch 2, Batch 32300, Loss: 0.005135757382959127\n",
      "Epoch 2, Batch 32350, Loss: 0.0044174049980938435\n",
      "Epoch 2, Batch 32400, Loss: 0.003401727182790637\n",
      "Epoch 2, Batch 32450, Loss: 0.002878623316064477\n",
      "Epoch 2, Batch 32500, Loss: 0.0033319066278636456\n",
      "Epoch 2, Batch 32550, Loss: 0.0022145018447190523\n",
      "Epoch 2, Batch 32600, Loss: 0.0020163487643003464\n",
      "Epoch 2, Batch 32650, Loss: 0.0023169631604105234\n",
      "Epoch 2, Batch 32700, Loss: 0.002019633539021015\n",
      "Epoch 2, Batch 32750, Loss: 0.002101426012814045\n",
      "Epoch 2, Batch 32800, Loss: 0.0026361257769167423\n",
      "Epoch 2, Batch 32850, Loss: 0.0034149144776165485\n",
      "Epoch 2, Batch 32900, Loss: 0.002513984451070428\n",
      "Epoch 2, Batch 32950, Loss: 0.0017828061245381832\n",
      "Epoch 2, Batch 33000, Loss: 0.0018499006982892752\n",
      "Epoch 2, Batch 33050, Loss: 0.0015204314840957522\n",
      "Epoch 2, Batch 33100, Loss: 0.002115630079060793\n",
      "Epoch 2, Batch 33150, Loss: 0.0032109455205500126\n",
      "Epoch 2, Batch 33200, Loss: 0.33382830023765564\n",
      "Epoch 2, Batch 33250, Loss: 0.0033898388501256704\n",
      "Epoch 2, Batch 33300, Loss: 0.003541103098541498\n",
      "Epoch 2, Batch 33350, Loss: 0.0027576142456382513\n",
      "Epoch 2, Batch 33400, Loss: 0.0038734462577849627\n",
      "Epoch 2, Batch 33450, Loss: 0.004901179578155279\n",
      "Epoch 2, Batch 33500, Loss: 0.004344118759036064\n",
      "Epoch 2, Batch 33550, Loss: 0.00368615728802979\n",
      "Epoch 2, Batch 33600, Loss: 0.003271984402090311\n",
      "Epoch 2, Batch 33650, Loss: 0.0026298994198441505\n",
      "Epoch 2, Batch 33700, Loss: 0.004026590846478939\n",
      "Epoch 2, Batch 33750, Loss: 0.0031466297805309296\n",
      "Epoch 2, Batch 33800, Loss: 0.0026438627392053604\n",
      "Epoch 2, Batch 33850, Loss: 0.003176699625328183\n",
      "Epoch 2, Batch 33900, Loss: 0.00299351429566741\n",
      "Epoch 2, Batch 33950, Loss: 0.00250916532240808\n",
      "Epoch 2, Batch 34000, Loss: 0.00415021600201726\n",
      "Epoch 2, Batch 34050, Loss: 0.003621685551479459\n",
      "Epoch 2, Batch 34100, Loss: 0.0026106720324605703\n",
      "Epoch 2, Batch 34150, Loss: 0.003418531734496355\n",
      "Epoch 2, Batch 34200, Loss: 0.0036459825932979584\n",
      "Epoch 2, Batch 34250, Loss: 0.0026917406357824802\n",
      "Epoch 2, Batch 34300, Loss: 0.002307593822479248\n",
      "Epoch 2, Batch 34350, Loss: 0.002534083556383848\n",
      "Epoch 2, Batch 34400, Loss: 0.0018654209561645985\n",
      "Epoch 2, Batch 34450, Loss: 0.0016085098031908274\n",
      "Epoch 2, Batch 34500, Loss: 0.0012475737603381276\n",
      "Epoch 2, Batch 34550, Loss: 0.0011863878462463617\n",
      "Epoch 2, Batch 34600, Loss: 0.002200052607804537\n",
      "Epoch 2, Batch 34650, Loss: 0.0016129498835653067\n",
      "Epoch 2, Batch 34700, Loss: 0.0012327643344178796\n",
      "Epoch 2, Batch 34750, Loss: 0.0016719806008040905\n",
      "Epoch 2, Batch 34800, Loss: 0.0014513559872284532\n",
      "Epoch 2, Batch 34850, Loss: 0.0016688244650140405\n",
      "Epoch 2, Batch 34900, Loss: 0.00199927412904799\n",
      "Epoch 2, Batch 34950, Loss: 0.001959775807335973\n",
      "Epoch 2, Batch 35000, Loss: 0.0021509802900254726\n",
      "Epoch 2, Batch 35050, Loss: 0.0020999733824282885\n",
      "Epoch 2, Batch 35100, Loss: 0.0014305494260042906\n",
      "Epoch 2, Batch 35150, Loss: 0.001495081465691328\n",
      "Epoch 2, Batch 35200, Loss: 0.0009776147780939937\n",
      "Epoch 2, Batch 35250, Loss: 0.0015076003037393093\n",
      "Epoch 2, Batch 35300, Loss: 0.0029666610062122345\n",
      "Epoch 2, Batch 35350, Loss: 0.0020390506833791733\n",
      "Epoch 2, Batch 35400, Loss: 0.0012756192591041327\n",
      "Epoch 2, Batch 35450, Loss: 0.0015734101179987192\n",
      "Epoch 2, Batch 35500, Loss: 0.0016860350733622909\n",
      "Epoch 2, Batch 35550, Loss: 0.0023600710555911064\n",
      "Epoch 2, Batch 35600, Loss: 0.0029302460607141256\n",
      "Epoch 2, Batch 35650, Loss: 0.0031598100904375315\n",
      "Epoch 2, Batch 35700, Loss: 0.002233969746157527\n",
      "Epoch 2, Batch 35750, Loss: 0.0020508929155766964\n",
      "Epoch 2, Batch 35800, Loss: 0.4100307822227478\n",
      "Epoch 2, Batch 35850, Loss: 0.0017033085459843278\n",
      "Epoch 2, Batch 35900, Loss: 0.002123008482158184\n",
      "Epoch 2, Batch 35950, Loss: 0.0027001015841960907\n",
      "Epoch 2, Batch 36000, Loss: 0.0020696581341326237\n",
      "Epoch 2, Batch 36050, Loss: 0.0026595795061439276\n",
      "Epoch 2, Batch 36100, Loss: 0.002254330087453127\n",
      "Epoch 2, Batch 36150, Loss: 0.0017018707003444433\n",
      "Epoch 2, Batch 36200, Loss: 0.0020497699733823538\n",
      "Epoch 2, Batch 36250, Loss: 0.002165877493098378\n",
      "Epoch 2, Batch 36300, Loss: 0.001565455342642963\n",
      "Epoch 2, Batch 36350, Loss: 0.0011157020926475525\n",
      "Epoch 2, Batch 36400, Loss: 0.002010770607739687\n",
      "Epoch 2, Batch 36450, Loss: 0.0022828003857284784\n",
      "Epoch 2, Batch 36500, Loss: 0.0032912059687078\n",
      "Epoch 2, Batch 36550, Loss: 0.00393677456304431\n",
      "Epoch 2, Batch 36600, Loss: 0.002994008595123887\n",
      "Epoch 2, Batch 36650, Loss: 0.002489685080945492\n",
      "Epoch 2, Batch 36700, Loss: 0.002393538597971201\n",
      "Epoch 2, Batch 36750, Loss: 0.003269675187766552\n",
      "Epoch 2, Batch 36800, Loss: 0.003962394781410694\n",
      "Epoch 2, Batch 36850, Loss: 0.0034527387470006943\n",
      "Epoch 2, Batch 36900, Loss: 0.002674902556464076\n",
      "Epoch 2, Batch 36950, Loss: 0.002232226775959134\n",
      "Epoch 2, Batch 37000, Loss: 0.0024001384153962135\n",
      "Epoch 2, Batch 37050, Loss: 0.0036504899617284536\n",
      "Epoch 2, Batch 37100, Loss: 0.003264186205342412\n",
      "Epoch 2, Batch 37150, Loss: 0.0037747640162706375\n",
      "Epoch 2, Batch 37200, Loss: 0.0031560086645185947\n",
      "Epoch 2, Batch 37250, Loss: 0.0024317880161106586\n",
      "Epoch 2, Batch 37300, Loss: 0.0018846779130399227\n",
      "Epoch 2, Batch 37350, Loss: 0.0026501903776079416\n",
      "Epoch 2, Batch 37400, Loss: 0.002666057087481022\n",
      "Epoch 2, Batch 37450, Loss: 0.0018090050434693694\n",
      "Epoch 2, Batch 37500, Loss: 0.001767949783243239\n",
      "Epoch 2, Batch 37550, Loss: 0.0014372521545737982\n",
      "Epoch 2, Batch 37600, Loss: 0.0014703965280205011\n",
      "Epoch 2, Batch 37650, Loss: 0.0012168379034847021\n",
      "Epoch 2, Batch 37700, Loss: 0.0013470391277223825\n",
      "Epoch 2, Batch 37750, Loss: 0.0013506179675459862\n",
      "Epoch 2, Batch 37800, Loss: 0.0014878404326736927\n",
      "Epoch 2, Batch 37850, Loss: 0.4009709060192108\n",
      "Epoch 2, Batch 37900, Loss: 0.002704611048102379\n",
      "Epoch 2, Batch 37950, Loss: 0.0026436783373355865\n",
      "Epoch 2, Batch 38000, Loss: 0.003433233592659235\n",
      "Epoch 2, Batch 38050, Loss: 0.0026830004062503576\n",
      "Epoch 2, Batch 38100, Loss: 0.0018028035992756486\n",
      "Epoch 2, Batch 38150, Loss: 0.0020334695000201464\n",
      "Epoch 2, Batch 38200, Loss: 0.0038457449991256\n",
      "Epoch 2, Batch 38250, Loss: 0.0038214102387428284\n",
      "Epoch 2, Batch 38300, Loss: 0.003117527812719345\n",
      "Epoch 2, Batch 38350, Loss: 0.003607384394854307\n",
      "Epoch 2, Batch 38400, Loss: 0.002651594113558531\n",
      "Epoch 2, Batch 38450, Loss: 0.003413199679926038\n",
      "Epoch 2, Batch 38500, Loss: 0.0033653161954134703\n",
      "Epoch 2, Batch 38550, Loss: 0.0022379106376320124\n",
      "Epoch 2, Batch 38600, Loss: 0.001901121693663299\n",
      "Epoch 2, Batch 38650, Loss: 0.0031012804247438908\n",
      "Epoch 2, Batch 38700, Loss: 0.0021829905454069376\n",
      "Epoch 2, Batch 38750, Loss: 0.002255117753520608\n",
      "Epoch 2, Batch 38800, Loss: 0.0026776804588735104\n",
      "Epoch 2, Batch 38850, Loss: 0.002418150659650564\n",
      "Epoch 2, Batch 38900, Loss: 0.0035768267698585987\n",
      "Epoch 2, Batch 38950, Loss: 0.0035554878413677216\n",
      "Epoch 2, Batch 39000, Loss: 0.0028895740397274494\n",
      "Epoch 2, Batch 39050, Loss: 0.0028371107764542103\n",
      "Epoch 2, Batch 39100, Loss: 0.003919361624866724\n",
      "Epoch 2, Batch 39150, Loss: 0.004625624045729637\n",
      "Epoch 2, Batch 39200, Loss: 0.004775722976773977\n",
      "Epoch 2, Batch 39250, Loss: 0.0032991510815918446\n",
      "Epoch 2, Batch 39300, Loss: 0.00387472752481699\n",
      "Epoch 2, Batch 39350, Loss: 0.004592068959027529\n",
      "Epoch 2, Batch 39400, Loss: 0.005644366145133972\n",
      "Epoch 2, Batch 39450, Loss: 0.009268131107091904\n",
      "Epoch 2, Batch 39500, Loss: 0.005623390898108482\n",
      "Epoch 2, Batch 39550, Loss: 0.006264536641538143\n",
      "Epoch 2, Batch 39600, Loss: 0.0038968503940850496\n",
      "Epoch 2, Batch 39650, Loss: 0.0029073646292090416\n",
      "Epoch 2, Batch 39700, Loss: 0.002524733543395996\n",
      "Epoch 2, Batch 39750, Loss: 0.002698848256841302\n",
      "Epoch 2, Batch 39800, Loss: 0.002762083662673831\n",
      "Epoch 2, Batch 39850, Loss: 0.004182633012533188\n",
      "Epoch 2, Batch 39900, Loss: 0.002657728735357523\n",
      "Epoch 2, Batch 39950, Loss: 0.0030742953531444073\n",
      "Epoch 2, Batch 40000, Loss: 0.0027733519673347473\n",
      "Epoch 2, Batch 40050, Loss: 0.39052748680114746\n",
      "Epoch 2, Batch 40100, Loss: 0.002978710224851966\n",
      "Epoch 2, Batch 40150, Loss: 0.002136221155524254\n",
      "Epoch 2, Batch 40200, Loss: 0.0017953270580619574\n",
      "Epoch 2, Batch 40250, Loss: 0.0033145772758871317\n",
      "Epoch 2, Batch 40300, Loss: 0.0024277055636048317\n",
      "Epoch 2, Batch 40350, Loss: 0.002061655977740884\n",
      "Epoch 2, Batch 40400, Loss: 0.3712252974510193\n",
      "Epoch 2, Batch 40450, Loss: 0.002926763379946351\n",
      "Epoch 2, Batch 40500, Loss: 0.0027832514606416225\n",
      "Epoch 2, Batch 40550, Loss: 0.0020752844866365194\n",
      "Epoch 2, Batch 40600, Loss: 0.0018477579578757286\n",
      "Epoch 2, Batch 40650, Loss: 0.002172561828047037\n",
      "Epoch 2, Batch 40700, Loss: 0.3683924674987793\n",
      "Epoch 2, Batch 40750, Loss: 0.0025676414370536804\n",
      "Epoch 2, Batch 40800, Loss: 0.0023041253443807364\n",
      "Epoch 2, Batch 40850, Loss: 0.0023921283427625895\n",
      "Epoch 2, Batch 40900, Loss: 0.0017821032088249922\n",
      "Epoch 2, Batch 40950, Loss: 0.0030820562969893217\n",
      "Epoch 2, Batch 41000, Loss: 0.002311013638973236\n",
      "Epoch 2, Batch 41050, Loss: 0.0022225030697882175\n",
      "Epoch 2, Batch 41100, Loss: 0.002781267510727048\n",
      "Epoch 2, Batch 41150, Loss: 0.002128486055880785\n",
      "Epoch 2, Batch 41200, Loss: 0.0017939392710104585\n",
      "Epoch 2, Batch 41250, Loss: 0.002222188515588641\n",
      "Epoch 2, Batch 41300, Loss: 0.002914148150011897\n",
      "Epoch 2, Batch 41350, Loss: 0.004770842380821705\n",
      "Epoch 2, Batch 41400, Loss: 0.0036037121899425983\n",
      "Epoch 2, Batch 41450, Loss: 0.0023159084375947714\n",
      "Epoch 2, Batch 41500, Loss: 0.002877755556255579\n",
      "Epoch 2, Batch 41550, Loss: 0.0022522362414747477\n",
      "Epoch 2, Batch 41600, Loss: 0.0017132475040853024\n",
      "Epoch 2, Batch 41650, Loss: 0.0018382627749815583\n",
      "Epoch 2, Batch 41700, Loss: 0.3947557210922241\n",
      "Epoch 2, Batch 41750, Loss: 0.002959698438644409\n",
      "Epoch 2, Batch 41800, Loss: 0.002750254701822996\n",
      "Epoch 2, Batch 41850, Loss: 0.003091317368671298\n",
      "Epoch 2, Batch 41900, Loss: 0.0025152447633445263\n",
      "Epoch 2, Batch 41950, Loss: 0.0029653816018253565\n",
      "Epoch 2, Batch 42000, Loss: 0.002287729876115918\n",
      "Epoch 2, Batch 42050, Loss: 0.0023852158337831497\n",
      "Epoch 2, Batch 42100, Loss: 0.002257121494039893\n",
      "Epoch 2, Batch 42150, Loss: 0.0025172990281134844\n",
      "Epoch 2, Batch 42200, Loss: 0.0022920987103134394\n",
      "Epoch 2, Batch 42250, Loss: 0.0018030352657660842\n",
      "Epoch 2, Batch 42300, Loss: 0.001567778061144054\n",
      "Epoch 2, Batch 42350, Loss: 0.3747507929801941\n",
      "Epoch 2, Batch 42400, Loss: 0.002284127287566662\n",
      "Epoch 2, Batch 42450, Loss: 0.0020474328193813562\n",
      "Epoch 2, Batch 42500, Loss: 0.0017661360325291753\n",
      "Epoch 2, Batch 42550, Loss: 0.0022522411309182644\n",
      "Epoch 2, Batch 42600, Loss: 0.0033883608411997557\n",
      "Epoch 2, Batch 42650, Loss: 0.003060093382373452\n",
      "Epoch 2, Batch 42700, Loss: 0.002473624888807535\n",
      "Epoch 2, Batch 42750, Loss: 0.0021284613758325577\n",
      "Epoch 2, Batch 42800, Loss: 0.40837621688842773\n",
      "Epoch 2, Batch 42850, Loss: 0.0022049101535230875\n",
      "Epoch 2, Batch 42900, Loss: 0.0025208485312759876\n",
      "Epoch 2, Batch 42950, Loss: 0.002648405497893691\n",
      "Epoch 2, Batch 43000, Loss: 0.002610014518722892\n",
      "Epoch 2, Batch 43050, Loss: 0.00228162482380867\n",
      "Epoch 2, Batch 43100, Loss: 0.0029509463347494602\n",
      "Epoch 2, Batch 43150, Loss: 0.0018948985962197185\n",
      "Epoch 2, Batch 43200, Loss: 0.0016877461457625031\n",
      "Epoch 2, Batch 43250, Loss: 0.002148783765733242\n",
      "Epoch 2, Batch 43300, Loss: 0.0025210240855813026\n",
      "Epoch 2, Batch 43350, Loss: 0.0029403145890682936\n",
      "Epoch 2, Batch 43400, Loss: 0.0032176650129258633\n",
      "Epoch 2, Batch 43450, Loss: 0.002011089352890849\n",
      "Epoch 2, Batch 43500, Loss: 0.0018701625522226095\n",
      "Epoch 2, Batch 43550, Loss: 0.0014770413981750607\n",
      "Epoch 2, Batch 43600, Loss: 0.0014661940513178706\n",
      "Epoch 2, Batch 43650, Loss: 0.001968155615031719\n",
      "Epoch 2, Batch 43700, Loss: 0.0016859525348991156\n",
      "Epoch 2, Batch 43750, Loss: 0.001282591954804957\n",
      "Epoch 2, Batch 43800, Loss: 0.0014044377021491528\n",
      "Epoch 2, Batch 43850, Loss: 0.0014431490562856197\n",
      "Epoch 2, Batch 43900, Loss: 0.0016144029796123505\n",
      "Epoch 2, Batch 43950, Loss: 0.0027711994480341673\n",
      "Epoch 2, Batch 44000, Loss: 0.002901359461247921\n",
      "Epoch 2, Batch 44050, Loss: 0.002248589415103197\n",
      "Epoch 2, Batch 44100, Loss: 0.0027370299212634563\n",
      "Epoch 2, Batch 44150, Loss: 0.002230432815849781\n",
      "Epoch 2, Batch 44200, Loss: 0.0015828697942197323\n",
      "Epoch 2, Batch 44250, Loss: 0.0017335229786112905\n",
      "Epoch 2, Batch 44300, Loss: 0.0016230180626735091\n",
      "Epoch 2, Batch 44350, Loss: 0.0014084794092923403\n",
      "Epoch 2, Batch 44400, Loss: 0.0029006930999457836\n",
      "Epoch 2, Batch 44450, Loss: 0.0025117238983511925\n",
      "Epoch 2, Batch 44500, Loss: 0.0022243850398808718\n",
      "Epoch 2, Batch 44550, Loss: 0.0020450837910175323\n",
      "Epoch 2, Batch 44600, Loss: 0.0028910525143146515\n",
      "Epoch 2, Batch 44650, Loss: 0.0027200705371797085\n",
      "Epoch 2, Batch 44700, Loss: 0.0032784210052341223\n",
      "Epoch 2, Batch 44750, Loss: 0.001986975781619549\n",
      "Epoch 2, Batch 44800, Loss: 0.0024224130902439356\n",
      "Epoch 2, Batch 44850, Loss: 0.002043857704848051\n",
      "Epoch 2, Batch 44900, Loss: 0.4073472321033478\n",
      "Epoch 2, Batch 44950, Loss: 0.0022105213720351458\n",
      "Epoch 2, Batch 45000, Loss: 0.002267805626615882\n",
      "Epoch 2, Batch 45050, Loss: 0.001978855347260833\n",
      "Epoch 2, Batch 45100, Loss: 0.001958194887265563\n",
      "Epoch 2, Batch 45150, Loss: 0.002991950837895274\n",
      "Epoch 2, Batch 45200, Loss: 0.0037230486050248146\n",
      "Epoch 2, Batch 45250, Loss: 0.0032821414060890675\n",
      "Epoch 2, Batch 45300, Loss: 0.0034073623828589916\n",
      "Epoch 2, Batch 45350, Loss: 0.0022713879588991404\n",
      "Epoch 2, Batch 45400, Loss: 0.4090821444988251\n",
      "Epoch 2, Batch 45450, Loss: 0.0018127169460058212\n",
      "Epoch 2, Batch 45500, Loss: 0.0016123616369441152\n",
      "Epoch 2, Batch 45550, Loss: 0.0024324588011950254\n",
      "Epoch 2, Batch 45600, Loss: 0.00265361531637609\n",
      "Epoch 2, Batch 45650, Loss: 0.0025300192646682262\n",
      "Epoch 2, Batch 45700, Loss: 0.35805177688598633\n",
      "Epoch 2, Batch 45750, Loss: 0.0034183140378445387\n",
      "Epoch 2, Batch 45800, Loss: 0.0029166871681809425\n",
      "Epoch 2, Batch 45850, Loss: 0.003436642000451684\n",
      "Epoch 2, Batch 45900, Loss: 0.004081652499735355\n",
      "Epoch 2, Batch 45950, Loss: 0.004113516770303249\n",
      "Epoch 2, Batch 46000, Loss: 0.005093223415315151\n",
      "Epoch 2, Batch 46050, Loss: 0.0038935127668082714\n",
      "Epoch 2, Batch 46100, Loss: 0.0044842930510640144\n",
      "Epoch 2, Batch 46150, Loss: 0.0029620123095810413\n",
      "Epoch 2, Batch 46200, Loss: 0.0020559285767376423\n",
      "Epoch 2, Batch 46250, Loss: 0.4112570285797119\n",
      "Epoch 2, Batch 46300, Loss: 0.0017364161321893334\n",
      "Epoch 2, Batch 46350, Loss: 0.002063172869384289\n",
      "Epoch 2, Batch 46400, Loss: 0.0023170525673776865\n",
      "Epoch 2, Batch 46450, Loss: 0.002359813777729869\n",
      "Epoch 2, Batch 46500, Loss: 0.0017025386914610863\n",
      "Epoch 2, Batch 46550, Loss: 0.0017177562694996595\n",
      "Epoch 2, Batch 46600, Loss: 0.0014464654959738255\n",
      "Epoch 2, Batch 46650, Loss: 0.0024556571152061224\n",
      "Epoch 2, Batch 46700, Loss: 0.0022016814909875393\n",
      "Epoch 2, Batch 46750, Loss: 0.0021259745117276907\n",
      "Epoch 2, Batch 46800, Loss: 0.003230438567698002\n",
      "Epoch 2, Batch 46850, Loss: 0.0031392001546919346\n",
      "Epoch 2, Batch 46900, Loss: 0.0020782367791980505\n",
      "Epoch 2, Batch 46950, Loss: 0.0018447614274919033\n",
      "Epoch 2, Batch 47000, Loss: 0.002081042854115367\n",
      "Epoch 2, Batch 47050, Loss: 0.003292451146990061\n",
      "Epoch 2, Batch 47100, Loss: 0.0029754152055829763\n",
      "Epoch 2, Batch 47150, Loss: 0.00310350488871336\n",
      "Epoch 2, Batch 47200, Loss: 0.00406898558139801\n",
      "Epoch 2, Batch 47250, Loss: 0.0031721657142043114\n",
      "Epoch 2, Batch 47300, Loss: 0.002882604021579027\n",
      "Epoch 2, Batch 47350, Loss: 0.0021210331469774246\n",
      "Epoch 2, Batch 47400, Loss: 0.002107469830662012\n",
      "Epoch 2, Batch 47450, Loss: 0.7841353416442871\n",
      "Epoch 2, Batch 47500, Loss: 0.0021039433777332306\n",
      "Epoch 2, Batch 47550, Loss: 0.00240451586432755\n",
      "Epoch 2, Batch 47600, Loss: 0.0025859398301690817\n",
      "Epoch 2, Batch 47650, Loss: 0.3848569393157959\n",
      "Epoch 2, Batch 47700, Loss: 0.0022963674273341894\n",
      "Epoch 2, Batch 47750, Loss: 0.0017204305622726679\n",
      "Epoch 2, Batch 47800, Loss: 0.0013440288603305817\n",
      "Epoch 2, Batch 47850, Loss: 0.0010870442492887378\n",
      "Epoch 2, Batch 47900, Loss: 0.0019637364894151688\n",
      "Epoch 2, Batch 47950, Loss: 0.0017389230197295547\n",
      "Epoch 2, Batch 48000, Loss: 0.0022414280101656914\n",
      "Epoch 2, Batch 48050, Loss: 0.0023554458748549223\n",
      "Epoch 2, Batch 48100, Loss: 0.0019587231799960136\n",
      "Epoch 2, Batch 48150, Loss: 0.0019433641573414207\n",
      "Epoch 2, Batch 48200, Loss: 0.0021280033979564905\n",
      "Epoch 2, Batch 48250, Loss: 0.001838771509937942\n",
      "Epoch 2, Batch 48300, Loss: 0.002647810149937868\n",
      "Epoch 2, Batch 48350, Loss: 0.002144393278285861\n",
      "Epoch 2, Batch 48400, Loss: 0.0015822857385501266\n",
      "Epoch 2, Batch 48450, Loss: 0.0025087748654186726\n",
      "Epoch 2, Batch 48500, Loss: 0.38106125593185425\n",
      "Epoch 2, Batch 48550, Loss: 0.0019092989386990666\n",
      "Epoch 2, Batch 48600, Loss: 0.0017941694241017103\n",
      "Epoch 2, Batch 48650, Loss: 0.3894447386264801\n",
      "Epoch 2, Batch 48700, Loss: 0.0021819008979946375\n",
      "Epoch 2, Batch 48750, Loss: 0.002428538864478469\n",
      "Epoch 2, Batch 48800, Loss: 0.0033389567397534847\n",
      "Epoch 2, Batch 48850, Loss: 0.005090606864541769\n",
      "Epoch 2, Batch 48900, Loss: 0.00480634393170476\n",
      "Epoch 2, Batch 48950, Loss: 0.003838519100099802\n",
      "Epoch 2, Batch 49000, Loss: 0.3711424171924591\n",
      "Epoch 2, Batch 49050, Loss: 0.0030385758727788925\n",
      "Epoch 2, Batch 49100, Loss: 0.003090577432885766\n",
      "Epoch 2, Batch 49150, Loss: 0.38795214891433716\n",
      "Epoch 2, Batch 49200, Loss: 0.003081105649471283\n",
      "Epoch 2, Batch 49250, Loss: 0.0022507274989038706\n",
      "Epoch 2, Batch 49300, Loss: 0.0026732205878943205\n",
      "Epoch 2, Batch 49350, Loss: 0.0016324750613421202\n",
      "Epoch 2, Batch 49400, Loss: 0.0018928699428215623\n",
      "Epoch 2, Batch 49450, Loss: 0.0035970157478004694\n",
      "Epoch 2, Batch 49500, Loss: 0.0030333446338772774\n",
      "Epoch 2, Batch 49550, Loss: 0.002559982007369399\n",
      "Epoch 2, Batch 49600, Loss: 0.002325574168935418\n",
      "Epoch 2, Batch 49650, Loss: 0.001315602450631559\n",
      "Epoch 2, Batch 49700, Loss: 0.002082349034026265\n",
      "Epoch 2, Batch 49750, Loss: 0.002071141032502055\n",
      "Epoch 2, Batch 49800, Loss: 0.0019273501820862293\n",
      "Epoch 2, Batch 49850, Loss: 0.002295388840138912\n",
      "Epoch 2, Batch 49900, Loss: 0.0019123951205983758\n",
      "Epoch 2, Batch 49950, Loss: 0.0022784220054745674\n",
      "Epoch 2, Batch 50000, Loss: 0.3824595808982849\n",
      "Epoch 2, Batch 50050, Loss: 0.0034354000817984343\n",
      "Epoch 2, Batch 50100, Loss: 0.002459889743477106\n",
      "Epoch 2, Batch 50150, Loss: 0.004108745139092207\n",
      "Epoch 2, Batch 50200, Loss: 0.0052368673495948315\n",
      "Epoch 2, Batch 50250, Loss: 0.004652625881135464\n",
      "Epoch 2, Batch 50300, Loss: 0.004172193352133036\n",
      "Epoch 2, Batch 50350, Loss: 0.0026248616632074118\n",
      "Epoch 2, Batch 50400, Loss: 0.0032193623483181\n",
      "Epoch 2, Batch 50450, Loss: 0.002896544523537159\n",
      "Epoch 2, Batch 50500, Loss: 0.0024626143276691437\n",
      "Epoch 2, Batch 50550, Loss: 0.002391131827607751\n",
      "Epoch 2, Batch 50600, Loss: 0.004031848628073931\n",
      "Epoch 2, Batch 50650, Loss: 0.0038527618162333965\n",
      "Epoch 2, Batch 50700, Loss: 0.0033030123449862003\n",
      "Epoch 2, Batch 50750, Loss: 0.0026782862842082977\n",
      "Epoch 2, Batch 50800, Loss: 0.0030672200955450535\n",
      "Epoch 2, Batch 50850, Loss: 0.0026665448676794767\n",
      "Epoch 2, Batch 50900, Loss: 0.3803696930408478\n",
      "Epoch 2, Batch 50950, Loss: 0.0035790528636425734\n",
      "Epoch 2, Batch 51000, Loss: 0.00410359026864171\n",
      "Epoch 2, Batch 51050, Loss: 0.0033299655187875032\n",
      "Epoch 2, Batch 51100, Loss: 0.0033618900924921036\n",
      "Epoch 2, Batch 51150, Loss: 0.002215953543782234\n",
      "Epoch 2, Batch 51200, Loss: 0.0019448298262432218\n",
      "Epoch 2, Batch 51250, Loss: 0.0025029960088431835\n",
      "Epoch 2, Batch 51300, Loss: 0.0017714106943458319\n",
      "Epoch 2, Batch 51350, Loss: 0.002225517760962248\n",
      "Epoch 2, Batch 51400, Loss: 0.003154423553496599\n",
      "Epoch 2, Batch 51450, Loss: 0.0030369567684829235\n",
      "Epoch 2, Batch 51500, Loss: 0.0019295570673421025\n",
      "Epoch 2, Batch 51550, Loss: 0.0015587980160489678\n",
      "Epoch 2, Batch 51600, Loss: 0.0013604783453047276\n",
      "Epoch 2, Batch 51650, Loss: 0.0025632595643401146\n",
      "Epoch 2, Batch 51700, Loss: 0.002018214901909232\n",
      "Epoch 2, Batch 51750, Loss: 0.002078906400129199\n",
      "Epoch 2, Batch 51800, Loss: 0.0018821773119270802\n",
      "Epoch 2, Batch 51850, Loss: 0.00171613076236099\n",
      "Epoch 2, Batch 51900, Loss: 0.4297974407672882\n",
      "Epoch 2, Batch 51950, Loss: 0.0017794952727854252\n",
      "Epoch 2, Batch 52000, Loss: 0.0013732651714235544\n",
      "Epoch 2, Batch 52050, Loss: 0.0016655332874506712\n",
      "Epoch 2, Batch 52100, Loss: 0.0012569832615554333\n",
      "Epoch 2, Batch 52150, Loss: 0.4339539706707001\n",
      "Epoch 2, Batch 52200, Loss: 0.0012576737208291888\n",
      "Epoch 2, Batch 52250, Loss: 0.0018434112425893545\n",
      "Epoch 2, Batch 52300, Loss: 0.004272474907338619\n",
      "Epoch 2, Batch 52350, Loss: 0.004813215229660273\n",
      "Epoch 2, Batch 52400, Loss: 0.0032547784503549337\n",
      "Epoch 2, Batch 52450, Loss: 0.0024905293248593807\n",
      "Epoch 2, Batch 52500, Loss: 0.002773138927295804\n",
      "Epoch 2, Batch 52550, Loss: 0.0026351686101406813\n",
      "Epoch 2, Batch 52600, Loss: 0.0018917694687843323\n",
      "Epoch 2, Batch 52650, Loss: 0.0017253418918699026\n",
      "Epoch 2, Batch 52700, Loss: 0.0013629966415464878\n",
      "Epoch 2, Batch 52750, Loss: 0.38407090306282043\n",
      "Epoch 2, Batch 52800, Loss: 0.004087488166987896\n",
      "Epoch 2, Batch 52850, Loss: 0.004001914523541927\n",
      "Epoch 2, Batch 52900, Loss: 0.0037660240195691586\n",
      "Epoch 2, Batch 52950, Loss: 0.004113676026463509\n",
      "Epoch 2, Batch 53000, Loss: 0.0037501156330108643\n",
      "Epoch 2, Batch 53050, Loss: 0.0034177040215581656\n",
      "Epoch 2, Batch 53100, Loss: 0.004135421477258205\n",
      "Epoch 2, Batch 53150, Loss: 0.005935578607022762\n",
      "Epoch 2, Batch 53200, Loss: 0.003827984444797039\n",
      "Epoch 2, Batch 53250, Loss: 0.002417388604953885\n",
      "Epoch 2, Batch 53300, Loss: 0.0025466487277299166\n",
      "Epoch 2, Batch 53350, Loss: 0.0019593555480241776\n",
      "Epoch 2, Batch 53400, Loss: 0.001570122898556292\n",
      "Epoch 2, Batch 53450, Loss: 0.0018270714208483696\n",
      "Epoch 2, Batch 53500, Loss: 0.37883177399635315\n",
      "Epoch 2, Batch 53550, Loss: 0.0024586550425738096\n",
      "Epoch 2, Batch 53600, Loss: 0.0030089393258094788\n",
      "Epoch 2, Batch 53650, Loss: 0.0036685278173536062\n",
      "Epoch 2, Batch 53700, Loss: 0.0032944383565336466\n",
      "Epoch 2, Batch 53750, Loss: 0.0030806411523371935\n",
      "Epoch 2, Batch 53800, Loss: 0.0032075359486043453\n",
      "Epoch 2, Batch 53850, Loss: 0.003568063722923398\n",
      "Epoch 2, Batch 53900, Loss: 0.0038915537297725677\n",
      "Epoch 2, Batch 53950, Loss: 0.0036970602814108133\n",
      "Epoch 2, Batch 54000, Loss: 0.0034489308018237352\n",
      "Epoch 2, Batch 54050, Loss: 0.003410322591662407\n",
      "Epoch 2, Batch 54100, Loss: 0.00419320585206151\n",
      "Epoch 2, Batch 54150, Loss: 0.0053702727891504765\n",
      "Epoch 2, Batch 54200, Loss: 0.006843909155577421\n",
      "Epoch 2, Batch 54250, Loss: 0.00652298191562295\n",
      "Epoch 2, Batch 54300, Loss: 0.36105188727378845\n",
      "Epoch 2, Batch 54350, Loss: 0.004104370251297951\n",
      "Epoch 2, Batch 54400, Loss: 0.0028397832065820694\n",
      "Epoch 2, Batch 54450, Loss: 0.003348663682118058\n",
      "Epoch 2, Batch 54500, Loss: 0.37132528424263\n",
      "Epoch 2, Batch 54550, Loss: 0.004154350608587265\n",
      "Epoch 2, Batch 54600, Loss: 0.0033276337198913097\n",
      "Epoch 2, Batch 54650, Loss: 0.002622246975079179\n",
      "Epoch 2, Batch 54700, Loss: 0.002348867943510413\n",
      "Epoch 2, Batch 54750, Loss: 0.002636185847222805\n",
      "Epoch 2, Batch 54800, Loss: 0.0024406409356743097\n",
      "Epoch 2, Batch 54850, Loss: 0.004278719890862703\n",
      "Epoch 2, Batch 54900, Loss: 0.0030762404203414917\n",
      "Epoch 2, Batch 54950, Loss: 0.0025348712224513292\n",
      "Epoch 2, Batch 55000, Loss: 0.0026700764428824186\n",
      "Epoch 2, Batch 55050, Loss: 0.0021193958818912506\n",
      "Epoch 2, Batch 55100, Loss: 0.0027058348059654236\n",
      "Epoch 2, Batch 55150, Loss: 0.0018359959358349442\n",
      "Epoch 2, Batch 55200, Loss: 0.0016924509545788169\n",
      "Epoch 2, Batch 55250, Loss: 0.001989622600376606\n",
      "Epoch 2, Batch 55300, Loss: 0.3891039192676544\n",
      "Epoch 2, Batch 55350, Loss: 0.002694379538297653\n",
      "Epoch 2, Batch 55400, Loss: 0.3640006482601166\n",
      "Epoch 2, Batch 55450, Loss: 0.0031918513122946024\n",
      "Epoch 2, Batch 55500, Loss: 0.003934880718588829\n",
      "Epoch 2, Batch 55550, Loss: 0.004601864609867334\n",
      "Epoch 2, Batch 55600, Loss: 0.3697773218154907\n",
      "Epoch 2, Batch 55650, Loss: 0.0040205419063568115\n",
      "Epoch 2, Batch 55700, Loss: 0.0032134049106389284\n",
      "Epoch 2, Batch 55750, Loss: 0.0031670378521084785\n",
      "Epoch 2, Batch 55800, Loss: 0.0027638974133878946\n",
      "Epoch 2, Batch 55850, Loss: 0.00351726240478456\n",
      "Epoch 2, Batch 55900, Loss: 0.0025474121794104576\n",
      "Epoch 2, Batch 55950, Loss: 0.0024894624948501587\n",
      "Epoch 2, Batch 56000, Loss: 0.0030487722251564264\n",
      "Epoch 2, Batch 56050, Loss: 0.0025606073904782534\n",
      "Epoch 2, Batch 56100, Loss: 0.001789972884580493\n",
      "Epoch 2, Batch 56150, Loss: 0.0018827869789674878\n",
      "Epoch 2, Batch 56200, Loss: 0.38460132479667664\n",
      "Epoch 2, Batch 56250, Loss: 0.003508697496727109\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Assuming the model, dataset, and device setup\n",
    "model = model.to(device)  # Ensure model is on the correct device\n",
    "optimizer = Adam(model.parameters(), lr=5e-5)  # Define optimizer\n",
    "\n",
    "# Define DataLoader for both training and validation datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=16)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 3  # Define the number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        # Ensure all data in the batch is moved to the correct device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=batch['input_ids'],\n",
    "                        attention_mask=batch['attention_mask'],\n",
    "                        protein_features=batch['protein_encodings'])\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = F.cross_entropy(outputs, batch['labels'])  # Assuming your model outputs raw logits\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print loss every 50 batches\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f\"Epoch {epoch}, Batch {i + 1}, Loss: {loss.item()}\")  # Output the loss\n",
    "\n",
    "    # Validation loop (optional, for model evaluation during training)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(input_ids=batch['input_ids'],\n",
    "                            attention_mask=batch['attention_mask'],\n",
    "                            protein_features=batch['protein_encodings'])\n",
    "            loss = F.cross_entropy(outputs, batch['labels'])\n",
    "            # Add additional code to track validation loss, accuracy, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "159e9962",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T23:54:24.986048Z",
     "iopub.status.busy": "2024-05-05T23:54:24.984786Z",
     "iopub.status.idle": "2024-05-05T23:54:25.574416Z",
     "shell.execute_reply": "2024-05-05T23:54:25.573615Z"
    },
    "papermill": {
     "duration": 0.858937,
     "end_time": "2024-05-05T23:54:25.576749",
     "exception": false,
     "start_time": "2024-05-05T23:54:24.717812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save only the state dict\n",
    "torch.save(model.state_dict(), 'model_state_dict.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "224796aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T23:54:26.122569Z",
     "iopub.status.busy": "2024-05-05T23:54:26.122242Z",
     "iopub.status.idle": "2024-05-05T23:54:26.712943Z",
     "shell.execute_reply": "2024-05-05T23:54:26.712072Z"
    },
    "papermill": {
     "duration": 0.869217,
     "end_time": "2024-05-05T23:54:26.715192",
     "exception": false,
     "start_time": "2024-05-05T23:54:25.845975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Save the entire model\n",
    "torch.save(model, 'entire_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb68d9fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T18:59:35.122901Z",
     "iopub.status.busy": "2024-05-05T18:59:35.122561Z",
     "iopub.status.idle": "2024-05-05T18:59:35.257471Z",
     "shell.execute_reply": "2024-05-05T18:59:35.256563Z",
     "shell.execute_reply.started": "2024-05-05T18:59:35.122877Z"
    },
    "papermill": {
     "duration": 0.307873,
     "end_time": "2024-05-05T23:54:27.373755",
     "exception": false,
     "start_time": "2024-05-05T23:54:27.065882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d9c88e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:01:24.693101Z",
     "iopub.status.busy": "2024-05-05T19:01:24.692167Z",
     "iopub.status.idle": "2024-05-05T19:01:24.700407Z",
     "shell.execute_reply": "2024-05-05T19:01:24.699470Z",
     "shell.execute_reply.started": "2024-05-05T19:01:24.693069Z"
    },
    "papermill": {
     "duration": 0.28322,
     "end_time": "2024-05-05T23:54:27.950657",
     "exception": false,
     "start_time": "2024-05-05T23:54:27.667437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f59fc1e9",
   "metadata": {
    "papermill": {
     "duration": 0.268514,
     "end_time": "2024-05-05T23:54:28.493495",
     "exception": false,
     "start_time": "2024-05-05T23:54:28.224981",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f24009f",
   "metadata": {
    "papermill": {
     "duration": 0.266536,
     "end_time": "2024-05-05T23:54:29.046784",
     "exception": false,
     "start_time": "2024-05-05T23:54:28.780248",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "LOading and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7de13d1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T23:54:29.583483Z",
     "iopub.status.busy": "2024-05-05T23:54:29.583133Z",
     "iopub.status.idle": "2024-05-05T23:54:29.587116Z",
     "shell.execute_reply": "2024-05-05T23:54:29.586217Z"
    },
    "papermill": {
     "duration": 0.275588,
     "end_time": "2024-05-05T23:54:29.588973",
     "exception": false,
     "start_time": "2024-05-05T23:54:29.313385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_test = pd.read_csv('/kaggle/input/leash-BELKA/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2295a7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T23:54:30.127641Z",
     "iopub.status.busy": "2024-05-05T23:54:30.127295Z",
     "iopub.status.idle": "2024-05-05T23:54:30.131234Z",
     "shell.execute_reply": "2024-05-05T23:54:30.130381Z"
    },
    "papermill": {
     "duration": 0.275215,
     "end_time": "2024-05-05T23:54:30.133139",
     "exception": false,
     "start_time": "2024-05-05T23:54:29.857924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8de3b229",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T23:54:30.667545Z",
     "iopub.status.busy": "2024-05-05T23:54:30.667214Z",
     "iopub.status.idle": "2024-05-05T23:54:30.671337Z",
     "shell.execute_reply": "2024-05-05T23:54:30.670426Z"
    },
    "papermill": {
     "duration": 0.271825,
     "end_time": "2024-05-05T23:54:30.673329",
     "exception": false,
     "start_time": "2024-05-05T23:54:30.401504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Assuming df_test is your test DataFrame with similar columns as df_train except 'binds'\n",
    "# test_encodings = tokenizer(df_test['molecule_smiles'].tolist(), truncation=True, padding=True, max_length=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c328b3f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T23:54:31.275287Z",
     "iopub.status.busy": "2024-05-05T23:54:31.274424Z",
     "iopub.status.idle": "2024-05-05T23:54:31.278708Z",
     "shell.execute_reply": "2024-05-05T23:54:31.277784Z"
    },
    "papermill": {
     "duration": 0.341099,
     "end_time": "2024-05-05T23:54:31.280536",
     "exception": false,
     "start_time": "2024-05-05T23:54:30.939437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_dataset = SMILESTestDataset(test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "30091f4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T23:54:31.819236Z",
     "iopub.status.busy": "2024-05-05T23:54:31.818883Z",
     "iopub.status.idle": "2024-05-05T23:54:31.822958Z",
     "shell.execute_reply": "2024-05-05T23:54:31.822113Z"
    },
    "papermill": {
     "duration": 0.274288,
     "end_time": "2024-05-05T23:54:31.824826",
     "exception": false,
     "start_time": "2024-05-05T23:54:31.550538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Predict\n",
    "# predictions = trainer.predict(test_dataset)\n",
    "\n",
    "# # The predictions object includes a predictions array, label_ids array (if available), and metrics (if labels provided during prediction)\n",
    "# pred_labels = predictions.predictions.argmax(-1)  # We use argmax to convert from logits to class labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c2821d88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T23:54:32.364750Z",
     "iopub.status.busy": "2024-05-05T23:54:32.364380Z",
     "iopub.status.idle": "2024-05-05T23:54:32.368436Z",
     "shell.execute_reply": "2024-05-05T23:54:32.367615Z"
    },
    "papermill": {
     "duration": 0.277719,
     "end_time": "2024-05-05T23:54:32.370244",
     "exception": false,
     "start_time": "2024-05-05T23:54:32.092525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_test['predicted_binds'] = pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a1f68d0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T23:54:32.903351Z",
     "iopub.status.busy": "2024-05-05T23:54:32.903013Z",
     "iopub.status.idle": "2024-05-05T23:54:32.906933Z",
     "shell.execute_reply": "2024-05-05T23:54:32.906060Z"
    },
    "papermill": {
     "duration": 0.272309,
     "end_time": "2024-05-05T23:54:32.908864",
     "exception": false,
     "start_time": "2024-05-05T23:54:32.636555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Saving the DataFrame with predictions to a new CSV file\n",
    "# df_test.to_csv('test_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b232d678",
   "metadata": {
    "papermill": {
     "duration": 0.268679,
     "end_time": "2024-05-05T23:54:33.441032",
     "exception": false,
     "start_time": "2024-05-05T23:54:33.172353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8006601,
     "sourceId": 67356,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14857.19599,
   "end_time": "2024-05-05T23:54:37.161536",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-05T19:46:59.965546",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00a2c521e904471d9fad4a242b7b0637": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "02cdcac3a1d44c28b6ebbc90c338777f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1514aa65984343af8211cf411a4e9482": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "153f13319c244408b240df116cf33cef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1850dc28f93641258781c2966758202d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1c7b5f1ed193437c9380b13355685a7e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d3e2d25e000a49419a6b079cf37ff696",
       "placeholder": "​",
       "style": "IPY_MODEL_cda1cf3b3bb949a2b365e9e303b06c46",
       "value": " 62.0/62.0 [00:00&lt;00:00, 4.97kB/s]"
      }
     },
     "20e97c13a44046a7b63aab1282a1ff41": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2438645c600147788a9a4361961bd817": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ef74e32e36944b7b8a7444126adf8b4e",
        "IPY_MODEL_cc0cad48963e45e7834c4b051b6fa6c5",
        "IPY_MODEL_2c5c7c306664493789afba04ff1e6a05"
       ],
       "layout": "IPY_MODEL_153f13319c244408b240df116cf33cef"
      }
     },
     "245e61f074294506985363ac5acf0147": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_42f8a632dbb9435b9cc313376ab59fe5",
       "placeholder": "​",
       "style": "IPY_MODEL_4d2b830304f447dfa11967f8f0de1ec3",
       "value": " 515/515 [00:00&lt;00:00, 45.3kB/s]"
      }
     },
     "2c5c7c306664493789afba04ff1e6a05": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_20e97c13a44046a7b63aab1282a1ff41",
       "placeholder": "​",
       "style": "IPY_MODEL_82daa6ec62a94af98803c6871afc4e08",
       "value": " 336M/336M [00:03&lt;00:00, 94.0MB/s]"
      }
     },
     "3564ce7879ed43e18c9bd1cac53e13c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3584db61af7c454eb23db05abf14eb52": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_bf01c42b41ce41cea63fb928389cbe52",
        "IPY_MODEL_5d9067f1c9f643408e4cfdd2b52076c5",
        "IPY_MODEL_1c7b5f1ed193437c9380b13355685a7e"
       ],
       "layout": "IPY_MODEL_1514aa65984343af8211cf411a4e9482"
      }
     },
     "35e56e98dbf64d85a23f1f109201c143": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3819edbc2070479da6ca43847e9f5732": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "38f538f52a0441f79f570622221aaf95": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c4b99447a37242509287abdd1330b338",
        "IPY_MODEL_49e23f1f366c432b9b87ffdd88f3e0a5",
        "IPY_MODEL_899d123a2116402fb5f422443b32366c"
       ],
       "layout": "IPY_MODEL_c84be96340d84fb89598830f3a68f0e7"
      }
     },
     "3d06140e4a83458992ac1de5ed9c71e1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "42f8a632dbb9435b9cc313376ab59fe5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "445dde75d6f347b5b65c844b6b6f9701": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "49e23f1f366c432b9b87ffdd88f3e0a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3d06140e4a83458992ac1de5ed9c71e1",
       "max": 101307.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_95cba7e6de1c4f1b94bd094f1daf5050",
       "value": 101307.0
      }
     },
     "4d2b830304f447dfa11967f8f0de1ec3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4e8fc2dbc621431e867570732bfc5d30": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4e9128f2baa349209cff08d249257cb1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "534a7939cb9e4ba096062ceba3a6810b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_59f78462c7a241db8788b4abb044c500",
       "max": 515.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_feabd83e7b17445da13b4e4ccb6d3b07",
       "value": 515.0
      }
     },
     "55f99308bf6e41d2b9cc80282a171a96": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fc6f2127106d4e83a80f5bc6f3aac0f9",
       "placeholder": "​",
       "style": "IPY_MODEL_1850dc28f93641258781c2966758202d",
       "value": "vocab.json: 100%"
      }
     },
     "59f78462c7a241db8788b4abb044c500": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5c62c50c1ac54865a3461917e02cb34e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_55f99308bf6e41d2b9cc80282a171a96",
        "IPY_MODEL_780ef5401feb4b249084439a3b9ef19d",
        "IPY_MODEL_f2ba3a8087d443d08447b2651fe3d09c"
       ],
       "layout": "IPY_MODEL_92d04ad6d80c4a87bd6fe8e8247d789f"
      }
     },
     "5c9249b4f9324a199d45973dbaa66f0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5d9067f1c9f643408e4cfdd2b52076c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_64559ea4e2594faa92f2b2d3896bccce",
       "max": 62.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6e29cf3693f240879e2b47ca8f31c1aa",
       "value": 62.0
      }
     },
     "64559ea4e2594faa92f2b2d3896bccce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "65a19cd88885474fa098ec9d967841e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_da2ad9326cff4799aee85ca7cef0d4f9",
        "IPY_MODEL_534a7939cb9e4ba096062ceba3a6810b",
        "IPY_MODEL_245e61f074294506985363ac5acf0147"
       ],
       "layout": "IPY_MODEL_b103e20bf59446a69f06ec1b76fcb5f4"
      }
     },
     "6ae61dfa91294beb8238a91bab3678d0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6e29cf3693f240879e2b47ca8f31c1aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "780ef5401feb4b249084439a3b9ef19d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_00a2c521e904471d9fad4a242b7b0637",
       "max": 164540.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5c9249b4f9324a199d45973dbaa66f0d",
       "value": 164540.0
      }
     },
     "7889bf166d424209b7042b43265f3330": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "792b428ba4da41babdbe0bed3a43c807": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7ca12edd0b2c41f6a19d585c40381d59": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7f17a39f38b94cceadaf50c7e714828a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a468506d266f44588a181a19bd2cda1a",
       "placeholder": "​",
       "style": "IPY_MODEL_bd4b067a57b84d069f5f1922cbf8edbc",
       "value": " 772/772 [00:00&lt;00:00, 66.4kB/s]"
      }
     },
     "8095ebcad98743c29832ca31deab778d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "82daa6ec62a94af98803c6871afc4e08": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8837800f5545406a9b3f1dff34db4697": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c833afdd79a744458b67b319dfce6308",
        "IPY_MODEL_97e0c2e56dbc491b92f7de449b70cba0",
        "IPY_MODEL_7f17a39f38b94cceadaf50c7e714828a"
       ],
       "layout": "IPY_MODEL_8095ebcad98743c29832ca31deab778d"
      }
     },
     "899d123a2116402fb5f422443b32366c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e7a0cc2221e940c48209270ff0e3498e",
       "placeholder": "​",
       "style": "IPY_MODEL_ac37ea0b33ce46d1a5a18cd99e434776",
       "value": " 101k/101k [00:00&lt;00:00, 512kB/s]"
      }
     },
     "92d04ad6d80c4a87bd6fe8e8247d789f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "95cba7e6de1c4f1b94bd094f1daf5050": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "97e0c2e56dbc491b92f7de449b70cba0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7889bf166d424209b7042b43265f3330",
       "max": 772.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_35e56e98dbf64d85a23f1f109201c143",
       "value": 772.0
      }
     },
     "9ff09fb589214a13b46a43227b8bf978": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a468506d266f44588a181a19bd2cda1a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a87db4eb11bf48f0bdf82aa5282b65ae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ac37ea0b33ce46d1a5a18cd99e434776": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b103e20bf59446a69f06ec1b76fcb5f4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bd4b067a57b84d069f5f1922cbf8edbc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "bf01c42b41ce41cea63fb928389cbe52": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d481c2810df9451492f91ca4ea580db8",
       "placeholder": "​",
       "style": "IPY_MODEL_3564ce7879ed43e18c9bd1cac53e13c5",
       "value": "tokenizer_config.json: 100%"
      }
     },
     "c4b99447a37242509287abdd1330b338": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fff69bee1f4f4dae84d6ccf82e1e7725",
       "placeholder": "​",
       "style": "IPY_MODEL_3819edbc2070479da6ca43847e9f5732",
       "value": "merges.txt: 100%"
      }
     },
     "c833afdd79a744458b67b319dfce6308": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_445dde75d6f347b5b65c844b6b6f9701",
       "placeholder": "​",
       "style": "IPY_MODEL_792b428ba4da41babdbe0bed3a43c807",
       "value": "special_tokens_map.json: 100%"
      }
     },
     "c84be96340d84fb89598830f3a68f0e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cc0cad48963e45e7834c4b051b6fa6c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_02cdcac3a1d44c28b6ebbc90c338777f",
       "max": 336422980.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7ca12edd0b2c41f6a19d585c40381d59",
       "value": 336422980.0
      }
     },
     "cda1cf3b3bb949a2b365e9e303b06c46": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d3e2d25e000a49419a6b079cf37ff696": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d481c2810df9451492f91ca4ea580db8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "da2ad9326cff4799aee85ca7cef0d4f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6ae61dfa91294beb8238a91bab3678d0",
       "placeholder": "​",
       "style": "IPY_MODEL_9ff09fb589214a13b46a43227b8bf978",
       "value": "config.json: 100%"
      }
     },
     "e7a0cc2221e940c48209270ff0e3498e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ebf30669c0b144389252393951de4996": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ef74e32e36944b7b8a7444126adf8b4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4e9128f2baa349209cff08d249257cb1",
       "placeholder": "​",
       "style": "IPY_MODEL_ebf30669c0b144389252393951de4996",
       "value": "pytorch_model.bin: 100%"
      }
     },
     "f2ba3a8087d443d08447b2651fe3d09c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a87db4eb11bf48f0bdf82aa5282b65ae",
       "placeholder": "​",
       "style": "IPY_MODEL_4e8fc2dbc621431e867570732bfc5d30",
       "value": " 165k/165k [00:00&lt;00:00, 417kB/s]"
      }
     },
     "fc6f2127106d4e83a80f5bc6f3aac0f9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "feabd83e7b17445da13b4e4ccb6d3b07": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "fff69bee1f4f4dae84d6ccf82e1e7725": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
