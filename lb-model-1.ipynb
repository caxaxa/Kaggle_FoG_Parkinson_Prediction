{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "054aa936",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-07T16:51:37.891922Z",
     "iopub.status.busy": "2024-05-07T16:51:37.891150Z",
     "iopub.status.idle": "2024-05-07T16:51:38.613418Z",
     "shell.execute_reply": "2024-05-07T16:51:38.612365Z"
    },
    "papermill": {
     "duration": 0.740017,
     "end_time": "2024-05-07T16:51:38.615673",
     "exception": false,
     "start_time": "2024-05-07T16:51:37.875656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/leash-BELKA/sample_submission.csv\n",
      "/kaggle/input/leash-BELKA/train.parquet\n",
      "/kaggle/input/leash-BELKA/test.parquet\n",
      "/kaggle/input/leash-BELKA/train.csv\n",
      "/kaggle/input/leash-BELKA/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under theinput directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939eaedf",
   "metadata": {
    "papermill": {
     "duration": 0.013394,
     "end_time": "2024-05-07T16:51:38.643068",
     "exception": false,
     "start_time": "2024-05-07T16:51:38.629674",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LB Competition:\n",
    "\n",
    "## 1. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c88e9b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:51:38.671566Z",
     "iopub.status.busy": "2024-05-07T16:51:38.671176Z",
     "iopub.status.idle": "2024-05-07T16:51:38.675065Z",
     "shell.execute_reply": "2024-05-07T16:51:38.674234Z"
    },
    "papermill": {
     "duration": 0.020355,
     "end_time": "2024-05-07T16:51:38.676952",
     "exception": false,
     "start_time": "2024-05-07T16:51:38.656597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## Loading The Data\n",
    "\n",
    "# # Change to full Dataseet  for Massive Training and for testing\n",
    "# df_train = pd.read_csv('/kaggle/input/leash-BELKA/train.csv', nrows=1000)\n",
    "# df_test = pd.read_csv('/kaggle/input/leash-BELKA/test.csv', nrows=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "993892e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:51:38.705750Z",
     "iopub.status.busy": "2024-05-07T16:51:38.705471Z",
     "iopub.status.idle": "2024-05-07T16:51:38.709174Z",
     "shell.execute_reply": "2024-05-07T16:51:38.708362Z"
    },
    "papermill": {
     "duration": 0.020574,
     "end_time": "2024-05-07T16:51:38.711039",
     "exception": false,
     "start_time": "2024-05-07T16:51:38.690465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "261d5d97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:51:38.739078Z",
     "iopub.status.busy": "2024-05-07T16:51:38.738842Z",
     "iopub.status.idle": "2024-05-07T16:51:38.742317Z",
     "shell.execute_reply": "2024-05-07T16:51:38.741580Z"
    },
    "papermill": {
     "duration": 0.019539,
     "end_time": "2024-05-07T16:51:38.744107",
     "exception": false,
     "start_time": "2024-05-07T16:51:38.724568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install rdkit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e2dc60",
   "metadata": {
    "papermill": {
     "duration": 0.013268,
     "end_time": "2024-05-07T16:51:38.770775",
     "exception": false,
     "start_time": "2024-05-07T16:51:38.757507",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Plotting 2d Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bbe477a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:51:38.798732Z",
     "iopub.status.busy": "2024-05-07T16:51:38.798484Z",
     "iopub.status.idle": "2024-05-07T16:51:38.802407Z",
     "shell.execute_reply": "2024-05-07T16:51:38.801580Z"
    },
    "papermill": {
     "duration": 0.019985,
     "end_time": "2024-05-07T16:51:38.804291",
     "exception": false,
     "start_time": "2024-05-07T16:51:38.784306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from rdkit import Chem\n",
    "# from rdkit.Chem import Draw\n",
    "\n",
    "# def plot_2d_molecule(df, molecule_id):\n",
    "#     # Filter the DataFrame for the given id\n",
    "#     row = df[df['id'] == molecule_id]\n",
    "#     # Get the SMILES string for the molecule\n",
    "#     smiles_string = row['molecule_smiles'].values[0]\n",
    "#     # Generate an RDKit molecule object\n",
    "#     mol = Chem.MolFromSmiles(smiles_string)\n",
    "#     # Use RDKit to draw the molecule\n",
    "#     img = Draw.MolToImage(mol)\n",
    "#     # Display the image\n",
    "#     return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df8245ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:51:38.832320Z",
     "iopub.status.busy": "2024-05-07T16:51:38.832083Z",
     "iopub.status.idle": "2024-05-07T16:51:38.835636Z",
     "shell.execute_reply": "2024-05-07T16:51:38.834788Z"
    },
    "papermill": {
     "duration": 0.019729,
     "end_time": "2024-05-07T16:51:38.837545",
     "exception": false,
     "start_time": "2024-05-07T16:51:38.817816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #Example usage:\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mpimg\n",
    "\n",
    "# img = plot_2d_molecule(df_train, 1)\n",
    "# plt.imshow(img)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62358fa",
   "metadata": {
    "papermill": {
     "duration": 0.013606,
     "end_time": "2024-05-07T16:51:38.864950",
     "exception": false,
     "start_time": "2024-05-07T16:51:38.851344",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Plotting 3d Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21344950",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:51:38.893378Z",
     "iopub.status.busy": "2024-05-07T16:51:38.892798Z",
     "iopub.status.idle": "2024-05-07T16:51:38.896544Z",
     "shell.execute_reply": "2024-05-07T16:51:38.895708Z"
    },
    "papermill": {
     "duration": 0.019883,
     "end_time": "2024-05-07T16:51:38.898323",
     "exception": false,
     "start_time": "2024-05-07T16:51:38.878440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install py3Dmol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93881d6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:51:38.927176Z",
     "iopub.status.busy": "2024-05-07T16:51:38.926633Z",
     "iopub.status.idle": "2024-05-07T16:51:38.931538Z",
     "shell.execute_reply": "2024-05-07T16:51:38.930732Z"
    },
    "papermill": {
     "duration": 0.02173,
     "end_time": "2024-05-07T16:51:38.933467",
     "exception": false,
     "start_time": "2024-05-07T16:51:38.911737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# from rdkit.Chem import AllChem\n",
    "# import py3Dmol\n",
    "\n",
    "# def plot_3d_molecule_by_id(df, molecule_id):\n",
    "#     # Filter the DataFrame for the given id\n",
    "#     row = df[df['id'] == molecule_id]\n",
    "#     if row.empty:\n",
    "#         return \"No entry with the given ID.\"\n",
    "\n",
    "#     # Get the SMILES string for the molecule\n",
    "#     smiles_string = row['molecule_smiles'].values[0]\n",
    "#     if not smiles_string:\n",
    "#         return \"No SMILES string found for the given ID.\"\n",
    "    \n",
    "#     # Create a molecule from a SMILES string\n",
    "#     mol = Chem.MolFromSmiles(smiles_string)\n",
    "#     if mol is None:\n",
    "#         return \"Invalid SMILES string.\"\n",
    "    \n",
    "#     # Generate 3D coordinates\n",
    "#     mol = Chem.AddHs(mol)  # Add hydrogens\n",
    "#     AllChem.EmbedMolecule(mol, AllChem.ETKDG())  # Embed molecule in 3D space using ETKDG methodology\n",
    "#     AllChem.UFFOptimizeMolecule(mol)  # Optimize the geometry\n",
    "\n",
    "#     # Use py3Dmol for visualization\n",
    "#     mb = Chem.MolToMolBlock(mol)\n",
    "#     viewer = py3Dmol.view(width=800, height=400)\n",
    "#     viewer.addModel(mb, \"mol\")\n",
    "#     viewer.setStyle({'stick': {}})\n",
    "#     viewer.zoomTo()\n",
    "#     return viewer.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a198af5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:51:38.962211Z",
     "iopub.status.busy": "2024-05-07T16:51:38.961573Z",
     "iopub.status.idle": "2024-05-07T16:51:38.965258Z",
     "shell.execute_reply": "2024-05-07T16:51:38.964420Z"
    },
    "papermill": {
     "duration": 0.020074,
     "end_time": "2024-05-07T16:51:38.967178",
     "exception": false,
     "start_time": "2024-05-07T16:51:38.947104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Example usage:\n",
    "# plot_3d_molecule_by_id(df_train, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6794b68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:51:38.996538Z",
     "iopub.status.busy": "2024-05-07T16:51:38.996207Z",
     "iopub.status.idle": "2024-05-07T16:51:38.999877Z",
     "shell.execute_reply": "2024-05-07T16:51:38.999103Z"
    },
    "papermill": {
     "duration": 0.020565,
     "end_time": "2024-05-07T16:51:39.001670",
     "exception": false,
     "start_time": "2024-05-07T16:51:38.981105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install rdkit-pypi networkx matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "679832f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:51:39.030256Z",
     "iopub.status.busy": "2024-05-07T16:51:39.029985Z",
     "iopub.status.idle": "2024-05-07T16:51:39.034525Z",
     "shell.execute_reply": "2024-05-07T16:51:39.033706Z"
    },
    "papermill": {
     "duration": 0.021443,
     "end_time": "2024-05-07T16:51:39.036394",
     "exception": false,
     "start_time": "2024-05-07T16:51:39.014951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# import pandas as pd\n",
    "# import networkx as nx\n",
    "# import matplotlib.pyplot as plt\n",
    "# from rdkit import Chem\n",
    "# from rdkit.Chem import Draw\n",
    "# from rdkit.Chem.rdmolops import GetAdjacencyMatrix\n",
    "\n",
    "# def plot_molecule_graph(df, molecule_id):\n",
    "#     # Find the molecule by ID\n",
    "#     row = df[df['id'] == molecule_id]\n",
    "#     if row.empty:\n",
    "#         print(\"No entry with the given ID.\")\n",
    "#         return\n",
    "\n",
    "#     # Extract the SMILES string\n",
    "#     smiles = row['molecule_smiles'].values[0]\n",
    "#     mol = Chem.MolFromSmiles(smiles)\n",
    "#     if mol is None:\n",
    "#         print(\"Invalid SMILES string.\")\n",
    "#         return\n",
    "\n",
    "#     # Create a graph from the molecule\n",
    "#     G = nx.Graph(Chem.rdmolops.GetAdjacencyMatrix(mol))\n",
    "#     labels = {}\n",
    "#     for idx, atom in enumerate(mol.GetAtoms()):\n",
    "#         G.nodes[idx]['label'] = atom.GetSymbol()\n",
    "#         labels[idx] = atom.GetSymbol()\n",
    "\n",
    "#     # Draw the graph\n",
    "#     pos = nx.spring_layout(G)  # positions for all nodes\n",
    "#     nx.draw(G, pos, with_labels=True, labels=labels, node_size=700, node_color='skyblue', font_size=16, font_weight='bold', edge_color='gray')\n",
    "#     plt.title(f'Molecular graph of ID {molecule_id}')\n",
    "#     plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ec57de7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:51:39.064300Z",
     "iopub.status.busy": "2024-05-07T16:51:39.064034Z",
     "iopub.status.idle": "2024-05-07T16:51:39.067775Z",
     "shell.execute_reply": "2024-05-07T16:51:39.066827Z"
    },
    "papermill": {
     "duration": 0.019957,
     "end_time": "2024-05-07T16:51:39.069756",
     "exception": false,
     "start_time": "2024-05-07T16:51:39.049799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Example usage:\n",
    "# plot_molecule_graph(df_train, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d540d7",
   "metadata": {
    "papermill": {
     "duration": 0.014323,
     "end_time": "2024-05-07T16:51:39.098807",
     "exception": false,
     "start_time": "2024-05-07T16:51:39.084484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9193aefc",
   "metadata": {
    "papermill": {
     "duration": 0.013148,
     "end_time": "2024-05-07T16:51:39.125606",
     "exception": false,
     "start_time": "2024-05-07T16:51:39.112458",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model 1 - SMILESBerth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db94b7bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:51:39.154885Z",
     "iopub.status.busy": "2024-05-07T16:51:39.154066Z",
     "iopub.status.idle": "2024-05-07T16:55:31.291954Z",
     "shell.execute_reply": "2024-05-07T16:55:31.291058Z"
    },
    "papermill": {
     "duration": 232.168668,
     "end_time": "2024-05-07T16:55:31.307781",
     "exception": false,
     "start_time": "2024-05-07T16:51:39.139113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluation datasets prepared.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define file path\n",
    "csv_file = '/kaggle/input/leash-BELKA/train.csv'\n",
    "\n",
    "# Load first 10M rows\n",
    "train_data = pd.read_csv(csv_file, nrows=60000000)\n",
    "\n",
    "# Filter for ones and zeros\n",
    "df_ones = train_data[train_data['binds'] == 1]\n",
    "df_zeros = train_data[train_data['binds'] == 0]\n",
    "\n",
    "df_zeros_balanced = df_zeros.sample(n=len(df_ones))\n",
    "df_train = pd.concat([df_ones, df_zeros_balanced]).sample(frac=1, random_state=42)\n",
    "\n",
    "# Load the next 100K rows for evaluation\n",
    "df_eval = pd.read_csv(csv_file, skiprows=range(1, 10000001), nrows=100000)\n",
    "\n",
    "# Now you have your train and eval datasets ready\n",
    "print(\"Training and evaluation datasets prepared.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e759317",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:55:31.336462Z",
     "iopub.status.busy": "2024-05-07T16:55:31.335831Z",
     "iopub.status.idle": "2024-05-07T16:55:39.846548Z",
     "shell.execute_reply": "2024-05-07T16:55:39.845701Z"
    },
    "papermill": {
     "duration": 8.527644,
     "end_time": "2024-05-07T16:55:39.848929",
     "exception": false,
     "start_time": "2024-05-07T16:55:31.321285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_eval = pd.read_csv(csv_file, skiprows=range(1, 10000001), nrows=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a36ba87f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:55:39.878853Z",
     "iopub.status.busy": "2024-05-07T16:55:39.878541Z",
     "iopub.status.idle": "2024-05-07T16:55:40.956686Z",
     "shell.execute_reply": "2024-05-07T16:55:40.955729Z"
    },
    "papermill": {
     "duration": 1.094986,
     "end_time": "2024-05-07T16:55:40.958633",
     "exception": false,
     "start_time": "2024-05-07T16:55:39.863647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a27834e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:55:41.032058Z",
     "iopub.status.busy": "2024-05-07T16:55:41.031245Z",
     "iopub.status.idle": "2024-05-07T16:55:41.083723Z",
     "shell.execute_reply": "2024-05-07T16:55:41.082799Z"
    },
    "papermill": {
     "duration": 0.112783,
     "end_time": "2024-05-07T16:55:41.085786",
     "exception": false,
     "start_time": "2024-05-07T16:55:40.973003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ad6325b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:55:41.115815Z",
     "iopub.status.busy": "2024-05-07T16:55:41.115201Z",
     "iopub.status.idle": "2024-05-07T16:55:41.119219Z",
     "shell.execute_reply": "2024-05-07T16:55:41.118403Z"
    },
    "papermill": {
     "duration": 0.020919,
     "end_time": "2024-05-07T16:55:41.121150",
     "exception": false,
     "start_time": "2024-05-07T16:55:41.100231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Save datasets if necessary\n",
    "# df_train_balanced.to_csv('/path/to/save/train_balanced.csv', index=False)\n",
    "# df_eval.to_csv('/path/to/save/eval.csv', index=False)\n",
    "\n",
    "# # Or proceed with further data processing, feature engineering, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09e6b21f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:55:41.149596Z",
     "iopub.status.busy": "2024-05-07T16:55:41.149241Z",
     "iopub.status.idle": "2024-05-07T16:55:41.152919Z",
     "shell.execute_reply": "2024-05-07T16:55:41.152124Z"
    },
    "papermill": {
     "duration": 0.019964,
     "end_time": "2024-05-07T16:55:41.154771",
     "exception": false,
     "start_time": "2024-05-07T16:55:41.134807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Split df_train to create a new training set and an evaluation set\n",
    "# df_train, df_eval = train_test_split(df, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35a659b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:55:41.182836Z",
     "iopub.status.busy": "2024-05-07T16:55:41.182581Z",
     "iopub.status.idle": "2024-05-07T16:55:41.188158Z",
     "shell.execute_reply": "2024-05-07T16:55:41.187329Z"
    },
    "papermill": {
     "duration": 0.021831,
     "end_time": "2024-05-07T16:55:41.190118",
     "exception": false,
     "start_time": "2024-05-07T16:55:41.168287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "589462"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ff5a049",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:55:41.218507Z",
     "iopub.status.busy": "2024-05-07T16:55:41.218226Z",
     "iopub.status.idle": "2024-05-07T16:55:41.231479Z",
     "shell.execute_reply": "2024-05-07T16:55:41.230593Z"
    },
    "papermill": {
     "duration": 0.029453,
     "end_time": "2024-05-07T16:55:41.233297",
     "exception": false,
     "start_time": "2024-05-07T16:55:41.203844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>buildingblock1_smiles</th>\n",
       "      <th>buildingblock2_smiles</th>\n",
       "      <th>buildingblock3_smiles</th>\n",
       "      <th>molecule_smiles</th>\n",
       "      <th>protein_name</th>\n",
       "      <th>binds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000000</td>\n",
       "      <td>C=CC[C@H](NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O</td>\n",
       "      <td>COC(=O)c1cscc1N.Cl</td>\n",
       "      <td>Cc1cccc2sc(N)nc12</td>\n",
       "      <td>C=CC[C@H](Nc1nc(Nc2nc3c(C)cccc3s2)nc(Nc2cscc2C...</td>\n",
       "      <td>HSA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000001</td>\n",
       "      <td>C=CC[C@H](NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O</td>\n",
       "      <td>COC(=O)c1cscc1N.Cl</td>\n",
       "      <td>Cc1cccc2sc(N)nc12</td>\n",
       "      <td>C=CC[C@H](Nc1nc(Nc2nc3c(C)cccc3s2)nc(Nc2cscc2C...</td>\n",
       "      <td>sEH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000002</td>\n",
       "      <td>C=CC[C@H](NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O</td>\n",
       "      <td>COC(=O)c1cscc1N.Cl</td>\n",
       "      <td>Cc1ccnc(N)c1</td>\n",
       "      <td>C=CC[C@H](Nc1nc(Nc2cc(C)ccn2)nc(Nc2cscc2C(=O)O...</td>\n",
       "      <td>BRD4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000003</td>\n",
       "      <td>C=CC[C@H](NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O</td>\n",
       "      <td>COC(=O)c1cscc1N.Cl</td>\n",
       "      <td>Cc1ccnc(N)c1</td>\n",
       "      <td>C=CC[C@H](Nc1nc(Nc2cc(C)ccn2)nc(Nc2cscc2C(=O)O...</td>\n",
       "      <td>HSA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000004</td>\n",
       "      <td>C=CC[C@H](NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O</td>\n",
       "      <td>COC(=O)c1cscc1N.Cl</td>\n",
       "      <td>Cc1ccnc(N)c1</td>\n",
       "      <td>C=CC[C@H](Nc1nc(Nc2cc(C)ccn2)nc(Nc2cscc2C(=O)O...</td>\n",
       "      <td>sEH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                          buildingblock1_smiles  \\\n",
       "0  10000000  C=CC[C@H](NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O   \n",
       "1  10000001  C=CC[C@H](NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O   \n",
       "2  10000002  C=CC[C@H](NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O   \n",
       "3  10000003  C=CC[C@H](NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O   \n",
       "4  10000004  C=CC[C@H](NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O   \n",
       "\n",
       "  buildingblock2_smiles buildingblock3_smiles  \\\n",
       "0    COC(=O)c1cscc1N.Cl     Cc1cccc2sc(N)nc12   \n",
       "1    COC(=O)c1cscc1N.Cl     Cc1cccc2sc(N)nc12   \n",
       "2    COC(=O)c1cscc1N.Cl          Cc1ccnc(N)c1   \n",
       "3    COC(=O)c1cscc1N.Cl          Cc1ccnc(N)c1   \n",
       "4    COC(=O)c1cscc1N.Cl          Cc1ccnc(N)c1   \n",
       "\n",
       "                                     molecule_smiles protein_name  binds  \n",
       "0  C=CC[C@H](Nc1nc(Nc2nc3c(C)cccc3s2)nc(Nc2cscc2C...          HSA      0  \n",
       "1  C=CC[C@H](Nc1nc(Nc2nc3c(C)cccc3s2)nc(Nc2cscc2C...          sEH      0  \n",
       "2  C=CC[C@H](Nc1nc(Nc2cc(C)ccn2)nc(Nc2cscc2C(=O)O...         BRD4      0  \n",
       "3  C=CC[C@H](Nc1nc(Nc2cc(C)ccn2)nc(Nc2cscc2C(=O)O...          HSA      0  \n",
       "4  C=CC[C@H](Nc1nc(Nc2cc(C)ccn2)nc(Nc2cscc2C(=O)O...          sEH      0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8654ff26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:55:41.262594Z",
     "iopub.status.busy": "2024-05-07T16:55:41.261938Z",
     "iopub.status.idle": "2024-05-07T16:55:55.122583Z",
     "shell.execute_reply": "2024-05-07T16:55:55.121633Z"
    },
    "papermill": {
     "duration": 13.877873,
     "end_time": "2024-05-07T16:55:55.125056",
     "exception": false,
     "start_time": "2024-05-07T16:55:41.247183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.2.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95f59564",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:55:55.157154Z",
     "iopub.status.busy": "2024-05-07T16:55:55.156818Z",
     "iopub.status.idle": "2024-05-07T16:56:04.419099Z",
     "shell.execute_reply": "2024-05-07T16:56:04.418327Z"
    },
    "papermill": {
     "duration": 9.280949,
     "end_time": "2024-05-07T16:56:04.421202",
     "exception": false,
     "start_time": "2024-05-07T16:55:55.140253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a34d02e6b05498da4ca962ee79893de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/62.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a475c236a714b1e88101d61fc5c9e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/515 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c313a402618a405facff79f440a3092c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/165k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409325c1b3344fa48678f7221ba4e45f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/101k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87684d328adb4a04bbfd0db67c3ee931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_name = \"seyonec/PubChem10M_SMILES_BPE_450k\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "708dffd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:56:04.454544Z",
     "iopub.status.busy": "2024-05-07T16:56:04.453839Z",
     "iopub.status.idle": "2024-05-07T16:57:06.706673Z",
     "shell.execute_reply": "2024-05-07T16:57:06.705751Z"
    },
    "papermill": {
     "duration": 62.271927,
     "end_time": "2024-05-07T16:57:06.709297",
     "exception": false,
     "start_time": "2024-05-07T16:56:04.437370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 16:56:08.271458: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-07 16:56:08.271562: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-07 16:56:08.397863: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "# Tokenizing the SMILES strings\n",
    "\n",
    "train_encodings = tokenizer(df_train['molecule_smiles'].tolist(), truncation=True, padding=True, max_length=512)\n",
    "eval_encodings = tokenizer(df_eval['molecule_smiles'].tolist(), truncation=True, padding=True, max_length=512)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "269302b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:57:06.742732Z",
     "iopub.status.busy": "2024-05-07T16:57:06.742135Z",
     "iopub.status.idle": "2024-05-07T16:57:07.000430Z",
     "shell.execute_reply": "2024-05-07T16:57:06.999480Z"
    },
    "papermill": {
     "duration": 0.277017,
     "end_time": "2024-05-07T16:57:07.002682",
     "exception": false,
     "start_time": "2024-05-07T16:57:06.725665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Encode protein names\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "train_proteins = encoder.fit_transform(df_train['protein_name'].values.reshape(-1, 1))\n",
    "eval_proteins = encoder.transform(df_eval['protein_name'].values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d24e1b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:57:07.037129Z",
     "iopub.status.busy": "2024-05-07T16:57:07.036805Z",
     "iopub.status.idle": "2024-05-07T16:57:07.043874Z",
     "shell.execute_reply": "2024-05-07T16:57:07.043106Z"
    },
    "papermill": {
     "duration": 0.026117,
     "end_time": "2024-05-07T16:57:07.045810",
     "exception": false,
     "start_time": "2024-05-07T16:57:07.019693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Creating a Dataset object for Hugging Face\n",
    "import torch\n",
    "\n",
    "class SMILESDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels, protein_encodings):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.protein_encodings = protein_encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        item['protein_encodings'] = torch.tensor(self.protein_encodings[idx], dtype=torch.float32)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8e03b3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:57:07.078521Z",
     "iopub.status.busy": "2024-05-07T16:57:07.078220Z",
     "iopub.status.idle": "2024-05-07T16:57:07.085481Z",
     "shell.execute_reply": "2024-05-07T16:57:07.084631Z"
    },
    "papermill": {
     "duration": 0.025795,
     "end_time": "2024-05-07T16:57:07.087471",
     "exception": false,
     "start_time": "2024-05-07T16:57:07.061676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ProteinBindingModel(nn.Module):\n",
    "    def __init__(self, transformer_model, num_protein_features):\n",
    "        super(ProteinBindingModel, self).__init__()\n",
    "        self.transformer = transformer_model\n",
    "        self.protein_features = nn.Linear(num_protein_features, 256)\n",
    "        self.classifier = nn.Linear(768 + 256, 2)  # Adjust sizes accordingly if using a different model\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, protein_features):\n",
    "        # Obtain the outputs from the transformer model\n",
    "        outputs = self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Use the last hidden state\n",
    "        last_hidden_state = outputs.last_hidden_state  # This is generally [batch size, sequence length, hidden size]\n",
    "        pooled_output = last_hidden_state[:, 0, :]  # Take the first token's embeddings across all batches\n",
    "        \n",
    "        # Process protein features\n",
    "        protein_features = self.protein_features(protein_features)\n",
    "        \n",
    "        # Concatenate pooled output and protein features\n",
    "        combined_features = torch.cat((pooled_output, protein_features), dim=1)\n",
    "        output = self.classifier(combined_features)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57ee0ddb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:57:07.119746Z",
     "iopub.status.busy": "2024-05-07T16:57:07.119488Z",
     "iopub.status.idle": "2024-05-07T16:57:07.136738Z",
     "shell.execute_reply": "2024-05-07T16:57:07.135999Z"
    },
    "papermill": {
     "duration": 0.035733,
     "end_time": "2024-05-07T16:57:07.138688",
     "exception": false,
     "start_time": "2024-05-07T16:57:07.102955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create Dataset\n",
    "train_dataset = SMILESDataset(train_encodings, df_train['binds'].tolist(), train_proteins)\n",
    "eval_dataset = SMILESDataset(eval_encodings, df_eval['binds'].tolist(), eval_proteins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "329531a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:57:07.171762Z",
     "iopub.status.busy": "2024-05-07T16:57:07.171465Z",
     "iopub.status.idle": "2024-05-07T16:57:12.908340Z",
     "shell.execute_reply": "2024-05-07T16:57:12.907404Z"
    },
    "papermill": {
     "duration": 5.756158,
     "end_time": "2024-05-07T16:57:12.910476",
     "exception": false,
     "start_time": "2024-05-07T16:57:07.154318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b287ce03eaa14696b20dfb9869efe636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/336M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at seyonec/PubChem10M_SMILES_BPE_450k and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the base transformer model without the classification head\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2).base_model\n",
    "model = ProteinBindingModel(base_model, train_proteins.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f18924ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:57:12.945111Z",
     "iopub.status.busy": "2024-05-07T16:57:12.944328Z",
     "iopub.status.idle": "2024-05-07T16:57:13.051475Z",
     "shell.execute_reply": "2024-05-07T16:57:13.050626Z"
    },
    "papermill": {
     "duration": 0.126743,
     "end_time": "2024-05-07T16:57:13.053733",
     "exception": false,
     "start_time": "2024-05-07T16:57:12.926990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='/kaggle/working/',           # output directory\n",
    "    num_train_epochs=30,                      # number of training epochs\n",
    "    per_device_train_batch_size=16,          # batch size for training\n",
    "    per_device_eval_batch_size=64,           # batch size for evaluation\n",
    "    warmup_steps=500,                        # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,                       # strength of weight decay\n",
    "    logging_dir='/kaggle/working/logs',      # directory for storing logs\n",
    "    logging_steps=1000,\n",
    "    report_to=\"none\",                        # suppress logging to WANDB\n",
    "    save_steps=10000,                        # save model every 10000 steps\n",
    "    evaluation_strategy='steps',             # evaluate each `eval_steps`\n",
    "    eval_steps=5000,                         # evaluation every 5000 steps\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be767fc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:57:13.087138Z",
     "iopub.status.busy": "2024-05-07T16:57:13.086815Z",
     "iopub.status.idle": "2024-05-07T16:57:14.789814Z",
     "shell.execute_reply": "2024-05-07T16:57:14.788866Z"
    },
    "papermill": {
     "duration": 1.721672,
     "end_time": "2024-05-07T16:57:14.791644",
     "exception": false,
     "start_time": "2024-05-07T16:57:13.069972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29854d18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:57:14.825318Z",
     "iopub.status.busy": "2024-05-07T16:57:14.825018Z",
     "iopub.status.idle": "2024-05-07T16:57:14.832151Z",
     "shell.execute_reply": "2024-05-07T16:57:14.831296Z"
    },
    "papermill": {
     "duration": 0.026004,
     "end_time": "2024-05-07T16:57:14.833983",
     "exception": false,
     "start_time": "2024-05-07T16:57:14.807979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ProteinBindingTrainer(Trainer):\n",
    "    def _prepare_inputs(self, inputs):\n",
    "        # Instead of modifying inputs, just pass them through.\n",
    "        return inputs\n",
    "\n",
    "    def training_step(self, model, batch):\n",
    "        # Move batch to device\n",
    "        batch = {k: v.to(self.args.device) for k, v in batch.items() if hasattr(v, 'to')}\n",
    "\n",
    "        # Extract inputs from batch\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        protein_features = batch['protein_encodings']\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, protein_features=protein_features)\n",
    "        logits = outputs.logits if hasattr(outputs, 'logits') else outputs[0]\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = self.compute_loss(logits, labels)\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da1175a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:57:14.867946Z",
     "iopub.status.busy": "2024-05-07T16:57:14.867350Z",
     "iopub.status.idle": "2024-05-07T16:57:14.957556Z",
     "shell.execute_reply": "2024-05-07T16:57:14.956615Z"
    },
    "papermill": {
     "duration": 0.109496,
     "end_time": "2024-05-07T16:57:14.959656",
     "exception": false,
     "start_time": "2024-05-07T16:57:14.850160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels', 'protein_encodings'])\n"
     ]
    }
   ],
   "source": [
    "test_loader = torch.utils.data.DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "test_batch = next(iter(test_loader))\n",
    "print(test_batch.keys())  # This should include 'labels' and 'protein_encodings'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7aad66f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:57:14.994513Z",
     "iopub.status.busy": "2024-05-07T16:57:14.993746Z",
     "iopub.status.idle": "2024-05-07T16:57:14.998289Z",
     "shell.execute_reply": "2024-05-07T16:57:14.997378Z"
    },
    "papermill": {
     "duration": 0.023909,
     "end_time": "2024-05-07T16:57:15.000286",
     "exception": false,
     "start_time": "2024-05-07T16:57:14.976377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Ensure the model is on the correct device\n",
    "# model.to(device)\n",
    "\n",
    "#THIS TRAINER IS NOT WORKING... SOMEHOW THE FUNCTION IS NOT GETTNG THE KEYS PROPERLY\n",
    "\n",
    "# # Initialize the trainer with all settings\n",
    "# trainer = ProteinBindingTrainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_dataset,  # Ensure this is your dataset, not DataLoader\n",
    "#     eval_dataset=eval_dataset     # Ensure this is your dataset, not DataLoader\n",
    "# )\n",
    "\n",
    "# # Start training\n",
    "# trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef922c8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:57:15.033794Z",
     "iopub.status.busy": "2024-05-07T16:57:15.033527Z",
     "iopub.status.idle": "2024-05-07T16:57:15.038595Z",
     "shell.execute_reply": "2024-05-07T16:57:15.037749Z"
    },
    "papermill": {
     "duration": 0.023924,
     "end_time": "2024-05-07T16:57:15.040528",
     "exception": false,
     "start_time": "2024-05-07T16:57:15.016604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set the device to GPU if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2642de23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:57:15.073874Z",
     "iopub.status.busy": "2024-05-07T16:57:15.073610Z",
     "iopub.status.idle": "2024-05-07T16:57:15.212924Z",
     "shell.execute_reply": "2024-05-07T16:57:15.212101Z"
    },
    "papermill": {
     "duration": 0.158686,
     "end_time": "2024-05-07T16:57:15.215315",
     "exception": false,
     "start_time": "2024-05-07T16:57:15.056629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Real-world frequencies\n",
    "real_world_freq_0 = 0.9946  # 99.46% are class 0\n",
    "real_world_freq_1 = 0.0054  # 0.54% are class 1\n",
    "\n",
    "# Calculate class weights\n",
    "weights = torch.tensor([1 / real_world_freq_0, 1 / real_world_freq_1], dtype=torch.float32)\n",
    "weights = weights / weights.sum() * 2  # Normalize so that weights sum to the number of classes (2 for binary classification)\n",
    "weights = weights.to(device)  # Move weights to the correct device\n",
    "\n",
    "# Initialize the loss function with these weights\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1fd35aeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T16:57:15.249713Z",
     "iopub.status.busy": "2024-05-07T16:57:15.249380Z",
     "iopub.status.idle": "2024-05-08T02:01:34.718834Z",
     "shell.execute_reply": "2024-05-08T02:01:34.717824Z"
    },
    "papermill": {
     "duration": 32659.797578,
     "end_time": "2024-05-08T02:01:35.029622",
     "exception": false,
     "start_time": "2024-05-07T16:57:15.232044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaders Defined\n",
      "Epoch 0, Batch 100, Loss: 0.06398466974496841\n",
      "Epoch 0, Batch 200, Loss: 0.05436128377914429\n",
      "Epoch 0, Batch 300, Loss: 0.024173609912395477\n",
      "Epoch 0, Batch 400, Loss: 0.050127122551202774\n",
      "Epoch 0, Batch 500, Loss: 0.022765278816223145\n",
      "Epoch 0, Batch 600, Loss: 0.03551884740591049\n",
      "Epoch 0, Batch 700, Loss: 0.03631770238280296\n",
      "Epoch 0, Batch 800, Loss: 0.028207281604409218\n",
      "Epoch 0, Batch 900, Loss: 0.010548037476837635\n",
      "Epoch 0, Batch 1000, Loss: 0.013104688376188278\n",
      "Epoch 0, Batch 1100, Loss: 0.02810114249587059\n",
      "Epoch 0, Batch 1200, Loss: 0.030723361298441887\n",
      "Epoch 0, Batch 1300, Loss: 0.031151089817285538\n",
      "Epoch 0, Batch 1400, Loss: 0.0215015709400177\n",
      "Epoch 0, Batch 1500, Loss: 0.008508019149303436\n",
      "Epoch 0, Batch 1600, Loss: 0.009553546085953712\n",
      "Epoch 0, Batch 1700, Loss: 0.01945960521697998\n",
      "Epoch 0, Batch 1800, Loss: 0.020823277533054352\n",
      "Epoch 0, Batch 1900, Loss: 0.027742775157094002\n",
      "Epoch 0, Batch 2000, Loss: 0.01968497969210148\n",
      "Epoch 0, Batch 2100, Loss: 0.020897896960377693\n",
      "Epoch 0, Batch 2200, Loss: 0.05566686764359474\n",
      "Epoch 0, Batch 2300, Loss: 0.012781222350895405\n",
      "Epoch 0, Batch 2400, Loss: 0.02093171328306198\n",
      "Epoch 0, Batch 2500, Loss: 0.044745396822690964\n",
      "Epoch 0, Batch 2600, Loss: 0.026587067171931267\n",
      "Epoch 0, Batch 2700, Loss: 0.015470519661903381\n",
      "Epoch 0, Batch 2800, Loss: 0.013786280527710915\n",
      "Epoch 0, Batch 2900, Loss: 0.03438697010278702\n",
      "Epoch 0, Batch 3000, Loss: 0.03373313695192337\n",
      "Epoch 0, Batch 3100, Loss: 0.010546262376010418\n",
      "Epoch 0, Batch 3200, Loss: 0.012943851761519909\n",
      "Epoch 0, Batch 3300, Loss: 0.019378021359443665\n",
      "Epoch 0, Batch 3400, Loss: 0.02033129893243313\n",
      "Epoch 0, Batch 3500, Loss: 0.022153235971927643\n",
      "Epoch 0, Batch 3600, Loss: 0.05928777903318405\n",
      "Epoch 0, Batch 3700, Loss: 0.013878470286726952\n",
      "Epoch 0, Batch 3800, Loss: 0.015553970821201801\n",
      "Epoch 0, Batch 3900, Loss: 0.02409246191382408\n",
      "Epoch 0, Batch 4000, Loss: 0.026031851768493652\n",
      "Epoch 0, Batch 4100, Loss: 0.01875206269323826\n",
      "Epoch 0, Batch 4200, Loss: 0.03224322199821472\n",
      "Epoch 0, Batch 4300, Loss: 0.025370053946971893\n",
      "Epoch 0, Batch 4400, Loss: 0.06559835374355316\n",
      "Epoch 0, Batch 4500, Loss: 0.039164092391729355\n",
      "Epoch 0, Batch 4600, Loss: 0.015311386436223984\n",
      "Epoch 0, Batch 4700, Loss: 0.019535141065716743\n",
      "Epoch 0, Batch 4800, Loss: 0.017160188406705856\n",
      "Epoch 0, Batch 4900, Loss: 0.011778784915804863\n",
      "Epoch 0, Batch 5000, Loss: 0.01631719432771206\n",
      "Epoch 0, Batch 5100, Loss: 0.02607928030192852\n",
      "Epoch 0, Batch 5200, Loss: 0.027295291423797607\n",
      "Epoch 0, Batch 5300, Loss: 0.015381348319351673\n",
      "Epoch 0, Batch 5400, Loss: 0.01366706658154726\n",
      "Epoch 0, Batch 5500, Loss: 0.07099020481109619\n",
      "Epoch 0, Batch 5600, Loss: 0.016577711328864098\n",
      "Epoch 0, Batch 5700, Loss: 0.022179342806339264\n",
      "Epoch 0, Batch 5800, Loss: 0.021033333614468575\n",
      "Epoch 0, Batch 5900, Loss: 0.01053140964359045\n",
      "Epoch 0, Batch 6000, Loss: 0.026708953082561493\n",
      "Epoch 0, Batch 6100, Loss: 0.0314532034099102\n",
      "Epoch 0, Batch 6200, Loss: 0.020263586193323135\n",
      "Epoch 0, Batch 6300, Loss: 0.1644812524318695\n",
      "Epoch 0, Batch 6400, Loss: 0.010475724935531616\n",
      "Epoch 0, Batch 6500, Loss: 0.006617754697799683\n",
      "Epoch 0, Batch 6600, Loss: 0.014455190859735012\n",
      "Epoch 0, Batch 6700, Loss: 0.012142942287027836\n",
      "Epoch 0, Batch 6800, Loss: 0.01598483696579933\n",
      "Epoch 0, Batch 6900, Loss: 0.018839001655578613\n",
      "Epoch 0, Batch 7000, Loss: 0.04002805054187775\n",
      "Epoch 0, Batch 7100, Loss: 0.06734272837638855\n",
      "Epoch 0, Batch 7200, Loss: 0.10596048831939697\n",
      "Epoch 0, Batch 7300, Loss: 0.03154834359884262\n",
      "Epoch 0, Batch 7400, Loss: 0.03779744729399681\n",
      "Epoch 0, Batch 7500, Loss: 0.016636069864034653\n",
      "Epoch 0, Batch 7600, Loss: 0.010286659933626652\n",
      "Epoch 0, Batch 7700, Loss: 0.029060769826173782\n",
      "Epoch 0, Batch 7800, Loss: 0.02832961082458496\n",
      "Epoch 0, Batch 7900, Loss: 0.015277939848601818\n",
      "Epoch 0, Batch 8000, Loss: 0.08822155743837357\n",
      "Epoch 0, Batch 8100, Loss: 0.054587170481681824\n",
      "Epoch 0, Batch 8200, Loss: 0.019475508481264114\n",
      "Epoch 0, Batch 8300, Loss: 0.020365389063954353\n",
      "Epoch 0, Batch 8400, Loss: 0.067576102912426\n",
      "Epoch 0, Batch 8500, Loss: 0.02743063122034073\n",
      "Epoch 0, Batch 8600, Loss: 0.008174819871783257\n",
      "Epoch 0, Batch 8700, Loss: 0.02163200080394745\n",
      "Epoch 0, Batch 8800, Loss: 0.03965418040752411\n",
      "Epoch 0, Batch 8900, Loss: 0.024825643748044968\n",
      "Epoch 0, Batch 9000, Loss: 0.04037543386220932\n",
      "Epoch 0, Batch 9100, Loss: 0.04006126895546913\n",
      "Epoch 0, Batch 9200, Loss: 0.05993752181529999\n",
      "Epoch 0, Batch 9300, Loss: 0.022042743861675262\n",
      "Epoch 0, Batch 9400, Loss: 0.07340970635414124\n",
      "Epoch 0, Batch 9500, Loss: 0.0432717464864254\n",
      "Epoch 0, Batch 9600, Loss: 0.024962376803159714\n",
      "Epoch 0, Batch 9700, Loss: 0.014240225777029991\n",
      "Epoch 0, Batch 9800, Loss: 0.010590110905468464\n",
      "Epoch 0, Batch 9900, Loss: 0.02262769266963005\n",
      "Epoch 0, Batch 10000, Loss: 0.014842910692095757\n",
      "Epoch 0, Batch 10100, Loss: 0.02911665290594101\n",
      "Epoch 0, Batch 10200, Loss: 0.041005346924066544\n",
      "Epoch 0, Batch 10300, Loss: 0.044619202613830566\n",
      "Epoch 0, Batch 10400, Loss: 0.0488910935819149\n",
      "Epoch 0, Batch 10500, Loss: 0.01665700227022171\n",
      "Epoch 0, Batch 10600, Loss: 0.017914753407239914\n",
      "Epoch 0, Batch 10700, Loss: 0.019425347447395325\n",
      "Epoch 0, Batch 10800, Loss: 0.033516548573970795\n",
      "Epoch 0, Batch 10900, Loss: 0.003436535596847534\n",
      "Epoch 0, Batch 11000, Loss: 0.028815537691116333\n",
      "Epoch 0, Batch 11100, Loss: 0.056666772812604904\n",
      "Epoch 0, Batch 11200, Loss: 0.029349736869335175\n",
      "Epoch 0, Batch 11300, Loss: 0.028251726180315018\n",
      "Epoch 0, Batch 11400, Loss: 0.008854983374476433\n",
      "Epoch 0, Batch 11500, Loss: 0.06469104439020157\n",
      "Epoch 0, Batch 11600, Loss: 0.016507599502801895\n",
      "Epoch 0, Batch 11700, Loss: 0.009582968428730965\n",
      "Epoch 0, Batch 11800, Loss: 0.015208123251795769\n",
      "Epoch 0, Batch 11900, Loss: 0.016538867726922035\n",
      "Epoch 0, Batch 12000, Loss: 0.025097189471125603\n",
      "Epoch 0, Batch 12100, Loss: 0.012891807593405247\n",
      "Epoch 0, Batch 12200, Loss: 0.055891215801239014\n",
      "Epoch 0, Batch 12300, Loss: 0.02870524860918522\n",
      "Epoch 0, Batch 12400, Loss: 0.02642359584569931\n",
      "Epoch 0, Batch 12500, Loss: 0.020556554198265076\n",
      "Epoch 0, Batch 12600, Loss: 0.0069658588618040085\n",
      "Epoch 0, Batch 12700, Loss: 0.013216296210885048\n",
      "Epoch 0, Batch 12800, Loss: 0.010278145782649517\n",
      "Epoch 0, Batch 12900, Loss: 0.009580418467521667\n",
      "Epoch 0, Batch 13000, Loss: 0.021145140752196312\n",
      "Epoch 0, Batch 13100, Loss: 0.008736600168049335\n",
      "Epoch 0, Batch 13200, Loss: 0.012553339824080467\n",
      "Epoch 0, Batch 13300, Loss: 0.02077554352581501\n",
      "Epoch 0, Batch 13400, Loss: 0.011371975764632225\n",
      "Epoch 0, Batch 13500, Loss: 0.01509787142276764\n",
      "Epoch 0, Batch 13600, Loss: 0.02325432375073433\n",
      "Epoch 0, Batch 13700, Loss: 0.03955565765500069\n",
      "Epoch 0, Batch 13800, Loss: 0.02012587897479534\n",
      "Epoch 0, Batch 13900, Loss: 0.015112075954675674\n",
      "Epoch 0, Batch 14000, Loss: 0.010085509158670902\n",
      "Epoch 0, Batch 14100, Loss: 0.03139365091919899\n",
      "Epoch 0, Batch 14200, Loss: 0.006284099537879229\n",
      "Epoch 0, Batch 14300, Loss: 0.022003276273608208\n",
      "Epoch 0, Batch 14400, Loss: 0.018437836319208145\n",
      "Epoch 0, Batch 14500, Loss: 0.014920925721526146\n",
      "Epoch 0, Batch 14600, Loss: 0.015613664872944355\n",
      "Epoch 0, Batch 14700, Loss: 0.02484998293220997\n",
      "Epoch 0, Batch 14800, Loss: 0.038559116423130035\n",
      "Epoch 0, Batch 14900, Loss: 0.016281895339488983\n",
      "Epoch 0, Batch 15000, Loss: 0.012811952270567417\n",
      "Epoch 0, Batch 15100, Loss: 0.034845661371946335\n",
      "Epoch 0, Batch 15200, Loss: 0.01931321993470192\n",
      "Epoch 0, Batch 15300, Loss: 0.008869622834026814\n",
      "Epoch 0, Batch 15400, Loss: 0.005847741849720478\n",
      "Epoch 0, Batch 15500, Loss: 0.043027836829423904\n",
      "Epoch 0, Batch 15600, Loss: 0.015461339615285397\n",
      "Epoch 0, Batch 15700, Loss: 0.021608557552099228\n",
      "Epoch 0, Batch 15800, Loss: 0.008531149476766586\n",
      "Epoch 0, Batch 15900, Loss: 0.03134002536535263\n",
      "Epoch 0, Batch 16000, Loss: 0.028996486216783524\n",
      "Epoch 0, Batch 16100, Loss: 0.027879148721694946\n",
      "Epoch 0, Batch 16200, Loss: 0.0417049266397953\n",
      "Epoch 0, Batch 16300, Loss: 0.02513922192156315\n",
      "Epoch 0, Batch 16400, Loss: 0.01888015680015087\n",
      "Epoch 0, Batch 16500, Loss: 0.04504718258976936\n",
      "Epoch 0, Batch 16600, Loss: 0.01563660427927971\n",
      "Epoch 0, Batch 16700, Loss: 0.013826640322804451\n",
      "Epoch 0, Batch 16800, Loss: 0.025924300774931908\n",
      "Epoch 0, Batch 16900, Loss: 0.02348783053457737\n",
      "Epoch 0, Batch 17000, Loss: 0.013876480981707573\n",
      "Epoch 0, Batch 17100, Loss: 0.020719408988952637\n",
      "Epoch 0, Batch 17200, Loss: 0.026042740792036057\n",
      "Epoch 0, Batch 17300, Loss: 0.014196930453181267\n",
      "Epoch 0, Batch 17400, Loss: 0.0321626253426075\n",
      "Epoch 0, Batch 17500, Loss: 0.021281825378537178\n",
      "Epoch 0, Batch 17600, Loss: 0.007931896485388279\n",
      "Epoch 0, Batch 17700, Loss: 0.03993777185678482\n",
      "Epoch 0, Batch 17800, Loss: 0.018945230171084404\n",
      "Epoch 0, Batch 17900, Loss: 0.006347027141600847\n",
      "Epoch 0, Batch 18000, Loss: 0.014146827161312103\n",
      "Epoch 0, Batch 18100, Loss: 0.0158945694565773\n",
      "Epoch 0, Batch 18200, Loss: 0.019925452768802643\n",
      "Epoch 0, Batch 18300, Loss: 0.011776622384786606\n",
      "Epoch 0, Batch 18400, Loss: 0.021902630105614662\n",
      "Epoch 0, Batch 18500, Loss: 0.014223995618522167\n",
      "Epoch 0, Batch 18600, Loss: 0.030835866928100586\n",
      "Epoch 0, Batch 18700, Loss: 0.012888727709650993\n",
      "Epoch 0, Batch 18800, Loss: 0.07388657331466675\n",
      "Epoch 0, Batch 18900, Loss: 0.01571384258568287\n",
      "Epoch 0, Batch 19000, Loss: 0.028990767896175385\n",
      "Epoch 0, Batch 19100, Loss: 0.026347093284130096\n",
      "Epoch 0, Batch 19200, Loss: 0.006162494421005249\n",
      "Epoch 0, Batch 19300, Loss: 0.028480546548962593\n",
      "Epoch 0, Batch 19400, Loss: 0.024377744644880295\n",
      "Epoch 0, Batch 19500, Loss: 0.0017174045788124204\n",
      "Epoch 0, Batch 19600, Loss: 0.017715144902467728\n",
      "Epoch 0, Batch 19700, Loss: 0.015648534521460533\n",
      "Epoch 0, Batch 19800, Loss: 0.027887264266610146\n",
      "Epoch 0, Batch 19900, Loss: 0.010982885025441647\n",
      "Epoch 0, Batch 20000, Loss: 0.015196012333035469\n",
      "Epoch 0, Batch 20100, Loss: 0.03352778032422066\n",
      "Epoch 0, Batch 20200, Loss: 0.0219942145049572\n",
      "Epoch 0, Batch 20300, Loss: 0.012953217141330242\n",
      "Epoch 0, Batch 20400, Loss: 0.04369902238249779\n",
      "Epoch 0, Batch 20500, Loss: 0.016298925504088402\n",
      "Epoch 0, Batch 20600, Loss: 0.013512831181287766\n",
      "Epoch 0, Batch 20700, Loss: 0.016320399940013885\n",
      "Epoch 0, Batch 20800, Loss: 0.02300828881561756\n",
      "Epoch 0, Batch 20900, Loss: 0.011947786435484886\n",
      "Epoch 0, Batch 21000, Loss: 0.040473900735378265\n",
      "Epoch 0, Batch 21100, Loss: 0.009628718718886375\n",
      "Epoch 0, Batch 21200, Loss: 0.02126680500805378\n",
      "Epoch 0, Batch 21300, Loss: 0.020162634551525116\n",
      "Epoch 0, Batch 21400, Loss: 0.03236934542655945\n",
      "Epoch 0, Batch 21500, Loss: 0.014581671915948391\n",
      "Epoch 0, Batch 21600, Loss: 0.013255293481051922\n",
      "Epoch 0, Batch 21700, Loss: 0.0628691017627716\n",
      "Epoch 0, Batch 21800, Loss: 0.020326482132077217\n",
      "Epoch 0, Batch 21900, Loss: 0.014640877023339272\n",
      "Epoch 0, Batch 22000, Loss: 0.016301346942782402\n",
      "Epoch 0, Batch 22100, Loss: 0.026415536180138588\n",
      "Epoch 0, Batch 22200, Loss: 0.019917070865631104\n",
      "Epoch 0, Batch 22300, Loss: 0.019895581528544426\n",
      "Epoch 0, Batch 22400, Loss: 0.01567145064473152\n",
      "Epoch 0, Batch 22500, Loss: 0.01946137845516205\n",
      "Epoch 0, Batch 22600, Loss: 0.03260388225317001\n",
      "Epoch 0, Batch 22700, Loss: 0.05995378643274307\n",
      "Epoch 0, Batch 22800, Loss: 0.010726951994001865\n",
      "Epoch 0, Batch 22900, Loss: 0.06048361212015152\n",
      "Epoch 0, Batch 23000, Loss: 0.02736302837729454\n",
      "Epoch 0, Batch 23100, Loss: 0.02211105264723301\n",
      "Epoch 0, Batch 23200, Loss: 0.04514268785715103\n",
      "Epoch 0, Batch 23300, Loss: 0.018448131158947945\n",
      "Epoch 0, Batch 23400, Loss: 0.0195755772292614\n",
      "Epoch 0, Batch 23500, Loss: 0.03833745792508125\n",
      "Epoch 0, Batch 23600, Loss: 0.01667790301144123\n",
      "Epoch 0, Batch 23700, Loss: 0.011524285189807415\n",
      "Epoch 0, Batch 23800, Loss: 0.03935971483588219\n",
      "Epoch 0, Batch 23900, Loss: 0.018337935209274292\n",
      "Epoch 0, Batch 24000, Loss: 0.01422252506017685\n",
      "Epoch 0, Batch 24100, Loss: 0.02990279532968998\n",
      "Epoch 0, Batch 24200, Loss: 0.017509454861283302\n",
      "Epoch 0, Batch 24300, Loss: 0.02139730378985405\n",
      "Epoch 0, Batch 24400, Loss: 0.011668339371681213\n",
      "Epoch 0, Batch 24500, Loss: 0.03594771400094032\n",
      "Epoch 0, Batch 24600, Loss: 0.01815825328230858\n",
      "Epoch 0, Batch 24700, Loss: 0.028982704505324364\n",
      "Epoch 0, Batch 24800, Loss: 0.01345861703157425\n",
      "Epoch 0, Batch 24900, Loss: 0.01089977566152811\n",
      "Epoch 0, Batch 25000, Loss: 0.02141115628182888\n",
      "Epoch 0, Batch 25100, Loss: 0.013716459274291992\n",
      "Epoch 0, Batch 25200, Loss: 0.02562522329390049\n",
      "Epoch 0, Batch 25300, Loss: 0.014212635345757008\n",
      "Epoch 0, Batch 25400, Loss: 0.018267204985022545\n",
      "Epoch 0, Batch 25500, Loss: 0.03588131442666054\n",
      "Epoch 0, Batch 25600, Loss: 0.027365343645215034\n",
      "Epoch 0, Batch 25700, Loss: 0.009839527308940887\n",
      "Epoch 0, Batch 25800, Loss: 0.028792621567845345\n",
      "Epoch 0, Batch 25900, Loss: 0.010555250570178032\n",
      "Epoch 0, Batch 26000, Loss: 0.028994180262088776\n",
      "Epoch 0, Batch 26100, Loss: 0.021057194098830223\n",
      "Epoch 0, Batch 26200, Loss: 0.03526023030281067\n",
      "Epoch 0, Batch 26300, Loss: 0.029002752155065536\n",
      "Epoch 0, Batch 26400, Loss: 0.030984247103333473\n",
      "Epoch 0, Batch 26500, Loss: 0.02297409251332283\n",
      "Epoch 0, Batch 26600, Loss: 0.05422448366880417\n",
      "Epoch 0, Batch 26700, Loss: 0.023563791066408157\n",
      "Epoch 0, Batch 26800, Loss: 0.01593131572008133\n",
      "Epoch 0, Batch 26900, Loss: 0.016634702682495117\n",
      "Epoch 0, Batch 27000, Loss: 0.03744976967573166\n",
      "Epoch 0, Batch 27100, Loss: 0.05080182105302811\n",
      "Epoch 0, Batch 27200, Loss: 0.011728421784937382\n",
      "Epoch 0, Batch 27300, Loss: 0.011019691824913025\n",
      "Epoch 0, Batch 27400, Loss: 0.007729982025921345\n",
      "Epoch 0, Batch 27500, Loss: 0.010699368081986904\n",
      "Epoch 0, Batch 27600, Loss: 0.02869821898639202\n",
      "Epoch 0, Batch 27700, Loss: 0.00994787085801363\n",
      "Epoch 0, Batch 27800, Loss: 0.028589554131031036\n",
      "Epoch 0, Batch 27900, Loss: 0.015523029491305351\n",
      "Epoch 0, Batch 28000, Loss: 0.04558178037405014\n",
      "Epoch 0, Batch 28100, Loss: 0.05735069513320923\n",
      "Epoch 0, Batch 28200, Loss: 0.018563350662589073\n",
      "Epoch 0, Batch 28300, Loss: 0.01461505051702261\n",
      "Epoch 0, Batch 28400, Loss: 0.015518943779170513\n",
      "Epoch 0, Batch 28500, Loss: 0.019353903830051422\n",
      "Epoch 0, Batch 28600, Loss: 0.009532665833830833\n",
      "Epoch 0, Batch 28700, Loss: 0.011855662800371647\n",
      "Epoch 0, Batch 28800, Loss: 0.021731164306402206\n",
      "Epoch 0, Batch 28900, Loss: 0.028791675344109535\n",
      "Epoch 0, Batch 29000, Loss: 0.017719756811857224\n",
      "Epoch 0, Batch 29100, Loss: 0.012304133735597134\n",
      "Epoch 0, Batch 29200, Loss: 0.04014809802174568\n",
      "Epoch 0, Batch 29300, Loss: 0.02165401726961136\n",
      "Epoch 0, Batch 29400, Loss: 0.03653370589017868\n",
      "Epoch 0, Batch 29500, Loss: 0.016284188255667686\n",
      "Epoch 0, Batch 29600, Loss: 0.013251828029751778\n",
      "Epoch 0, Batch 29700, Loss: 0.2518251836299896\n",
      "Epoch 0, Batch 29800, Loss: 0.021513966843485832\n",
      "Epoch 0, Batch 29900, Loss: 0.036718253046274185\n",
      "Epoch 0, Batch 30000, Loss: 0.020457731559872627\n",
      "Epoch 0, Batch 30100, Loss: 0.01841473951935768\n",
      "Epoch 0, Batch 30200, Loss: 0.01781618222594261\n",
      "Epoch 0, Batch 30300, Loss: 0.018742192536592484\n",
      "Epoch 0, Batch 30400, Loss: 0.016584258526563644\n",
      "Epoch 0, Batch 30500, Loss: 0.019069716334342957\n",
      "Epoch 0, Batch 30600, Loss: 0.01631631702184677\n",
      "Epoch 0, Batch 30700, Loss: 0.01560210157185793\n",
      "Epoch 0, Batch 30800, Loss: 0.01775447465479374\n",
      "Epoch 0, Batch 30900, Loss: 0.015256838873028755\n",
      "Epoch 0, Batch 31000, Loss: 0.021703965961933136\n",
      "Epoch 0, Batch 31100, Loss: 0.03472520038485527\n",
      "Epoch 0, Batch 31200, Loss: 0.0293359886854887\n",
      "Epoch 0, Batch 31300, Loss: 0.026111606508493423\n",
      "Epoch 0, Batch 31400, Loss: 0.023751845583319664\n",
      "Epoch 0, Batch 31500, Loss: 0.01400761678814888\n",
      "Epoch 0, Batch 31600, Loss: 0.016184629872441292\n",
      "Epoch 0, Batch 31700, Loss: 0.011864847503602505\n",
      "Epoch 0, Batch 31800, Loss: 0.018389210104942322\n",
      "Epoch 0, Batch 31900, Loss: 0.013510020449757576\n",
      "Epoch 0, Batch 32000, Loss: 0.009758605621755123\n",
      "Epoch 0, Batch 32100, Loss: 0.017788749188184738\n",
      "Epoch 0, Batch 32200, Loss: 0.015337763354182243\n",
      "Epoch 0, Batch 32300, Loss: 0.019662996754050255\n",
      "Epoch 0, Batch 32400, Loss: 0.009161857888102531\n",
      "Epoch 0, Batch 32500, Loss: 0.11999977380037308\n",
      "Epoch 0, Batch 32600, Loss: 0.04764360189437866\n",
      "Epoch 0, Batch 32700, Loss: 0.010561221279203892\n",
      "Epoch 0, Batch 32800, Loss: 0.015458691865205765\n",
      "Epoch 0, Batch 32900, Loss: 0.017857864499092102\n",
      "Epoch 0, Batch 33000, Loss: 0.010580994188785553\n",
      "Epoch 0, Batch 33100, Loss: 0.012754054740071297\n",
      "Epoch 0, Batch 33200, Loss: 0.025179775431752205\n",
      "Epoch 0, Batch 33300, Loss: 0.030361799523234367\n",
      "Epoch 0, Batch 33400, Loss: 0.008252162486314774\n",
      "Epoch 0, Batch 33500, Loss: 0.015191612765192986\n",
      "Epoch 0, Batch 33600, Loss: 0.014732356183230877\n",
      "Epoch 0, Batch 33700, Loss: 0.009391323663294315\n",
      "Epoch 0, Batch 33800, Loss: 0.07027031481266022\n",
      "Epoch 0, Batch 33900, Loss: 0.015342622064054012\n",
      "Epoch 0, Batch 34000, Loss: 0.05372123047709465\n",
      "Epoch 0, Batch 34100, Loss: 0.021125657483935356\n",
      "Epoch 0, Batch 34200, Loss: 0.01678619347512722\n",
      "Epoch 0, Batch 34300, Loss: 0.044351767748594284\n",
      "Epoch 0, Batch 34400, Loss: 0.005919760558754206\n",
      "Epoch 0, Batch 34500, Loss: 0.02350037172436714\n",
      "Epoch 0, Batch 34600, Loss: 0.03452730178833008\n",
      "Epoch 0, Batch 34700, Loss: 0.02373410202562809\n",
      "Epoch 0, Batch 34800, Loss: 0.023200038820505142\n",
      "Epoch 0, Batch 34900, Loss: 0.014788483269512653\n",
      "Epoch 0, Batch 35000, Loss: 0.015010258182883263\n",
      "Epoch 0, Batch 35100, Loss: 0.015137509442865849\n",
      "Epoch 0, Batch 35200, Loss: 0.21939927339553833\n",
      "Epoch 0, Batch 35300, Loss: 0.022801123559474945\n",
      "Epoch 0, Batch 35400, Loss: 0.010681903921067715\n",
      "Epoch 0, Batch 35500, Loss: 0.014695070683956146\n",
      "Epoch 0, Batch 35600, Loss: 0.046021390706300735\n",
      "Epoch 0, Batch 35700, Loss: 0.026136867702007294\n",
      "Epoch 0, Batch 35800, Loss: 0.023738542571663857\n",
      "Epoch 0, Batch 35900, Loss: 0.01493688765913248\n",
      "Epoch 0, Batch 36000, Loss: 0.004788260906934738\n",
      "Epoch 0, Batch 36100, Loss: 0.00880049541592598\n",
      "Epoch 0, Batch 36200, Loss: 0.026951950043439865\n",
      "Epoch 0, Batch 36300, Loss: 0.005529594141989946\n",
      "Epoch 0, Batch 36400, Loss: 0.02136177569627762\n",
      "Epoch 0, Batch 36500, Loss: 0.029746506363153458\n",
      "Epoch 0, Batch 36600, Loss: 0.011176569387316704\n",
      "Epoch 0, Batch 36700, Loss: 0.03031693957746029\n",
      "Epoch 0, Batch 36800, Loss: 0.025761384516954422\n",
      "Validation Loss: 3.3921396148753167\n",
      "Epoch 1, Batch 100, Loss: 0.006803826428949833\n",
      "Epoch 1, Batch 200, Loss: 0.029915902763605118\n",
      "Epoch 1, Batch 300, Loss: 0.12037983536720276\n",
      "Epoch 1, Batch 400, Loss: 0.012959855608642101\n",
      "Epoch 1, Batch 500, Loss: 0.0115802101790905\n",
      "Epoch 1, Batch 600, Loss: 0.0076174321584403515\n",
      "Epoch 1, Batch 700, Loss: 0.039603378623723984\n",
      "Epoch 1, Batch 800, Loss: 0.015414864756166935\n",
      "Epoch 1, Batch 900, Loss: 0.013911490328609943\n",
      "Epoch 1, Batch 1000, Loss: 0.029136335477232933\n",
      "Epoch 1, Batch 1100, Loss: 0.02725484035909176\n",
      "Epoch 1, Batch 1200, Loss: 0.0453314334154129\n",
      "Epoch 1, Batch 1300, Loss: 0.02927762269973755\n",
      "Epoch 1, Batch 1400, Loss: 0.015284446068108082\n",
      "Epoch 1, Batch 1500, Loss: 0.014464200474321842\n",
      "Epoch 1, Batch 1600, Loss: 0.0265184473246336\n",
      "Epoch 1, Batch 1700, Loss: 0.014939169399440289\n",
      "Epoch 1, Batch 1800, Loss: 0.016811951994895935\n",
      "Epoch 1, Batch 1900, Loss: 0.01887987181544304\n",
      "Epoch 1, Batch 2000, Loss: 0.01491278875619173\n",
      "Epoch 1, Batch 2100, Loss: 0.06664992868900299\n",
      "Epoch 1, Batch 2200, Loss: 0.011902655474841595\n",
      "Epoch 1, Batch 2300, Loss: 0.038165222853422165\n",
      "Epoch 1, Batch 2400, Loss: 0.009282848797738552\n",
      "Epoch 1, Batch 2500, Loss: 0.02245224639773369\n",
      "Epoch 1, Batch 2600, Loss: 0.023165320977568626\n",
      "Epoch 1, Batch 2700, Loss: 0.017819421365857124\n",
      "Epoch 1, Batch 2800, Loss: 0.04234649986028671\n",
      "Epoch 1, Batch 2900, Loss: 0.013975213281810284\n",
      "Epoch 1, Batch 3000, Loss: 0.014149702154099941\n",
      "Epoch 1, Batch 3100, Loss: 0.011589976027607918\n",
      "Epoch 1, Batch 3200, Loss: 0.03859557583928108\n",
      "Epoch 1, Batch 3300, Loss: 0.05331270769238472\n",
      "Epoch 1, Batch 3400, Loss: 0.014732711017131805\n",
      "Epoch 1, Batch 3500, Loss: 0.015986496582627296\n",
      "Epoch 1, Batch 3600, Loss: 0.01744276098906994\n",
      "Epoch 1, Batch 3700, Loss: 0.03600761294364929\n",
      "Epoch 1, Batch 3800, Loss: 0.011474414728581905\n",
      "Epoch 1, Batch 3900, Loss: 0.013281982392072678\n",
      "Epoch 1, Batch 4000, Loss: 0.01715863309800625\n",
      "Epoch 1, Batch 4100, Loss: 0.011711654253304005\n",
      "Epoch 1, Batch 4200, Loss: 0.03941481187939644\n",
      "Epoch 1, Batch 4300, Loss: 0.014698824845254421\n",
      "Epoch 1, Batch 4400, Loss: 0.01916581764817238\n",
      "Epoch 1, Batch 4500, Loss: 0.016392484307289124\n",
      "Epoch 1, Batch 4600, Loss: 0.05235224962234497\n",
      "Epoch 1, Batch 4700, Loss: 0.01505428459495306\n",
      "Epoch 1, Batch 4800, Loss: 0.025088908150792122\n",
      "Epoch 1, Batch 4900, Loss: 0.0652160719037056\n",
      "Epoch 1, Batch 5000, Loss: 0.025522977113723755\n",
      "Epoch 1, Batch 5100, Loss: 0.030188072472810745\n",
      "Epoch 1, Batch 5200, Loss: 0.027254607528448105\n",
      "Epoch 1, Batch 5300, Loss: 0.03402814269065857\n",
      "Epoch 1, Batch 5400, Loss: 0.07344791293144226\n",
      "Epoch 1, Batch 5500, Loss: 0.09369564801454544\n",
      "Epoch 1, Batch 5600, Loss: 0.022062186151742935\n",
      "Epoch 1, Batch 5700, Loss: 0.009052546694874763\n",
      "Epoch 1, Batch 5800, Loss: 0.009100300259888172\n",
      "Epoch 1, Batch 5900, Loss: 0.027568364515900612\n",
      "Epoch 1, Batch 6000, Loss: 0.0747939869761467\n",
      "Epoch 1, Batch 6100, Loss: 0.04035347327589989\n",
      "Epoch 1, Batch 6200, Loss: 0.02837330475449562\n",
      "Epoch 1, Batch 6300, Loss: 0.018138641491532326\n",
      "Epoch 1, Batch 6400, Loss: 0.020726006478071213\n",
      "Epoch 1, Batch 6500, Loss: 0.015134486369788647\n",
      "Epoch 1, Batch 6600, Loss: 0.026884719729423523\n",
      "Epoch 1, Batch 6700, Loss: 0.022394079715013504\n",
      "Epoch 1, Batch 6800, Loss: 0.020246434956789017\n",
      "Epoch 1, Batch 6900, Loss: 0.012579511851072311\n",
      "Epoch 1, Batch 7000, Loss: 0.016779311001300812\n",
      "Epoch 1, Batch 7100, Loss: 0.017153799533843994\n",
      "Epoch 1, Batch 7200, Loss: 0.019575703889131546\n",
      "Epoch 1, Batch 7300, Loss: 0.011889670044183731\n",
      "Epoch 1, Batch 7400, Loss: 0.025312665849924088\n",
      "Epoch 1, Batch 7500, Loss: 0.035267576575279236\n",
      "Epoch 1, Batch 7600, Loss: 0.03322036191821098\n",
      "Epoch 1, Batch 7700, Loss: 0.028533458709716797\n",
      "Epoch 1, Batch 7800, Loss: 0.0349624827504158\n",
      "Epoch 1, Batch 7900, Loss: 0.017946425825357437\n",
      "Epoch 1, Batch 8000, Loss: 0.03986574336886406\n",
      "Epoch 1, Batch 8100, Loss: 0.017500076442956924\n",
      "Epoch 1, Batch 8200, Loss: 0.021554982289671898\n",
      "Epoch 1, Batch 8300, Loss: 0.024535685777664185\n",
      "Epoch 1, Batch 8400, Loss: 0.022183485329151154\n",
      "Epoch 1, Batch 8500, Loss: 0.02926783636212349\n",
      "Epoch 1, Batch 8600, Loss: 0.019699662923812866\n",
      "Epoch 1, Batch 8700, Loss: 0.01615523174405098\n",
      "Epoch 1, Batch 8800, Loss: 0.036990802735090256\n",
      "Epoch 1, Batch 8900, Loss: 0.010004828684031963\n",
      "Epoch 1, Batch 9000, Loss: 0.011117071844637394\n",
      "Epoch 1, Batch 9100, Loss: 0.00499782245606184\n",
      "Epoch 1, Batch 9200, Loss: 0.03088509477674961\n",
      "Epoch 1, Batch 9300, Loss: 0.012026418931782246\n",
      "Epoch 1, Batch 9400, Loss: 0.05640314891934395\n",
      "Epoch 1, Batch 9500, Loss: 0.018806086853146553\n",
      "Epoch 1, Batch 9600, Loss: 0.0198174100369215\n",
      "Epoch 1, Batch 9700, Loss: 0.008081639185547829\n",
      "Epoch 1, Batch 9800, Loss: 0.018344653770327568\n",
      "Epoch 1, Batch 9900, Loss: 0.01300216093659401\n",
      "Epoch 1, Batch 10000, Loss: 0.01480039581656456\n",
      "Epoch 1, Batch 10100, Loss: 0.03891384229063988\n",
      "Epoch 1, Batch 10200, Loss: 0.018287843093276024\n",
      "Epoch 1, Batch 10300, Loss: 0.01918330043554306\n",
      "Epoch 1, Batch 10400, Loss: 0.01057946216315031\n",
      "Epoch 1, Batch 10500, Loss: 0.02511838637292385\n",
      "Epoch 1, Batch 10600, Loss: 0.020919378846883774\n",
      "Epoch 1, Batch 10700, Loss: 0.012636624276638031\n",
      "Epoch 1, Batch 10800, Loss: 0.04140893742442131\n",
      "Epoch 1, Batch 10900, Loss: 0.03469357267022133\n",
      "Epoch 1, Batch 11000, Loss: 0.013497457839548588\n",
      "Epoch 1, Batch 11100, Loss: 0.030358213931322098\n",
      "Epoch 1, Batch 11200, Loss: 0.02137335203588009\n",
      "Epoch 1, Batch 11300, Loss: 0.042215876281261444\n",
      "Epoch 1, Batch 11400, Loss: 0.02239128388464451\n",
      "Epoch 1, Batch 11500, Loss: 0.005680453032255173\n",
      "Epoch 1, Batch 11600, Loss: 0.018291236832737923\n",
      "Epoch 1, Batch 11700, Loss: 0.02325458452105522\n",
      "Epoch 1, Batch 11800, Loss: 0.01047199685126543\n",
      "Epoch 1, Batch 11900, Loss: 0.02071465738117695\n",
      "Epoch 1, Batch 12000, Loss: 0.024265779182314873\n",
      "Epoch 1, Batch 12100, Loss: 0.04035824537277222\n",
      "Epoch 1, Batch 12200, Loss: 0.018186332657933235\n",
      "Epoch 1, Batch 12300, Loss: 0.02112371101975441\n",
      "Epoch 1, Batch 12400, Loss: 0.023775670677423477\n",
      "Epoch 1, Batch 12500, Loss: 0.006368035916239023\n",
      "Epoch 1, Batch 12600, Loss: 0.06719031929969788\n",
      "Epoch 1, Batch 12700, Loss: 0.03946167230606079\n",
      "Epoch 1, Batch 12800, Loss: 0.023086080327630043\n",
      "Epoch 1, Batch 12900, Loss: 0.02273332141339779\n",
      "Epoch 1, Batch 13000, Loss: 0.022398436442017555\n",
      "Epoch 1, Batch 13100, Loss: 0.008687382563948631\n",
      "Epoch 1, Batch 13200, Loss: 0.034664299339056015\n",
      "Epoch 1, Batch 13300, Loss: 0.032369185239076614\n",
      "Epoch 1, Batch 13400, Loss: 0.013221215456724167\n",
      "Epoch 1, Batch 13500, Loss: 0.018824534490704536\n",
      "Epoch 1, Batch 13600, Loss: 0.013934667222201824\n",
      "Epoch 1, Batch 13700, Loss: 0.013080555014312267\n",
      "Epoch 1, Batch 13800, Loss: 0.021771345287561417\n",
      "Epoch 1, Batch 13900, Loss: 0.04214628413319588\n",
      "Epoch 1, Batch 14000, Loss: 0.00818526092916727\n",
      "Epoch 1, Batch 14100, Loss: 0.018997425213456154\n",
      "Epoch 1, Batch 14200, Loss: 0.0270366370677948\n",
      "Epoch 1, Batch 14300, Loss: 0.028086736798286438\n",
      "Epoch 1, Batch 14400, Loss: 0.018741728737950325\n",
      "Epoch 1, Batch 14500, Loss: 0.04068079963326454\n",
      "Epoch 1, Batch 14600, Loss: 0.011457226239144802\n",
      "Epoch 1, Batch 14700, Loss: 0.023679953068494797\n",
      "Epoch 1, Batch 14800, Loss: 0.016894031316041946\n",
      "Epoch 1, Batch 14900, Loss: 0.03858175501227379\n",
      "Epoch 1, Batch 15000, Loss: 0.03217846527695656\n",
      "Epoch 1, Batch 15100, Loss: 0.008228650316596031\n",
      "Epoch 1, Batch 15200, Loss: 0.018118351697921753\n",
      "Epoch 1, Batch 15300, Loss: 0.008863350376486778\n",
      "Epoch 1, Batch 15400, Loss: 0.041153453290462494\n",
      "Epoch 1, Batch 15500, Loss: 0.011261377483606339\n",
      "Epoch 1, Batch 15600, Loss: 0.040855471044778824\n",
      "Epoch 1, Batch 15700, Loss: 0.014538370072841644\n",
      "Epoch 1, Batch 15800, Loss: 0.01117805764079094\n",
      "Epoch 1, Batch 15900, Loss: 0.013345186598598957\n",
      "Epoch 1, Batch 16000, Loss: 0.012401959858834743\n",
      "Epoch 1, Batch 16100, Loss: 0.05098418891429901\n",
      "Epoch 1, Batch 16200, Loss: 0.01700814999639988\n",
      "Epoch 1, Batch 16300, Loss: 0.022195326164364815\n",
      "Epoch 1, Batch 16400, Loss: 0.02130100689828396\n",
      "Epoch 1, Batch 16500, Loss: 0.03128111734986305\n",
      "Epoch 1, Batch 16600, Loss: 0.013422338292002678\n",
      "Epoch 1, Batch 16700, Loss: 0.017037389799952507\n",
      "Epoch 1, Batch 16800, Loss: 0.02441597543656826\n",
      "Epoch 1, Batch 16900, Loss: 0.01593935117125511\n",
      "Epoch 1, Batch 17000, Loss: 0.02733445167541504\n",
      "Epoch 1, Batch 17100, Loss: 0.011261471547186375\n",
      "Epoch 1, Batch 17200, Loss: 0.006731747649610043\n",
      "Epoch 1, Batch 17300, Loss: 0.043466392904520035\n",
      "Epoch 1, Batch 17400, Loss: 0.017387639731168747\n",
      "Epoch 1, Batch 17500, Loss: 0.01552118081599474\n",
      "Epoch 1, Batch 17600, Loss: 0.03208938613533974\n",
      "Epoch 1, Batch 17700, Loss: 0.017611365765333176\n",
      "Epoch 1, Batch 17800, Loss: 0.019888196140527725\n",
      "Epoch 1, Batch 17900, Loss: 0.02091795764863491\n",
      "Epoch 1, Batch 18000, Loss: 0.015259801410138607\n",
      "Epoch 1, Batch 18100, Loss: 0.011800659820437431\n",
      "Epoch 1, Batch 18200, Loss: 0.023840898647904396\n",
      "Epoch 1, Batch 18300, Loss: 0.023719478398561478\n",
      "Epoch 1, Batch 18400, Loss: 0.015689516440033913\n",
      "Epoch 1, Batch 18500, Loss: 0.02665780670940876\n",
      "Epoch 1, Batch 18600, Loss: 0.03034796379506588\n",
      "Epoch 1, Batch 18700, Loss: 0.02110810950398445\n",
      "Epoch 1, Batch 18800, Loss: 0.019044499844312668\n",
      "Epoch 1, Batch 18900, Loss: 0.016875779256224632\n",
      "Epoch 1, Batch 19000, Loss: 0.01776174269616604\n",
      "Epoch 1, Batch 19100, Loss: 0.024064045399427414\n",
      "Epoch 1, Batch 19200, Loss: 0.015364842489361763\n",
      "Epoch 1, Batch 19300, Loss: 0.013712630607187748\n",
      "Epoch 1, Batch 19400, Loss: 0.007124352268874645\n",
      "Epoch 1, Batch 19500, Loss: 0.024189027026295662\n",
      "Epoch 1, Batch 19600, Loss: 0.008529921993613243\n",
      "Epoch 1, Batch 19700, Loss: 0.029239149764180183\n",
      "Epoch 1, Batch 19800, Loss: 0.04407964274287224\n",
      "Epoch 1, Batch 19900, Loss: 0.019820205867290497\n",
      "Epoch 1, Batch 20000, Loss: 0.010419249534606934\n",
      "Epoch 1, Batch 20100, Loss: 0.017741722986102104\n",
      "Epoch 1, Batch 20200, Loss: 0.12466801702976227\n",
      "Epoch 1, Batch 20300, Loss: 0.02525567077100277\n",
      "Epoch 1, Batch 20400, Loss: 0.013555153273046017\n",
      "Epoch 1, Batch 20500, Loss: 0.016133341938257217\n",
      "Epoch 1, Batch 20600, Loss: 0.024112431332468987\n",
      "Epoch 1, Batch 20700, Loss: 0.05326537415385246\n",
      "Epoch 1, Batch 20800, Loss: 0.021352926269173622\n",
      "Epoch 1, Batch 20900, Loss: 0.024325905367732048\n",
      "Epoch 1, Batch 21000, Loss: 0.023641103878617287\n",
      "Epoch 1, Batch 21100, Loss: 0.05391789972782135\n",
      "Epoch 1, Batch 21200, Loss: 0.15875288844108582\n",
      "Epoch 1, Batch 21300, Loss: 0.014861525036394596\n",
      "Epoch 1, Batch 21400, Loss: 0.01747981272637844\n",
      "Epoch 1, Batch 21500, Loss: 0.04822585731744766\n",
      "Epoch 1, Batch 21600, Loss: 0.03048667311668396\n",
      "Epoch 1, Batch 21700, Loss: 0.0470711924135685\n",
      "Epoch 1, Batch 21800, Loss: 0.05432090163230896\n",
      "Epoch 1, Batch 21900, Loss: 0.019986458122730255\n",
      "Epoch 1, Batch 22000, Loss: 0.024639133363962173\n",
      "Epoch 1, Batch 22100, Loss: 0.01949094794690609\n",
      "Epoch 1, Batch 22200, Loss: 0.015884818509221077\n",
      "Epoch 1, Batch 22300, Loss: 0.006292912643402815\n",
      "Epoch 1, Batch 22400, Loss: 0.014253183268010616\n",
      "Epoch 1, Batch 22500, Loss: 0.015655523166060448\n",
      "Epoch 1, Batch 22600, Loss: 0.0365573950111866\n",
      "Epoch 1, Batch 22700, Loss: 0.014790579676628113\n",
      "Epoch 1, Batch 22800, Loss: 0.01330486498773098\n",
      "Epoch 1, Batch 22900, Loss: 0.016771730035543442\n",
      "Epoch 1, Batch 23000, Loss: 0.03982818126678467\n",
      "Epoch 1, Batch 23100, Loss: 0.014035901054739952\n",
      "Epoch 1, Batch 23200, Loss: 0.006835236679762602\n",
      "Epoch 1, Batch 23300, Loss: 0.04340691491961479\n",
      "Epoch 1, Batch 23400, Loss: 0.022814277559518814\n",
      "Epoch 1, Batch 23500, Loss: 0.026445971801877022\n",
      "Epoch 1, Batch 23600, Loss: 0.023159245029091835\n",
      "Epoch 1, Batch 23700, Loss: 0.009502899833023548\n",
      "Epoch 1, Batch 23800, Loss: 0.04769701138138771\n",
      "Epoch 1, Batch 23900, Loss: 0.010600069537758827\n",
      "Epoch 1, Batch 24000, Loss: 0.01686098985373974\n",
      "Epoch 1, Batch 24100, Loss: 0.016836514696478844\n",
      "Epoch 1, Batch 24200, Loss: 0.005679755005985498\n",
      "Epoch 1, Batch 24300, Loss: 0.020415635779500008\n",
      "Epoch 1, Batch 24400, Loss: 0.027437789365649223\n",
      "Epoch 1, Batch 24500, Loss: 0.010371009819209576\n",
      "Epoch 1, Batch 24600, Loss: 0.027360841631889343\n",
      "Epoch 1, Batch 24700, Loss: 0.0160604827105999\n",
      "Epoch 1, Batch 24800, Loss: 0.011315916664898396\n",
      "Epoch 1, Batch 24900, Loss: 0.008108794689178467\n",
      "Epoch 1, Batch 25000, Loss: 0.017304696142673492\n",
      "Epoch 1, Batch 25100, Loss: 0.009097667410969734\n",
      "Epoch 1, Batch 25200, Loss: 0.013533082790672779\n",
      "Epoch 1, Batch 25300, Loss: 0.019335981458425522\n",
      "Epoch 1, Batch 25400, Loss: 0.026164652779698372\n",
      "Epoch 1, Batch 25500, Loss: 0.01617705263197422\n",
      "Epoch 1, Batch 25600, Loss: 0.03274787589907646\n",
      "Epoch 1, Batch 25700, Loss: 0.021192315965890884\n",
      "Epoch 1, Batch 25800, Loss: 0.014617111533880234\n",
      "Epoch 1, Batch 25900, Loss: 0.020066507160663605\n",
      "Epoch 1, Batch 26000, Loss: 0.024075550958514214\n",
      "Epoch 1, Batch 26100, Loss: 0.029467904940247536\n",
      "Epoch 1, Batch 26200, Loss: 0.03166329488158226\n",
      "Epoch 1, Batch 26300, Loss: 0.01799449510872364\n",
      "Epoch 1, Batch 26400, Loss: 0.017726955935359\n",
      "Epoch 1, Batch 26500, Loss: 0.017449572682380676\n",
      "Epoch 1, Batch 26600, Loss: 0.019413752481341362\n",
      "Epoch 1, Batch 26700, Loss: 0.031921014189720154\n",
      "Epoch 1, Batch 26800, Loss: 0.023284241557121277\n",
      "Epoch 1, Batch 26900, Loss: 0.04231121763586998\n",
      "Epoch 1, Batch 27000, Loss: 0.012706354260444641\n",
      "Epoch 1, Batch 27100, Loss: 0.016639316454529762\n",
      "Epoch 1, Batch 27200, Loss: 0.02660498023033142\n",
      "Epoch 1, Batch 27300, Loss: 0.008205113932490349\n",
      "Epoch 1, Batch 27400, Loss: 0.027675621211528778\n",
      "Epoch 1, Batch 27500, Loss: 0.031965311616659164\n",
      "Epoch 1, Batch 27600, Loss: 0.01679159328341484\n",
      "Epoch 1, Batch 27700, Loss: 0.029885299503803253\n",
      "Epoch 1, Batch 27800, Loss: 0.027196193113923073\n",
      "Epoch 1, Batch 27900, Loss: 0.013494640588760376\n",
      "Epoch 1, Batch 28000, Loss: 0.021189898252487183\n",
      "Epoch 1, Batch 28100, Loss: 0.03196590393781662\n",
      "Epoch 1, Batch 28200, Loss: 0.023589815944433212\n",
      "Epoch 1, Batch 28300, Loss: 0.03717992827296257\n",
      "Epoch 1, Batch 28400, Loss: 0.023638470098376274\n",
      "Epoch 1, Batch 28500, Loss: 0.01600559614598751\n",
      "Epoch 1, Batch 28600, Loss: 0.01634722389280796\n",
      "Epoch 1, Batch 28700, Loss: 0.03709970787167549\n",
      "Epoch 1, Batch 28800, Loss: 0.06783073395490646\n",
      "Epoch 1, Batch 28900, Loss: 0.03226049244403839\n",
      "Epoch 1, Batch 29000, Loss: 0.01730496808886528\n",
      "Epoch 1, Batch 29100, Loss: 0.01734517514705658\n",
      "Epoch 1, Batch 29200, Loss: 0.05585300922393799\n",
      "Epoch 1, Batch 29300, Loss: 0.01445410493761301\n",
      "Epoch 1, Batch 29400, Loss: 0.04305082932114601\n",
      "Epoch 1, Batch 29500, Loss: 0.04766354337334633\n",
      "Epoch 1, Batch 29600, Loss: 0.03824407979846001\n",
      "Epoch 1, Batch 29700, Loss: 0.017833607271313667\n",
      "Epoch 1, Batch 29800, Loss: 0.01366336364299059\n",
      "Epoch 1, Batch 29900, Loss: 0.05079048126935959\n",
      "Epoch 1, Batch 30000, Loss: 0.012916815467178822\n",
      "Epoch 1, Batch 30100, Loss: 0.030497869476675987\n",
      "Epoch 1, Batch 30200, Loss: 0.018166011199355125\n",
      "Epoch 1, Batch 30300, Loss: 0.01603204570710659\n",
      "Epoch 1, Batch 30400, Loss: 0.041876696050167084\n",
      "Epoch 1, Batch 30500, Loss: 0.031448982656002045\n",
      "Epoch 1, Batch 30600, Loss: 0.02345288172364235\n",
      "Epoch 1, Batch 30700, Loss: 0.024107489734888077\n",
      "Epoch 1, Batch 30800, Loss: 0.02243451029062271\n",
      "Epoch 1, Batch 30900, Loss: 0.03478917106986046\n",
      "Epoch 1, Batch 31000, Loss: 0.012661888264119625\n",
      "Epoch 1, Batch 31100, Loss: 0.010086658410727978\n",
      "Epoch 1, Batch 31200, Loss: 0.026214905083179474\n",
      "Epoch 1, Batch 31300, Loss: 0.009956424124538898\n",
      "Epoch 1, Batch 31400, Loss: 0.014817767776548862\n",
      "Epoch 1, Batch 31500, Loss: 0.03753724694252014\n",
      "Epoch 1, Batch 31600, Loss: 0.012688764370977879\n",
      "Epoch 1, Batch 31700, Loss: 0.022749830037355423\n",
      "Epoch 1, Batch 31800, Loss: 0.020201243460178375\n",
      "Epoch 1, Batch 31900, Loss: 0.018698925152420998\n",
      "Epoch 1, Batch 32000, Loss: 0.013621574267745018\n",
      "Epoch 1, Batch 32100, Loss: 0.015149569138884544\n",
      "Epoch 1, Batch 32200, Loss: 0.023705676198005676\n",
      "Epoch 1, Batch 32300, Loss: 0.020714692771434784\n",
      "Epoch 1, Batch 32400, Loss: 0.049190621823072433\n",
      "Epoch 1, Batch 32500, Loss: 0.011960155330598354\n",
      "Epoch 1, Batch 32600, Loss: 0.00989040918648243\n",
      "Epoch 1, Batch 32700, Loss: 0.017400242388248444\n",
      "Epoch 1, Batch 32800, Loss: 0.010337132029235363\n",
      "Epoch 1, Batch 32900, Loss: 0.011556507088243961\n",
      "Epoch 1, Batch 33000, Loss: 0.01363829430192709\n",
      "Epoch 1, Batch 33100, Loss: 0.028869284316897392\n",
      "Epoch 1, Batch 33200, Loss: 0.015898484736680984\n",
      "Epoch 1, Batch 33300, Loss: 0.021502623334527016\n",
      "Epoch 1, Batch 33400, Loss: 0.013476046733558178\n",
      "Epoch 1, Batch 33500, Loss: 0.03381336107850075\n",
      "Epoch 1, Batch 33600, Loss: 0.10372380912303925\n",
      "Epoch 1, Batch 33700, Loss: 0.013843788765370846\n",
      "Epoch 1, Batch 33800, Loss: 0.013647956773638725\n",
      "Epoch 1, Batch 33900, Loss: 0.0235536377876997\n",
      "Epoch 1, Batch 34000, Loss: 0.02046246826648712\n",
      "Epoch 1, Batch 34100, Loss: 0.01658005081117153\n",
      "Epoch 1, Batch 34200, Loss: 0.011970240622758865\n",
      "Epoch 1, Batch 34300, Loss: 0.016027923673391342\n",
      "Epoch 1, Batch 34400, Loss: 0.050199493765830994\n",
      "Epoch 1, Batch 34500, Loss: 0.015147557482123375\n",
      "Epoch 1, Batch 34600, Loss: 0.026286175474524498\n",
      "Epoch 1, Batch 34700, Loss: 0.007227967493236065\n",
      "Epoch 1, Batch 34800, Loss: 0.009420199319720268\n",
      "Epoch 1, Batch 34900, Loss: 0.01244855485856533\n",
      "Epoch 1, Batch 35000, Loss: 0.04134805127978325\n",
      "Epoch 1, Batch 35100, Loss: 0.03709781542420387\n",
      "Epoch 1, Batch 35200, Loss: 0.027459053322672844\n",
      "Epoch 1, Batch 35300, Loss: 0.016507234424352646\n",
      "Epoch 1, Batch 35400, Loss: 0.014924759976565838\n",
      "Epoch 1, Batch 35500, Loss: 0.015013686381280422\n",
      "Epoch 1, Batch 35600, Loss: 0.010737505741417408\n",
      "Epoch 1, Batch 35700, Loss: 0.06008484214544296\n",
      "Epoch 1, Batch 35800, Loss: 0.012671533972024918\n",
      "Epoch 1, Batch 35900, Loss: 0.01953972317278385\n",
      "Epoch 1, Batch 36000, Loss: 0.017484845593571663\n",
      "Epoch 1, Batch 36100, Loss: 0.017676638439297676\n",
      "Epoch 1, Batch 36200, Loss: 0.015422779135406017\n",
      "Epoch 1, Batch 36300, Loss: 0.013454578816890717\n",
      "Epoch 1, Batch 36400, Loss: 0.008889202028512955\n",
      "Epoch 1, Batch 36500, Loss: 0.011568284593522549\n",
      "Epoch 1, Batch 36600, Loss: 0.023698294535279274\n",
      "Epoch 1, Batch 36700, Loss: 0.02983727864921093\n",
      "Epoch 1, Batch 36800, Loss: 0.010008158162236214\n",
      "Validation Loss: 2.5737472141957283\n",
      "Epoch 2, Batch 100, Loss: 0.04271335527300835\n",
      "Epoch 2, Batch 200, Loss: 0.0450112447142601\n",
      "Epoch 2, Batch 300, Loss: 0.013197888620197773\n",
      "Epoch 2, Batch 400, Loss: 0.0645066425204277\n",
      "Epoch 2, Batch 500, Loss: 0.003594376379624009\n",
      "Epoch 2, Batch 600, Loss: 0.020320245996117592\n",
      "Epoch 2, Batch 700, Loss: 0.05484629422426224\n",
      "Epoch 2, Batch 800, Loss: 0.017024895176291466\n",
      "Epoch 2, Batch 900, Loss: 0.07075881212949753\n",
      "Epoch 2, Batch 1000, Loss: 0.03451904281973839\n",
      "Epoch 2, Batch 1100, Loss: 0.025738883763551712\n",
      "Epoch 2, Batch 1200, Loss: 0.020939035341143608\n",
      "Epoch 2, Batch 1300, Loss: 0.022191714495420456\n",
      "Epoch 2, Batch 1400, Loss: 0.017788443714380264\n",
      "Epoch 2, Batch 1500, Loss: 0.01543661393225193\n",
      "Epoch 2, Batch 1600, Loss: 0.034811846911907196\n",
      "Epoch 2, Batch 1700, Loss: 0.0914168730378151\n",
      "Epoch 2, Batch 1800, Loss: 0.01382001768797636\n",
      "Epoch 2, Batch 1900, Loss: 0.029347525909543037\n",
      "Epoch 2, Batch 2000, Loss: 0.009324806742370129\n",
      "Epoch 2, Batch 2100, Loss: 0.02378666028380394\n",
      "Epoch 2, Batch 2200, Loss: 0.014996608719229698\n",
      "Epoch 2, Batch 2300, Loss: 0.01250479556620121\n",
      "Epoch 2, Batch 2400, Loss: 0.007330609951168299\n",
      "Epoch 2, Batch 2500, Loss: 0.0349821075797081\n",
      "Epoch 2, Batch 2600, Loss: 0.0407869853079319\n",
      "Epoch 2, Batch 2700, Loss: 0.016423536464571953\n",
      "Epoch 2, Batch 2800, Loss: 0.028362775221467018\n",
      "Epoch 2, Batch 2900, Loss: 0.03788895159959793\n",
      "Epoch 2, Batch 3000, Loss: 0.016798973083496094\n",
      "Epoch 2, Batch 3100, Loss: 0.04246189817786217\n",
      "Epoch 2, Batch 3200, Loss: 0.028055870905518532\n",
      "Epoch 2, Batch 3300, Loss: 0.029054604470729828\n",
      "Epoch 2, Batch 3400, Loss: 0.030652008950710297\n",
      "Epoch 2, Batch 3500, Loss: 0.004255696199834347\n",
      "Epoch 2, Batch 3600, Loss: 0.07885918766260147\n",
      "Epoch 2, Batch 3700, Loss: 0.021528996527194977\n",
      "Epoch 2, Batch 3800, Loss: 0.01430987473577261\n",
      "Epoch 2, Batch 3900, Loss: 0.027640780434012413\n",
      "Epoch 2, Batch 4000, Loss: 0.02210189960896969\n",
      "Epoch 2, Batch 4100, Loss: 0.0173970777541399\n",
      "Epoch 2, Batch 4200, Loss: 0.020934149622917175\n",
      "Epoch 2, Batch 4300, Loss: 0.027227893471717834\n",
      "Epoch 2, Batch 4400, Loss: 0.028887487947940826\n",
      "Epoch 2, Batch 4500, Loss: 0.020782409235835075\n",
      "Epoch 2, Batch 4600, Loss: 0.026991790160536766\n",
      "Epoch 2, Batch 4700, Loss: 0.01939835213124752\n",
      "Epoch 2, Batch 4800, Loss: 0.03573692962527275\n",
      "Epoch 2, Batch 4900, Loss: 0.015828531235456467\n",
      "Epoch 2, Batch 5000, Loss: 0.04823894798755646\n",
      "Epoch 2, Batch 5100, Loss: 0.017533965408802032\n",
      "Epoch 2, Batch 5200, Loss: 0.021390831097960472\n",
      "Epoch 2, Batch 5300, Loss: 0.03003925271332264\n",
      "Epoch 2, Batch 5400, Loss: 0.036394111812114716\n",
      "Epoch 2, Batch 5500, Loss: 0.09416133165359497\n",
      "Epoch 2, Batch 5600, Loss: 0.022232910618185997\n",
      "Epoch 2, Batch 5700, Loss: 0.009626733139157295\n",
      "Epoch 2, Batch 5800, Loss: 0.012133770622313023\n",
      "Epoch 2, Batch 5900, Loss: 0.017983587458729744\n",
      "Epoch 2, Batch 6000, Loss: 0.01487694587558508\n",
      "Epoch 2, Batch 6100, Loss: 0.016382915899157524\n",
      "Epoch 2, Batch 6200, Loss: 0.021297156810760498\n",
      "Epoch 2, Batch 6300, Loss: 0.0140269435942173\n",
      "Epoch 2, Batch 6400, Loss: 0.02515874058008194\n",
      "Epoch 2, Batch 6500, Loss: 0.009141910821199417\n",
      "Epoch 2, Batch 6600, Loss: 0.015930967405438423\n",
      "Epoch 2, Batch 6700, Loss: 0.010331268422305584\n",
      "Epoch 2, Batch 6800, Loss: 0.010255370289087296\n",
      "Epoch 2, Batch 6900, Loss: 0.009024603292346\n",
      "Epoch 2, Batch 7000, Loss: 0.01979967951774597\n",
      "Epoch 2, Batch 7100, Loss: 0.038656577467918396\n",
      "Epoch 2, Batch 7200, Loss: 0.017109815031290054\n",
      "Epoch 2, Batch 7300, Loss: 0.030292106792330742\n",
      "Epoch 2, Batch 7400, Loss: 0.028875041753053665\n",
      "Epoch 2, Batch 7500, Loss: 0.020225290209054947\n",
      "Epoch 2, Batch 7600, Loss: 0.02735798805952072\n",
      "Epoch 2, Batch 7700, Loss: 0.029518848285079002\n",
      "Epoch 2, Batch 7800, Loss: 0.037002645432949066\n",
      "Epoch 2, Batch 7900, Loss: 0.08001711964607239\n",
      "Epoch 2, Batch 8000, Loss: 0.0505080409348011\n",
      "Epoch 2, Batch 8100, Loss: 0.024519603699445724\n",
      "Epoch 2, Batch 8200, Loss: 0.02341269887983799\n",
      "Epoch 2, Batch 8300, Loss: 0.011743548326194286\n",
      "Epoch 2, Batch 8400, Loss: 0.019024107605218887\n",
      "Epoch 2, Batch 8500, Loss: 0.014736770652234554\n",
      "Epoch 2, Batch 8600, Loss: 0.01112540066242218\n",
      "Epoch 2, Batch 8700, Loss: 0.01592613011598587\n",
      "Epoch 2, Batch 8800, Loss: 0.0241807010024786\n",
      "Epoch 2, Batch 8900, Loss: 0.008389798924326897\n",
      "Epoch 2, Batch 9000, Loss: 0.021634506061673164\n",
      "Epoch 2, Batch 9100, Loss: 0.05039774626493454\n",
      "Epoch 2, Batch 9200, Loss: 0.019021907821297646\n",
      "Epoch 2, Batch 9300, Loss: 0.008410283364355564\n",
      "Epoch 2, Batch 9400, Loss: 0.01906939409673214\n",
      "Epoch 2, Batch 9500, Loss: 0.03516360744833946\n",
      "Epoch 2, Batch 9600, Loss: 0.03406200185418129\n",
      "Epoch 2, Batch 9700, Loss: 0.026577528566122055\n",
      "Epoch 2, Batch 9800, Loss: 0.02736770361661911\n",
      "Epoch 2, Batch 9900, Loss: 0.009970150887966156\n",
      "Epoch 2, Batch 10000, Loss: 0.007945646531879902\n",
      "Epoch 2, Batch 10100, Loss: 0.023142104968428612\n",
      "Epoch 2, Batch 10200, Loss: 0.01928403042256832\n",
      "Epoch 2, Batch 10300, Loss: 0.016742676496505737\n",
      "Epoch 2, Batch 10400, Loss: 0.003215887350961566\n",
      "Epoch 2, Batch 10500, Loss: 0.03296958655118942\n",
      "Epoch 2, Batch 10600, Loss: 0.01253514364361763\n",
      "Epoch 2, Batch 10700, Loss: 0.007350022904574871\n",
      "Epoch 2, Batch 10800, Loss: 0.004503452684730291\n",
      "Epoch 2, Batch 10900, Loss: 0.05630672350525856\n",
      "Epoch 2, Batch 11000, Loss: 0.044064413756132126\n",
      "Epoch 2, Batch 11100, Loss: 0.036056309938430786\n",
      "Epoch 2, Batch 11200, Loss: 0.01458936370909214\n",
      "Epoch 2, Batch 11300, Loss: 0.023253239691257477\n",
      "Epoch 2, Batch 11400, Loss: 0.029780296608805656\n",
      "Epoch 2, Batch 11500, Loss: 0.014818189665675163\n",
      "Epoch 2, Batch 11600, Loss: 0.021400991827249527\n",
      "Epoch 2, Batch 11700, Loss: 0.03586903214454651\n",
      "Epoch 2, Batch 11800, Loss: 0.013499550521373749\n",
      "Epoch 2, Batch 11900, Loss: 0.02900133840739727\n",
      "Epoch 2, Batch 12000, Loss: 0.020815396681427956\n",
      "Epoch 2, Batch 12100, Loss: 0.011846775189042091\n",
      "Epoch 2, Batch 12200, Loss: 0.02857244946062565\n",
      "Epoch 2, Batch 12300, Loss: 0.028170133009552956\n",
      "Epoch 2, Batch 12400, Loss: 0.05506239831447601\n",
      "Epoch 2, Batch 12500, Loss: 0.024724164977669716\n",
      "Epoch 2, Batch 12600, Loss: 0.012523244135081768\n",
      "Epoch 2, Batch 12700, Loss: 0.022175850346684456\n",
      "Epoch 2, Batch 12800, Loss: 0.06269016116857529\n",
      "Epoch 2, Batch 12900, Loss: 0.043614376336336136\n",
      "Epoch 2, Batch 13000, Loss: 0.006167369894683361\n",
      "Epoch 2, Batch 13100, Loss: 0.04017377272248268\n",
      "Epoch 2, Batch 13200, Loss: 0.03163875266909599\n",
      "Epoch 2, Batch 13300, Loss: 0.015035942196846008\n",
      "Epoch 2, Batch 13400, Loss: 0.03982750326395035\n",
      "Epoch 2, Batch 13500, Loss: 0.011456534266471863\n",
      "Epoch 2, Batch 13600, Loss: 0.04131506010890007\n",
      "Epoch 2, Batch 13700, Loss: 0.039511483162641525\n",
      "Epoch 2, Batch 13800, Loss: 0.019083982333540916\n",
      "Epoch 2, Batch 13900, Loss: 0.011611570604145527\n",
      "Epoch 2, Batch 14000, Loss: 0.011616386473178864\n",
      "Epoch 2, Batch 14100, Loss: 0.021604489535093307\n",
      "Epoch 2, Batch 14200, Loss: 0.023221736773848534\n",
      "Epoch 2, Batch 14300, Loss: 0.015492149628698826\n",
      "Epoch 2, Batch 14400, Loss: 0.016545375809073448\n",
      "Epoch 2, Batch 14500, Loss: 0.011458332650363445\n",
      "Epoch 2, Batch 14600, Loss: 0.008434850722551346\n",
      "Epoch 2, Batch 14700, Loss: 0.024804089218378067\n",
      "Epoch 2, Batch 14800, Loss: 0.01973303034901619\n",
      "Epoch 2, Batch 14900, Loss: 0.022876866161823273\n",
      "Epoch 2, Batch 15000, Loss: 0.029275476932525635\n",
      "Epoch 2, Batch 15100, Loss: 0.01791921630501747\n",
      "Epoch 2, Batch 15200, Loss: 0.021420253440737724\n",
      "Epoch 2, Batch 15300, Loss: 0.02535882219672203\n",
      "Epoch 2, Batch 15400, Loss: 0.00870637409389019\n",
      "Epoch 2, Batch 15500, Loss: 0.03252871707081795\n",
      "Epoch 2, Batch 15600, Loss: 0.011965185403823853\n",
      "Epoch 2, Batch 15700, Loss: 0.017848826944828033\n",
      "Epoch 2, Batch 15800, Loss: 0.013950604014098644\n",
      "Epoch 2, Batch 15900, Loss: 0.021949797868728638\n",
      "Epoch 2, Batch 16000, Loss: 0.022387048229575157\n",
      "Epoch 2, Batch 16100, Loss: 0.032418567687273026\n",
      "Epoch 2, Batch 16200, Loss: 0.03859711438417435\n",
      "Epoch 2, Batch 16300, Loss: 0.02556508034467697\n",
      "Epoch 2, Batch 16400, Loss: 0.014531631022691727\n",
      "Epoch 2, Batch 16500, Loss: 0.012717819772660732\n",
      "Epoch 2, Batch 16600, Loss: 0.018175778910517693\n",
      "Epoch 2, Batch 16700, Loss: 0.0150858573615551\n",
      "Epoch 2, Batch 16800, Loss: 0.011335124261677265\n",
      "Epoch 2, Batch 16900, Loss: 0.007740231696516275\n",
      "Epoch 2, Batch 17000, Loss: 0.014349706470966339\n",
      "Epoch 2, Batch 17100, Loss: 0.021584177389740944\n",
      "Epoch 2, Batch 17200, Loss: 0.027442697435617447\n",
      "Epoch 2, Batch 17300, Loss: 0.008170844987034798\n",
      "Epoch 2, Batch 17400, Loss: 0.028747737407684326\n",
      "Epoch 2, Batch 17500, Loss: 0.031170325353741646\n",
      "Epoch 2, Batch 17600, Loss: 0.011381570249795914\n",
      "Epoch 2, Batch 17700, Loss: 0.06056877598166466\n",
      "Epoch 2, Batch 17800, Loss: 0.02771901711821556\n",
      "Epoch 2, Batch 17900, Loss: 0.025655236095190048\n",
      "Epoch 2, Batch 18000, Loss: 0.035079844295978546\n",
      "Epoch 2, Batch 18100, Loss: 0.005028251558542252\n",
      "Epoch 2, Batch 18200, Loss: 0.029312334954738617\n",
      "Epoch 2, Batch 18300, Loss: 0.015373434871435165\n",
      "Epoch 2, Batch 18400, Loss: 0.06553782522678375\n",
      "Epoch 2, Batch 18500, Loss: 0.023552848026156425\n",
      "Epoch 2, Batch 18600, Loss: 0.010525447316467762\n",
      "Epoch 2, Batch 18700, Loss: 0.020915767177939415\n",
      "Epoch 2, Batch 18800, Loss: 0.011406775563955307\n",
      "Epoch 2, Batch 18900, Loss: 0.018007295206189156\n",
      "Epoch 2, Batch 19000, Loss: 0.028260234743356705\n",
      "Epoch 2, Batch 19100, Loss: 0.020852165296673775\n",
      "Epoch 2, Batch 19200, Loss: 0.007527686655521393\n",
      "Epoch 2, Batch 19300, Loss: 0.020742088556289673\n",
      "Epoch 2, Batch 19400, Loss: 0.023476876318454742\n",
      "Epoch 2, Batch 19500, Loss: 0.015833808109164238\n",
      "Epoch 2, Batch 19600, Loss: 0.01903797872364521\n",
      "Epoch 2, Batch 19700, Loss: 0.040897078812122345\n",
      "Epoch 2, Batch 19800, Loss: 0.045702967792749405\n",
      "Epoch 2, Batch 19900, Loss: 0.036537833511829376\n",
      "Epoch 2, Batch 20000, Loss: 0.021398236975073814\n",
      "Epoch 2, Batch 20100, Loss: 0.01720571704208851\n",
      "Epoch 2, Batch 20200, Loss: 0.011784768663346767\n",
      "Epoch 2, Batch 20300, Loss: 0.02857457660138607\n",
      "Epoch 2, Batch 20400, Loss: 0.020947188138961792\n",
      "Epoch 2, Batch 20500, Loss: 0.009258131496608257\n",
      "Epoch 2, Batch 20600, Loss: 0.034029796719551086\n",
      "Epoch 2, Batch 20700, Loss: 0.04352055490016937\n",
      "Epoch 2, Batch 20800, Loss: 0.02149946615099907\n",
      "Epoch 2, Batch 20900, Loss: 0.028151681646704674\n",
      "Epoch 2, Batch 21000, Loss: 0.015902990475296974\n",
      "Epoch 2, Batch 21100, Loss: 0.030805807560682297\n",
      "Epoch 2, Batch 21200, Loss: 0.019585294649004936\n",
      "Epoch 2, Batch 21300, Loss: 0.033290665596723557\n",
      "Epoch 2, Batch 21400, Loss: 0.02343933843076229\n",
      "Epoch 2, Batch 21500, Loss: 0.011454963125288486\n",
      "Epoch 2, Batch 21600, Loss: 0.011424734257161617\n",
      "Epoch 2, Batch 21700, Loss: 0.011359652504324913\n",
      "Epoch 2, Batch 21800, Loss: 0.013493388891220093\n",
      "Epoch 2, Batch 21900, Loss: 0.015425016172230244\n",
      "Epoch 2, Batch 22000, Loss: 0.004547263029962778\n",
      "Epoch 2, Batch 22100, Loss: 0.013987123966217041\n",
      "Epoch 2, Batch 22200, Loss: 0.0158778578042984\n",
      "Epoch 2, Batch 22300, Loss: 0.018974050879478455\n",
      "Epoch 2, Batch 22400, Loss: 0.012596854008734226\n",
      "Epoch 2, Batch 22500, Loss: 0.009813262149691582\n",
      "Epoch 2, Batch 22600, Loss: 0.010325775481760502\n",
      "Epoch 2, Batch 22700, Loss: 0.014409220777451992\n",
      "Epoch 2, Batch 22800, Loss: 0.00940315518528223\n",
      "Epoch 2, Batch 22900, Loss: 0.0401732437312603\n",
      "Epoch 2, Batch 23000, Loss: 0.020491568371653557\n",
      "Epoch 2, Batch 23100, Loss: 0.021088654175400734\n",
      "Epoch 2, Batch 23200, Loss: 0.014918401837348938\n",
      "Epoch 2, Batch 23300, Loss: 0.017960213124752045\n",
      "Epoch 2, Batch 23400, Loss: 0.01549187395721674\n",
      "Epoch 2, Batch 23500, Loss: 0.025411495938897133\n",
      "Epoch 2, Batch 23600, Loss: 0.01895192638039589\n",
      "Epoch 2, Batch 23700, Loss: 0.015089618973433971\n",
      "Epoch 2, Batch 23800, Loss: 0.038566891103982925\n",
      "Epoch 2, Batch 23900, Loss: 0.055107422173023224\n",
      "Epoch 2, Batch 24000, Loss: 0.016486985608935356\n",
      "Epoch 2, Batch 24100, Loss: 0.022735467180609703\n",
      "Epoch 2, Batch 24200, Loss: 0.014473114162683487\n",
      "Epoch 2, Batch 24300, Loss: 0.023304803296923637\n",
      "Epoch 2, Batch 24400, Loss: 0.04029729962348938\n",
      "Epoch 2, Batch 24500, Loss: 0.031896643340587616\n",
      "Epoch 2, Batch 24600, Loss: 0.021721720695495605\n",
      "Epoch 2, Batch 24700, Loss: 0.005646395962685347\n",
      "Epoch 2, Batch 24800, Loss: 0.02761154994368553\n",
      "Epoch 2, Batch 24900, Loss: 0.020625021308660507\n",
      "Epoch 2, Batch 25000, Loss: 0.01177971437573433\n",
      "Epoch 2, Batch 25100, Loss: 0.01123756729066372\n",
      "Epoch 2, Batch 25200, Loss: 0.024291086941957474\n",
      "Epoch 2, Batch 25300, Loss: 0.028246713802218437\n",
      "Epoch 2, Batch 25400, Loss: 0.09131479263305664\n",
      "Epoch 2, Batch 25500, Loss: 0.018506450578570366\n",
      "Epoch 2, Batch 25600, Loss: 0.03893033787608147\n",
      "Epoch 2, Batch 25700, Loss: 0.026920698583126068\n",
      "Epoch 2, Batch 25800, Loss: 0.038595110177993774\n",
      "Epoch 2, Batch 25900, Loss: 0.022702384740114212\n",
      "Epoch 2, Batch 26000, Loss: 0.009048258885741234\n",
      "Epoch 2, Batch 26100, Loss: 0.025493228808045387\n",
      "Epoch 2, Batch 26200, Loss: 0.02525385655462742\n",
      "Epoch 2, Batch 26300, Loss: 0.013432207517325878\n",
      "Epoch 2, Batch 26400, Loss: 0.04548182338476181\n",
      "Epoch 2, Batch 26500, Loss: 0.04110626131296158\n",
      "Epoch 2, Batch 26600, Loss: 0.020411211997270584\n",
      "Epoch 2, Batch 26700, Loss: 0.02170936018228531\n",
      "Epoch 2, Batch 26800, Loss: 0.026750629767775536\n",
      "Epoch 2, Batch 26900, Loss: 0.03008163906633854\n",
      "Epoch 2, Batch 27000, Loss: 0.06206433102488518\n",
      "Epoch 2, Batch 27100, Loss: 0.02046367898583412\n",
      "Epoch 2, Batch 27200, Loss: 0.01080070436000824\n",
      "Epoch 2, Batch 27300, Loss: 0.00757468631491065\n",
      "Epoch 2, Batch 27400, Loss: 0.026958666741847992\n",
      "Epoch 2, Batch 27500, Loss: 0.018154606223106384\n",
      "Epoch 2, Batch 27600, Loss: 0.020287824794650078\n",
      "Epoch 2, Batch 27700, Loss: 0.013098007999360561\n",
      "Epoch 2, Batch 27800, Loss: 0.02224297821521759\n",
      "Epoch 2, Batch 27900, Loss: 0.00751273799687624\n",
      "Epoch 2, Batch 28000, Loss: 0.021342987194657326\n",
      "Epoch 2, Batch 28100, Loss: 0.009665986523032188\n",
      "Epoch 2, Batch 28200, Loss: 0.02647015079855919\n",
      "Epoch 2, Batch 28300, Loss: 0.028955494984984398\n",
      "Epoch 2, Batch 28400, Loss: 0.007774475496262312\n",
      "Epoch 2, Batch 28500, Loss: 0.051825109869241714\n",
      "Epoch 2, Batch 28600, Loss: 0.03156227618455887\n",
      "Epoch 2, Batch 28700, Loss: 0.013577003963291645\n",
      "Epoch 2, Batch 28800, Loss: 0.02714136429131031\n",
      "Epoch 2, Batch 28900, Loss: 0.02159709297120571\n",
      "Epoch 2, Batch 29000, Loss: 0.06434043496847153\n",
      "Epoch 2, Batch 29100, Loss: 0.01943015307188034\n",
      "Epoch 2, Batch 29200, Loss: 0.034460682421922684\n",
      "Epoch 2, Batch 29300, Loss: 0.028302166610956192\n",
      "Epoch 2, Batch 29400, Loss: 0.031811632215976715\n",
      "Epoch 2, Batch 29500, Loss: 0.021980727091431618\n",
      "Epoch 2, Batch 29600, Loss: 0.02519061416387558\n",
      "Epoch 2, Batch 29700, Loss: 0.0256365817040205\n",
      "Epoch 2, Batch 29800, Loss: 0.030143920332193375\n",
      "Epoch 2, Batch 29900, Loss: 0.012989475391805172\n",
      "Epoch 2, Batch 30000, Loss: 0.02634424716234207\n",
      "Epoch 2, Batch 30100, Loss: 0.04890108481049538\n",
      "Epoch 2, Batch 30200, Loss: 0.025235870853066444\n",
      "Epoch 2, Batch 30300, Loss: 0.030299406498670578\n",
      "Epoch 2, Batch 30400, Loss: 0.016357721760869026\n",
      "Epoch 2, Batch 30500, Loss: 0.02366887405514717\n",
      "Epoch 2, Batch 30600, Loss: 0.03411400318145752\n",
      "Epoch 2, Batch 30700, Loss: 0.06211669743061066\n",
      "Epoch 2, Batch 30800, Loss: 0.0402294285595417\n",
      "Epoch 2, Batch 30900, Loss: 0.012153388932347298\n",
      "Epoch 2, Batch 31000, Loss: 0.012515867128968239\n",
      "Epoch 2, Batch 31100, Loss: 0.020634077489376068\n",
      "Epoch 2, Batch 31200, Loss: 0.015879269689321518\n",
      "Epoch 2, Batch 31300, Loss: 0.01898893527686596\n",
      "Epoch 2, Batch 31400, Loss: 0.01922020874917507\n",
      "Epoch 2, Batch 31500, Loss: 0.016596268862485886\n",
      "Epoch 2, Batch 31600, Loss: 0.022477783262729645\n",
      "Epoch 2, Batch 31700, Loss: 0.017161818221211433\n",
      "Epoch 2, Batch 31800, Loss: 0.027129290625452995\n",
      "Epoch 2, Batch 31900, Loss: 0.05034073069691658\n",
      "Epoch 2, Batch 32000, Loss: 0.019274042919278145\n",
      "Epoch 2, Batch 32100, Loss: 0.034880075603723526\n",
      "Epoch 2, Batch 32200, Loss: 0.00916624441742897\n",
      "Epoch 2, Batch 32300, Loss: 0.03373705968260765\n",
      "Epoch 2, Batch 32400, Loss: 0.016003888100385666\n",
      "Epoch 2, Batch 32500, Loss: 0.02978035807609558\n",
      "Epoch 2, Batch 32600, Loss: 0.01686112768948078\n",
      "Epoch 2, Batch 32700, Loss: 0.032696682959795\n",
      "Epoch 2, Batch 32800, Loss: 0.01696161739528179\n",
      "Epoch 2, Batch 32900, Loss: 0.015366983599960804\n",
      "Epoch 2, Batch 33000, Loss: 0.015341413207352161\n",
      "Epoch 2, Batch 33100, Loss: 0.01691049337387085\n",
      "Epoch 2, Batch 33200, Loss: 0.019812028855085373\n",
      "Epoch 2, Batch 33300, Loss: 0.010836277157068253\n",
      "Epoch 2, Batch 33400, Loss: 0.07233842462301254\n",
      "Epoch 2, Batch 33500, Loss: 0.026489460840821266\n",
      "Epoch 2, Batch 33600, Loss: 0.012838137336075306\n",
      "Epoch 2, Batch 33700, Loss: 0.03801345080137253\n",
      "Epoch 2, Batch 33800, Loss: 0.02435203269124031\n",
      "Epoch 2, Batch 33900, Loss: 0.0671822652220726\n",
      "Epoch 2, Batch 34000, Loss: 0.021307116374373436\n",
      "Epoch 2, Batch 34100, Loss: 0.012522352859377861\n",
      "Epoch 2, Batch 34200, Loss: 0.020619049668312073\n",
      "Epoch 2, Batch 34300, Loss: 0.01980147883296013\n",
      "Epoch 2, Batch 34400, Loss: 0.06693495810031891\n",
      "Epoch 2, Batch 34500, Loss: 0.016659541055560112\n",
      "Epoch 2, Batch 34600, Loss: 0.013623114675283432\n",
      "Epoch 2, Batch 34700, Loss: 0.017290104180574417\n",
      "Epoch 2, Batch 34800, Loss: 0.01819019764661789\n",
      "Epoch 2, Batch 34900, Loss: 0.011825858615338802\n",
      "Epoch 2, Batch 35000, Loss: 0.027960794046521187\n",
      "Epoch 2, Batch 35100, Loss: 0.04897605627775192\n",
      "Epoch 2, Batch 35200, Loss: 0.028789611533284187\n",
      "Epoch 2, Batch 35300, Loss: 0.04872644320130348\n",
      "Epoch 2, Batch 35400, Loss: 0.011573519557714462\n",
      "Epoch 2, Batch 35500, Loss: 0.012940392829477787\n",
      "Epoch 2, Batch 35600, Loss: 0.018419736996293068\n",
      "Epoch 2, Batch 35700, Loss: 0.020377978682518005\n",
      "Epoch 2, Batch 35800, Loss: 0.018134145066142082\n",
      "Epoch 2, Batch 35900, Loss: 0.02088497206568718\n",
      "Epoch 2, Batch 36000, Loss: 0.002956910990178585\n",
      "Epoch 2, Batch 36100, Loss: 0.01348275225609541\n",
      "Epoch 2, Batch 36200, Loss: 0.012854977510869503\n",
      "Epoch 2, Batch 36300, Loss: 0.02575138583779335\n",
      "Epoch 2, Batch 36400, Loss: 0.0154813751578331\n",
      "Epoch 2, Batch 36500, Loss: 0.01563185453414917\n",
      "Epoch 2, Batch 36600, Loss: 0.03918996453285217\n",
      "Epoch 2, Batch 36700, Loss: 0.011170469224452972\n",
      "Epoch 2, Batch 36800, Loss: 0.021382678300142288\n",
      "Validation Loss: 2.3540679404067992\n",
      "Epoch 3, Batch 100, Loss: 0.039470456540584564\n",
      "Epoch 3, Batch 200, Loss: 0.008891552686691284\n",
      "Epoch 3, Batch 300, Loss: 0.01925365813076496\n",
      "Epoch 3, Batch 400, Loss: 0.035869769752025604\n",
      "Epoch 3, Batch 500, Loss: 0.021985765546560287\n",
      "Epoch 3, Batch 600, Loss: 0.01680097170174122\n",
      "Epoch 3, Batch 700, Loss: 0.010249943472445011\n",
      "Epoch 3, Batch 800, Loss: 0.012897977605462074\n",
      "Epoch 3, Batch 900, Loss: 0.028335753828287125\n",
      "Epoch 3, Batch 1000, Loss: 0.010810289531946182\n",
      "Epoch 3, Batch 1100, Loss: 0.03240421786904335\n",
      "Epoch 3, Batch 1200, Loss: 0.016208529472351074\n",
      "Epoch 3, Batch 1300, Loss: 0.05532079562544823\n",
      "Epoch 3, Batch 1400, Loss: 0.018224067986011505\n",
      "Epoch 3, Batch 1500, Loss: 0.12477561086416245\n",
      "Epoch 3, Batch 1600, Loss: 0.026763897389173508\n",
      "Epoch 3, Batch 1700, Loss: 0.021716881543397903\n",
      "Epoch 3, Batch 1800, Loss: 0.027376864105463028\n",
      "Epoch 3, Batch 1900, Loss: 0.040905535221099854\n",
      "Epoch 3, Batch 2000, Loss: 0.03132465481758118\n",
      "Epoch 3, Batch 2100, Loss: 0.02803046628832817\n",
      "Epoch 3, Batch 2200, Loss: 0.03515176847577095\n",
      "Epoch 3, Batch 2300, Loss: 0.015890102833509445\n",
      "Epoch 3, Batch 2400, Loss: 0.011410162784159184\n",
      "Epoch 3, Batch 2500, Loss: 0.02272823080420494\n",
      "Epoch 3, Batch 2600, Loss: 0.02639399655163288\n",
      "Epoch 3, Batch 2700, Loss: 0.03698793426156044\n",
      "Epoch 3, Batch 2800, Loss: 0.008752118796110153\n",
      "Epoch 3, Batch 2900, Loss: 0.010932699777185917\n",
      "Epoch 3, Batch 3000, Loss: 0.06878026574850082\n",
      "Epoch 3, Batch 3100, Loss: 0.019717209041118622\n",
      "Epoch 3, Batch 3200, Loss: 0.018055720254778862\n",
      "Epoch 3, Batch 3300, Loss: 0.02084425464272499\n",
      "Epoch 3, Batch 3400, Loss: 0.018115641549229622\n",
      "Epoch 3, Batch 3500, Loss: 0.030959440395236015\n",
      "Epoch 3, Batch 3600, Loss: 0.025838248431682587\n",
      "Epoch 3, Batch 3700, Loss: 0.026077257469296455\n",
      "Epoch 3, Batch 3800, Loss: 0.022908808663487434\n",
      "Epoch 3, Batch 3900, Loss: 0.02122863195836544\n",
      "Epoch 3, Batch 4000, Loss: 0.018190179020166397\n",
      "Epoch 3, Batch 4100, Loss: 0.008868268691003323\n",
      "Epoch 3, Batch 4200, Loss: 0.017657818272709846\n",
      "Epoch 3, Batch 4300, Loss: 0.051991306245326996\n",
      "Epoch 3, Batch 4400, Loss: 0.015476488508284092\n",
      "Epoch 3, Batch 4500, Loss: 0.012902215123176575\n",
      "Epoch 3, Batch 4600, Loss: 0.01625639572739601\n",
      "Epoch 3, Batch 4700, Loss: 0.014235957525670528\n",
      "Epoch 3, Batch 4800, Loss: 0.09198526293039322\n",
      "Epoch 3, Batch 4900, Loss: 0.02483038231730461\n",
      "Epoch 3, Batch 5000, Loss: 0.015894053503870964\n",
      "Epoch 3, Batch 5100, Loss: 0.016813406720757484\n",
      "Epoch 3, Batch 5200, Loss: 0.032428573817014694\n",
      "Epoch 3, Batch 5300, Loss: 0.03926637023687363\n",
      "Epoch 3, Batch 5400, Loss: 0.023874633014202118\n",
      "Epoch 3, Batch 5500, Loss: 0.011631582863628864\n",
      "Epoch 3, Batch 5600, Loss: 0.015005981549620628\n",
      "Epoch 3, Batch 5700, Loss: 0.02307036891579628\n",
      "Epoch 3, Batch 5800, Loss: 0.02273659221827984\n",
      "Epoch 3, Batch 5900, Loss: 0.01837265118956566\n",
      "Epoch 3, Batch 6000, Loss: 0.007834245450794697\n",
      "Epoch 3, Batch 6100, Loss: 0.011114104650914669\n",
      "Epoch 3, Batch 6200, Loss: 0.026450078934431076\n",
      "Epoch 3, Batch 6300, Loss: 0.04649696126580238\n",
      "Epoch 3, Batch 6400, Loss: 0.018998757004737854\n",
      "Epoch 3, Batch 6500, Loss: 0.021513352170586586\n",
      "Epoch 3, Batch 6600, Loss: 0.017740104347467422\n",
      "Epoch 3, Batch 6700, Loss: 0.009895963594317436\n",
      "Epoch 3, Batch 6800, Loss: 0.03857297822833061\n",
      "Epoch 3, Batch 6900, Loss: 0.004713851027190685\n",
      "Epoch 3, Batch 7000, Loss: 0.017803920432925224\n",
      "Epoch 3, Batch 7100, Loss: 0.01288207434117794\n",
      "Epoch 3, Batch 7200, Loss: 0.025087961927056313\n",
      "Epoch 3, Batch 7300, Loss: 0.005498896352946758\n",
      "Epoch 3, Batch 7400, Loss: 0.025855662301182747\n",
      "Epoch 3, Batch 7500, Loss: 0.016478143632411957\n",
      "Epoch 3, Batch 7600, Loss: 0.02508760802447796\n",
      "Epoch 3, Batch 7700, Loss: 0.014861216768622398\n",
      "Epoch 3, Batch 7800, Loss: 0.020586751401424408\n",
      "Epoch 3, Batch 7900, Loss: 0.027571294456720352\n",
      "Epoch 3, Batch 8000, Loss: 0.0282010268419981\n",
      "Epoch 3, Batch 8100, Loss: 0.021752821281552315\n",
      "Epoch 3, Batch 8200, Loss: 0.028204457834362984\n",
      "Epoch 3, Batch 8300, Loss: 0.011912062764167786\n",
      "Epoch 3, Batch 8400, Loss: 0.02141209878027439\n",
      "Epoch 3, Batch 8500, Loss: 0.01750078983604908\n",
      "Epoch 3, Batch 8600, Loss: 0.017827535048127174\n",
      "Epoch 3, Batch 8700, Loss: 0.014870742335915565\n",
      "Epoch 3, Batch 8800, Loss: 0.008714568801224232\n",
      "Epoch 3, Batch 8900, Loss: 0.023380661383271217\n",
      "Epoch 3, Batch 9000, Loss: 0.04617037624120712\n",
      "Epoch 3, Batch 9100, Loss: 0.012476340867578983\n",
      "Epoch 3, Batch 9200, Loss: 0.0202114749699831\n",
      "Epoch 3, Batch 9300, Loss: 0.011985354125499725\n",
      "Epoch 3, Batch 9400, Loss: 0.027037108317017555\n",
      "Epoch 3, Batch 9500, Loss: 0.021221578121185303\n",
      "Epoch 3, Batch 9600, Loss: 0.021495677530765533\n",
      "Epoch 3, Batch 9700, Loss: 0.04462648928165436\n",
      "Epoch 3, Batch 9800, Loss: 0.027771122753620148\n",
      "Epoch 3, Batch 9900, Loss: 0.02599494345486164\n",
      "Epoch 3, Batch 10000, Loss: 0.011006576009094715\n",
      "Epoch 3, Batch 10100, Loss: 0.022187748923897743\n",
      "Epoch 3, Batch 10200, Loss: 0.013753441162407398\n",
      "Epoch 3, Batch 10300, Loss: 0.02406962215900421\n",
      "Epoch 3, Batch 10400, Loss: 0.015353170223534107\n",
      "Epoch 3, Batch 10500, Loss: 0.021381361410021782\n",
      "Epoch 3, Batch 10600, Loss: 0.01732230931520462\n",
      "Epoch 3, Batch 10700, Loss: 0.028769785538315773\n",
      "Epoch 3, Batch 10800, Loss: 0.027377936989068985\n",
      "Epoch 3, Batch 10900, Loss: 0.020426126196980476\n",
      "Epoch 3, Batch 11000, Loss: 0.014338012784719467\n",
      "Epoch 3, Batch 11100, Loss: 0.059440914541482925\n",
      "Epoch 3, Batch 11200, Loss: 0.014366144314408302\n",
      "Epoch 3, Batch 11300, Loss: 0.020491069182753563\n",
      "Epoch 3, Batch 11400, Loss: 0.03149321675300598\n",
      "Epoch 3, Batch 11500, Loss: 0.01927933283150196\n",
      "Epoch 3, Batch 11600, Loss: 0.06008850783109665\n",
      "Epoch 3, Batch 11700, Loss: 0.016410447657108307\n",
      "Epoch 3, Batch 11800, Loss: 0.03429760783910751\n",
      "Epoch 3, Batch 11900, Loss: 0.0231295395642519\n",
      "Epoch 3, Batch 12000, Loss: 0.027636995539069176\n",
      "Epoch 3, Batch 12100, Loss: 0.028195371851325035\n",
      "Epoch 3, Batch 12200, Loss: 0.024395255371928215\n",
      "Epoch 3, Batch 12300, Loss: 0.02495628222823143\n",
      "Epoch 3, Batch 12400, Loss: 0.025460124015808105\n",
      "Epoch 3, Batch 12500, Loss: 0.08411317318677902\n",
      "Epoch 3, Batch 12600, Loss: 0.03279804065823555\n",
      "Epoch 3, Batch 12700, Loss: 0.021230163052678108\n",
      "Epoch 3, Batch 12800, Loss: 0.08558854460716248\n",
      "Epoch 3, Batch 12900, Loss: 0.044627320021390915\n",
      "Epoch 3, Batch 13000, Loss: 0.01844451203942299\n",
      "Epoch 3, Batch 13100, Loss: 0.0586375892162323\n",
      "Epoch 3, Batch 13200, Loss: 0.011157517321407795\n",
      "Epoch 3, Batch 13300, Loss: 0.02731155790388584\n",
      "Epoch 3, Batch 13400, Loss: 0.016387248411774635\n",
      "Epoch 3, Batch 13500, Loss: 0.046130891889333725\n",
      "Epoch 3, Batch 13600, Loss: 0.01567486673593521\n",
      "Epoch 3, Batch 13700, Loss: 0.025421012192964554\n",
      "Epoch 3, Batch 13800, Loss: 0.018876755610108376\n",
      "Epoch 3, Batch 13900, Loss: 0.012292257510125637\n",
      "Epoch 3, Batch 14000, Loss: 0.01460088137537241\n",
      "Epoch 3, Batch 14100, Loss: 0.018776332959532738\n",
      "Epoch 3, Batch 14200, Loss: 0.021155783906579018\n",
      "Epoch 3, Batch 14300, Loss: 0.013016466051340103\n",
      "Epoch 3, Batch 14400, Loss: 0.032382477074861526\n",
      "Epoch 3, Batch 14500, Loss: 0.017326978966593742\n",
      "Epoch 3, Batch 14600, Loss: 0.009747478179633617\n",
      "Epoch 3, Batch 14700, Loss: 0.017584217712283134\n",
      "Epoch 3, Batch 14800, Loss: 0.03263752534985542\n",
      "Epoch 3, Batch 14900, Loss: 0.030216746032238007\n",
      "Epoch 3, Batch 15000, Loss: 0.018843505531549454\n",
      "Epoch 3, Batch 15100, Loss: 0.03491729870438576\n",
      "Epoch 3, Batch 15200, Loss: 0.01754993200302124\n",
      "Epoch 3, Batch 15300, Loss: 0.06562059372663498\n",
      "Epoch 3, Batch 15400, Loss: 0.01682719774544239\n",
      "Epoch 3, Batch 15500, Loss: 0.056942280381917953\n",
      "Epoch 3, Batch 15600, Loss: 0.010969583876430988\n",
      "Epoch 3, Batch 15700, Loss: 0.026166612282395363\n",
      "Epoch 3, Batch 15800, Loss: 0.013630496338009834\n",
      "Epoch 3, Batch 15900, Loss: 0.02636173740029335\n",
      "Epoch 3, Batch 16000, Loss: 0.00857863761484623\n",
      "Epoch 3, Batch 16100, Loss: 0.014401341788470745\n",
      "Epoch 3, Batch 16200, Loss: 0.01845529116690159\n",
      "Epoch 3, Batch 16300, Loss: 0.031658582389354706\n",
      "Epoch 3, Batch 16400, Loss: 0.017325110733509064\n",
      "Epoch 3, Batch 16500, Loss: 0.01100768893957138\n",
      "Epoch 3, Batch 16600, Loss: 0.028795747086405754\n",
      "Epoch 3, Batch 16700, Loss: 0.029978659003973007\n",
      "Epoch 3, Batch 16800, Loss: 0.014793147332966328\n",
      "Epoch 3, Batch 16900, Loss: 0.04663967713713646\n",
      "Epoch 3, Batch 17000, Loss: 0.02930257096886635\n",
      "Epoch 3, Batch 17100, Loss: 0.028561079874634743\n",
      "Epoch 3, Batch 17200, Loss: 0.03167819604277611\n",
      "Epoch 3, Batch 17300, Loss: 0.013126280158758163\n",
      "Epoch 3, Batch 17400, Loss: 0.01908179745078087\n",
      "Epoch 3, Batch 17500, Loss: 0.015387654304504395\n",
      "Epoch 3, Batch 17600, Loss: 0.025124553591012955\n",
      "Epoch 3, Batch 17700, Loss: 0.012375890277326107\n",
      "Epoch 3, Batch 17800, Loss: 0.028288211673498154\n",
      "Epoch 3, Batch 17900, Loss: 0.015513269230723381\n",
      "Epoch 3, Batch 18000, Loss: 0.011801565065979958\n",
      "Epoch 3, Batch 18100, Loss: 0.017453568056225777\n",
      "Epoch 3, Batch 18200, Loss: 0.03844311833381653\n",
      "Epoch 3, Batch 18300, Loss: 0.012491533532738686\n",
      "Epoch 3, Batch 18400, Loss: 0.039040178060531616\n",
      "Epoch 3, Batch 18500, Loss: 0.020919740200042725\n",
      "Epoch 3, Batch 18600, Loss: 0.010641542263329029\n",
      "Epoch 3, Batch 18700, Loss: 0.020283900201320648\n",
      "Epoch 3, Batch 18800, Loss: 0.04755653813481331\n",
      "Epoch 3, Batch 18900, Loss: 0.012812439352273941\n",
      "Epoch 3, Batch 19000, Loss: 0.022603442892432213\n",
      "Epoch 3, Batch 19100, Loss: 0.022124487906694412\n",
      "Epoch 3, Batch 19200, Loss: 0.0552198700606823\n",
      "Epoch 3, Batch 19300, Loss: 0.03463735431432724\n",
      "Epoch 3, Batch 19400, Loss: 0.026554852724075317\n",
      "Epoch 3, Batch 19500, Loss: 0.025517059490084648\n",
      "Epoch 3, Batch 19600, Loss: 0.007089054211974144\n",
      "Epoch 3, Batch 19700, Loss: 0.028501976281404495\n",
      "Epoch 3, Batch 19800, Loss: 0.03327270224690437\n",
      "Epoch 3, Batch 19900, Loss: 0.009616066701710224\n",
      "Epoch 3, Batch 20000, Loss: 0.05405660718679428\n",
      "Epoch 3, Batch 20100, Loss: 0.017106181010603905\n",
      "Epoch 3, Batch 20200, Loss: 0.04720588028430939\n",
      "Epoch 3, Batch 20300, Loss: 0.025492282584309578\n",
      "Epoch 3, Batch 20400, Loss: 0.028042230755090714\n",
      "Epoch 3, Batch 20500, Loss: 0.01834697462618351\n",
      "Epoch 3, Batch 20600, Loss: 0.014243941754102707\n",
      "Epoch 3, Batch 20700, Loss: 0.021641692146658897\n",
      "Epoch 3, Batch 20800, Loss: 0.03226861730217934\n",
      "Epoch 3, Batch 20900, Loss: 0.03040102683007717\n",
      "Epoch 3, Batch 21000, Loss: 0.03239235281944275\n",
      "Epoch 3, Batch 21100, Loss: 0.02811562456190586\n",
      "Epoch 3, Batch 21200, Loss: 0.01607399806380272\n",
      "Epoch 3, Batch 21300, Loss: 0.10739219188690186\n",
      "Epoch 3, Batch 21400, Loss: 0.02061733603477478\n",
      "Epoch 3, Batch 21500, Loss: 0.03130592778325081\n",
      "Epoch 3, Batch 21600, Loss: 0.01869928278028965\n",
      "Epoch 3, Batch 21700, Loss: 0.03319014981389046\n",
      "Epoch 3, Batch 21800, Loss: 0.06722765415906906\n",
      "Epoch 3, Batch 21900, Loss: 0.015310305170714855\n",
      "Epoch 3, Batch 22000, Loss: 0.013653809204697609\n",
      "Epoch 3, Batch 22100, Loss: 0.010684159584343433\n",
      "Epoch 3, Batch 22200, Loss: 0.11189230531454086\n",
      "Epoch 3, Batch 22300, Loss: 0.01993812806904316\n",
      "Epoch 3, Batch 22400, Loss: 0.03467549383640289\n",
      "Epoch 3, Batch 22500, Loss: 0.024628659710288048\n",
      "Epoch 3, Batch 22600, Loss: 0.05016101896762848\n",
      "Epoch 3, Batch 22700, Loss: 0.01610194891691208\n",
      "Epoch 3, Batch 22800, Loss: 0.0346686989068985\n",
      "Epoch 3, Batch 22900, Loss: 0.015529747121036053\n",
      "Epoch 3, Batch 23000, Loss: 0.03543781489133835\n",
      "Epoch 3, Batch 23100, Loss: 0.02152421325445175\n",
      "Epoch 3, Batch 23200, Loss: 0.011795684695243835\n",
      "Epoch 3, Batch 23300, Loss: 0.01018081046640873\n",
      "Epoch 3, Batch 23400, Loss: 0.02222844772040844\n",
      "Epoch 3, Batch 23500, Loss: 0.024779291823506355\n",
      "Epoch 3, Batch 23600, Loss: 0.017228087410330772\n",
      "Epoch 3, Batch 23700, Loss: 0.015376935712993145\n",
      "Epoch 3, Batch 23800, Loss: 0.0180054884403944\n",
      "Epoch 3, Batch 23900, Loss: 0.025413118302822113\n",
      "Epoch 3, Batch 24000, Loss: 0.023055395111441612\n",
      "Epoch 3, Batch 24100, Loss: 0.010673889890313148\n",
      "Epoch 3, Batch 24200, Loss: 0.0210986640304327\n",
      "Epoch 3, Batch 24300, Loss: 0.012178867124021053\n",
      "Epoch 3, Batch 24400, Loss: 0.0188593789935112\n",
      "Epoch 3, Batch 24500, Loss: 0.0212667528539896\n",
      "Epoch 3, Batch 24600, Loss: 0.021860111504793167\n",
      "Epoch 3, Batch 24700, Loss: 0.023050671443343163\n",
      "Epoch 3, Batch 24800, Loss: 0.06851622462272644\n",
      "Epoch 3, Batch 24900, Loss: 0.052261438220739365\n",
      "Epoch 3, Batch 25000, Loss: 0.05350133776664734\n",
      "Epoch 3, Batch 25100, Loss: 0.019049637019634247\n",
      "Epoch 3, Batch 25200, Loss: 0.013837321661412716\n",
      "Epoch 3, Batch 25300, Loss: 0.01901795156300068\n",
      "Epoch 3, Batch 25400, Loss: 0.032034732401371\n",
      "Epoch 3, Batch 25500, Loss: 0.07093042135238647\n",
      "Epoch 3, Batch 25600, Loss: 0.06049523130059242\n",
      "Epoch 3, Batch 25700, Loss: 0.023685092106461525\n",
      "Epoch 3, Batch 25800, Loss: 0.016347508877515793\n",
      "Epoch 3, Batch 25900, Loss: 0.011267520487308502\n",
      "Epoch 3, Batch 26000, Loss: 0.024837512522935867\n",
      "Epoch 3, Batch 26100, Loss: 0.017503289505839348\n",
      "Epoch 3, Batch 26200, Loss: 0.027923841029405594\n",
      "Epoch 3, Batch 26300, Loss: 0.023241890594363213\n",
      "Epoch 3, Batch 26400, Loss: 0.016653750091791153\n",
      "Epoch 3, Batch 26500, Loss: 0.04110307991504669\n",
      "Epoch 3, Batch 26600, Loss: 0.04621773958206177\n",
      "Epoch 3, Batch 26700, Loss: 0.026635175570845604\n",
      "Epoch 3, Batch 26800, Loss: 0.022287651896476746\n",
      "Epoch 3, Batch 26900, Loss: 0.03904629126191139\n",
      "Epoch 3, Batch 27000, Loss: 0.03192000463604927\n",
      "Epoch 3, Batch 27100, Loss: 0.03175727650523186\n",
      "Epoch 3, Batch 27200, Loss: 0.015384038910269737\n",
      "Epoch 3, Batch 27300, Loss: 0.033888887614011765\n",
      "Epoch 3, Batch 27400, Loss: 0.017308389768004417\n",
      "Epoch 3, Batch 27500, Loss: 0.009256715886294842\n",
      "Epoch 3, Batch 27600, Loss: 0.011355781927704811\n",
      "Epoch 3, Batch 27700, Loss: 0.03646385669708252\n",
      "Epoch 3, Batch 27800, Loss: 0.022031394764780998\n",
      "Epoch 3, Batch 27900, Loss: 0.03719506040215492\n",
      "Epoch 3, Batch 28000, Loss: 0.014873795211315155\n",
      "Epoch 3, Batch 28100, Loss: 0.019834743812680244\n",
      "Epoch 3, Batch 28200, Loss: 0.02043089270591736\n",
      "Epoch 3, Batch 28300, Loss: 0.015730954706668854\n",
      "Epoch 3, Batch 28400, Loss: 0.02248755656182766\n",
      "Epoch 3, Batch 28500, Loss: 0.01766498200595379\n",
      "Epoch 3, Batch 28600, Loss: 0.016165219247341156\n",
      "Epoch 3, Batch 28700, Loss: 0.008879635483026505\n",
      "Epoch 3, Batch 28800, Loss: 0.029521428048610687\n",
      "Epoch 3, Batch 28900, Loss: 0.015916811302304268\n",
      "Epoch 3, Batch 29000, Loss: 0.011656622402369976\n",
      "Epoch 3, Batch 29100, Loss: 0.008135035634040833\n",
      "Epoch 3, Batch 29200, Loss: 0.013174692168831825\n",
      "Epoch 3, Batch 29300, Loss: 0.009160593152046204\n",
      "Epoch 3, Batch 29400, Loss: 0.030293330550193787\n",
      "Epoch 3, Batch 29500, Loss: 0.021968597546219826\n",
      "Epoch 3, Batch 29600, Loss: 0.01891443319618702\n",
      "Epoch 3, Batch 29700, Loss: 0.012592807412147522\n",
      "Epoch 3, Batch 29800, Loss: 0.01826661266386509\n",
      "Epoch 3, Batch 29900, Loss: 0.03467748314142227\n",
      "Epoch 3, Batch 30000, Loss: 0.010924901813268661\n",
      "Epoch 3, Batch 30100, Loss: 0.11986739933490753\n",
      "Epoch 3, Batch 30200, Loss: 0.03180999681353569\n",
      "Epoch 3, Batch 30300, Loss: 0.043030064553022385\n",
      "Epoch 3, Batch 30400, Loss: 0.018449297174811363\n",
      "Epoch 3, Batch 30500, Loss: 0.0471084862947464\n",
      "Epoch 3, Batch 30600, Loss: 0.028429746627807617\n",
      "Epoch 3, Batch 30700, Loss: 0.036645859479904175\n",
      "Epoch 3, Batch 30800, Loss: 0.021808912977576256\n",
      "Epoch 3, Batch 30900, Loss: 0.019895607605576515\n",
      "Epoch 3, Batch 31000, Loss: 0.020964354276657104\n",
      "Epoch 3, Batch 31100, Loss: 0.011497661471366882\n",
      "Epoch 3, Batch 31200, Loss: 0.02183252014219761\n",
      "Epoch 3, Batch 31300, Loss: 0.006131445523351431\n",
      "Epoch 3, Batch 31400, Loss: 0.032120462507009506\n",
      "Epoch 3, Batch 31500, Loss: 0.025865577161312103\n",
      "Epoch 3, Batch 31600, Loss: 0.01731196604669094\n",
      "Epoch 3, Batch 31700, Loss: 0.014691295102238655\n",
      "Epoch 3, Batch 31800, Loss: 0.02439964935183525\n",
      "Epoch 3, Batch 31900, Loss: 0.011385251767933369\n",
      "Epoch 3, Batch 32000, Loss: 0.030912041664123535\n",
      "Epoch 3, Batch 32100, Loss: 0.015210960991680622\n",
      "Epoch 3, Batch 32200, Loss: 0.013305379077792168\n",
      "Epoch 3, Batch 32300, Loss: 0.025953082367777824\n",
      "Epoch 3, Batch 32400, Loss: 0.048278991132974625\n",
      "Epoch 3, Batch 32500, Loss: 0.013019464910030365\n",
      "Epoch 3, Batch 32600, Loss: 0.02079620398581028\n",
      "Epoch 3, Batch 32700, Loss: 0.02843497321009636\n",
      "Epoch 3, Batch 32800, Loss: 0.006903293542563915\n",
      "Epoch 3, Batch 32900, Loss: 0.025387054309248924\n",
      "Epoch 3, Batch 33000, Loss: 0.024894829839468002\n",
      "Epoch 3, Batch 33100, Loss: 0.016010696068406105\n",
      "Epoch 3, Batch 33200, Loss: 0.02553936466574669\n",
      "Epoch 3, Batch 33300, Loss: 0.02069520391523838\n",
      "Epoch 3, Batch 33400, Loss: 0.021399900317192078\n",
      "Epoch 3, Batch 33500, Loss: 0.02820420078933239\n",
      "Epoch 3, Batch 33600, Loss: 0.015366953797638416\n",
      "Epoch 3, Batch 33700, Loss: 0.009604782797396183\n",
      "Epoch 3, Batch 33800, Loss: 0.013248604722321033\n",
      "Epoch 3, Batch 33900, Loss: 0.034847553819417953\n",
      "Epoch 3, Batch 34000, Loss: 0.02201058156788349\n",
      "Epoch 3, Batch 34100, Loss: 0.025200363248586655\n",
      "Epoch 3, Batch 34200, Loss: 0.01405889168381691\n",
      "Epoch 3, Batch 34300, Loss: 0.016941528767347336\n",
      "Epoch 3, Batch 34400, Loss: 0.059636641293764114\n",
      "Epoch 3, Batch 34500, Loss: 0.015524596907198429\n",
      "Epoch 3, Batch 34600, Loss: 0.025938404724001884\n",
      "Epoch 3, Batch 34700, Loss: 0.01899351365864277\n",
      "Epoch 3, Batch 34800, Loss: 0.017623960971832275\n",
      "Epoch 3, Batch 34900, Loss: 0.021223705261945724\n",
      "Epoch 3, Batch 35000, Loss: 0.019204922020435333\n",
      "Epoch 3, Batch 35100, Loss: 0.02424457296729088\n",
      "Epoch 3, Batch 35200, Loss: 0.012565072625875473\n",
      "Epoch 3, Batch 35300, Loss: 0.03076976165175438\n",
      "Epoch 3, Batch 35400, Loss: 0.051405973732471466\n",
      "Epoch 3, Batch 35500, Loss: 0.018763704225420952\n",
      "Epoch 3, Batch 35600, Loss: 0.012716510333120823\n",
      "Epoch 3, Batch 35700, Loss: 0.01902906782925129\n",
      "Epoch 3, Batch 35800, Loss: 0.019675005227327347\n",
      "Epoch 3, Batch 35900, Loss: 0.029441529884934425\n",
      "Epoch 3, Batch 36000, Loss: 0.028475552797317505\n",
      "Epoch 3, Batch 36100, Loss: 0.04293258488178253\n",
      "Epoch 3, Batch 36200, Loss: 0.015800245106220245\n",
      "Epoch 3, Batch 36300, Loss: 0.03809027746319771\n",
      "Epoch 3, Batch 36400, Loss: 0.01839180663228035\n",
      "Epoch 3, Batch 36500, Loss: 0.026872731745243073\n",
      "Epoch 3, Batch 36600, Loss: 0.013898367062211037\n",
      "Epoch 3, Batch 36700, Loss: 0.016054276376962662\n",
      "Epoch 3, Batch 36800, Loss: 0.026014110073447227\n",
      "Validation Loss: 4.055604537167549\n",
      "Epoch 4, Batch 100, Loss: 0.01595195196568966\n",
      "Epoch 4, Batch 200, Loss: 0.011986655183136463\n",
      "Epoch 4, Batch 300, Loss: 0.013439412228763103\n",
      "Epoch 4, Batch 400, Loss: 0.016319073736667633\n",
      "Epoch 4, Batch 500, Loss: 0.007685125805437565\n",
      "Epoch 4, Batch 600, Loss: 0.017356865108013153\n",
      "Epoch 4, Batch 700, Loss: 0.016642440110445023\n",
      "Epoch 4, Batch 800, Loss: 0.022896727547049522\n",
      "Epoch 4, Batch 900, Loss: 0.021495802327990532\n",
      "Epoch 4, Batch 1000, Loss: 0.014245769008994102\n",
      "Epoch 4, Batch 1100, Loss: 0.015107264742255211\n",
      "Epoch 4, Batch 1200, Loss: 0.022887779399752617\n",
      "Epoch 4, Batch 1300, Loss: 0.012190286070108414\n",
      "Epoch 4, Batch 1400, Loss: 0.028457654640078545\n",
      "Epoch 4, Batch 1500, Loss: 0.012498894706368446\n",
      "Epoch 4, Batch 1600, Loss: 0.020123664289712906\n",
      "Epoch 4, Batch 1700, Loss: 0.011409149505198002\n",
      "Epoch 4, Batch 1800, Loss: 0.03717266023159027\n",
      "Epoch 4, Batch 1900, Loss: 0.031817518174648285\n",
      "Epoch 4, Batch 2000, Loss: 0.022689856588840485\n",
      "Epoch 4, Batch 2100, Loss: 0.02053341642022133\n",
      "Epoch 4, Batch 2200, Loss: 0.01913660578429699\n",
      "Epoch 4, Batch 2300, Loss: 0.009848215617239475\n",
      "Epoch 4, Batch 2400, Loss: 0.019002793356776237\n",
      "Epoch 4, Batch 2500, Loss: 0.01557124312967062\n",
      "Epoch 4, Batch 2600, Loss: 0.022860758006572723\n",
      "Epoch 4, Batch 2700, Loss: 0.022260431200265884\n",
      "Epoch 4, Batch 2800, Loss: 0.021055569872260094\n",
      "Epoch 4, Batch 2900, Loss: 0.025412000715732574\n",
      "Epoch 4, Batch 3000, Loss: 0.010707678273320198\n",
      "Epoch 4, Batch 3100, Loss: 0.022397272288799286\n",
      "Epoch 4, Batch 3200, Loss: 0.03411795571446419\n",
      "Epoch 4, Batch 3300, Loss: 0.05199837684631348\n",
      "Epoch 4, Batch 3400, Loss: 0.025964386761188507\n",
      "Epoch 4, Batch 3500, Loss: 0.03607518970966339\n",
      "Epoch 4, Batch 3600, Loss: 0.015833314508199692\n",
      "Epoch 4, Batch 3700, Loss: 0.026708347722887993\n",
      "Epoch 4, Batch 3800, Loss: 0.016263766214251518\n",
      "Epoch 4, Batch 3900, Loss: 0.04039504751563072\n",
      "Epoch 4, Batch 4000, Loss: 0.02331882156431675\n",
      "Epoch 4, Batch 4100, Loss: 0.022525593638420105\n",
      "Epoch 4, Batch 4200, Loss: 0.018787628039717674\n",
      "Epoch 4, Batch 4300, Loss: 0.019171014428138733\n",
      "Epoch 4, Batch 4400, Loss: 0.015016532503068447\n",
      "Epoch 4, Batch 4500, Loss: 0.03675439953804016\n",
      "Epoch 4, Batch 4600, Loss: 0.03002544306218624\n",
      "Epoch 4, Batch 4700, Loss: 0.01360626146197319\n",
      "Epoch 4, Batch 4800, Loss: 0.04325198754668236\n",
      "Epoch 4, Batch 4900, Loss: 0.024527056142687798\n",
      "Epoch 4, Batch 5000, Loss: 0.020524777472019196\n",
      "Epoch 4, Batch 5100, Loss: 0.035924602299928665\n",
      "Epoch 4, Batch 5200, Loss: 0.018722616136074066\n",
      "Epoch 4, Batch 5300, Loss: 0.031020667403936386\n",
      "Epoch 4, Batch 5400, Loss: 0.019819781184196472\n",
      "Epoch 4, Batch 5500, Loss: 0.023471703752875328\n",
      "Epoch 4, Batch 5600, Loss: 0.018197542056441307\n",
      "Epoch 4, Batch 5700, Loss: 0.018545065075159073\n",
      "Epoch 4, Batch 5800, Loss: 0.015432984568178654\n",
      "Epoch 4, Batch 5900, Loss: 0.03157961741089821\n",
      "Epoch 4, Batch 6000, Loss: 0.034174393862485886\n",
      "Epoch 4, Batch 6100, Loss: 0.011050944216549397\n",
      "Epoch 4, Batch 6200, Loss: 0.01341103296726942\n",
      "Epoch 4, Batch 6300, Loss: 0.020761724561452866\n",
      "Epoch 4, Batch 6400, Loss: 0.008676601573824883\n",
      "Epoch 4, Batch 6500, Loss: 0.02865154668688774\n",
      "Epoch 4, Batch 6600, Loss: 0.01988060586154461\n",
      "Epoch 4, Batch 6700, Loss: 0.03388595208525658\n",
      "Epoch 4, Batch 6800, Loss: 0.0112982839345932\n",
      "Epoch 4, Batch 6900, Loss: 0.02240728586912155\n",
      "Epoch 4, Batch 7000, Loss: 0.01085183210670948\n",
      "Epoch 4, Batch 7100, Loss: 0.02460036613047123\n",
      "Epoch 4, Batch 7200, Loss: 0.023052409291267395\n",
      "Epoch 4, Batch 7300, Loss: 0.024234818294644356\n",
      "Epoch 4, Batch 7400, Loss: 0.049257803708314896\n",
      "Epoch 4, Batch 7500, Loss: 0.018187958747148514\n",
      "Epoch 4, Batch 7600, Loss: 0.04731680452823639\n",
      "Epoch 4, Batch 7700, Loss: 0.022941788658499718\n",
      "Epoch 4, Batch 7800, Loss: 0.023410739377141\n",
      "Epoch 4, Batch 7900, Loss: 0.0202251635491848\n",
      "Epoch 4, Batch 8000, Loss: 0.02231493405997753\n",
      "Epoch 4, Batch 8100, Loss: 0.04932761937379837\n",
      "Epoch 4, Batch 8200, Loss: 0.05429330840706825\n",
      "Epoch 4, Batch 8300, Loss: 0.014572594314813614\n",
      "Epoch 4, Batch 8400, Loss: 0.015365885570645332\n",
      "Epoch 4, Batch 8500, Loss: 0.018862171098589897\n",
      "Epoch 4, Batch 8600, Loss: 0.024385668337345123\n",
      "Epoch 4, Batch 8700, Loss: 0.03521759435534477\n",
      "Epoch 4, Batch 8800, Loss: 0.017430191859602928\n",
      "Epoch 4, Batch 8900, Loss: 0.015162115916609764\n",
      "Epoch 4, Batch 9000, Loss: 0.03368304669857025\n",
      "Epoch 4, Batch 9100, Loss: 0.034351248294115067\n",
      "Epoch 4, Batch 9200, Loss: 0.013971477746963501\n",
      "Epoch 4, Batch 9300, Loss: 0.024012820795178413\n",
      "Epoch 4, Batch 9400, Loss: 0.014700382947921753\n",
      "Epoch 4, Batch 9500, Loss: 0.04104871675372124\n",
      "Epoch 4, Batch 9600, Loss: 0.01757882907986641\n",
      "Epoch 4, Batch 9700, Loss: 0.03573451191186905\n",
      "Epoch 4, Batch 9800, Loss: 0.01916489005088806\n",
      "Epoch 4, Batch 9900, Loss: 0.023541994392871857\n",
      "Epoch 4, Batch 10000, Loss: 0.00884044449776411\n",
      "Epoch 4, Batch 10100, Loss: 0.029535187408328056\n",
      "Epoch 4, Batch 10200, Loss: 0.02476055547595024\n",
      "Epoch 4, Batch 10300, Loss: 0.029234791174530983\n",
      "Epoch 4, Batch 10400, Loss: 0.016936685889959335\n",
      "Epoch 4, Batch 10500, Loss: 0.007534951902925968\n",
      "Epoch 4, Batch 10600, Loss: 0.03290858864784241\n",
      "Epoch 4, Batch 10700, Loss: 0.012589859776198864\n",
      "Epoch 4, Batch 10800, Loss: 0.033433783799409866\n",
      "Epoch 4, Batch 10900, Loss: 0.04505603387951851\n",
      "Epoch 4, Batch 11000, Loss: 0.02918959967792034\n",
      "Epoch 4, Batch 11100, Loss: 0.011188670992851257\n",
      "Epoch 4, Batch 11200, Loss: 0.01315397024154663\n",
      "Epoch 4, Batch 11300, Loss: 0.01248795073479414\n",
      "Epoch 4, Batch 11400, Loss: 0.01727219484746456\n",
      "Epoch 4, Batch 11500, Loss: 0.016778480261564255\n",
      "Epoch 4, Batch 11600, Loss: 0.021514596417546272\n",
      "Epoch 4, Batch 11700, Loss: 0.0174415223300457\n",
      "Epoch 4, Batch 11800, Loss: 0.003218177706003189\n",
      "Epoch 4, Batch 11900, Loss: 0.02939559891819954\n",
      "Epoch 4, Batch 12000, Loss: 0.028218833729624748\n",
      "Epoch 4, Batch 12100, Loss: 0.021199729293584824\n",
      "Epoch 4, Batch 12200, Loss: 0.035585805773735046\n",
      "Epoch 4, Batch 12300, Loss: 0.027044184505939484\n",
      "Epoch 4, Batch 12400, Loss: 0.014409899711608887\n",
      "Epoch 4, Batch 12500, Loss: 0.004891017451882362\n",
      "Epoch 4, Batch 12600, Loss: 0.025478454306721687\n",
      "Epoch 4, Batch 12700, Loss: 0.019471382722258568\n",
      "Epoch 4, Batch 12800, Loss: 0.015666095539927483\n",
      "Epoch 4, Batch 12900, Loss: 0.025298744440078735\n",
      "Epoch 4, Batch 13000, Loss: 0.013624408282339573\n",
      "Epoch 4, Batch 13100, Loss: 0.02689795009791851\n",
      "Epoch 4, Batch 13200, Loss: 0.02479916252195835\n",
      "Epoch 4, Batch 13300, Loss: 0.008863966912031174\n",
      "Epoch 4, Batch 13400, Loss: 0.020104102790355682\n",
      "Epoch 4, Batch 13500, Loss: 0.014236165210604668\n",
      "Epoch 4, Batch 13600, Loss: 0.03275309130549431\n",
      "Epoch 4, Batch 13700, Loss: 0.013717829249799252\n",
      "Epoch 4, Batch 13800, Loss: 0.009001024067401886\n",
      "Epoch 4, Batch 13900, Loss: 0.030993297696113586\n",
      "Epoch 4, Batch 14000, Loss: 0.03385080769658089\n",
      "Epoch 4, Batch 14100, Loss: 0.015942106023430824\n",
      "Epoch 4, Batch 14200, Loss: 0.029182903468608856\n",
      "Epoch 4, Batch 14300, Loss: 0.02544097602367401\n",
      "Epoch 4, Batch 14400, Loss: 0.0054587433114647865\n",
      "Epoch 4, Batch 14500, Loss: 0.025461958721280098\n",
      "Epoch 4, Batch 14600, Loss: 0.022627733647823334\n",
      "Epoch 4, Batch 14700, Loss: 0.02406146377325058\n",
      "Epoch 4, Batch 14800, Loss: 0.05156930536031723\n",
      "Epoch 4, Batch 14900, Loss: 0.01648762822151184\n",
      "Epoch 4, Batch 15000, Loss: 0.015862274914979935\n",
      "Epoch 4, Batch 15100, Loss: 0.024495532736182213\n",
      "Epoch 4, Batch 15200, Loss: 0.015135492198169231\n",
      "Epoch 4, Batch 15300, Loss: 0.01806514896452427\n",
      "Epoch 4, Batch 15400, Loss: 0.024793218821287155\n",
      "Epoch 4, Batch 15500, Loss: 0.013480087742209435\n",
      "Epoch 4, Batch 15600, Loss: 0.027683567255735397\n",
      "Epoch 4, Batch 15700, Loss: 0.024818575009703636\n",
      "Epoch 4, Batch 15800, Loss: 0.043242376297712326\n",
      "Epoch 4, Batch 15900, Loss: 0.01372439693659544\n",
      "Epoch 4, Batch 16000, Loss: 0.024836841970682144\n",
      "Epoch 4, Batch 16100, Loss: 0.011412368156015873\n",
      "Epoch 4, Batch 16200, Loss: 0.009885273873806\n",
      "Epoch 4, Batch 16300, Loss: 0.039235569536685944\n",
      "Epoch 4, Batch 16400, Loss: 0.027631979435682297\n",
      "Epoch 4, Batch 16500, Loss: 0.01552467793226242\n",
      "Epoch 4, Batch 16600, Loss: 0.026265570893883705\n",
      "Epoch 4, Batch 16700, Loss: 0.037999894469976425\n",
      "Epoch 4, Batch 16800, Loss: 0.016684604808688164\n",
      "Epoch 4, Batch 16900, Loss: 0.03676813468337059\n",
      "Epoch 4, Batch 17000, Loss: 0.03386140987277031\n",
      "Epoch 4, Batch 17100, Loss: 0.020469905808568\n",
      "Epoch 4, Batch 17200, Loss: 0.012927567586302757\n",
      "Epoch 4, Batch 17300, Loss: 0.011150633916258812\n",
      "Epoch 4, Batch 17400, Loss: 0.006656259298324585\n",
      "Epoch 4, Batch 17500, Loss: 0.017051493749022484\n",
      "Epoch 4, Batch 17600, Loss: 0.02201012521982193\n",
      "Epoch 4, Batch 17700, Loss: 0.013049796223640442\n",
      "Epoch 4, Batch 17800, Loss: 0.012099552899599075\n",
      "Epoch 4, Batch 17900, Loss: 0.02963333949446678\n",
      "Epoch 4, Batch 18000, Loss: 0.01985670067369938\n",
      "Epoch 4, Batch 18100, Loss: 0.01085328683257103\n",
      "Epoch 4, Batch 18200, Loss: 0.061768729239702225\n",
      "Epoch 4, Batch 18300, Loss: 0.04482622072100639\n",
      "Epoch 4, Batch 18400, Loss: 0.02556871622800827\n",
      "Epoch 4, Batch 18500, Loss: 0.010955440811812878\n",
      "Epoch 4, Batch 18600, Loss: 0.028392110019922256\n",
      "Epoch 4, Batch 18700, Loss: 0.029711607843637466\n",
      "Epoch 4, Batch 18800, Loss: 0.01505968440324068\n",
      "Epoch 4, Batch 18900, Loss: 0.013592150062322617\n",
      "Epoch 4, Batch 19000, Loss: 0.0311881136149168\n",
      "Epoch 4, Batch 19100, Loss: 0.012797263450920582\n",
      "Epoch 4, Batch 19200, Loss: 0.008740917779505253\n",
      "Epoch 4, Batch 19300, Loss: 0.013786586932837963\n",
      "Epoch 4, Batch 19400, Loss: 0.02054508402943611\n",
      "Epoch 4, Batch 19500, Loss: 0.00989050604403019\n",
      "Epoch 4, Batch 19600, Loss: 0.02380697801709175\n",
      "Epoch 4, Batch 19700, Loss: 0.0121185053139925\n",
      "Epoch 4, Batch 19800, Loss: 0.024073459208011627\n",
      "Epoch 4, Batch 19900, Loss: 0.022650666534900665\n",
      "Epoch 4, Batch 20000, Loss: 0.04205239191651344\n",
      "Epoch 4, Batch 20100, Loss: 0.0273393876850605\n",
      "Epoch 4, Batch 20200, Loss: 0.03105604462325573\n",
      "Epoch 4, Batch 20300, Loss: 0.024594338610768318\n",
      "Epoch 4, Batch 20400, Loss: 0.0311777014285326\n",
      "Epoch 4, Batch 20500, Loss: 0.02333870157599449\n",
      "Epoch 4, Batch 20600, Loss: 0.024447401985526085\n",
      "Epoch 4, Batch 20700, Loss: 0.07635082304477692\n",
      "Epoch 4, Batch 20800, Loss: 0.013056314550340176\n",
      "Epoch 4, Batch 20900, Loss: 0.011758102104067802\n",
      "Epoch 4, Batch 21000, Loss: 0.02094472199678421\n",
      "Epoch 4, Batch 21100, Loss: 0.014451535418629646\n",
      "Epoch 4, Batch 21200, Loss: 0.04119952395558357\n",
      "Epoch 4, Batch 21300, Loss: 0.01700410433113575\n",
      "Epoch 4, Batch 21400, Loss: 0.016384171321988106\n",
      "Epoch 4, Batch 21500, Loss: 0.01443440094590187\n",
      "Epoch 4, Batch 21600, Loss: 0.023675689473748207\n",
      "Epoch 4, Batch 21700, Loss: 0.06537092477083206\n",
      "Epoch 4, Batch 21800, Loss: 0.016566229984164238\n",
      "Epoch 4, Batch 21900, Loss: 0.022977154701948166\n",
      "Epoch 4, Batch 22000, Loss: 0.013048207387328148\n",
      "Epoch 4, Batch 22100, Loss: 0.028085289523005486\n",
      "Epoch 4, Batch 22200, Loss: 0.08240380138158798\n",
      "Epoch 4, Batch 22300, Loss: 0.04097982868552208\n",
      "Epoch 4, Batch 22400, Loss: 0.02742776647210121\n",
      "Epoch 4, Batch 22500, Loss: 0.06540858000516891\n",
      "Epoch 4, Batch 22600, Loss: 0.030108071863651276\n",
      "Epoch 4, Batch 22700, Loss: 0.024686407297849655\n",
      "Epoch 4, Batch 22800, Loss: 0.023044146597385406\n",
      "Epoch 4, Batch 22900, Loss: 0.01744825392961502\n",
      "Epoch 4, Batch 23000, Loss: 0.0072956448420882225\n",
      "Epoch 4, Batch 23100, Loss: 0.014517529867589474\n",
      "Epoch 4, Batch 23200, Loss: 0.017225118353962898\n",
      "Epoch 4, Batch 23300, Loss: 0.0228569433093071\n",
      "Epoch 4, Batch 23400, Loss: 0.036044731736183167\n",
      "Epoch 4, Batch 23500, Loss: 0.007176539860665798\n",
      "Epoch 4, Batch 23600, Loss: 0.007341186050325632\n",
      "Epoch 4, Batch 23700, Loss: 0.06345926225185394\n",
      "Epoch 4, Batch 23800, Loss: 0.016312308609485626\n",
      "Epoch 4, Batch 23900, Loss: 0.01380108017474413\n",
      "Epoch 4, Batch 24000, Loss: 0.015951963141560555\n",
      "Epoch 4, Batch 24100, Loss: 0.031572505831718445\n",
      "Epoch 4, Batch 24200, Loss: 0.027873950079083443\n",
      "Epoch 4, Batch 24300, Loss: 0.023812899366021156\n",
      "Epoch 4, Batch 24400, Loss: 0.012361112050712109\n",
      "Epoch 4, Batch 24500, Loss: 0.01496038120239973\n",
      "Epoch 4, Batch 24600, Loss: 0.016571564599871635\n",
      "Epoch 4, Batch 24700, Loss: 0.03217005729675293\n",
      "Epoch 4, Batch 24800, Loss: 0.02696341462433338\n",
      "Epoch 4, Batch 24900, Loss: 0.019792987033724785\n",
      "Epoch 4, Batch 25000, Loss: 0.02009081281721592\n",
      "Epoch 4, Batch 25100, Loss: 0.02575048990547657\n",
      "Epoch 4, Batch 25200, Loss: 0.03139466047286987\n",
      "Epoch 4, Batch 25300, Loss: 0.048403821885585785\n",
      "Epoch 4, Batch 25400, Loss: 0.021344993263483047\n",
      "Epoch 4, Batch 25500, Loss: 0.03451989218592644\n",
      "Epoch 4, Batch 25600, Loss: 0.03581976145505905\n",
      "Epoch 4, Batch 25700, Loss: 0.034802354872226715\n",
      "Epoch 4, Batch 25800, Loss: 0.024936571717262268\n",
      "Epoch 4, Batch 25900, Loss: 0.03071863017976284\n",
      "Epoch 4, Batch 26000, Loss: 0.01661699265241623\n",
      "Epoch 4, Batch 26100, Loss: 0.02985604666173458\n",
      "Epoch 4, Batch 26200, Loss: 0.02472151629626751\n",
      "Epoch 4, Batch 26300, Loss: 0.021288348361849785\n",
      "Epoch 4, Batch 26400, Loss: 0.01643679104745388\n",
      "Epoch 4, Batch 26500, Loss: 0.016438061371445656\n",
      "Epoch 4, Batch 26600, Loss: 0.022517800331115723\n",
      "Epoch 4, Batch 26700, Loss: 0.002902403473854065\n",
      "Epoch 4, Batch 26800, Loss: 0.007808413356542587\n",
      "Epoch 4, Batch 26900, Loss: 0.016147403046488762\n",
      "Epoch 4, Batch 27000, Loss: 0.0060091339983046055\n",
      "Epoch 4, Batch 27100, Loss: 0.013940486125648022\n",
      "Epoch 4, Batch 27200, Loss: 0.020598571747541428\n",
      "Epoch 4, Batch 27300, Loss: 0.03332379087805748\n",
      "Epoch 4, Batch 27400, Loss: 0.02141152322292328\n",
      "Epoch 4, Batch 27500, Loss: 0.018534988164901733\n",
      "Epoch 4, Batch 27600, Loss: 0.011907700449228287\n",
      "Epoch 4, Batch 27700, Loss: 0.020125526934862137\n",
      "Epoch 4, Batch 27800, Loss: 0.03464808687567711\n",
      "Epoch 4, Batch 27900, Loss: 0.00809731986373663\n",
      "Epoch 4, Batch 28000, Loss: 0.027785658836364746\n",
      "Epoch 4, Batch 28100, Loss: 0.01390151772648096\n",
      "Epoch 4, Batch 28200, Loss: 0.03617359325289726\n",
      "Epoch 4, Batch 28300, Loss: 0.02559259720146656\n",
      "Epoch 4, Batch 28400, Loss: 0.0420127809047699\n",
      "Epoch 4, Batch 28500, Loss: 0.041512809693813324\n",
      "Epoch 4, Batch 28600, Loss: 0.021435245871543884\n",
      "Epoch 4, Batch 28700, Loss: 0.024047529324889183\n",
      "Epoch 4, Batch 28800, Loss: 0.04531991109251976\n",
      "Epoch 4, Batch 28900, Loss: 0.02229992300271988\n",
      "Epoch 4, Batch 29000, Loss: 0.03035236895084381\n",
      "Epoch 4, Batch 29100, Loss: 0.015105025842785835\n",
      "Epoch 4, Batch 29200, Loss: 0.0283706896007061\n",
      "Epoch 4, Batch 29300, Loss: 0.0215096864849329\n",
      "Epoch 4, Batch 29400, Loss: 0.034858956933021545\n",
      "Epoch 4, Batch 29500, Loss: 0.012237120419740677\n",
      "Epoch 4, Batch 29600, Loss: 0.031083913519978523\n",
      "Epoch 4, Batch 29700, Loss: 0.02884209342300892\n",
      "Epoch 4, Batch 29800, Loss: 0.028937047347426414\n",
      "Epoch 4, Batch 29900, Loss: 0.028401881456375122\n",
      "Epoch 4, Batch 30000, Loss: 0.023392606526613235\n",
      "Epoch 4, Batch 30100, Loss: 0.012893527746200562\n",
      "Epoch 4, Batch 30200, Loss: 0.00867291446775198\n",
      "Epoch 4, Batch 30300, Loss: 0.008561055175960064\n",
      "Epoch 4, Batch 30400, Loss: 0.017061373218894005\n",
      "Epoch 4, Batch 30500, Loss: 0.05801088735461235\n",
      "Epoch 4, Batch 30600, Loss: 0.007647185120731592\n",
      "Epoch 4, Batch 30700, Loss: 0.017426015809178352\n",
      "Epoch 4, Batch 30800, Loss: 0.038806311786174774\n",
      "Epoch 4, Batch 30900, Loss: 0.0513465479016304\n",
      "Epoch 4, Batch 31000, Loss: 0.010497163981199265\n",
      "Epoch 4, Batch 31100, Loss: 0.0465414859354496\n",
      "Epoch 4, Batch 31200, Loss: 0.015959082171320915\n",
      "Epoch 4, Batch 31300, Loss: 0.012852642685174942\n",
      "Epoch 4, Batch 31400, Loss: 0.03244857117533684\n",
      "Epoch 4, Batch 31500, Loss: 0.01035354658961296\n",
      "Epoch 4, Batch 31600, Loss: 0.018631869927048683\n",
      "Epoch 4, Batch 31700, Loss: 0.013775826431810856\n",
      "Epoch 4, Batch 31800, Loss: 0.02351946383714676\n",
      "Epoch 4, Batch 31900, Loss: 0.02324204333126545\n",
      "Epoch 4, Batch 32000, Loss: 0.012583711184561253\n",
      "Epoch 4, Batch 32100, Loss: 0.0612967386841774\n",
      "Epoch 4, Batch 32200, Loss: 0.04082252085208893\n",
      "Epoch 4, Batch 32300, Loss: 0.02338748425245285\n",
      "Epoch 4, Batch 32400, Loss: 0.013528218492865562\n",
      "Epoch 4, Batch 32500, Loss: 0.049695707857608795\n",
      "Epoch 4, Batch 32600, Loss: 0.005028946790844202\n",
      "Epoch 4, Batch 32700, Loss: 0.04355847090482712\n",
      "Epoch 4, Batch 32800, Loss: 0.0239640474319458\n",
      "Epoch 4, Batch 32900, Loss: 0.012302934192121029\n",
      "Epoch 4, Batch 33000, Loss: 0.0032225358299911022\n",
      "Epoch 4, Batch 33100, Loss: 0.026417475193738937\n",
      "Epoch 4, Batch 33200, Loss: 0.04043254628777504\n",
      "Epoch 4, Batch 33300, Loss: 0.021852880716323853\n",
      "Epoch 4, Batch 33400, Loss: 0.04139179736375809\n",
      "Epoch 4, Batch 33500, Loss: 0.016061048954725266\n",
      "Epoch 4, Batch 33600, Loss: 0.06897176802158356\n",
      "Epoch 4, Batch 33700, Loss: 0.022617332637310028\n",
      "Epoch 4, Batch 33800, Loss: 0.023018747568130493\n",
      "Epoch 4, Batch 33900, Loss: 0.013851291500031948\n",
      "Epoch 4, Batch 34000, Loss: 0.009671338833868504\n",
      "Epoch 4, Batch 34100, Loss: 0.03583566099405289\n",
      "Epoch 4, Batch 34200, Loss: 0.04684974253177643\n",
      "Epoch 4, Batch 34300, Loss: 0.035750579088926315\n",
      "Epoch 4, Batch 34400, Loss: 0.12338392436504364\n",
      "Epoch 4, Batch 34500, Loss: 0.008615540340542793\n",
      "Epoch 4, Batch 34600, Loss: 0.045093994587659836\n",
      "Epoch 4, Batch 34700, Loss: 0.02010614238679409\n",
      "Epoch 4, Batch 34800, Loss: 0.025697143748402596\n",
      "Epoch 4, Batch 34900, Loss: 0.0333382673561573\n",
      "Epoch 4, Batch 35000, Loss: 0.010044602677226067\n",
      "Epoch 4, Batch 35100, Loss: 0.02888377755880356\n",
      "Epoch 4, Batch 35200, Loss: 0.024588316679000854\n",
      "Epoch 4, Batch 35300, Loss: 0.03003845550119877\n",
      "Epoch 4, Batch 35400, Loss: 0.03825710341334343\n",
      "Epoch 4, Batch 35500, Loss: 0.011800468899309635\n",
      "Epoch 4, Batch 35600, Loss: 0.017671259120106697\n",
      "Epoch 4, Batch 35700, Loss: 0.023230070248246193\n",
      "Epoch 4, Batch 35800, Loss: 0.047762125730514526\n",
      "Epoch 4, Batch 35900, Loss: 0.019556988030672073\n",
      "Epoch 4, Batch 36000, Loss: 0.030350754037499428\n",
      "Epoch 4, Batch 36100, Loss: 0.02060546912252903\n",
      "Epoch 4, Batch 36200, Loss: 0.01765945553779602\n",
      "Epoch 4, Batch 36300, Loss: 0.047697193920612335\n",
      "Epoch 4, Batch 36400, Loss: 0.0358380563557148\n",
      "Epoch 4, Batch 36500, Loss: 0.030637472867965698\n",
      "Epoch 4, Batch 36600, Loss: 0.01571844518184662\n",
      "Epoch 4, Batch 36700, Loss: 0.027711890637874603\n",
      "Epoch 4, Batch 36800, Loss: 0.043559178709983826\n",
      "Validation Loss: 2.6777489565312864\n",
      "Epoch 5, Batch 100, Loss: 0.02928289771080017\n",
      "Epoch 5, Batch 200, Loss: 0.03201774135231972\n",
      "Epoch 5, Batch 300, Loss: 0.025016238912940025\n",
      "Epoch 5, Batch 400, Loss: 0.038881875574588776\n",
      "Epoch 5, Batch 500, Loss: 0.006854730192571878\n",
      "Epoch 5, Batch 600, Loss: 0.021927250549197197\n",
      "Epoch 5, Batch 700, Loss: 0.01878351718187332\n",
      "Epoch 5, Batch 800, Loss: 0.015909792855381966\n",
      "Epoch 5, Batch 900, Loss: 0.015629833564162254\n",
      "Epoch 5, Batch 1000, Loss: 0.02698318101465702\n",
      "Epoch 5, Batch 1100, Loss: 0.011957019567489624\n",
      "Epoch 5, Batch 1200, Loss: 0.012877559289336205\n",
      "Epoch 5, Batch 1300, Loss: 0.010600741021335125\n",
      "Epoch 5, Batch 1400, Loss: 0.019168108701705933\n",
      "Epoch 5, Batch 1500, Loss: 0.019583581015467644\n",
      "Epoch 5, Batch 1600, Loss: 0.015344307757914066\n",
      "Epoch 5, Batch 1700, Loss: 0.009979547001421452\n",
      "Epoch 5, Batch 1800, Loss: 0.023010291159152985\n",
      "Epoch 5, Batch 1900, Loss: 0.015791213139891624\n",
      "Epoch 5, Batch 2000, Loss: 0.02164519764482975\n",
      "Epoch 5, Batch 2100, Loss: 0.01152979489415884\n",
      "Epoch 5, Batch 2200, Loss: 0.017523346468806267\n",
      "Epoch 5, Batch 2300, Loss: 0.015352808870375156\n",
      "Epoch 5, Batch 2400, Loss: 0.012435708194971085\n",
      "Epoch 5, Batch 2500, Loss: 0.035523705184459686\n",
      "Epoch 5, Batch 2600, Loss: 0.01573023945093155\n",
      "Epoch 5, Batch 2700, Loss: 0.027849705889821053\n",
      "Epoch 5, Batch 2800, Loss: 0.009305140934884548\n",
      "Epoch 5, Batch 2900, Loss: 0.02264237217605114\n",
      "Epoch 5, Batch 3000, Loss: 0.027050800621509552\n",
      "Epoch 5, Batch 3100, Loss: 0.01932981237769127\n",
      "Epoch 5, Batch 3200, Loss: 0.01900370977818966\n",
      "Epoch 5, Batch 3300, Loss: 0.01727609895169735\n",
      "Epoch 5, Batch 3400, Loss: 0.018303116783499718\n",
      "Epoch 5, Batch 3500, Loss: 0.03918816149234772\n",
      "Epoch 5, Batch 3600, Loss: 0.025336580350995064\n",
      "Epoch 5, Batch 3700, Loss: 0.012099739164113998\n",
      "Epoch 5, Batch 3800, Loss: 0.016867803409695625\n",
      "Epoch 5, Batch 3900, Loss: 0.017997529357671738\n",
      "Epoch 5, Batch 4000, Loss: 0.04645228758454323\n",
      "Epoch 5, Batch 4100, Loss: 0.019697092473506927\n",
      "Epoch 5, Batch 4200, Loss: 0.012067913077771664\n",
      "Epoch 5, Batch 4300, Loss: 0.03333398327231407\n",
      "Epoch 5, Batch 4400, Loss: 0.015235129743814468\n",
      "Epoch 5, Batch 4500, Loss: 0.024686018005013466\n",
      "Epoch 5, Batch 4600, Loss: 0.01000330038368702\n",
      "Epoch 5, Batch 4700, Loss: 0.011812349781394005\n",
      "Epoch 5, Batch 4800, Loss: 0.04547220468521118\n",
      "Epoch 5, Batch 4900, Loss: 0.02157995104789734\n",
      "Epoch 5, Batch 5000, Loss: 0.024731673300266266\n",
      "Epoch 5, Batch 5100, Loss: 0.026474790647625923\n",
      "Epoch 5, Batch 5200, Loss: 0.021855082362890244\n",
      "Epoch 5, Batch 5300, Loss: 0.008500637486577034\n",
      "Epoch 5, Batch 5400, Loss: 0.03483200445771217\n",
      "Epoch 5, Batch 5500, Loss: 0.014504519291222095\n",
      "Epoch 5, Batch 5600, Loss: 0.005292987916618586\n",
      "Epoch 5, Batch 5700, Loss: 0.023830588907003403\n",
      "Epoch 5, Batch 5800, Loss: 0.014615683816373348\n",
      "Epoch 5, Batch 5900, Loss: 0.05144195258617401\n",
      "Epoch 5, Batch 6000, Loss: 0.012173467315733433\n",
      "Epoch 5, Batch 6100, Loss: 0.027789665386080742\n",
      "Epoch 5, Batch 6200, Loss: 0.008908562362194061\n",
      "Epoch 5, Batch 6300, Loss: 0.005900314077734947\n",
      "Epoch 5, Batch 6400, Loss: 0.02453121915459633\n",
      "Epoch 5, Batch 6500, Loss: 0.013355215080082417\n",
      "Epoch 5, Batch 6600, Loss: 0.029399488121271133\n",
      "Epoch 5, Batch 6700, Loss: 0.021555917337536812\n",
      "Epoch 5, Batch 6800, Loss: 0.02191532589495182\n",
      "Epoch 5, Batch 6900, Loss: 0.018117709085345268\n",
      "Epoch 5, Batch 7000, Loss: 0.03173127397894859\n",
      "Epoch 5, Batch 7100, Loss: 0.011836240999400616\n",
      "Epoch 5, Batch 7200, Loss: 0.033963654190301895\n",
      "Epoch 5, Batch 7300, Loss: 0.02191907912492752\n",
      "Epoch 5, Batch 7400, Loss: 0.049639299511909485\n",
      "Epoch 5, Batch 7500, Loss: 0.04261919483542442\n",
      "Epoch 5, Batch 7600, Loss: 0.021015355363488197\n",
      "Epoch 5, Batch 7700, Loss: 0.016966253519058228\n",
      "Epoch 5, Batch 7800, Loss: 0.021986521780490875\n",
      "Epoch 5, Batch 7900, Loss: 0.025454483926296234\n",
      "Epoch 5, Batch 8000, Loss: 0.06712987273931503\n",
      "Epoch 5, Batch 8100, Loss: 0.013049023225903511\n",
      "Epoch 5, Batch 8200, Loss: 0.015350292436778545\n",
      "Epoch 5, Batch 8300, Loss: 0.01396318431943655\n",
      "Epoch 5, Batch 8400, Loss: 0.015880068764090538\n",
      "Epoch 5, Batch 8500, Loss: 0.03882784768939018\n",
      "Epoch 5, Batch 8600, Loss: 0.011384254321455956\n",
      "Epoch 5, Batch 8700, Loss: 0.01780550926923752\n",
      "Epoch 5, Batch 8800, Loss: 0.054620880633592606\n",
      "Epoch 5, Batch 8900, Loss: 0.027502011507749557\n",
      "Epoch 5, Batch 9000, Loss: 0.03283333405852318\n",
      "Epoch 5, Batch 9100, Loss: 0.018487483263015747\n",
      "Epoch 5, Batch 9200, Loss: 0.017352953553199768\n",
      "Epoch 5, Batch 9300, Loss: 0.02826753258705139\n",
      "Epoch 5, Batch 9400, Loss: 0.02269291691482067\n",
      "Epoch 5, Batch 9500, Loss: 0.010023378767073154\n",
      "Epoch 5, Batch 9600, Loss: 0.02464941143989563\n",
      "Epoch 5, Batch 9700, Loss: 0.03728507459163666\n",
      "Epoch 5, Batch 9800, Loss: 0.06093668192625046\n",
      "Epoch 5, Batch 9900, Loss: 0.021930398419499397\n",
      "Epoch 5, Batch 10000, Loss: 0.028599441051483154\n",
      "Epoch 5, Batch 10100, Loss: 0.029756655916571617\n",
      "Epoch 5, Batch 10200, Loss: 0.037239920347929\n",
      "Epoch 5, Batch 10300, Loss: 0.018482359126210213\n",
      "Epoch 5, Batch 10400, Loss: 0.027492783963680267\n",
      "Epoch 5, Batch 10500, Loss: 0.017052961513400078\n",
      "Epoch 5, Batch 10600, Loss: 0.021689405664801598\n",
      "Epoch 5, Batch 10700, Loss: 0.03729017823934555\n",
      "Epoch 5, Batch 10800, Loss: 0.02529769390821457\n",
      "Epoch 5, Batch 10900, Loss: 0.046419233083724976\n",
      "Epoch 5, Batch 11000, Loss: 0.046735234558582306\n",
      "Epoch 5, Batch 11100, Loss: 0.05251097306609154\n",
      "Epoch 5, Batch 11200, Loss: 0.010900015011429787\n",
      "Epoch 5, Batch 11300, Loss: 0.012464557774364948\n",
      "Epoch 5, Batch 11400, Loss: 0.038988057523965836\n",
      "Epoch 5, Batch 11500, Loss: 0.02531171590089798\n",
      "Epoch 5, Batch 11600, Loss: 0.00834445096552372\n",
      "Epoch 5, Batch 11700, Loss: 0.017912210896611214\n",
      "Epoch 5, Batch 11800, Loss: 0.022227594628930092\n",
      "Epoch 5, Batch 11900, Loss: 0.023988496512174606\n",
      "Epoch 5, Batch 12000, Loss: 0.04200182110071182\n",
      "Epoch 5, Batch 12100, Loss: 0.045254312455654144\n",
      "Epoch 5, Batch 12200, Loss: 0.02641817182302475\n",
      "Epoch 5, Batch 12300, Loss: 0.02566850557923317\n",
      "Epoch 5, Batch 12400, Loss: 0.018315406516194344\n",
      "Epoch 5, Batch 12500, Loss: 0.027516847476363182\n",
      "Epoch 5, Batch 12600, Loss: 0.0287290271371603\n",
      "Epoch 5, Batch 12700, Loss: 0.050280503928661346\n",
      "Epoch 5, Batch 12800, Loss: 0.02591067925095558\n",
      "Epoch 5, Batch 12900, Loss: 0.03490247577428818\n",
      "Epoch 5, Batch 13000, Loss: 0.020674681290984154\n",
      "Epoch 5, Batch 13100, Loss: 0.03246219828724861\n",
      "Epoch 5, Batch 13200, Loss: 0.02228178270161152\n",
      "Epoch 5, Batch 13300, Loss: 0.0442313626408577\n",
      "Epoch 5, Batch 13400, Loss: 0.030889498069882393\n",
      "Epoch 5, Batch 13500, Loss: 0.02972140535712242\n",
      "Epoch 5, Batch 13600, Loss: 0.0308242104947567\n",
      "Epoch 5, Batch 13700, Loss: 0.0367528535425663\n",
      "Epoch 5, Batch 13800, Loss: 0.033898141235113144\n",
      "Epoch 5, Batch 13900, Loss: 0.07402627170085907\n",
      "Epoch 5, Batch 14000, Loss: 0.033648163080215454\n",
      "Epoch 5, Batch 14100, Loss: 0.01903178170323372\n",
      "Epoch 5, Batch 14200, Loss: 0.03490355238318443\n",
      "Epoch 5, Batch 14300, Loss: 0.014548646286129951\n",
      "Epoch 5, Batch 14400, Loss: 0.03866923972964287\n",
      "Epoch 5, Batch 14500, Loss: 0.018610112369060516\n",
      "Epoch 5, Batch 14600, Loss: 0.049702927470207214\n",
      "Epoch 5, Batch 14700, Loss: 0.022024331614375114\n",
      "Epoch 5, Batch 14800, Loss: 0.040903229266405106\n",
      "Epoch 5, Batch 14900, Loss: 0.027606893330812454\n",
      "Epoch 5, Batch 15000, Loss: 0.023936869576573372\n",
      "Epoch 5, Batch 15100, Loss: 0.026153508573770523\n",
      "Epoch 5, Batch 15200, Loss: 0.05546322092413902\n",
      "Epoch 5, Batch 15300, Loss: 0.014196380041539669\n",
      "Epoch 5, Batch 15400, Loss: 0.0224091075360775\n",
      "Epoch 5, Batch 15500, Loss: 0.01780719868838787\n",
      "Epoch 5, Batch 15600, Loss: 0.009420708753168583\n",
      "Epoch 5, Batch 15700, Loss: 0.020237809047102928\n",
      "Epoch 5, Batch 15800, Loss: 0.022223839536309242\n",
      "Epoch 5, Batch 15900, Loss: 0.025070341303944588\n",
      "Epoch 5, Batch 16000, Loss: 0.020594965666532516\n",
      "Epoch 5, Batch 16100, Loss: 0.030514387413859367\n",
      "Epoch 5, Batch 16200, Loss: 0.026605866849422455\n",
      "Epoch 5, Batch 16300, Loss: 0.0756048783659935\n",
      "Epoch 5, Batch 16400, Loss: 0.03828820213675499\n",
      "Epoch 5, Batch 16500, Loss: 0.03338691219687462\n",
      "Epoch 5, Batch 16600, Loss: 0.05451473966240883\n",
      "Epoch 5, Batch 16700, Loss: 0.027851181104779243\n",
      "Epoch 5, Batch 16800, Loss: 0.02099515311419964\n",
      "Epoch 5, Batch 16900, Loss: 0.02435184456408024\n",
      "Epoch 5, Batch 17000, Loss: 0.016558561474084854\n",
      "Epoch 5, Batch 17100, Loss: 0.012304001487791538\n",
      "Epoch 5, Batch 17200, Loss: 0.01488049142062664\n",
      "Epoch 5, Batch 17300, Loss: 0.028893254697322845\n",
      "Epoch 5, Batch 17400, Loss: 0.028659507632255554\n",
      "Epoch 5, Batch 17500, Loss: 0.02403263933956623\n",
      "Epoch 5, Batch 17600, Loss: 0.017789319157600403\n",
      "Epoch 5, Batch 17700, Loss: 0.02674473635852337\n",
      "Epoch 5, Batch 17800, Loss: 0.01862749643623829\n",
      "Epoch 5, Batch 17900, Loss: 0.011804348789155483\n",
      "Epoch 5, Batch 18000, Loss: 0.04523424431681633\n",
      "Epoch 5, Batch 18100, Loss: 0.027347328141331673\n",
      "Epoch 5, Batch 18200, Loss: 0.028553431853652\n",
      "Epoch 5, Batch 18300, Loss: 0.04158378764986992\n",
      "Epoch 5, Batch 18400, Loss: 0.013257403858006\n",
      "Epoch 5, Batch 18500, Loss: 0.013244942761957645\n",
      "Epoch 5, Batch 18600, Loss: 0.023204751312732697\n",
      "Epoch 5, Batch 18700, Loss: 0.016519641503691673\n",
      "Epoch 5, Batch 18800, Loss: 0.022493401542305946\n",
      "Epoch 5, Batch 18900, Loss: 0.03838951885700226\n",
      "Epoch 5, Batch 19000, Loss: 0.02171277441084385\n",
      "Epoch 5, Batch 19100, Loss: 0.020796244964003563\n",
      "Epoch 5, Batch 19200, Loss: 0.0222270879894495\n",
      "Epoch 5, Batch 19300, Loss: 0.016311146318912506\n",
      "Epoch 5, Batch 19400, Loss: 0.02982155606150627\n",
      "Epoch 5, Batch 19500, Loss: 0.005373424384742975\n",
      "Epoch 5, Batch 19600, Loss: 0.016740545630455017\n",
      "Epoch 5, Batch 19700, Loss: 0.030374502763152122\n",
      "Epoch 5, Batch 19800, Loss: 0.014362746849656105\n",
      "Epoch 5, Batch 19900, Loss: 0.025036141276359558\n",
      "Epoch 5, Batch 20000, Loss: 0.04345248267054558\n",
      "Epoch 5, Batch 20100, Loss: 0.04559221491217613\n",
      "Epoch 5, Batch 20200, Loss: 0.03332648426294327\n",
      "Epoch 5, Batch 20300, Loss: 0.026238657534122467\n",
      "Epoch 5, Batch 20400, Loss: 0.023851631209254265\n",
      "Epoch 5, Batch 20500, Loss: 0.018901845440268517\n",
      "Epoch 5, Batch 20600, Loss: 0.041112303733825684\n",
      "Epoch 5, Batch 20700, Loss: 0.04500391706824303\n",
      "Epoch 5, Batch 20800, Loss: 0.016093317419290543\n",
      "Epoch 5, Batch 20900, Loss: 0.01035314705222845\n",
      "Epoch 5, Batch 21000, Loss: 0.025861568748950958\n",
      "Epoch 5, Batch 21100, Loss: 0.005407040473073721\n",
      "Epoch 5, Batch 21200, Loss: 0.017213547602295876\n",
      "Epoch 5, Batch 21300, Loss: 0.008804150857031345\n",
      "Epoch 5, Batch 21400, Loss: 0.0290511604398489\n",
      "Epoch 5, Batch 21500, Loss: 0.036284469068050385\n",
      "Epoch 5, Batch 21600, Loss: 0.027685845270752907\n",
      "Epoch 5, Batch 21700, Loss: 0.01684412732720375\n",
      "Epoch 5, Batch 21800, Loss: 0.01880773901939392\n",
      "Epoch 5, Batch 21900, Loss: 0.03422640264034271\n",
      "Epoch 5, Batch 22000, Loss: 0.01387475710362196\n",
      "Epoch 5, Batch 22100, Loss: 0.02079063467681408\n",
      "Epoch 5, Batch 22200, Loss: 0.023037288337945938\n",
      "Epoch 5, Batch 22300, Loss: 0.022935714572668076\n",
      "Epoch 5, Batch 22400, Loss: 0.01809820532798767\n",
      "Epoch 5, Batch 22500, Loss: 0.013095492497086525\n",
      "Epoch 5, Batch 22600, Loss: 0.01035781018435955\n",
      "Epoch 5, Batch 22700, Loss: 0.04630040004849434\n",
      "Epoch 5, Batch 22800, Loss: 0.027278104797005653\n",
      "Epoch 5, Batch 22900, Loss: 0.029007159173488617\n",
      "Epoch 5, Batch 23000, Loss: 0.02754022181034088\n",
      "Epoch 5, Batch 23100, Loss: 0.012660104781389236\n",
      "Epoch 5, Batch 23200, Loss: 0.008347753435373306\n",
      "Epoch 5, Batch 23300, Loss: 0.02206805720925331\n",
      "Epoch 5, Batch 23400, Loss: 0.012375633232295513\n",
      "Epoch 5, Batch 23500, Loss: 0.015687264502048492\n",
      "Epoch 5, Batch 23600, Loss: 0.04665282741189003\n",
      "Epoch 5, Batch 23700, Loss: 0.021684588864445686\n",
      "Epoch 5, Batch 23800, Loss: 0.01888556033372879\n",
      "Epoch 5, Batch 23900, Loss: 0.022100668400526047\n",
      "Epoch 5, Batch 24000, Loss: 0.011736149899661541\n",
      "Epoch 5, Batch 24100, Loss: 0.017884910106658936\n",
      "Epoch 5, Batch 24200, Loss: 0.015585272572934628\n",
      "Epoch 5, Batch 24300, Loss: 0.0664447620511055\n",
      "Epoch 5, Batch 24400, Loss: 0.016972990706562996\n",
      "Epoch 5, Batch 24500, Loss: 0.009070676751434803\n",
      "Epoch 5, Batch 24600, Loss: 0.01980682834982872\n",
      "Epoch 5, Batch 24700, Loss: 0.007621906232088804\n",
      "Epoch 5, Batch 24800, Loss: 0.044191185384988785\n",
      "Epoch 5, Batch 24900, Loss: 0.02820288948714733\n",
      "Epoch 5, Batch 25000, Loss: 0.03181386739015579\n",
      "Epoch 5, Batch 25100, Loss: 0.03247005492448807\n",
      "Epoch 5, Batch 25200, Loss: 0.043459340929985046\n",
      "Epoch 5, Batch 25300, Loss: 0.010247303172945976\n",
      "Epoch 5, Batch 25400, Loss: 0.03618449345231056\n",
      "Epoch 5, Batch 25500, Loss: 0.018626084551215172\n",
      "Epoch 5, Batch 25600, Loss: 0.027855580672621727\n",
      "Epoch 5, Batch 25700, Loss: 0.008330616168677807\n",
      "Epoch 5, Batch 25800, Loss: 0.01307738572359085\n",
      "Epoch 5, Batch 25900, Loss: 0.03165016323328018\n",
      "Epoch 5, Batch 26000, Loss: 0.018028564751148224\n",
      "Epoch 5, Batch 26100, Loss: 0.007516493089497089\n",
      "Epoch 5, Batch 26200, Loss: 0.025037288665771484\n",
      "Epoch 5, Batch 26300, Loss: 0.03119778260588646\n",
      "Epoch 5, Batch 26400, Loss: 0.024449050426483154\n",
      "Epoch 5, Batch 26500, Loss: 0.019040774554014206\n",
      "Epoch 5, Batch 26600, Loss: 0.025093182921409607\n",
      "Epoch 5, Batch 26700, Loss: 0.009963639080524445\n",
      "Epoch 5, Batch 26800, Loss: 0.016359154134988785\n",
      "Epoch 5, Batch 26900, Loss: 0.01988789066672325\n",
      "Epoch 5, Batch 27000, Loss: 0.017057571560144424\n",
      "Epoch 5, Batch 27100, Loss: 0.032381847500801086\n",
      "Epoch 5, Batch 27200, Loss: 0.05543523654341698\n",
      "Epoch 5, Batch 27300, Loss: 0.027516862377524376\n",
      "Epoch 5, Batch 27400, Loss: 0.018512021750211716\n",
      "Epoch 5, Batch 27500, Loss: 0.022607753053307533\n",
      "Epoch 5, Batch 27600, Loss: 0.07371316850185394\n",
      "Epoch 5, Batch 27700, Loss: 0.025511514395475388\n",
      "Epoch 5, Batch 27800, Loss: 0.03619331121444702\n",
      "Epoch 5, Batch 27900, Loss: 0.016733814030885696\n",
      "Epoch 5, Batch 28000, Loss: 0.030471039935946465\n",
      "Epoch 5, Batch 28100, Loss: 0.022151900455355644\n",
      "Epoch 5, Batch 28200, Loss: 0.03382948040962219\n",
      "Epoch 5, Batch 28300, Loss: 0.025759965181350708\n",
      "Epoch 5, Batch 28400, Loss: 0.013430777937173843\n",
      "Epoch 5, Batch 28500, Loss: 0.06975378096103668\n",
      "Epoch 5, Batch 28600, Loss: 0.0244431272149086\n",
      "Epoch 5, Batch 28700, Loss: 0.07061029225587845\n",
      "Epoch 5, Batch 28800, Loss: 0.019432464614510536\n",
      "Epoch 5, Batch 28900, Loss: 0.043074604123830795\n",
      "Epoch 5, Batch 29000, Loss: 0.021878302097320557\n",
      "Epoch 5, Batch 29100, Loss: 0.01111025083810091\n",
      "Epoch 5, Batch 29200, Loss: 0.03068746067583561\n",
      "Epoch 5, Batch 29300, Loss: 0.03063875250518322\n",
      "Epoch 5, Batch 29400, Loss: 0.017857100814580917\n",
      "Epoch 5, Batch 29500, Loss: 0.01413772813975811\n",
      "Epoch 5, Batch 29600, Loss: 0.037940382957458496\n",
      "Epoch 5, Batch 29700, Loss: 0.040224164724349976\n",
      "Epoch 5, Batch 29800, Loss: 0.020067116245627403\n",
      "Epoch 5, Batch 29900, Loss: 0.020698754116892815\n",
      "Epoch 5, Batch 30000, Loss: 0.014251970686018467\n",
      "Epoch 5, Batch 30100, Loss: 0.01785953901708126\n",
      "Epoch 5, Batch 30200, Loss: 0.021861979737877846\n",
      "Epoch 5, Batch 30300, Loss: 0.02965673804283142\n",
      "Epoch 5, Batch 30400, Loss: 0.030474944040179253\n",
      "Epoch 5, Batch 30500, Loss: 0.030012251809239388\n",
      "Epoch 5, Batch 30600, Loss: 0.05446192994713783\n",
      "Epoch 5, Batch 30700, Loss: 0.0539683997631073\n",
      "Epoch 5, Batch 30800, Loss: 0.01827906258404255\n",
      "Epoch 5, Batch 30900, Loss: 0.013266188092529774\n",
      "Epoch 5, Batch 31000, Loss: 0.0308272372931242\n",
      "Epoch 5, Batch 31100, Loss: 0.023245861753821373\n",
      "Epoch 5, Batch 31200, Loss: 0.013202492147684097\n",
      "Epoch 5, Batch 31300, Loss: 0.10667048394680023\n",
      "Epoch 5, Batch 31400, Loss: 0.017076708376407623\n",
      "Epoch 5, Batch 31500, Loss: 0.025718223303556442\n",
      "Epoch 5, Batch 31600, Loss: 0.021339725703001022\n",
      "Epoch 5, Batch 31700, Loss: 0.023730609565973282\n",
      "Epoch 5, Batch 31800, Loss: 0.041475024074316025\n",
      "Epoch 5, Batch 31900, Loss: 0.014664391055703163\n",
      "Epoch 5, Batch 32000, Loss: 0.023254038766026497\n",
      "Epoch 5, Batch 32100, Loss: 0.05426816642284393\n",
      "Epoch 5, Batch 32200, Loss: 0.030150387436151505\n",
      "Epoch 5, Batch 32300, Loss: 0.013754956424236298\n",
      "Epoch 5, Batch 32400, Loss: 0.01781083457171917\n",
      "Epoch 5, Batch 32500, Loss: 0.019918784499168396\n",
      "Epoch 5, Batch 32600, Loss: 0.02069251611828804\n",
      "Epoch 5, Batch 32700, Loss: 0.0939188152551651\n",
      "Epoch 5, Batch 32800, Loss: 0.08560983836650848\n",
      "Epoch 5, Batch 32900, Loss: 0.011277069337666035\n",
      "Epoch 5, Batch 33000, Loss: 0.016337450593709946\n",
      "Epoch 5, Batch 33100, Loss: 0.03351929411292076\n",
      "Epoch 5, Batch 33200, Loss: 0.009951071813702583\n",
      "Epoch 5, Batch 33300, Loss: 0.032549530267715454\n",
      "Epoch 5, Batch 33400, Loss: 0.020735206082463264\n",
      "Epoch 5, Batch 33500, Loss: 0.031349875032901764\n",
      "Epoch 5, Batch 33600, Loss: 0.020996836945414543\n",
      "Epoch 5, Batch 33700, Loss: 0.03198230639100075\n",
      "Epoch 5, Batch 33800, Loss: 0.01967475563287735\n",
      "Epoch 5, Batch 33900, Loss: 0.02658797614276409\n",
      "Epoch 5, Batch 34000, Loss: 0.014936961233615875\n",
      "Epoch 5, Batch 34100, Loss: 0.029044976457953453\n",
      "Epoch 5, Batch 34200, Loss: 0.008578955195844173\n",
      "Epoch 5, Batch 34300, Loss: 0.01934020407497883\n",
      "Epoch 5, Batch 34400, Loss: 0.044035304337739944\n",
      "Epoch 5, Batch 34500, Loss: 0.01788979023694992\n",
      "Epoch 5, Batch 34600, Loss: 0.025197913870215416\n",
      "Epoch 5, Batch 34700, Loss: 0.013816005550324917\n",
      "Epoch 5, Batch 34800, Loss: 0.010332767851650715\n",
      "Epoch 5, Batch 34900, Loss: 0.04785488545894623\n",
      "Epoch 5, Batch 35000, Loss: 0.023114513605833054\n",
      "Epoch 5, Batch 35100, Loss: 0.02135254628956318\n",
      "Epoch 5, Batch 35200, Loss: 0.03418460860848427\n",
      "Epoch 5, Batch 35300, Loss: 0.01560771744698286\n",
      "Epoch 5, Batch 35400, Loss: 0.007510615512728691\n",
      "Epoch 5, Batch 35500, Loss: 0.01381006557494402\n",
      "Epoch 5, Batch 35600, Loss: 0.020362060517072678\n",
      "Epoch 5, Batch 35700, Loss: 0.013131782412528992\n",
      "Epoch 5, Batch 35800, Loss: 0.0621032640337944\n",
      "Epoch 5, Batch 35900, Loss: 0.012266496196389198\n",
      "Epoch 5, Batch 36000, Loss: 0.04307197034358978\n",
      "Epoch 5, Batch 36100, Loss: 0.018729843199253082\n",
      "Epoch 5, Batch 36200, Loss: 0.014330428093671799\n",
      "Epoch 5, Batch 36300, Loss: 0.12950265407562256\n",
      "Epoch 5, Batch 36400, Loss: 0.027559593319892883\n",
      "Epoch 5, Batch 36500, Loss: 0.022655293345451355\n",
      "Epoch 5, Batch 36600, Loss: 0.006876114755868912\n",
      "Epoch 5, Batch 36700, Loss: 0.030061708763241768\n",
      "Epoch 5, Batch 36800, Loss: 0.02705048955976963\n",
      "Validation Loss: 2.894422938579321\n",
      "Epoch 6, Batch 100, Loss: 0.024603769183158875\n",
      "Epoch 6, Batch 200, Loss: 0.04291130602359772\n",
      "Epoch 6, Batch 300, Loss: 0.0159563310444355\n",
      "Epoch 6, Batch 400, Loss: 0.01659618690609932\n",
      "Epoch 6, Batch 500, Loss: 0.04473253712058067\n",
      "Epoch 6, Batch 600, Loss: 0.009966310113668442\n",
      "Epoch 6, Batch 700, Loss: 0.019970176741480827\n",
      "Epoch 6, Batch 800, Loss: 0.02831198088824749\n",
      "Epoch 6, Batch 900, Loss: 0.01405270490795374\n",
      "Epoch 6, Batch 1000, Loss: 0.03227746859192848\n",
      "Epoch 6, Batch 1100, Loss: 0.016883637756109238\n",
      "Epoch 6, Batch 1200, Loss: 0.029484204947948456\n",
      "Epoch 6, Batch 1300, Loss: 0.022205587476491928\n",
      "Epoch 6, Batch 1400, Loss: 0.012804771773517132\n",
      "Epoch 6, Batch 1500, Loss: 0.03343551233410835\n",
      "Epoch 6, Batch 1600, Loss: 0.012144952081143856\n",
      "Epoch 6, Batch 1700, Loss: 0.03771137073636055\n",
      "Epoch 6, Batch 1800, Loss: 0.01883985847234726\n",
      "Epoch 6, Batch 1900, Loss: 0.04607532173395157\n",
      "Epoch 6, Batch 2000, Loss: 0.03049967624247074\n",
      "Epoch 6, Batch 2100, Loss: 0.014362477697432041\n",
      "Epoch 6, Batch 2200, Loss: 0.022447675466537476\n",
      "Epoch 6, Batch 2300, Loss: 0.04281100630760193\n",
      "Epoch 6, Batch 2400, Loss: 0.018740706145763397\n",
      "Epoch 6, Batch 2500, Loss: 0.014692593365907669\n",
      "Epoch 6, Batch 2600, Loss: 0.018580744042992592\n",
      "Epoch 6, Batch 2700, Loss: 0.03111538663506508\n",
      "Epoch 6, Batch 2800, Loss: 0.027292024344205856\n",
      "Epoch 6, Batch 2900, Loss: 0.003487634938210249\n",
      "Epoch 6, Batch 3000, Loss: 0.025076547637581825\n",
      "Epoch 6, Batch 3100, Loss: 0.01153021864593029\n",
      "Epoch 6, Batch 3200, Loss: 0.016815077513456345\n",
      "Epoch 6, Batch 3300, Loss: 0.009289363399147987\n",
      "Epoch 6, Batch 3400, Loss: 0.018263014033436775\n",
      "Epoch 6, Batch 3500, Loss: 0.02683538757264614\n",
      "Epoch 6, Batch 3600, Loss: 0.01878204569220543\n",
      "Epoch 6, Batch 3700, Loss: 0.04147914797067642\n",
      "Epoch 6, Batch 3800, Loss: 0.009139463305473328\n",
      "Epoch 6, Batch 3900, Loss: 0.007625366561114788\n",
      "Epoch 6, Batch 4000, Loss: 0.027817318215966225\n",
      "Epoch 6, Batch 4100, Loss: 0.023197423666715622\n",
      "Epoch 6, Batch 4200, Loss: 0.014688407070934772\n",
      "Epoch 6, Batch 4300, Loss: 0.01322813332080841\n",
      "Epoch 6, Batch 4400, Loss: 0.02671867422759533\n",
      "Epoch 6, Batch 4500, Loss: 0.019307255744934082\n",
      "Epoch 6, Batch 4600, Loss: 0.024625040590763092\n",
      "Epoch 6, Batch 4700, Loss: 0.02150297909975052\n",
      "Epoch 6, Batch 4800, Loss: 0.030218537896871567\n",
      "Epoch 6, Batch 4900, Loss: 0.030543284490704536\n",
      "Epoch 6, Batch 5000, Loss: 0.034507524222135544\n",
      "Epoch 6, Batch 5100, Loss: 0.06240503489971161\n",
      "Epoch 6, Batch 5200, Loss: 0.019079536199569702\n",
      "Epoch 6, Batch 5300, Loss: 0.019081829115748405\n",
      "Epoch 6, Batch 5400, Loss: 0.007152883801609278\n",
      "Epoch 6, Batch 5500, Loss: 0.009538596495985985\n",
      "Epoch 6, Batch 5600, Loss: 0.03604135289788246\n",
      "Epoch 6, Batch 5700, Loss: 0.009682569652795792\n",
      "Epoch 6, Batch 5800, Loss: 0.013821220956742764\n",
      "Epoch 6, Batch 5900, Loss: 0.024196669459342957\n",
      "Epoch 6, Batch 6000, Loss: 0.012717816978693008\n",
      "Epoch 6, Batch 6100, Loss: 0.02529667131602764\n",
      "Epoch 6, Batch 6200, Loss: 0.019175009801983833\n",
      "Epoch 6, Batch 6300, Loss: 0.030028264969587326\n",
      "Epoch 6, Batch 6400, Loss: 0.023403825238347054\n",
      "Epoch 6, Batch 6500, Loss: 0.009931324981153011\n",
      "Epoch 6, Batch 6600, Loss: 0.0144883431494236\n",
      "Epoch 6, Batch 6700, Loss: 0.02037469670176506\n",
      "Epoch 6, Batch 6800, Loss: 0.025221122428774834\n",
      "Epoch 6, Batch 6900, Loss: 0.018623948097229004\n",
      "Epoch 6, Batch 7000, Loss: 0.019018590450286865\n",
      "Epoch 6, Batch 7100, Loss: 0.03642710670828819\n",
      "Epoch 6, Batch 7200, Loss: 0.029924070462584496\n",
      "Epoch 6, Batch 7300, Loss: 0.025837620720267296\n",
      "Epoch 6, Batch 7400, Loss: 0.04018167406320572\n",
      "Epoch 6, Batch 7500, Loss: 0.010734755545854568\n",
      "Epoch 6, Batch 7600, Loss: 0.039195798337459564\n",
      "Epoch 6, Batch 7700, Loss: 0.01226646639406681\n",
      "Epoch 6, Batch 7800, Loss: 0.03747494891285896\n",
      "Epoch 6, Batch 7900, Loss: 0.011576724238693714\n",
      "Epoch 6, Batch 8000, Loss: 0.03211843594908714\n",
      "Epoch 6, Batch 8100, Loss: 0.017444351688027382\n",
      "Epoch 6, Batch 8200, Loss: 0.015872932970523834\n",
      "Epoch 6, Batch 8300, Loss: 0.0357825830578804\n",
      "Epoch 6, Batch 8400, Loss: 0.023950237780809402\n",
      "Epoch 6, Batch 8500, Loss: 0.002688345033675432\n",
      "Epoch 6, Batch 8600, Loss: 0.01389326248317957\n",
      "Epoch 6, Batch 8700, Loss: 0.01838994026184082\n",
      "Epoch 6, Batch 8800, Loss: 0.03560427576303482\n",
      "Epoch 6, Batch 8900, Loss: 0.02031129226088524\n",
      "Epoch 6, Batch 9000, Loss: 0.0055394829250872135\n",
      "Epoch 6, Batch 9100, Loss: 0.05360547453165054\n",
      "Epoch 6, Batch 9200, Loss: 0.024057261645793915\n",
      "Epoch 6, Batch 9300, Loss: 0.05239935219287872\n",
      "Epoch 6, Batch 9400, Loss: 0.019873840734362602\n",
      "Epoch 6, Batch 9500, Loss: 0.04043561592698097\n",
      "Epoch 6, Batch 9600, Loss: 0.03311210125684738\n",
      "Epoch 6, Batch 9700, Loss: 0.018036553636193275\n",
      "Epoch 6, Batch 9800, Loss: 0.024974076077342033\n",
      "Epoch 6, Batch 9900, Loss: 0.028037669137120247\n",
      "Epoch 6, Batch 10000, Loss: 0.008516720496118069\n",
      "Epoch 6, Batch 10100, Loss: 0.010543715208768845\n",
      "Epoch 6, Batch 10200, Loss: 0.04034920036792755\n",
      "Epoch 6, Batch 10300, Loss: 0.02419297955930233\n",
      "Epoch 6, Batch 10400, Loss: 0.028658119961619377\n",
      "Epoch 6, Batch 10500, Loss: 0.05557043477892876\n",
      "Epoch 6, Batch 10600, Loss: 0.014204613864421844\n",
      "Epoch 6, Batch 10700, Loss: 0.044595204293727875\n",
      "Epoch 6, Batch 10800, Loss: 0.013247048482298851\n",
      "Epoch 6, Batch 10900, Loss: 0.06195404380559921\n",
      "Epoch 6, Batch 11000, Loss: 0.022035742178559303\n",
      "Epoch 6, Batch 11100, Loss: 0.017931487411260605\n",
      "Epoch 6, Batch 11200, Loss: 0.03991769254207611\n",
      "Epoch 6, Batch 11300, Loss: 0.02373848855495453\n",
      "Epoch 6, Batch 11400, Loss: 0.024758385494351387\n",
      "Epoch 6, Batch 11500, Loss: 0.04211388900876045\n",
      "Epoch 6, Batch 11600, Loss: 0.02326982095837593\n",
      "Epoch 6, Batch 11700, Loss: 0.05260775610804558\n",
      "Epoch 6, Batch 11800, Loss: 0.017156453803181648\n",
      "Epoch 6, Batch 11900, Loss: 0.02551579661667347\n",
      "Epoch 6, Batch 12000, Loss: 0.021056899800896645\n",
      "Epoch 6, Batch 12100, Loss: 0.02884795516729355\n",
      "Epoch 6, Batch 12200, Loss: 0.04143347963690758\n",
      "Epoch 6, Batch 12300, Loss: 0.027891764417290688\n",
      "Epoch 6, Batch 12400, Loss: 0.013616434298455715\n",
      "Epoch 6, Batch 12500, Loss: 0.016168519854545593\n",
      "Epoch 6, Batch 12600, Loss: 0.015427691861987114\n",
      "Epoch 6, Batch 12700, Loss: 0.025381052866578102\n",
      "Epoch 6, Batch 12800, Loss: 0.01477221492677927\n",
      "Epoch 6, Batch 12900, Loss: 0.03699609264731407\n",
      "Epoch 6, Batch 13000, Loss: 0.03407614678144455\n",
      "Epoch 6, Batch 13100, Loss: 0.022243106737732887\n",
      "Epoch 6, Batch 13200, Loss: 0.02814950793981552\n",
      "Epoch 6, Batch 13300, Loss: 0.010626585222780704\n",
      "Epoch 6, Batch 13400, Loss: 0.01763063296675682\n",
      "Epoch 6, Batch 13500, Loss: 0.020921172574162483\n",
      "Epoch 6, Batch 13600, Loss: 0.014697790145874023\n",
      "Epoch 6, Batch 13700, Loss: 0.019081775099039078\n",
      "Epoch 6, Batch 13800, Loss: 0.025141684338450432\n",
      "Epoch 6, Batch 13900, Loss: 0.038319043815135956\n",
      "Epoch 6, Batch 14000, Loss: 0.01283024251461029\n",
      "Epoch 6, Batch 14100, Loss: 0.024643750861287117\n",
      "Epoch 6, Batch 14200, Loss: 0.044497523456811905\n",
      "Epoch 6, Batch 14300, Loss: 0.03411272540688515\n",
      "Epoch 6, Batch 14400, Loss: 0.018231188878417015\n",
      "Epoch 6, Batch 14500, Loss: 0.04367629066109657\n",
      "Epoch 6, Batch 14600, Loss: 0.027698714286088943\n",
      "Epoch 6, Batch 14700, Loss: 0.02111893892288208\n",
      "Epoch 6, Batch 14800, Loss: 0.01190943457186222\n",
      "Epoch 6, Batch 14900, Loss: 0.03166775405406952\n",
      "Epoch 6, Batch 15000, Loss: 0.025420431047677994\n",
      "Epoch 6, Batch 15100, Loss: 0.02404443919658661\n",
      "Epoch 6, Batch 15200, Loss: 0.01179772149771452\n",
      "Epoch 6, Batch 15300, Loss: 0.012681160122156143\n",
      "Epoch 6, Batch 15400, Loss: 0.012744171544909477\n",
      "Epoch 6, Batch 15500, Loss: 0.027523839846253395\n",
      "Epoch 6, Batch 15600, Loss: 0.023082345724105835\n",
      "Epoch 6, Batch 15700, Loss: 0.04963693022727966\n",
      "Epoch 6, Batch 15800, Loss: 0.022693833336234093\n",
      "Epoch 6, Batch 15900, Loss: 0.020101800560951233\n",
      "Epoch 6, Batch 16000, Loss: 0.03471781685948372\n",
      "Epoch 6, Batch 16100, Loss: 0.0076234289444983006\n",
      "Epoch 6, Batch 16200, Loss: 0.060522209852933884\n",
      "Epoch 6, Batch 16300, Loss: 0.014076299034059048\n",
      "Epoch 6, Batch 16400, Loss: 0.025818025693297386\n",
      "Epoch 6, Batch 16500, Loss: 0.03345108777284622\n",
      "Epoch 6, Batch 16600, Loss: 0.023435231298208237\n",
      "Epoch 6, Batch 16700, Loss: 0.03190001845359802\n",
      "Epoch 6, Batch 16800, Loss: 0.006380048580467701\n",
      "Epoch 6, Batch 16900, Loss: 0.013279424980282784\n",
      "Epoch 6, Batch 17000, Loss: 0.022579221054911613\n",
      "Epoch 6, Batch 17100, Loss: 0.02094680443406105\n",
      "Epoch 6, Batch 17200, Loss: 0.017603065818548203\n",
      "Epoch 6, Batch 17300, Loss: 0.021299762651324272\n",
      "Epoch 6, Batch 17400, Loss: 0.02059432491660118\n",
      "Epoch 6, Batch 17500, Loss: 0.006261187605559826\n",
      "Epoch 6, Batch 17600, Loss: 0.026005227118730545\n",
      "Epoch 6, Batch 17700, Loss: 0.023435315117239952\n",
      "Epoch 6, Batch 17800, Loss: 0.010089639574289322\n",
      "Epoch 6, Batch 17900, Loss: 0.033517368137836456\n",
      "Epoch 6, Batch 18000, Loss: 0.027229173108935356\n",
      "Epoch 6, Batch 18100, Loss: 0.01674470119178295\n",
      "Epoch 6, Batch 18200, Loss: 0.018278975039720535\n",
      "Epoch 6, Batch 18300, Loss: 0.015339041128754616\n",
      "Epoch 6, Batch 18400, Loss: 0.019941765815019608\n",
      "Epoch 6, Batch 18500, Loss: 0.01932327076792717\n",
      "Epoch 6, Batch 18600, Loss: 0.012095781974494457\n",
      "Epoch 6, Batch 18700, Loss: 0.04333281144499779\n",
      "Epoch 6, Batch 18800, Loss: 0.04102019593119621\n",
      "Epoch 6, Batch 18900, Loss: 0.019309256225824356\n",
      "Epoch 6, Batch 19000, Loss: 0.018486641347408295\n",
      "Epoch 6, Batch 19100, Loss: 0.020559489727020264\n",
      "Epoch 6, Batch 19200, Loss: 0.015857864171266556\n",
      "Epoch 6, Batch 19300, Loss: 0.011282081715762615\n",
      "Epoch 6, Batch 19400, Loss: 0.016316525638103485\n",
      "Epoch 6, Batch 19500, Loss: 0.014881160110235214\n",
      "Epoch 6, Batch 19600, Loss: 0.024354979395866394\n",
      "Epoch 6, Batch 19700, Loss: 0.021191595122218132\n",
      "Epoch 6, Batch 19800, Loss: 0.017288347706198692\n",
      "Epoch 6, Batch 19900, Loss: 0.015326791442930698\n",
      "Epoch 6, Batch 20000, Loss: 0.020816178992390633\n",
      "Epoch 6, Batch 20100, Loss: 0.020575210452079773\n",
      "Epoch 6, Batch 20200, Loss: 0.021954093128442764\n",
      "Epoch 6, Batch 20300, Loss: 0.0639466643333435\n",
      "Epoch 6, Batch 20400, Loss: 0.03126206248998642\n",
      "Epoch 6, Batch 20500, Loss: 0.006840413901954889\n",
      "Epoch 6, Batch 20600, Loss: 0.014306901954114437\n",
      "Epoch 6, Batch 20700, Loss: 0.03238414227962494\n",
      "Epoch 6, Batch 20800, Loss: 0.055028073489665985\n",
      "Epoch 6, Batch 20900, Loss: 0.0265594981610775\n",
      "Epoch 6, Batch 21000, Loss: 0.00879578199237585\n",
      "Epoch 6, Batch 21100, Loss: 0.01608007587492466\n",
      "Epoch 6, Batch 21200, Loss: 0.0381963849067688\n",
      "Epoch 6, Batch 21300, Loss: 0.04437539726495743\n",
      "Epoch 6, Batch 21400, Loss: 0.04369466379284859\n",
      "Epoch 6, Batch 21500, Loss: 0.04450777918100357\n",
      "Epoch 6, Batch 21600, Loss: 0.025335723534226418\n",
      "Epoch 6, Batch 21700, Loss: 0.02823067083954811\n",
      "Epoch 6, Batch 21800, Loss: 0.025259265676140785\n",
      "Epoch 6, Batch 21900, Loss: 0.006546373944729567\n",
      "Epoch 6, Batch 22000, Loss: 0.012011867016553879\n",
      "Epoch 6, Batch 22100, Loss: 0.029692601412534714\n",
      "Epoch 6, Batch 22200, Loss: 0.05061584338545799\n",
      "Epoch 6, Batch 22300, Loss: 0.04879923164844513\n",
      "Epoch 6, Batch 22400, Loss: 0.030614206567406654\n",
      "Epoch 6, Batch 22500, Loss: 0.024660220369696617\n",
      "Epoch 6, Batch 22600, Loss: 0.023242633789777756\n",
      "Epoch 6, Batch 22700, Loss: 0.037869177758693695\n",
      "Epoch 6, Batch 22800, Loss: 0.016907965764403343\n",
      "Epoch 6, Batch 22900, Loss: 0.024270540103316307\n",
      "Epoch 6, Batch 23000, Loss: 0.031649958342313766\n",
      "Epoch 6, Batch 23100, Loss: 0.028759507462382317\n",
      "Epoch 6, Batch 23200, Loss: 0.024460813030600548\n",
      "Epoch 6, Batch 23300, Loss: 0.03346652165055275\n",
      "Epoch 6, Batch 23400, Loss: 0.04798464477062225\n",
      "Epoch 6, Batch 23500, Loss: 0.0428185760974884\n",
      "Epoch 6, Batch 23600, Loss: 0.03900422900915146\n",
      "Epoch 6, Batch 23700, Loss: 0.011122209951281548\n",
      "Epoch 6, Batch 23800, Loss: 0.031491175293922424\n",
      "Epoch 6, Batch 23900, Loss: 0.02197461947798729\n",
      "Epoch 6, Batch 24000, Loss: 0.02340271696448326\n",
      "Epoch 6, Batch 24100, Loss: 0.030354097485542297\n",
      "Epoch 6, Batch 24200, Loss: 0.0408826544880867\n",
      "Epoch 6, Batch 24300, Loss: 0.04100281745195389\n",
      "Epoch 6, Batch 24400, Loss: 0.06273709982633591\n",
      "Epoch 6, Batch 24500, Loss: 0.040626224130392075\n",
      "Epoch 6, Batch 24600, Loss: 0.01050071232020855\n",
      "Epoch 6, Batch 24700, Loss: 0.020593170076608658\n",
      "Epoch 6, Batch 24800, Loss: 0.025273902341723442\n",
      "Epoch 6, Batch 24900, Loss: 0.016787607222795486\n",
      "Epoch 6, Batch 25000, Loss: 0.013316448777914047\n",
      "Epoch 6, Batch 25100, Loss: 0.04288313165307045\n",
      "Epoch 6, Batch 25200, Loss: 0.019635453820228577\n",
      "Epoch 6, Batch 25300, Loss: 0.018722400069236755\n",
      "Epoch 6, Batch 25400, Loss: 0.10127604007720947\n",
      "Epoch 6, Batch 25500, Loss: 0.012205277569591999\n",
      "Epoch 6, Batch 25600, Loss: 0.02188033238053322\n",
      "Epoch 6, Batch 25700, Loss: 0.0320775993168354\n",
      "Epoch 6, Batch 25800, Loss: 0.032240886241197586\n",
      "Epoch 6, Batch 25900, Loss: 0.155949205160141\n",
      "Epoch 6, Batch 26000, Loss: 0.022689450532197952\n",
      "Epoch 6, Batch 26100, Loss: 0.023039670661091805\n",
      "Epoch 6, Batch 26200, Loss: 0.031071390956640244\n",
      "Epoch 6, Batch 26300, Loss: 0.013363722711801529\n",
      "Epoch 6, Batch 26400, Loss: 0.037383634597063065\n",
      "Epoch 6, Batch 26500, Loss: 0.018001878634095192\n",
      "Epoch 6, Batch 26600, Loss: 0.01971353031694889\n",
      "Epoch 6, Batch 26700, Loss: 0.024696558713912964\n",
      "Epoch 6, Batch 26800, Loss: 0.07819037139415741\n",
      "Epoch 6, Batch 26900, Loss: 0.030646907165646553\n",
      "Epoch 6, Batch 27000, Loss: 0.026702087372541428\n",
      "Epoch 6, Batch 27100, Loss: 0.031240666285157204\n",
      "Epoch 6, Batch 27200, Loss: 0.055812444537878036\n",
      "Epoch 6, Batch 27300, Loss: 0.02467951364815235\n",
      "Epoch 6, Batch 27400, Loss: 0.05033164471387863\n",
      "Epoch 6, Batch 27500, Loss: 0.03126998245716095\n",
      "Epoch 6, Batch 27600, Loss: 0.02619967795908451\n",
      "Epoch 6, Batch 27700, Loss: 0.01812836527824402\n",
      "Epoch 6, Batch 27800, Loss: 0.03977305814623833\n",
      "Epoch 6, Batch 27900, Loss: 0.022043202072381973\n",
      "Epoch 6, Batch 28000, Loss: 0.02803719975054264\n",
      "Epoch 6, Batch 28100, Loss: 0.050755344331264496\n",
      "Epoch 6, Batch 28200, Loss: 0.030183760449290276\n",
      "Epoch 6, Batch 28300, Loss: 0.05257559195160866\n",
      "Epoch 6, Batch 28400, Loss: 0.05030389875173569\n",
      "Epoch 6, Batch 28500, Loss: 0.030667388811707497\n",
      "Epoch 6, Batch 28600, Loss: 0.09858895093202591\n",
      "Epoch 6, Batch 28700, Loss: 0.032333917915821075\n",
      "Epoch 6, Batch 28800, Loss: 0.029899591580033302\n",
      "Epoch 6, Batch 28900, Loss: 0.025355283170938492\n",
      "Epoch 6, Batch 29000, Loss: 0.030298804864287376\n",
      "Epoch 6, Batch 29100, Loss: 0.019816478714346886\n",
      "Epoch 6, Batch 29200, Loss: 0.036478299647569656\n",
      "Epoch 6, Batch 29300, Loss: 0.04632438346743584\n",
      "Epoch 6, Batch 29400, Loss: 0.056669775396585464\n",
      "Epoch 6, Batch 29500, Loss: 0.16602593660354614\n",
      "Epoch 6, Batch 29600, Loss: 0.03180792182683945\n",
      "Epoch 6, Batch 29700, Loss: 0.017451511695981026\n",
      "Epoch 6, Batch 29800, Loss: 0.015186053700745106\n",
      "Epoch 6, Batch 29900, Loss: 0.061855386942625046\n",
      "Epoch 6, Batch 30000, Loss: 0.07732155174016953\n",
      "Epoch 6, Batch 30100, Loss: 0.02574855089187622\n",
      "Epoch 6, Batch 30200, Loss: 0.040680356323719025\n",
      "Epoch 6, Batch 30300, Loss: 0.05306578055024147\n",
      "Epoch 6, Batch 30400, Loss: 0.012662593275308609\n",
      "Epoch 6, Batch 30500, Loss: 0.031935710459947586\n",
      "Epoch 6, Batch 30600, Loss: 0.02167411893606186\n",
      "Epoch 6, Batch 30700, Loss: 0.10454817116260529\n",
      "Epoch 6, Batch 30800, Loss: 0.03456490486860275\n",
      "Epoch 6, Batch 30900, Loss: 0.0412091389298439\n",
      "Epoch 6, Batch 31000, Loss: 0.016576608642935753\n",
      "Epoch 6, Batch 31100, Loss: 0.02893749251961708\n",
      "Epoch 6, Batch 31200, Loss: 0.02264932170510292\n",
      "Epoch 6, Batch 31300, Loss: 0.03751081973314285\n",
      "Epoch 6, Batch 31400, Loss: 0.023140354081988335\n",
      "Epoch 6, Batch 31500, Loss: 0.020383987575769424\n",
      "Epoch 6, Batch 31600, Loss: 0.04281146451830864\n",
      "Epoch 6, Batch 31700, Loss: 0.032391760498285294\n",
      "Epoch 6, Batch 31800, Loss: 0.03679689019918442\n",
      "Epoch 6, Batch 31900, Loss: 0.022558212280273438\n",
      "Epoch 6, Batch 32000, Loss: 0.02946508675813675\n",
      "Epoch 6, Batch 32100, Loss: 0.028264576569199562\n",
      "Epoch 6, Batch 32200, Loss: 0.030624505132436752\n",
      "Epoch 6, Batch 32300, Loss: 0.024683093652129173\n",
      "Epoch 6, Batch 32400, Loss: 0.02073568105697632\n",
      "Epoch 6, Batch 32500, Loss: 0.07507452368736267\n",
      "Epoch 6, Batch 32600, Loss: 0.01766975037753582\n",
      "Epoch 6, Batch 32700, Loss: 0.03061138279736042\n",
      "Epoch 6, Batch 32800, Loss: 0.052672840654850006\n",
      "Epoch 6, Batch 32900, Loss: 0.04252307116985321\n",
      "Epoch 6, Batch 33000, Loss: 0.021577294915914536\n",
      "Epoch 6, Batch 33100, Loss: 0.04498739168047905\n",
      "Epoch 6, Batch 33200, Loss: 0.053235478699207306\n",
      "Epoch 6, Batch 33300, Loss: 0.01940242387354374\n",
      "Epoch 6, Batch 33400, Loss: 0.02618636190891266\n",
      "Epoch 6, Batch 33500, Loss: 0.031480640172958374\n",
      "Epoch 6, Batch 33600, Loss: 0.027238408103585243\n",
      "Epoch 6, Batch 33700, Loss: 0.015925344079732895\n",
      "Epoch 6, Batch 33800, Loss: 0.0594274066388607\n",
      "Epoch 6, Batch 33900, Loss: 0.03665124997496605\n",
      "Epoch 6, Batch 34000, Loss: 0.020805010572075844\n",
      "Epoch 6, Batch 34100, Loss: 0.017471009865403175\n",
      "Epoch 6, Batch 34200, Loss: 0.020024998113512993\n",
      "Epoch 6, Batch 34300, Loss: 0.03128563240170479\n",
      "Epoch 6, Batch 34400, Loss: 0.022335782647132874\n",
      "Epoch 6, Batch 34500, Loss: 0.018663480877876282\n",
      "Epoch 6, Batch 34600, Loss: 0.018345871940255165\n",
      "Epoch 6, Batch 34700, Loss: 0.008982277475297451\n",
      "Epoch 6, Batch 34800, Loss: 0.025552209466695786\n",
      "Epoch 6, Batch 34900, Loss: 0.03440054506063461\n",
      "Epoch 6, Batch 35000, Loss: 0.03958018124103546\n",
      "Epoch 6, Batch 35100, Loss: 0.053278014063835144\n",
      "Epoch 6, Batch 35200, Loss: 0.02814626693725586\n",
      "Epoch 6, Batch 35300, Loss: 0.03761697933077812\n",
      "Epoch 6, Batch 35400, Loss: 0.013664201833307743\n",
      "Epoch 6, Batch 35500, Loss: 0.008149825036525726\n",
      "Epoch 6, Batch 35600, Loss: 0.023717695847153664\n",
      "Epoch 6, Batch 35700, Loss: 0.030919013544917107\n",
      "Epoch 6, Batch 35800, Loss: 0.024719923734664917\n",
      "Epoch 6, Batch 35900, Loss: 0.04871772602200508\n",
      "Epoch 6, Batch 36000, Loss: 0.012789009138941765\n",
      "Epoch 6, Batch 36100, Loss: 0.02102351374924183\n",
      "Epoch 6, Batch 36200, Loss: 0.013160795904695988\n",
      "Epoch 6, Batch 36300, Loss: 0.02078222669661045\n",
      "Epoch 6, Batch 36400, Loss: 0.015542782843112946\n",
      "Epoch 6, Batch 36500, Loss: 0.02017621323466301\n",
      "Epoch 6, Batch 36600, Loss: 0.024579059332609177\n",
      "Epoch 6, Batch 36700, Loss: 0.05359724909067154\n",
      "Epoch 6, Batch 36800, Loss: 0.056108418852090836\n",
      "Validation Loss: 3.0501506892812253\n",
      "Epoch 7, Batch 100, Loss: 0.030904576182365417\n",
      "Epoch 7, Batch 200, Loss: 0.0078217051923275\n",
      "Epoch 7, Batch 300, Loss: 0.027007000520825386\n",
      "Epoch 7, Batch 400, Loss: 0.020114565268158913\n",
      "Epoch 7, Batch 500, Loss: 0.010593348182737827\n",
      "Epoch 7, Batch 600, Loss: 0.0187482088804245\n",
      "Epoch 7, Batch 700, Loss: 0.022122295573353767\n",
      "Epoch 7, Batch 800, Loss: 0.017993289977312088\n",
      "Epoch 7, Batch 900, Loss: 0.02054048888385296\n",
      "Epoch 7, Batch 1000, Loss: 0.02134418860077858\n",
      "Epoch 7, Batch 1100, Loss: 0.022615807130932808\n",
      "Epoch 7, Batch 1200, Loss: 0.048680905252695084\n",
      "Epoch 7, Batch 1300, Loss: 0.016175059601664543\n",
      "Epoch 7, Batch 1400, Loss: 0.03136521950364113\n",
      "Epoch 7, Batch 1500, Loss: 0.016116982325911522\n",
      "Epoch 7, Batch 1600, Loss: 0.01789001189172268\n",
      "Epoch 7, Batch 1700, Loss: 0.04494698718190193\n",
      "Epoch 7, Batch 1800, Loss: 0.020285092294216156\n",
      "Epoch 7, Batch 1900, Loss: 0.02414594031870365\n",
      "Epoch 7, Batch 2000, Loss: 0.024285223335027695\n",
      "Epoch 7, Batch 2100, Loss: 0.03870300203561783\n",
      "Epoch 7, Batch 2200, Loss: 0.031096380203962326\n",
      "Epoch 7, Batch 2300, Loss: 0.04444200545549393\n",
      "Epoch 7, Batch 2400, Loss: 0.04993722215294838\n",
      "Epoch 7, Batch 2500, Loss: 0.02038317546248436\n",
      "Epoch 7, Batch 2600, Loss: 0.018889859318733215\n",
      "Epoch 7, Batch 2700, Loss: 0.0315946564078331\n",
      "Epoch 7, Batch 2800, Loss: 0.021853886544704437\n",
      "Epoch 7, Batch 2900, Loss: 0.015808874741196632\n",
      "Epoch 7, Batch 3000, Loss: 0.028601376339793205\n",
      "Epoch 7, Batch 3100, Loss: 0.02282167226076126\n",
      "Epoch 7, Batch 3200, Loss: 0.03360050544142723\n",
      "Epoch 7, Batch 3300, Loss: 0.02547609433531761\n",
      "Epoch 7, Batch 3400, Loss: 0.028207870200276375\n",
      "Epoch 7, Batch 3500, Loss: 0.03657163679599762\n",
      "Epoch 7, Batch 3600, Loss: 0.029921740293502808\n",
      "Epoch 7, Batch 3700, Loss: 0.021344482898712158\n",
      "Epoch 7, Batch 3800, Loss: 0.013256740756332874\n",
      "Epoch 7, Batch 3900, Loss: 0.02070186473429203\n",
      "Epoch 7, Batch 4000, Loss: 0.027654822915792465\n",
      "Epoch 7, Batch 4100, Loss: 0.037309400737285614\n",
      "Epoch 7, Batch 4200, Loss: 0.021267637610435486\n",
      "Epoch 7, Batch 4300, Loss: 0.010165643878281116\n",
      "Epoch 7, Batch 4400, Loss: 0.03743420168757439\n",
      "Epoch 7, Batch 4500, Loss: 0.03987570106983185\n",
      "Epoch 7, Batch 4600, Loss: 0.04570792242884636\n",
      "Epoch 7, Batch 4700, Loss: 0.03420819714665413\n",
      "Epoch 7, Batch 4800, Loss: 0.022448396310210228\n",
      "Epoch 7, Batch 4900, Loss: 0.031214240938425064\n",
      "Epoch 7, Batch 5000, Loss: 0.023523930460214615\n",
      "Epoch 7, Batch 5100, Loss: 0.05456961691379547\n",
      "Epoch 7, Batch 5200, Loss: 0.022957872599363327\n",
      "Epoch 7, Batch 5300, Loss: 0.018223697319626808\n",
      "Epoch 7, Batch 5400, Loss: 0.027199765667319298\n",
      "Epoch 7, Batch 5500, Loss: 0.01931302435696125\n",
      "Epoch 7, Batch 5600, Loss: 0.029266398400068283\n",
      "Epoch 7, Batch 5700, Loss: 0.13172492384910583\n",
      "Epoch 7, Batch 5800, Loss: 0.021231267601251602\n",
      "Epoch 7, Batch 5900, Loss: 0.01876804418861866\n",
      "Epoch 7, Batch 6000, Loss: 0.04376469925045967\n",
      "Epoch 7, Batch 6100, Loss: 0.010207707062363625\n",
      "Epoch 7, Batch 6200, Loss: 0.026436543092131615\n",
      "Epoch 7, Batch 6300, Loss: 0.03139246255159378\n",
      "Epoch 7, Batch 6400, Loss: 0.021993599832057953\n",
      "Epoch 7, Batch 6500, Loss: 0.03881041705608368\n",
      "Epoch 7, Batch 6600, Loss: 0.027796346694231033\n",
      "Epoch 7, Batch 6700, Loss: 0.027389248833060265\n",
      "Epoch 7, Batch 6800, Loss: 0.03031831607222557\n",
      "Epoch 7, Batch 6900, Loss: 0.04965752735733986\n",
      "Epoch 7, Batch 7000, Loss: 0.04634853079915047\n",
      "Epoch 7, Batch 7100, Loss: 0.019820647314190865\n",
      "Epoch 7, Batch 7200, Loss: 0.028020821511745453\n",
      "Epoch 7, Batch 7300, Loss: 0.04461969807744026\n",
      "Epoch 7, Batch 7400, Loss: 0.022541875019669533\n",
      "Epoch 7, Batch 7500, Loss: 0.012636769562959671\n",
      "Epoch 7, Batch 7600, Loss: 0.02254827693104744\n",
      "Epoch 7, Batch 7700, Loss: 0.031173326075077057\n",
      "Epoch 7, Batch 7800, Loss: 0.020451096817851067\n",
      "Epoch 7, Batch 7900, Loss: 0.014270424842834473\n",
      "Epoch 7, Batch 8000, Loss: 0.022131940349936485\n",
      "Epoch 7, Batch 8100, Loss: 0.0193948894739151\n",
      "Epoch 7, Batch 8200, Loss: 0.01193558145314455\n",
      "Epoch 7, Batch 8300, Loss: 0.007949263788759708\n",
      "Epoch 7, Batch 8400, Loss: 0.03312010318040848\n",
      "Epoch 7, Batch 8500, Loss: 0.02565232291817665\n",
      "Epoch 7, Batch 8600, Loss: 0.02526869997382164\n",
      "Epoch 7, Batch 8700, Loss: 0.018127940595149994\n",
      "Epoch 7, Batch 8800, Loss: 0.018312053754925728\n",
      "Epoch 7, Batch 8900, Loss: 0.018366632983088493\n",
      "Epoch 7, Batch 9000, Loss: 0.018060877919197083\n",
      "Epoch 7, Batch 9100, Loss: 0.021807275712490082\n",
      "Epoch 7, Batch 9200, Loss: 0.020517801865935326\n",
      "Epoch 7, Batch 9300, Loss: 0.01732614077627659\n",
      "Epoch 7, Batch 9400, Loss: 0.030330462381243706\n",
      "Epoch 7, Batch 9500, Loss: 0.03720925375819206\n",
      "Epoch 7, Batch 9600, Loss: 0.031503040343523026\n",
      "Epoch 7, Batch 9700, Loss: 0.014372602105140686\n",
      "Epoch 7, Batch 9800, Loss: 0.053574491292238235\n",
      "Epoch 7, Batch 9900, Loss: 0.041004203259944916\n",
      "Epoch 7, Batch 10000, Loss: 0.030281292274594307\n",
      "Epoch 7, Batch 10100, Loss: 0.028158674016594887\n",
      "Epoch 7, Batch 10200, Loss: 0.018955208361148834\n",
      "Epoch 7, Batch 10300, Loss: 0.025871461257338524\n",
      "Epoch 7, Batch 10400, Loss: 0.029634881764650345\n",
      "Epoch 7, Batch 10500, Loss: 0.017759475857019424\n",
      "Epoch 7, Batch 10600, Loss: 0.030416984111070633\n",
      "Epoch 7, Batch 10700, Loss: 0.010568949393928051\n",
      "Epoch 7, Batch 10800, Loss: 0.04696419835090637\n",
      "Epoch 7, Batch 10900, Loss: 0.016566051170229912\n",
      "Epoch 7, Batch 11000, Loss: 0.032446473836898804\n",
      "Epoch 7, Batch 11100, Loss: 0.029069911688566208\n",
      "Epoch 7, Batch 11200, Loss: 0.05873388051986694\n",
      "Epoch 7, Batch 11300, Loss: 0.07889255881309509\n",
      "Epoch 7, Batch 11400, Loss: 0.021477874368429184\n",
      "Epoch 7, Batch 11500, Loss: 0.02038688212633133\n",
      "Epoch 7, Batch 11600, Loss: 0.03228602185845375\n",
      "Epoch 7, Batch 11700, Loss: 0.03616951406002045\n",
      "Epoch 7, Batch 11800, Loss: 0.005572465248405933\n",
      "Epoch 7, Batch 11900, Loss: 0.025884848088026047\n",
      "Epoch 7, Batch 12000, Loss: 0.022318299859762192\n",
      "Epoch 7, Batch 12100, Loss: 0.021444842219352722\n",
      "Epoch 7, Batch 12200, Loss: 0.010890147648751736\n",
      "Epoch 7, Batch 12300, Loss: 0.030335480347275734\n",
      "Epoch 7, Batch 12400, Loss: 0.031558286398649216\n",
      "Epoch 7, Batch 12500, Loss: 0.05842394754290581\n",
      "Epoch 7, Batch 12600, Loss: 0.0256461501121521\n",
      "Epoch 7, Batch 12700, Loss: 0.010953818447887897\n",
      "Epoch 7, Batch 12800, Loss: 0.023816276341676712\n",
      "Epoch 7, Batch 12900, Loss: 0.02545437216758728\n",
      "Epoch 7, Batch 13000, Loss: 0.01657446101307869\n",
      "Epoch 7, Batch 13100, Loss: 0.01774865947663784\n",
      "Epoch 7, Batch 13200, Loss: 0.02739330753684044\n",
      "Epoch 7, Batch 13300, Loss: 0.023048115894198418\n",
      "Epoch 7, Batch 13400, Loss: 0.014995697885751724\n",
      "Epoch 7, Batch 13500, Loss: 0.027291957288980484\n",
      "Epoch 7, Batch 13600, Loss: 0.01710958033800125\n",
      "Epoch 7, Batch 13700, Loss: 0.027226010337471962\n",
      "Epoch 7, Batch 13800, Loss: 0.017217649146914482\n",
      "Epoch 7, Batch 13900, Loss: 0.036389585584402084\n",
      "Epoch 7, Batch 14000, Loss: 0.043263863772153854\n",
      "Epoch 7, Batch 14100, Loss: 0.03431854024529457\n",
      "Epoch 7, Batch 14200, Loss: 0.03907214477658272\n",
      "Epoch 7, Batch 14300, Loss: 0.022208407521247864\n",
      "Epoch 7, Batch 14400, Loss: 0.019903484731912613\n",
      "Epoch 7, Batch 14500, Loss: 0.015485021285712719\n",
      "Epoch 7, Batch 14600, Loss: 0.040372323244810104\n",
      "Epoch 7, Batch 14700, Loss: 0.015427553094923496\n",
      "Epoch 7, Batch 14800, Loss: 0.0121594974771142\n",
      "Epoch 7, Batch 14900, Loss: 0.0439433753490448\n",
      "Epoch 7, Batch 15000, Loss: 0.026052530854940414\n",
      "Epoch 7, Batch 15100, Loss: 0.028838081285357475\n",
      "Epoch 7, Batch 15200, Loss: 0.02182730846107006\n",
      "Epoch 7, Batch 15300, Loss: 0.012500784359872341\n",
      "Epoch 7, Batch 15400, Loss: 0.02433941885828972\n",
      "Epoch 7, Batch 15500, Loss: 0.019237961620092392\n",
      "Epoch 7, Batch 15600, Loss: 0.016726745292544365\n",
      "Epoch 7, Batch 15700, Loss: 0.013965888880193233\n",
      "Epoch 7, Batch 15800, Loss: 0.010522943921387196\n",
      "Epoch 7, Batch 15900, Loss: 0.03297698497772217\n",
      "Epoch 7, Batch 16000, Loss: 0.016396841034293175\n",
      "Epoch 7, Batch 16100, Loss: 0.05561855807900429\n",
      "Epoch 7, Batch 16200, Loss: 0.024738363921642303\n",
      "Epoch 7, Batch 16300, Loss: 0.04424083232879639\n",
      "Epoch 7, Batch 16400, Loss: 0.01299695111811161\n",
      "Epoch 7, Batch 16500, Loss: 0.035075027495622635\n",
      "Epoch 7, Batch 16600, Loss: 0.0121186887845397\n",
      "Epoch 7, Batch 16700, Loss: 0.05511495843529701\n",
      "Epoch 7, Batch 16800, Loss: 0.05095632001757622\n",
      "Epoch 7, Batch 16900, Loss: 0.010540035553276539\n",
      "Epoch 7, Batch 17000, Loss: 0.020836928859353065\n",
      "Epoch 7, Batch 17100, Loss: 0.018993325531482697\n",
      "Epoch 7, Batch 17200, Loss: 0.007722522597759962\n",
      "Epoch 7, Batch 17300, Loss: 0.02341650053858757\n",
      "Epoch 7, Batch 17400, Loss: 0.027708617970347404\n",
      "Epoch 7, Batch 17500, Loss: 0.02171521633863449\n",
      "Epoch 7, Batch 17600, Loss: 0.02274206653237343\n",
      "Epoch 7, Batch 17700, Loss: 0.03615385666489601\n",
      "Epoch 7, Batch 17800, Loss: 0.020073041319847107\n",
      "Epoch 7, Batch 17900, Loss: 0.030628280714154243\n",
      "Epoch 7, Batch 18000, Loss: 0.03426720201969147\n",
      "Epoch 7, Batch 18100, Loss: 0.037991080433130264\n",
      "Epoch 7, Batch 18200, Loss: 0.005693611688911915\n",
      "Epoch 7, Batch 18300, Loss: 0.012822996824979782\n",
      "Epoch 7, Batch 18400, Loss: 0.014421871863305569\n",
      "Epoch 7, Batch 18500, Loss: 0.014112377539277077\n",
      "Epoch 7, Batch 18600, Loss: 0.020386310294270515\n",
      "Epoch 7, Batch 18700, Loss: 0.01762399636209011\n",
      "Epoch 7, Batch 18800, Loss: 0.029872005805373192\n",
      "Epoch 7, Batch 18900, Loss: 0.026428909972310066\n",
      "Epoch 7, Batch 19000, Loss: 0.026178333908319473\n",
      "Epoch 7, Batch 19100, Loss: 0.03827500715851784\n",
      "Epoch 7, Batch 19200, Loss: 0.027592068538069725\n",
      "Epoch 7, Batch 19300, Loss: 0.019767483696341515\n",
      "Epoch 7, Batch 19400, Loss: 0.00912050437182188\n",
      "Epoch 7, Batch 19500, Loss: 0.01153220422565937\n",
      "Epoch 7, Batch 19600, Loss: 0.012157648801803589\n",
      "Epoch 7, Batch 19700, Loss: 0.038041386753320694\n",
      "Epoch 7, Batch 19800, Loss: 0.023065835237503052\n",
      "Epoch 7, Batch 19900, Loss: 0.019446445629000664\n",
      "Epoch 7, Batch 20000, Loss: 0.04884982481598854\n",
      "Epoch 7, Batch 20100, Loss: 0.05009687691926956\n",
      "Epoch 7, Batch 20200, Loss: 0.013065491802990437\n",
      "Epoch 7, Batch 20300, Loss: 0.03905973955988884\n",
      "Epoch 7, Batch 20400, Loss: 0.015083752572536469\n",
      "Epoch 7, Batch 20500, Loss: 0.018308300524950027\n",
      "Epoch 7, Batch 20600, Loss: 0.02519211918115616\n",
      "Epoch 7, Batch 20700, Loss: 0.03827165439724922\n",
      "Epoch 7, Batch 20800, Loss: 0.01886584796011448\n",
      "Epoch 7, Batch 20900, Loss: 0.013434763066470623\n",
      "Epoch 7, Batch 21000, Loss: 0.029390376061201096\n",
      "Epoch 7, Batch 21100, Loss: 0.012655152939260006\n",
      "Epoch 7, Batch 21200, Loss: 0.0163344144821167\n",
      "Epoch 7, Batch 21300, Loss: 0.00913929007947445\n",
      "Epoch 7, Batch 21400, Loss: 0.061476219445466995\n",
      "Epoch 7, Batch 21500, Loss: 0.03362772613763809\n",
      "Epoch 7, Batch 21600, Loss: 0.045806724578142166\n",
      "Epoch 7, Batch 21700, Loss: 0.011272716335952282\n",
      "Epoch 7, Batch 21800, Loss: 0.04104916751384735\n",
      "Epoch 7, Batch 21900, Loss: 0.010291166603565216\n",
      "Epoch 7, Batch 22000, Loss: 0.040527794510126114\n",
      "Epoch 7, Batch 22100, Loss: 0.03507648780941963\n",
      "Epoch 7, Batch 22200, Loss: 0.018375826999545097\n",
      "Epoch 7, Batch 22300, Loss: 0.030923228710889816\n",
      "Epoch 7, Batch 22400, Loss: 0.014446032233536243\n",
      "Epoch 7, Batch 22500, Loss: 0.027358217164874077\n",
      "Epoch 7, Batch 22600, Loss: 0.01328462827950716\n",
      "Epoch 7, Batch 22700, Loss: 0.015350543893873692\n",
      "Epoch 7, Batch 22800, Loss: 0.037242040038108826\n",
      "Epoch 7, Batch 22900, Loss: 0.03262758627533913\n",
      "Epoch 7, Batch 23000, Loss: 0.027713457122445107\n",
      "Epoch 7, Batch 23100, Loss: 0.01954931765794754\n",
      "Epoch 7, Batch 23200, Loss: 0.02308737486600876\n",
      "Epoch 7, Batch 23300, Loss: 0.01471763476729393\n",
      "Epoch 7, Batch 23400, Loss: 0.036684248596429825\n",
      "Epoch 7, Batch 23500, Loss: 0.0317004919052124\n",
      "Epoch 7, Batch 23600, Loss: 0.019526740536093712\n",
      "Epoch 7, Batch 23700, Loss: 0.025240518152713776\n",
      "Epoch 7, Batch 23800, Loss: 0.03381652384996414\n",
      "Epoch 7, Batch 23900, Loss: 0.04067886993288994\n",
      "Epoch 7, Batch 24000, Loss: 0.0155860036611557\n",
      "Epoch 7, Batch 24100, Loss: 0.01964162290096283\n",
      "Epoch 7, Batch 24200, Loss: 0.060089703649282455\n",
      "Epoch 7, Batch 24300, Loss: 0.04152354970574379\n",
      "Epoch 7, Batch 24400, Loss: 0.014654813334345818\n",
      "Epoch 7, Batch 24500, Loss: 0.02655135467648506\n",
      "Epoch 7, Batch 24600, Loss: 0.018230296671390533\n",
      "Epoch 7, Batch 24700, Loss: 0.021867169067263603\n",
      "Epoch 7, Batch 24800, Loss: 0.028922658413648605\n",
      "Epoch 7, Batch 24900, Loss: 0.018185263499617577\n",
      "Epoch 7, Batch 25000, Loss: 0.020566577091813087\n",
      "Epoch 7, Batch 25100, Loss: 0.009628030471503735\n",
      "Epoch 7, Batch 25200, Loss: 0.017857398837804794\n",
      "Epoch 7, Batch 25300, Loss: 0.020333554595708847\n",
      "Epoch 7, Batch 25400, Loss: 0.017389310523867607\n",
      "Epoch 7, Batch 25500, Loss: 0.012003455311059952\n",
      "Epoch 7, Batch 25600, Loss: 0.021677054464817047\n",
      "Epoch 7, Batch 25700, Loss: 0.0351419635117054\n",
      "Epoch 7, Batch 25800, Loss: 0.024446796625852585\n",
      "Epoch 7, Batch 25900, Loss: 0.021314634010195732\n",
      "Epoch 7, Batch 26000, Loss: 0.021798282861709595\n",
      "Epoch 7, Batch 26100, Loss: 0.02271740883588791\n",
      "Epoch 7, Batch 26200, Loss: 0.0213982705026865\n",
      "Epoch 7, Batch 26300, Loss: 0.015449585393071175\n",
      "Epoch 7, Batch 26400, Loss: 0.014184443280100822\n",
      "Epoch 7, Batch 26500, Loss: 0.02269899658858776\n",
      "Epoch 7, Batch 26600, Loss: 0.02404683455824852\n",
      "Epoch 7, Batch 26700, Loss: 0.01027408055961132\n",
      "Epoch 7, Batch 26800, Loss: 0.0342552550137043\n",
      "Epoch 7, Batch 26900, Loss: 0.021493423730134964\n",
      "Epoch 7, Batch 27000, Loss: 0.023655245080590248\n",
      "Epoch 7, Batch 27100, Loss: 0.030750008299946785\n",
      "Epoch 7, Batch 27200, Loss: 0.013729619793593884\n",
      "Epoch 7, Batch 27300, Loss: 0.01428154669702053\n",
      "Epoch 7, Batch 27400, Loss: 0.014529275707900524\n",
      "Epoch 7, Batch 27500, Loss: 0.02872639149427414\n",
      "Epoch 7, Batch 27600, Loss: 0.017185254022479057\n",
      "Epoch 7, Batch 27700, Loss: 0.039985235780477524\n",
      "Epoch 7, Batch 27800, Loss: 0.05636969581246376\n",
      "Epoch 7, Batch 27900, Loss: 0.013716568239033222\n",
      "Epoch 7, Batch 28000, Loss: 0.1282355636358261\n",
      "Epoch 7, Batch 28100, Loss: 0.02113472856581211\n",
      "Epoch 7, Batch 28200, Loss: 0.05417222902178764\n",
      "Epoch 7, Batch 28300, Loss: 0.050809137523174286\n",
      "Epoch 7, Batch 28400, Loss: 0.06091224029660225\n",
      "Epoch 7, Batch 28500, Loss: 0.018958715721964836\n",
      "Epoch 7, Batch 28600, Loss: 0.08050886541604996\n",
      "Epoch 7, Batch 28700, Loss: 0.021009497344493866\n",
      "Epoch 7, Batch 28800, Loss: 0.01956542395055294\n",
      "Epoch 7, Batch 28900, Loss: 0.03959834575653076\n",
      "Epoch 7, Batch 29000, Loss: 0.030788592994213104\n",
      "Epoch 7, Batch 29100, Loss: 0.012554614804685116\n",
      "Epoch 7, Batch 29200, Loss: 0.030980365350842476\n",
      "Epoch 7, Batch 29300, Loss: 0.02429204247891903\n",
      "Epoch 7, Batch 29400, Loss: 0.025103792548179626\n",
      "Epoch 7, Batch 29500, Loss: 0.022401655092835426\n",
      "Epoch 7, Batch 29600, Loss: 0.02340283803641796\n",
      "Epoch 7, Batch 29700, Loss: 0.047501906752586365\n",
      "Epoch 7, Batch 29800, Loss: 0.025164952501654625\n",
      "Epoch 7, Batch 29900, Loss: 0.021534055471420288\n",
      "Epoch 7, Batch 30000, Loss: 0.012036622501909733\n",
      "Epoch 7, Batch 30100, Loss: 0.012782749719917774\n",
      "Epoch 7, Batch 30200, Loss: 0.032795198261737823\n",
      "Epoch 7, Batch 30300, Loss: 0.029587898403406143\n",
      "Epoch 7, Batch 30400, Loss: 0.020103508606553078\n",
      "Epoch 7, Batch 30500, Loss: 0.029944509267807007\n",
      "Epoch 7, Batch 30600, Loss: 0.03247756138443947\n",
      "Epoch 7, Batch 30700, Loss: 0.03111869841814041\n",
      "Epoch 7, Batch 30800, Loss: 0.016998441889882088\n",
      "Epoch 7, Batch 30900, Loss: 0.030041957274079323\n",
      "Epoch 7, Batch 31000, Loss: 0.056298140436410904\n",
      "Epoch 7, Batch 31100, Loss: 0.04646627977490425\n",
      "Epoch 7, Batch 31200, Loss: 0.006729276850819588\n",
      "Epoch 7, Batch 31300, Loss: 0.01850464940071106\n",
      "Epoch 7, Batch 31400, Loss: 0.02296457253396511\n",
      "Epoch 7, Batch 31500, Loss: 0.03168075159192085\n",
      "Epoch 7, Batch 31600, Loss: 0.029245425015687943\n",
      "Epoch 7, Batch 31700, Loss: 0.01107824221253395\n",
      "Epoch 7, Batch 31800, Loss: 0.03972853347659111\n",
      "Epoch 7, Batch 31900, Loss: 0.01970098726451397\n",
      "Epoch 7, Batch 32000, Loss: 0.02010774053633213\n",
      "Epoch 7, Batch 32100, Loss: 0.03312913700938225\n",
      "Epoch 7, Batch 32200, Loss: 0.027360744774341583\n",
      "Epoch 7, Batch 32300, Loss: 0.019737353548407555\n",
      "Epoch 7, Batch 32400, Loss: 0.004758055321872234\n",
      "Epoch 7, Batch 32500, Loss: 0.021647492423653603\n",
      "Epoch 7, Batch 32600, Loss: 0.03470982238650322\n",
      "Epoch 7, Batch 32700, Loss: 0.06074228882789612\n",
      "Epoch 7, Batch 32800, Loss: 0.01530041266232729\n",
      "Epoch 7, Batch 32900, Loss: 0.014496143907308578\n",
      "Epoch 7, Batch 33000, Loss: 0.012666119262576103\n",
      "Epoch 7, Batch 33100, Loss: 0.023270832374691963\n",
      "Epoch 7, Batch 33200, Loss: 0.017068538814783096\n",
      "Epoch 7, Batch 33300, Loss: 0.08807813376188278\n",
      "Epoch 7, Batch 33400, Loss: 0.03656502440571785\n",
      "Epoch 7, Batch 33500, Loss: 0.03413564711809158\n",
      "Epoch 7, Batch 33600, Loss: 0.0626775473356247\n",
      "Epoch 7, Batch 33700, Loss: 0.024036012589931488\n",
      "Epoch 7, Batch 33800, Loss: 0.055601537227630615\n",
      "Epoch 7, Batch 33900, Loss: 0.029705699533224106\n",
      "Epoch 7, Batch 34000, Loss: 0.010927128605544567\n",
      "Epoch 7, Batch 34100, Loss: 0.13626523315906525\n",
      "Epoch 7, Batch 34200, Loss: 0.023607613518834114\n",
      "Epoch 7, Batch 34300, Loss: 0.013246824964880943\n",
      "Epoch 7, Batch 34400, Loss: 0.011554080992937088\n",
      "Epoch 7, Batch 34500, Loss: 0.026045644655823708\n",
      "Epoch 7, Batch 34600, Loss: 0.03495572507381439\n",
      "Epoch 7, Batch 34700, Loss: 0.049266405403614044\n",
      "Epoch 7, Batch 34800, Loss: 0.013571604155004025\n",
      "Epoch 7, Batch 34900, Loss: 0.012680680491030216\n",
      "Epoch 7, Batch 35000, Loss: 0.013468961231410503\n",
      "Epoch 7, Batch 35100, Loss: 0.039518438279628754\n",
      "Epoch 7, Batch 35200, Loss: 0.050597261637449265\n",
      "Epoch 7, Batch 35300, Loss: 0.01348448172211647\n",
      "Epoch 7, Batch 35400, Loss: 0.018486417829990387\n",
      "Epoch 7, Batch 35500, Loss: 0.024285996332764626\n",
      "Epoch 7, Batch 35600, Loss: 0.02702028863132\n",
      "Epoch 7, Batch 35700, Loss: 0.01849939115345478\n",
      "Epoch 7, Batch 35800, Loss: 0.020948003977537155\n",
      "Epoch 7, Batch 35900, Loss: 0.012853983789682388\n",
      "Epoch 7, Batch 36000, Loss: 0.029053518548607826\n",
      "Epoch 7, Batch 36100, Loss: 0.011378227733075619\n",
      "Epoch 7, Batch 36200, Loss: 0.016721105203032494\n",
      "Epoch 7, Batch 36300, Loss: 0.016389740630984306\n",
      "Epoch 7, Batch 36400, Loss: 0.026716751977801323\n",
      "Epoch 7, Batch 36500, Loss: 0.01951681636273861\n",
      "Epoch 7, Batch 36600, Loss: 0.022677233442664146\n",
      "Epoch 7, Batch 36700, Loss: 0.022300992161035538\n",
      "Epoch 7, Batch 36800, Loss: 0.016705472022294998\n",
      "Validation Loss: 2.4997164057838916\n",
      "Epoch 8, Batch 100, Loss: 0.017830554395914078\n",
      "Epoch 8, Batch 200, Loss: 0.02490171231329441\n",
      "Epoch 8, Batch 300, Loss: 0.05270065739750862\n",
      "Epoch 8, Batch 400, Loss: 0.01905117928981781\n",
      "Epoch 8, Batch 500, Loss: 0.042981088161468506\n",
      "Epoch 8, Batch 600, Loss: 0.006322022061794996\n",
      "Epoch 8, Batch 700, Loss: 0.01989806815981865\n",
      "Epoch 8, Batch 800, Loss: 0.05176910385489464\n",
      "Epoch 8, Batch 900, Loss: 0.035781294107437134\n",
      "Epoch 8, Batch 1000, Loss: 0.023245254531502724\n",
      "Epoch 8, Batch 1100, Loss: 0.015868594869971275\n",
      "Epoch 8, Batch 1200, Loss: 0.022472362965345383\n",
      "Epoch 8, Batch 1300, Loss: 0.04068876430392265\n",
      "Epoch 8, Batch 1400, Loss: 0.023709608241915703\n",
      "Epoch 8, Batch 1500, Loss: 0.010826259851455688\n",
      "Epoch 8, Batch 1600, Loss: 0.015602270141243935\n",
      "Epoch 8, Batch 1700, Loss: 0.09148911386728287\n",
      "Epoch 8, Batch 1800, Loss: 0.013826880604028702\n",
      "Epoch 8, Batch 1900, Loss: 0.017360594123601913\n",
      "Epoch 8, Batch 2000, Loss: 0.00712798023596406\n",
      "Epoch 8, Batch 2100, Loss: 0.014718434773385525\n",
      "Epoch 8, Batch 2200, Loss: 0.03180820494890213\n",
      "Epoch 8, Batch 2300, Loss: 0.01470677275210619\n",
      "Epoch 8, Batch 2400, Loss: 0.0199492946267128\n",
      "Epoch 8, Batch 2500, Loss: 0.02142951264977455\n",
      "Epoch 8, Batch 2600, Loss: 0.009240901097655296\n",
      "Epoch 8, Batch 2700, Loss: 0.023630764335393906\n",
      "Epoch 8, Batch 2800, Loss: 0.025534970685839653\n",
      "Epoch 8, Batch 2900, Loss: 0.011776812374591827\n",
      "Epoch 8, Batch 3000, Loss: 0.01351158693432808\n",
      "Epoch 8, Batch 3100, Loss: 0.03550899028778076\n",
      "Epoch 8, Batch 3200, Loss: 0.02742113173007965\n",
      "Epoch 8, Batch 3300, Loss: 0.012770313769578934\n",
      "Epoch 8, Batch 3400, Loss: 0.028411122038960457\n",
      "Epoch 8, Batch 3500, Loss: 0.025250885635614395\n",
      "Epoch 8, Batch 3600, Loss: 0.020870428532361984\n",
      "Epoch 8, Batch 3700, Loss: 0.011676552705466747\n",
      "Epoch 8, Batch 3800, Loss: 0.006857788190245628\n",
      "Epoch 8, Batch 3900, Loss: 0.02061644196510315\n",
      "Epoch 8, Batch 4000, Loss: 0.026436680927872658\n",
      "Epoch 8, Batch 4100, Loss: 0.029465680941939354\n",
      "Epoch 8, Batch 4200, Loss: 0.0206556748598814\n",
      "Epoch 8, Batch 4300, Loss: 0.020832575857639313\n",
      "Epoch 8, Batch 4400, Loss: 0.033959969878196716\n",
      "Epoch 8, Batch 4500, Loss: 0.03562917932868004\n",
      "Epoch 8, Batch 4600, Loss: 0.01826174184679985\n",
      "Epoch 8, Batch 4700, Loss: 0.012122089974582195\n",
      "Epoch 8, Batch 4800, Loss: 0.01577194780111313\n",
      "Epoch 8, Batch 4900, Loss: 0.05714792385697365\n",
      "Epoch 8, Batch 5000, Loss: 0.03799969702959061\n",
      "Epoch 8, Batch 5100, Loss: 0.042109206318855286\n",
      "Epoch 8, Batch 5200, Loss: 0.027637245133519173\n",
      "Epoch 8, Batch 5300, Loss: 0.017938628792762756\n",
      "Epoch 8, Batch 5400, Loss: 0.016052044928073883\n",
      "Epoch 8, Batch 5500, Loss: 0.025715433061122894\n",
      "Epoch 8, Batch 5600, Loss: 0.058642420917749405\n",
      "Epoch 8, Batch 5700, Loss: 0.024610232561826706\n",
      "Epoch 8, Batch 5800, Loss: 0.025431761518120766\n",
      "Epoch 8, Batch 5900, Loss: 0.012136363424360752\n",
      "Epoch 8, Batch 6000, Loss: 0.04333512857556343\n",
      "Epoch 8, Batch 6100, Loss: 0.03018486499786377\n",
      "Epoch 8, Batch 6200, Loss: 0.017710713669657707\n",
      "Epoch 8, Batch 6300, Loss: 0.014144650660455227\n",
      "Epoch 8, Batch 6400, Loss: 0.010297304019331932\n",
      "Epoch 8, Batch 6500, Loss: 0.020429270341992378\n",
      "Epoch 8, Batch 6600, Loss: 0.04449757561087608\n",
      "Epoch 8, Batch 6700, Loss: 0.01473414245992899\n",
      "Epoch 8, Batch 6800, Loss: 0.012799483723938465\n",
      "Epoch 8, Batch 6900, Loss: 0.01895023323595524\n",
      "Epoch 8, Batch 7000, Loss: 0.02454550750553608\n",
      "Epoch 8, Batch 7100, Loss: 0.013426574878394604\n",
      "Epoch 8, Batch 7200, Loss: 0.017683304846286774\n",
      "Epoch 8, Batch 7300, Loss: 0.01873372122645378\n",
      "Epoch 8, Batch 7400, Loss: 0.02321852184832096\n",
      "Epoch 8, Batch 7500, Loss: 0.013663711957633495\n",
      "Epoch 8, Batch 7600, Loss: 0.017943885177373886\n",
      "Epoch 8, Batch 7700, Loss: 0.015210029669106007\n",
      "Epoch 8, Batch 7800, Loss: 0.014280143193900585\n",
      "Epoch 8, Batch 7900, Loss: 0.013102990575134754\n",
      "Epoch 8, Batch 8000, Loss: 0.019363166764378548\n",
      "Epoch 8, Batch 8100, Loss: 0.025994950905442238\n",
      "Epoch 8, Batch 8200, Loss: 0.023148654028773308\n",
      "Epoch 8, Batch 8300, Loss: 0.02563261240720749\n",
      "Epoch 8, Batch 8400, Loss: 0.02079332433640957\n",
      "Epoch 8, Batch 8500, Loss: 0.007813921198248863\n",
      "Epoch 8, Batch 8600, Loss: 0.025825032964348793\n",
      "Epoch 8, Batch 8700, Loss: 0.021906273439526558\n",
      "Epoch 8, Batch 8800, Loss: 0.02736016921699047\n",
      "Epoch 8, Batch 8900, Loss: 0.011681866832077503\n",
      "Epoch 8, Batch 9000, Loss: 0.03248831257224083\n",
      "Epoch 8, Batch 9100, Loss: 0.04986543208360672\n",
      "Epoch 8, Batch 9200, Loss: 0.02381141111254692\n",
      "Epoch 8, Batch 9300, Loss: 0.026946458965539932\n",
      "Epoch 8, Batch 9400, Loss: 0.018294617533683777\n",
      "Epoch 8, Batch 9500, Loss: 0.043529849499464035\n",
      "Epoch 8, Batch 9600, Loss: 0.01905537210404873\n",
      "Epoch 8, Batch 9700, Loss: 0.10426748543977737\n",
      "Epoch 8, Batch 9800, Loss: 0.030571935698390007\n",
      "Epoch 8, Batch 9900, Loss: 0.05064692720770836\n",
      "Epoch 8, Batch 10000, Loss: 0.016177719458937645\n",
      "Epoch 8, Batch 10100, Loss: 0.04259095713496208\n",
      "Epoch 8, Batch 10200, Loss: 0.03425714373588562\n",
      "Epoch 8, Batch 10300, Loss: 0.06371740996837616\n",
      "Epoch 8, Batch 10400, Loss: 0.01954616978764534\n",
      "Epoch 8, Batch 10500, Loss: 0.024316610768437386\n",
      "Epoch 8, Batch 10600, Loss: 0.0280232522636652\n",
      "Epoch 8, Batch 10700, Loss: 0.05324171110987663\n",
      "Epoch 8, Batch 10800, Loss: 0.045187003910541534\n",
      "Epoch 8, Batch 10900, Loss: 0.02836187370121479\n",
      "Epoch 8, Batch 11000, Loss: 0.03535468503832817\n",
      "Epoch 8, Batch 11100, Loss: 0.026501797139644623\n",
      "Epoch 8, Batch 11200, Loss: 0.06886841356754303\n",
      "Epoch 8, Batch 11300, Loss: 0.022998282685875893\n",
      "Epoch 8, Batch 11400, Loss: 0.027526017278432846\n",
      "Epoch 8, Batch 11500, Loss: 0.10939440131187439\n",
      "Epoch 8, Batch 11600, Loss: 0.028680521994829178\n",
      "Epoch 8, Batch 11700, Loss: 0.03978349268436432\n",
      "Epoch 8, Batch 11800, Loss: 0.024449547752738\n",
      "Epoch 8, Batch 11900, Loss: 0.05001832917332649\n",
      "Epoch 8, Batch 12000, Loss: 0.03917108476161957\n",
      "Epoch 8, Batch 12100, Loss: 0.03726811334490776\n",
      "Epoch 8, Batch 12200, Loss: 0.024470802396535873\n",
      "Epoch 8, Batch 12300, Loss: 0.009667521342635155\n",
      "Epoch 8, Batch 12400, Loss: 0.01417735405266285\n",
      "Epoch 8, Batch 12500, Loss: 0.024577107280492783\n",
      "Epoch 8, Batch 12600, Loss: 0.05658085271716118\n",
      "Epoch 8, Batch 12700, Loss: 0.04643382504582405\n",
      "Epoch 8, Batch 12800, Loss: 0.037465743720531464\n",
      "Epoch 8, Batch 12900, Loss: 0.05219227075576782\n",
      "Epoch 8, Batch 13000, Loss: 0.02322203479707241\n",
      "Epoch 8, Batch 13100, Loss: 0.030712539330124855\n",
      "Epoch 8, Batch 13200, Loss: 0.052821703255176544\n",
      "Epoch 8, Batch 13300, Loss: 0.02194826677441597\n",
      "Epoch 8, Batch 13400, Loss: 0.02795022539794445\n",
      "Epoch 8, Batch 13500, Loss: 0.028209839016199112\n",
      "Epoch 8, Batch 13600, Loss: 0.021124452352523804\n",
      "Epoch 8, Batch 13700, Loss: 0.01682494580745697\n",
      "Epoch 8, Batch 13800, Loss: 0.030278529971837997\n",
      "Epoch 8, Batch 13900, Loss: 0.04628278687596321\n",
      "Epoch 8, Batch 14000, Loss: 0.0291102584451437\n",
      "Epoch 8, Batch 14100, Loss: 0.02753051556646824\n",
      "Epoch 8, Batch 14200, Loss: 0.020390674471855164\n",
      "Epoch 8, Batch 14300, Loss: 0.017291592434048653\n",
      "Epoch 8, Batch 14400, Loss: 0.045652441680431366\n",
      "Epoch 8, Batch 14500, Loss: 0.017921727150678635\n",
      "Epoch 8, Batch 14600, Loss: 0.023952940478920937\n",
      "Epoch 8, Batch 14700, Loss: 0.02205844223499298\n",
      "Epoch 8, Batch 14800, Loss: 0.01919839158654213\n",
      "Epoch 8, Batch 14900, Loss: 0.02594914101064205\n",
      "Epoch 8, Batch 15000, Loss: 0.01442022155970335\n",
      "Epoch 8, Batch 15100, Loss: 0.0854494497179985\n",
      "Epoch 8, Batch 15200, Loss: 0.09461340308189392\n",
      "Epoch 8, Batch 15300, Loss: 0.022052528336644173\n",
      "Epoch 8, Batch 15400, Loss: 0.019619204103946686\n",
      "Epoch 8, Batch 15500, Loss: 0.016678599640727043\n",
      "Epoch 8, Batch 15600, Loss: 0.03841376304626465\n",
      "Epoch 8, Batch 15700, Loss: 0.04880010336637497\n",
      "Epoch 8, Batch 15800, Loss: 0.020034775137901306\n",
      "Epoch 8, Batch 15900, Loss: 0.02936655655503273\n",
      "Epoch 8, Batch 16000, Loss: 0.018532786518335342\n",
      "Epoch 8, Batch 16100, Loss: 0.020485149696469307\n",
      "Epoch 8, Batch 16200, Loss: 0.02321433834731579\n",
      "Epoch 8, Batch 16300, Loss: 0.04852340370416641\n",
      "Epoch 8, Batch 16400, Loss: 0.03219795599579811\n",
      "Epoch 8, Batch 16500, Loss: 0.023323960602283478\n",
      "Epoch 8, Batch 16600, Loss: 0.02667461521923542\n",
      "Epoch 8, Batch 16700, Loss: 0.01900257170200348\n",
      "Epoch 8, Batch 16800, Loss: 0.06364982575178146\n",
      "Epoch 8, Batch 16900, Loss: 0.04184025898575783\n",
      "Epoch 8, Batch 17000, Loss: 0.022572126239538193\n",
      "Epoch 8, Batch 17100, Loss: 0.046365853399038315\n",
      "Epoch 8, Batch 17200, Loss: 0.0482994019985199\n",
      "Epoch 8, Batch 17300, Loss: 0.028586341068148613\n",
      "Epoch 8, Batch 17400, Loss: 0.0233121570199728\n",
      "Epoch 8, Batch 17500, Loss: 0.024190092459321022\n",
      "Epoch 8, Batch 17600, Loss: 0.03234102949500084\n",
      "Epoch 8, Batch 17700, Loss: 0.0541546568274498\n",
      "Epoch 8, Batch 17800, Loss: 0.017198845744132996\n",
      "Epoch 8, Batch 17900, Loss: 0.02248404175043106\n",
      "Epoch 8, Batch 18000, Loss: 0.026521388441324234\n",
      "Epoch 8, Batch 18100, Loss: 0.0281300600618124\n",
      "Epoch 8, Batch 18200, Loss: 0.017357073724269867\n",
      "Epoch 8, Batch 18300, Loss: 0.0360390767455101\n",
      "Epoch 8, Batch 18400, Loss: 0.028035899624228477\n",
      "Epoch 8, Batch 18500, Loss: 0.04450698569417\n",
      "Epoch 8, Batch 18600, Loss: 0.012924127280712128\n",
      "Epoch 8, Batch 18700, Loss: 0.047264691442251205\n",
      "Epoch 8, Batch 18800, Loss: 0.020533021539449692\n",
      "Epoch 8, Batch 18900, Loss: 0.022619249299168587\n",
      "Epoch 8, Batch 19000, Loss: 0.03801150992512703\n",
      "Epoch 8, Batch 19100, Loss: 0.022195180878043175\n",
      "Epoch 8, Batch 19200, Loss: 0.012289253063499928\n",
      "Epoch 8, Batch 19300, Loss: 0.022348923608660698\n",
      "Epoch 8, Batch 19400, Loss: 0.013262099586427212\n",
      "Epoch 8, Batch 19500, Loss: 0.07820919156074524\n",
      "Epoch 8, Batch 19600, Loss: 0.024760805070400238\n",
      "Epoch 8, Batch 19700, Loss: 0.01747136190533638\n",
      "Epoch 8, Batch 19800, Loss: 0.020359370857477188\n",
      "Epoch 8, Batch 19900, Loss: 0.025383831933140755\n",
      "Epoch 8, Batch 20000, Loss: 0.013577679172158241\n",
      "Epoch 8, Batch 20100, Loss: 0.016296613961458206\n",
      "Epoch 8, Batch 20200, Loss: 0.04984528198838234\n",
      "Epoch 8, Batch 20300, Loss: 0.014628367498517036\n",
      "Epoch 8, Batch 20400, Loss: 0.01908542588353157\n",
      "Epoch 8, Batch 20500, Loss: 0.014792951755225658\n",
      "Epoch 8, Batch 20600, Loss: 0.06728611141443253\n",
      "Epoch 8, Batch 20700, Loss: 0.025746725499629974\n",
      "Epoch 8, Batch 20800, Loss: 0.038464486598968506\n",
      "Epoch 8, Batch 20900, Loss: 0.019667210057377815\n",
      "Epoch 8, Batch 21000, Loss: 0.0299000795930624\n",
      "Epoch 8, Batch 21100, Loss: 0.034469861537218094\n",
      "Epoch 8, Batch 21200, Loss: 0.018780965358018875\n",
      "Epoch 8, Batch 21300, Loss: 0.04899006336927414\n",
      "Epoch 8, Batch 21400, Loss: 0.016523361206054688\n",
      "Epoch 8, Batch 21500, Loss: 0.02130092680454254\n",
      "Epoch 8, Batch 21600, Loss: 0.02277355268597603\n",
      "Epoch 8, Batch 21700, Loss: 0.014734084717929363\n",
      "Epoch 8, Batch 21800, Loss: 0.06360059231519699\n",
      "Epoch 8, Batch 21900, Loss: 0.03104173019528389\n",
      "Epoch 8, Batch 22000, Loss: 0.07617495208978653\n",
      "Epoch 8, Batch 22100, Loss: 0.03310512378811836\n",
      "Epoch 8, Batch 22200, Loss: 0.030681312084197998\n",
      "Epoch 8, Batch 22300, Loss: 0.02585333026945591\n",
      "Epoch 8, Batch 22400, Loss: 0.015337741933763027\n",
      "Epoch 8, Batch 22500, Loss: 0.0197673998773098\n",
      "Epoch 8, Batch 22600, Loss: 0.01332015823572874\n",
      "Epoch 8, Batch 22700, Loss: 0.012190300039947033\n",
      "Epoch 8, Batch 22800, Loss: 0.044195182621479034\n",
      "Epoch 8, Batch 22900, Loss: 0.019842229783535004\n",
      "Epoch 8, Batch 23000, Loss: 0.015322817489504814\n",
      "Epoch 8, Batch 23100, Loss: 0.010453362949192524\n",
      "Epoch 8, Batch 23200, Loss: 0.02253098227083683\n",
      "Epoch 8, Batch 23300, Loss: 0.030296606943011284\n",
      "Epoch 8, Batch 23400, Loss: 0.02118363045156002\n",
      "Epoch 8, Batch 23500, Loss: 0.034933771938085556\n",
      "Epoch 8, Batch 23600, Loss: 0.04074186086654663\n",
      "Epoch 8, Batch 23700, Loss: 0.017452029511332512\n",
      "Epoch 8, Batch 23800, Loss: 0.04253962263464928\n",
      "Epoch 8, Batch 23900, Loss: 0.0230855792760849\n",
      "Epoch 8, Batch 24000, Loss: 0.016525108367204666\n",
      "Epoch 8, Batch 24100, Loss: 0.014602701179683208\n",
      "Epoch 8, Batch 24200, Loss: 0.01795092038810253\n",
      "Epoch 8, Batch 24300, Loss: 0.015459373593330383\n",
      "Epoch 8, Batch 24400, Loss: 0.026253782212734222\n",
      "Epoch 8, Batch 24500, Loss: 0.017239471897482872\n",
      "Epoch 8, Batch 24600, Loss: 0.02807948738336563\n",
      "Epoch 8, Batch 24700, Loss: 0.0242010410875082\n",
      "Epoch 8, Batch 24800, Loss: 0.020296772941946983\n",
      "Epoch 8, Batch 24900, Loss: 0.030455294996500015\n",
      "Epoch 8, Batch 25000, Loss: 0.06400842219591141\n",
      "Epoch 8, Batch 25100, Loss: 0.027785910293459892\n",
      "Epoch 8, Batch 25200, Loss: 0.073671355843544\n",
      "Epoch 8, Batch 25300, Loss: 0.05082957074046135\n",
      "Epoch 8, Batch 25400, Loss: 0.016566811129450798\n",
      "Epoch 8, Batch 25500, Loss: 0.029245808720588684\n",
      "Epoch 8, Batch 25600, Loss: 0.03259166702628136\n",
      "Epoch 8, Batch 25700, Loss: 0.058899782598018646\n",
      "Epoch 8, Batch 25800, Loss: 0.026471156626939774\n",
      "Epoch 8, Batch 25900, Loss: 0.02889450080692768\n",
      "Epoch 8, Batch 26000, Loss: 0.04772903770208359\n",
      "Epoch 8, Batch 26100, Loss: 0.011698020622134209\n",
      "Epoch 8, Batch 26200, Loss: 0.016391828656196594\n",
      "Epoch 8, Batch 26300, Loss: 0.014313925057649612\n",
      "Epoch 8, Batch 26400, Loss: 0.03473740443587303\n",
      "Epoch 8, Batch 26500, Loss: 0.029141511768102646\n",
      "Epoch 8, Batch 26600, Loss: 0.01486002653837204\n",
      "Epoch 8, Batch 26700, Loss: 0.014242349192500114\n",
      "Epoch 8, Batch 26800, Loss: 0.024498313665390015\n",
      "Epoch 8, Batch 26900, Loss: 0.02330157719552517\n",
      "Epoch 8, Batch 27000, Loss: 0.02202465943992138\n",
      "Epoch 8, Batch 27100, Loss: 0.042527057230472565\n",
      "Epoch 8, Batch 27200, Loss: 0.03017697110772133\n",
      "Epoch 8, Batch 27300, Loss: 0.01956912875175476\n",
      "Epoch 8, Batch 27400, Loss: 0.024210797622799873\n",
      "Epoch 8, Batch 27500, Loss: 0.02340962179005146\n",
      "Epoch 8, Batch 27600, Loss: 0.023402826860547066\n",
      "Epoch 8, Batch 27700, Loss: 0.014903121627867222\n",
      "Epoch 8, Batch 27800, Loss: 0.015316554345190525\n",
      "Epoch 8, Batch 27900, Loss: 0.025707222521305084\n",
      "Epoch 8, Batch 28000, Loss: 0.010607780888676643\n",
      "Epoch 8, Batch 28100, Loss: 0.03383680433034897\n",
      "Epoch 8, Batch 28200, Loss: 0.022290760651230812\n",
      "Epoch 8, Batch 28300, Loss: 0.013970901258289814\n",
      "Epoch 8, Batch 28400, Loss: 0.04626806825399399\n",
      "Epoch 8, Batch 28500, Loss: 0.02400730364024639\n",
      "Epoch 8, Batch 28600, Loss: 0.028054744005203247\n",
      "Epoch 8, Batch 28700, Loss: 0.014267852529883385\n",
      "Epoch 8, Batch 28800, Loss: 0.02941030263900757\n",
      "Epoch 8, Batch 28900, Loss: 0.030711814761161804\n",
      "Epoch 8, Batch 29000, Loss: 0.014341897331178188\n",
      "Epoch 8, Batch 29100, Loss: 0.02865719422698021\n",
      "Epoch 8, Batch 29200, Loss: 0.0210121963173151\n",
      "Epoch 8, Batch 29300, Loss: 0.033822134137153625\n",
      "Epoch 8, Batch 29400, Loss: 0.036335017532110214\n",
      "Epoch 8, Batch 29500, Loss: 0.020618805661797523\n",
      "Epoch 8, Batch 29600, Loss: 0.04108629375696182\n",
      "Epoch 8, Batch 29700, Loss: 0.017296800389885902\n",
      "Epoch 8, Batch 29800, Loss: 0.01328929141163826\n",
      "Epoch 8, Batch 29900, Loss: 0.03826940059661865\n",
      "Epoch 8, Batch 30000, Loss: 0.007889592088758945\n",
      "Epoch 8, Batch 30100, Loss: 0.01062186062335968\n",
      "Epoch 8, Batch 30200, Loss: 0.024420158937573433\n",
      "Epoch 8, Batch 30300, Loss: 0.030394161120057106\n",
      "Epoch 8, Batch 30400, Loss: 0.025948630645871162\n",
      "Epoch 8, Batch 30500, Loss: 0.03477058187127113\n",
      "Epoch 8, Batch 30600, Loss: 0.01859232783317566\n",
      "Epoch 8, Batch 30700, Loss: 0.06754624098539352\n",
      "Epoch 8, Batch 30800, Loss: 0.018460426479578018\n",
      "Epoch 8, Batch 30900, Loss: 0.022660542279481888\n",
      "Epoch 8, Batch 31000, Loss: 0.026344511657953262\n",
      "Epoch 8, Batch 31100, Loss: 0.015688838437199593\n",
      "Epoch 8, Batch 31200, Loss: 0.0177061315625906\n",
      "Epoch 8, Batch 31300, Loss: 0.05285486951470375\n",
      "Epoch 8, Batch 31400, Loss: 0.02609432302415371\n",
      "Epoch 8, Batch 31500, Loss: 0.04124099761247635\n",
      "Epoch 8, Batch 31600, Loss: 0.01309905294328928\n",
      "Epoch 8, Batch 31700, Loss: 0.01825825683772564\n",
      "Epoch 8, Batch 31800, Loss: 0.04703987389802933\n",
      "Epoch 8, Batch 31900, Loss: 0.020911339670419693\n",
      "Epoch 8, Batch 32000, Loss: 0.01598682440817356\n",
      "Epoch 8, Batch 32100, Loss: 0.016354665160179138\n",
      "Epoch 8, Batch 32200, Loss: 0.018931861966848373\n",
      "Epoch 8, Batch 32300, Loss: 0.013333461247384548\n",
      "Epoch 8, Batch 32400, Loss: 0.01783154346048832\n",
      "Epoch 8, Batch 32500, Loss: 0.004484099335968494\n",
      "Epoch 8, Batch 32600, Loss: 0.11596377938985825\n",
      "Epoch 8, Batch 32700, Loss: 0.026590505614876747\n",
      "Epoch 8, Batch 32800, Loss: 0.020653728395700455\n",
      "Epoch 8, Batch 32900, Loss: 0.027792342007160187\n",
      "Epoch 8, Batch 33000, Loss: 0.054404012858867645\n",
      "Epoch 8, Batch 33100, Loss: 0.025967374444007874\n",
      "Epoch 8, Batch 33200, Loss: 0.020593740046024323\n",
      "Epoch 8, Batch 33300, Loss: 0.018755564466118813\n",
      "Epoch 8, Batch 33400, Loss: 0.02757481299340725\n",
      "Epoch 8, Batch 33500, Loss: 0.04263009876012802\n",
      "Epoch 8, Batch 33600, Loss: 0.017364172264933586\n",
      "Epoch 8, Batch 33700, Loss: 0.02556302770972252\n",
      "Epoch 8, Batch 33800, Loss: 0.014208756387233734\n",
      "Epoch 8, Batch 33900, Loss: 0.02262459695339203\n",
      "Epoch 8, Batch 34000, Loss: 0.020458422601222992\n",
      "Epoch 8, Batch 34100, Loss: 0.04535309970378876\n",
      "Epoch 8, Batch 34200, Loss: 0.015734722837805748\n",
      "Epoch 8, Batch 34300, Loss: 0.03640994429588318\n",
      "Epoch 8, Batch 34400, Loss: 0.014156338758766651\n",
      "Epoch 8, Batch 34500, Loss: 0.0236982312053442\n",
      "Epoch 8, Batch 34600, Loss: 0.008276168256998062\n",
      "Epoch 8, Batch 34700, Loss: 0.028269415721297264\n",
      "Epoch 8, Batch 34800, Loss: 0.01756642386317253\n",
      "Epoch 8, Batch 34900, Loss: 0.03242380917072296\n",
      "Epoch 8, Batch 35000, Loss: 0.03260047733783722\n",
      "Epoch 8, Batch 35100, Loss: 0.02777952514588833\n",
      "Epoch 8, Batch 35200, Loss: 0.03689788281917572\n",
      "Epoch 8, Batch 35300, Loss: 0.07059696316719055\n",
      "Epoch 8, Batch 35400, Loss: 0.03049994260072708\n",
      "Epoch 8, Batch 35500, Loss: 0.014411254785954952\n",
      "Epoch 8, Batch 35600, Loss: 0.023627445101737976\n",
      "Epoch 8, Batch 35700, Loss: 0.05285480245947838\n",
      "Epoch 8, Batch 35800, Loss: 0.016194982454180717\n",
      "Epoch 8, Batch 35900, Loss: 0.022496122866868973\n",
      "Epoch 8, Batch 36000, Loss: 0.023805297911167145\n",
      "Epoch 8, Batch 36100, Loss: 0.010901878587901592\n",
      "Epoch 8, Batch 36200, Loss: 0.02373930811882019\n",
      "Epoch 8, Batch 36300, Loss: 0.015038866549730301\n",
      "Epoch 8, Batch 36400, Loss: 0.014532940462231636\n",
      "Epoch 8, Batch 36500, Loss: 0.013040538877248764\n",
      "Epoch 8, Batch 36600, Loss: 0.020683156326413155\n",
      "Epoch 8, Batch 36700, Loss: 0.010270779952406883\n",
      "Epoch 8, Batch 36800, Loss: 0.03172523155808449\n",
      "Validation Loss: 2.699700722552538\n",
      "Epoch 9, Batch 100, Loss: 0.024994105100631714\n",
      "Epoch 9, Batch 200, Loss: 0.010069268755614758\n",
      "Epoch 9, Batch 300, Loss: 0.0362900085747242\n",
      "Epoch 9, Batch 400, Loss: 0.016484295949339867\n",
      "Epoch 9, Batch 500, Loss: 0.022025708109140396\n",
      "Epoch 9, Batch 600, Loss: 0.021727489307522774\n",
      "Epoch 9, Batch 700, Loss: 0.018880503252148628\n",
      "Epoch 9, Batch 800, Loss: 0.03545784950256348\n",
      "Epoch 9, Batch 900, Loss: 0.014112873002886772\n",
      "Epoch 9, Batch 1000, Loss: 0.020512618124485016\n",
      "Epoch 9, Batch 1100, Loss: 0.01680697314441204\n",
      "Epoch 9, Batch 1200, Loss: 0.02295856736600399\n",
      "Epoch 9, Batch 1300, Loss: 0.04011555388569832\n",
      "Epoch 9, Batch 1400, Loss: 0.016517100855708122\n",
      "Epoch 9, Batch 1500, Loss: 0.032218459993600845\n",
      "Epoch 9, Batch 1600, Loss: 0.019120624288916588\n",
      "Epoch 9, Batch 1700, Loss: 0.009194373153150082\n",
      "Epoch 9, Batch 1800, Loss: 0.013316131196916103\n",
      "Epoch 9, Batch 1900, Loss: 0.02950901910662651\n",
      "Epoch 9, Batch 2000, Loss: 0.015221050009131432\n",
      "Epoch 9, Batch 2100, Loss: 0.030619747936725616\n",
      "Epoch 9, Batch 2200, Loss: 0.012626618146896362\n",
      "Epoch 9, Batch 2300, Loss: 0.014929844997823238\n",
      "Epoch 9, Batch 2400, Loss: 0.03763503581285477\n",
      "Epoch 9, Batch 2500, Loss: 0.028442366048693657\n",
      "Epoch 9, Batch 2600, Loss: 0.09175663441419601\n",
      "Epoch 9, Batch 2700, Loss: 0.023092754185199738\n",
      "Epoch 9, Batch 2800, Loss: 0.0312446728348732\n",
      "Epoch 9, Batch 2900, Loss: 0.03297000005841255\n",
      "Epoch 9, Batch 3000, Loss: 0.0433802530169487\n",
      "Epoch 9, Batch 3100, Loss: 0.03087918646633625\n",
      "Epoch 9, Batch 3200, Loss: 0.01903487741947174\n",
      "Epoch 9, Batch 3300, Loss: 0.01610281504690647\n",
      "Epoch 9, Batch 3400, Loss: 0.02998616360127926\n",
      "Epoch 9, Batch 3500, Loss: 0.014838107861578465\n",
      "Epoch 9, Batch 3600, Loss: 0.014329373836517334\n",
      "Epoch 9, Batch 3700, Loss: 0.015261691994965076\n",
      "Epoch 9, Batch 3800, Loss: 0.03568801283836365\n",
      "Epoch 9, Batch 3900, Loss: 0.025199903175234795\n",
      "Epoch 9, Batch 4000, Loss: 0.015974415466189384\n",
      "Epoch 9, Batch 4100, Loss: 0.02563782036304474\n",
      "Epoch 9, Batch 4200, Loss: 0.03363125026226044\n",
      "Epoch 9, Batch 4300, Loss: 0.03611152246594429\n",
      "Epoch 9, Batch 4400, Loss: 0.03494790941476822\n",
      "Epoch 9, Batch 4500, Loss: 0.006918489933013916\n",
      "Epoch 9, Batch 4600, Loss: 0.029252473264932632\n",
      "Epoch 9, Batch 4700, Loss: 0.02790161408483982\n",
      "Epoch 9, Batch 4800, Loss: 0.03090852126479149\n",
      "Epoch 9, Batch 4900, Loss: 0.019076770171523094\n",
      "Epoch 9, Batch 5000, Loss: 0.04530923813581467\n",
      "Epoch 9, Batch 5100, Loss: 0.027407966554164886\n",
      "Epoch 9, Batch 5200, Loss: 0.04103241115808487\n",
      "Epoch 9, Batch 5300, Loss: 0.021084407344460487\n",
      "Epoch 9, Batch 5400, Loss: 0.015894591808319092\n",
      "Epoch 9, Batch 5500, Loss: 0.018588166683912277\n",
      "Epoch 9, Batch 5600, Loss: 0.031088491901755333\n",
      "Epoch 9, Batch 5700, Loss: 0.011118665337562561\n",
      "Epoch 9, Batch 5800, Loss: 0.01809883303940296\n",
      "Epoch 9, Batch 5900, Loss: 0.01125628687441349\n",
      "Epoch 9, Batch 6000, Loss: 0.015383808873593807\n",
      "Epoch 9, Batch 6100, Loss: 0.054466769099235535\n",
      "Epoch 9, Batch 6200, Loss: 0.026297548785805702\n",
      "Epoch 9, Batch 6300, Loss: 0.029765386134386063\n",
      "Epoch 9, Batch 6400, Loss: 0.029988611117005348\n",
      "Epoch 9, Batch 6500, Loss: 0.020583035424351692\n",
      "Epoch 9, Batch 6600, Loss: 0.005201279651373625\n",
      "Epoch 9, Batch 6700, Loss: 0.00930803082883358\n",
      "Epoch 9, Batch 6800, Loss: 0.020831694826483727\n",
      "Epoch 9, Batch 6900, Loss: 0.023913560435175896\n",
      "Epoch 9, Batch 7000, Loss: 0.0536964125931263\n",
      "Epoch 9, Batch 7100, Loss: 0.04610360413789749\n",
      "Epoch 9, Batch 7200, Loss: 0.01899200864136219\n",
      "Epoch 9, Batch 7300, Loss: 0.01545337587594986\n",
      "Epoch 9, Batch 7400, Loss: 0.023538140580058098\n",
      "Epoch 9, Batch 7500, Loss: 0.04404175281524658\n",
      "Epoch 9, Batch 7600, Loss: 0.0607793815433979\n",
      "Epoch 9, Batch 7700, Loss: 0.015308630652725697\n",
      "Epoch 9, Batch 7800, Loss: 0.00854997057467699\n",
      "Epoch 9, Batch 7900, Loss: 0.01957312785089016\n",
      "Epoch 9, Batch 8000, Loss: 0.025061331689357758\n",
      "Epoch 9, Batch 8100, Loss: 0.027558010071516037\n",
      "Epoch 9, Batch 8200, Loss: 0.0218869186937809\n",
      "Epoch 9, Batch 8300, Loss: 0.024303872138261795\n",
      "Epoch 9, Batch 8400, Loss: 0.0823889747262001\n",
      "Epoch 9, Batch 8500, Loss: 0.02612598054111004\n",
      "Epoch 9, Batch 8600, Loss: 0.03127674013376236\n",
      "Epoch 9, Batch 8700, Loss: 0.02410617098212242\n",
      "Epoch 9, Batch 8800, Loss: 0.020035289227962494\n",
      "Epoch 9, Batch 8900, Loss: 0.020965304225683212\n",
      "Epoch 9, Batch 9000, Loss: 0.017359534278512\n",
      "Epoch 9, Batch 9100, Loss: 0.00982670858502388\n",
      "Epoch 9, Batch 9200, Loss: 0.031053248792886734\n",
      "Epoch 9, Batch 9300, Loss: 0.014929642900824547\n",
      "Epoch 9, Batch 9400, Loss: 0.02750798501074314\n",
      "Epoch 9, Batch 9500, Loss: 0.00690421462059021\n",
      "Epoch 9, Batch 9600, Loss: 0.015873899683356285\n",
      "Epoch 9, Batch 9700, Loss: 0.012001844123005867\n",
      "Epoch 9, Batch 9800, Loss: 0.026798775419592857\n",
      "Epoch 9, Batch 9900, Loss: 0.029802169650793076\n",
      "Epoch 9, Batch 10000, Loss: 0.06264407932758331\n",
      "Epoch 9, Batch 10100, Loss: 0.02040858194231987\n",
      "Epoch 9, Batch 10200, Loss: 0.027694592252373695\n",
      "Epoch 9, Batch 10300, Loss: 0.031028063967823982\n",
      "Epoch 9, Batch 10400, Loss: 0.01706191897392273\n",
      "Epoch 9, Batch 10500, Loss: 0.04862663149833679\n",
      "Epoch 9, Batch 10600, Loss: 0.015777340158820152\n",
      "Epoch 9, Batch 10700, Loss: 0.029153399169445038\n",
      "Epoch 9, Batch 10800, Loss: 0.03157322108745575\n",
      "Epoch 9, Batch 10900, Loss: 0.02218778431415558\n",
      "Epoch 9, Batch 11000, Loss: 0.023865802213549614\n",
      "Epoch 9, Batch 11100, Loss: 0.03433667868375778\n",
      "Epoch 9, Batch 11200, Loss: 0.016888178884983063\n",
      "Epoch 9, Batch 11300, Loss: 0.022376861423254013\n",
      "Epoch 9, Batch 11400, Loss: 0.028795666992664337\n",
      "Epoch 9, Batch 11500, Loss: 0.025712499395012856\n",
      "Epoch 9, Batch 11600, Loss: 0.019921060651540756\n",
      "Epoch 9, Batch 11700, Loss: 0.017220400273799896\n",
      "Epoch 9, Batch 11800, Loss: 0.047695305198431015\n",
      "Epoch 9, Batch 11900, Loss: 0.011239281855523586\n",
      "Epoch 9, Batch 12000, Loss: 0.02501906268298626\n",
      "Epoch 9, Batch 12100, Loss: 0.013854123651981354\n",
      "Epoch 9, Batch 12200, Loss: 0.029743781313300133\n",
      "Epoch 9, Batch 12300, Loss: 0.07606092095375061\n",
      "Epoch 9, Batch 12400, Loss: 0.019287286326289177\n",
      "Epoch 9, Batch 12500, Loss: 0.04660644754767418\n",
      "Epoch 9, Batch 12600, Loss: 0.00925663486123085\n",
      "Epoch 9, Batch 12700, Loss: 0.02941027283668518\n",
      "Epoch 9, Batch 12800, Loss: 0.024656623601913452\n",
      "Epoch 9, Batch 12900, Loss: 0.03279436379671097\n",
      "Epoch 9, Batch 13000, Loss: 0.039130404591560364\n",
      "Epoch 9, Batch 13100, Loss: 0.020255517214536667\n",
      "Epoch 9, Batch 13200, Loss: 0.05184946581721306\n",
      "Epoch 9, Batch 13300, Loss: 0.014011082239449024\n",
      "Epoch 9, Batch 13400, Loss: 0.023432202637195587\n",
      "Epoch 9, Batch 13500, Loss: 0.027017949149012566\n",
      "Epoch 9, Batch 13600, Loss: 0.027961580082774162\n",
      "Epoch 9, Batch 13700, Loss: 0.012924599461257458\n",
      "Epoch 9, Batch 13800, Loss: 0.044048208743333817\n",
      "Epoch 9, Batch 13900, Loss: 0.010823520831763744\n",
      "Epoch 9, Batch 14000, Loss: 0.05915430560708046\n",
      "Epoch 9, Batch 14100, Loss: 0.039197634905576706\n",
      "Epoch 9, Batch 14200, Loss: 0.03543011099100113\n",
      "Epoch 9, Batch 14300, Loss: 0.03283869847655296\n",
      "Epoch 9, Batch 14400, Loss: 0.021559197455644608\n",
      "Epoch 9, Batch 14500, Loss: 0.017902404069900513\n",
      "Epoch 9, Batch 14600, Loss: 0.014875245280563831\n",
      "Epoch 9, Batch 14700, Loss: 0.03724562004208565\n",
      "Epoch 9, Batch 14800, Loss: 0.030912956222891808\n",
      "Epoch 9, Batch 14900, Loss: 0.02390323206782341\n",
      "Epoch 9, Batch 15000, Loss: 0.01796562783420086\n",
      "Epoch 9, Batch 15100, Loss: 0.024942977353930473\n",
      "Epoch 9, Batch 15200, Loss: 0.03277922421693802\n",
      "Epoch 9, Batch 15300, Loss: 0.01783997006714344\n",
      "Epoch 9, Batch 15400, Loss: 0.023798808455467224\n",
      "Epoch 9, Batch 15500, Loss: 0.02351316250860691\n",
      "Epoch 9, Batch 15600, Loss: 0.012327268719673157\n",
      "Epoch 9, Batch 15700, Loss: 0.04169343039393425\n",
      "Epoch 9, Batch 15800, Loss: 0.02586403861641884\n",
      "Epoch 9, Batch 15900, Loss: 0.011522958055138588\n",
      "Epoch 9, Batch 16000, Loss: 0.024601642042398453\n",
      "Epoch 9, Batch 16100, Loss: 0.015409035608172417\n",
      "Epoch 9, Batch 16200, Loss: 0.01804821938276291\n",
      "Epoch 9, Batch 16300, Loss: 0.06560168415307999\n",
      "Epoch 9, Batch 16400, Loss: 0.023312009871006012\n",
      "Epoch 9, Batch 16500, Loss: 0.0356309711933136\n",
      "Epoch 9, Batch 16600, Loss: 0.014647760428488255\n",
      "Epoch 9, Batch 16700, Loss: 0.01337997242808342\n",
      "Epoch 9, Batch 16800, Loss: 0.03753022849559784\n",
      "Epoch 9, Batch 16900, Loss: 0.016712544485926628\n",
      "Epoch 9, Batch 17000, Loss: 0.11963961273431778\n",
      "Epoch 9, Batch 17100, Loss: 0.01956544816493988\n",
      "Epoch 9, Batch 17200, Loss: 0.035713572055101395\n",
      "Epoch 9, Batch 17300, Loss: 0.025522703304886818\n",
      "Epoch 9, Batch 17400, Loss: 0.024902720004320145\n",
      "Epoch 9, Batch 17500, Loss: 0.018531696870923042\n",
      "Epoch 9, Batch 17600, Loss: 0.02531520090997219\n",
      "Epoch 9, Batch 17700, Loss: 0.03392910584807396\n",
      "Epoch 9, Batch 17800, Loss: 0.026003511622548103\n",
      "Epoch 9, Batch 17900, Loss: 0.0313817523419857\n",
      "Epoch 9, Batch 18000, Loss: 0.03609980642795563\n",
      "Epoch 9, Batch 18100, Loss: 0.0150668416172266\n",
      "Epoch 9, Batch 18200, Loss: 0.04152867943048477\n",
      "Epoch 9, Batch 18300, Loss: 0.02590455859899521\n",
      "Epoch 9, Batch 18400, Loss: 0.029399501159787178\n",
      "Epoch 9, Batch 18500, Loss: 0.017460834234952927\n",
      "Epoch 9, Batch 18600, Loss: 0.013929923996329308\n",
      "Epoch 9, Batch 18700, Loss: 0.007069615181535482\n",
      "Epoch 9, Batch 18800, Loss: 0.03695608302950859\n",
      "Epoch 9, Batch 18900, Loss: 0.0705394595861435\n",
      "Epoch 9, Batch 19000, Loss: 0.010786333121359348\n",
      "Epoch 9, Batch 19100, Loss: 0.02956141158938408\n",
      "Epoch 9, Batch 19200, Loss: 0.012184752151370049\n",
      "Epoch 9, Batch 19300, Loss: 0.030644718557596207\n",
      "Epoch 9, Batch 19400, Loss: 0.020350171253085136\n",
      "Epoch 9, Batch 19500, Loss: 0.03972986713051796\n",
      "Epoch 9, Batch 19600, Loss: 0.022999729961156845\n",
      "Epoch 9, Batch 19700, Loss: 0.013040767051279545\n",
      "Epoch 9, Batch 19800, Loss: 0.015071477741003036\n",
      "Epoch 9, Batch 19900, Loss: 0.03591635450720787\n",
      "Epoch 9, Batch 20000, Loss: 0.03211958706378937\n",
      "Epoch 9, Batch 20100, Loss: 0.035583555698394775\n",
      "Epoch 9, Batch 20200, Loss: 0.01928105391561985\n",
      "Epoch 9, Batch 20300, Loss: 0.016035614535212517\n",
      "Epoch 9, Batch 20400, Loss: 0.030571086332201958\n",
      "Epoch 9, Batch 20500, Loss: 0.024146443232893944\n",
      "Epoch 9, Batch 20600, Loss: 0.027620891109108925\n",
      "Epoch 9, Batch 20700, Loss: 0.054595015943050385\n",
      "Epoch 9, Batch 20800, Loss: 0.0128097552806139\n",
      "Epoch 9, Batch 20900, Loss: 0.02456640638411045\n",
      "Epoch 9, Batch 21000, Loss: 0.030069692060351372\n",
      "Epoch 9, Batch 21100, Loss: 0.016494452953338623\n",
      "Epoch 9, Batch 21200, Loss: 0.01973734423518181\n",
      "Epoch 9, Batch 21300, Loss: 0.027799280360341072\n",
      "Epoch 9, Batch 21400, Loss: 0.018206201493740082\n",
      "Epoch 9, Batch 21500, Loss: 0.008245433680713177\n",
      "Epoch 9, Batch 21600, Loss: 0.04885895922780037\n",
      "Epoch 9, Batch 21700, Loss: 0.017697758972644806\n",
      "Epoch 9, Batch 21800, Loss: 0.020230229943990707\n",
      "Epoch 9, Batch 21900, Loss: 0.06099264323711395\n",
      "Epoch 9, Batch 22000, Loss: 0.014794553630053997\n",
      "Epoch 9, Batch 22100, Loss: 0.03326752036809921\n",
      "Epoch 9, Batch 22200, Loss: 0.012152216397225857\n",
      "Epoch 9, Batch 22300, Loss: 0.02447391115128994\n",
      "Epoch 9, Batch 22400, Loss: 0.011595879681408405\n",
      "Epoch 9, Batch 22500, Loss: 0.019667496904730797\n",
      "Epoch 9, Batch 22600, Loss: 0.04963652417063713\n",
      "Epoch 9, Batch 22700, Loss: 0.023410683497786522\n",
      "Epoch 9, Batch 22800, Loss: 0.03540622070431709\n",
      "Epoch 9, Batch 22900, Loss: 0.02076081931591034\n",
      "Epoch 9, Batch 23000, Loss: 0.032779425382614136\n",
      "Epoch 9, Batch 23100, Loss: 0.020100539550185204\n",
      "Epoch 9, Batch 23200, Loss: 0.06329706311225891\n",
      "Epoch 9, Batch 23300, Loss: 0.0237731970846653\n",
      "Epoch 9, Batch 23400, Loss: 0.026979079470038414\n",
      "Epoch 9, Batch 23500, Loss: 0.014920816756784916\n",
      "Epoch 9, Batch 23600, Loss: 0.02947445772588253\n",
      "Epoch 9, Batch 23700, Loss: 0.058465782552957535\n",
      "Epoch 9, Batch 23800, Loss: 0.016409626230597496\n",
      "Epoch 9, Batch 23900, Loss: 0.006810647901147604\n",
      "Epoch 9, Batch 24000, Loss: 0.00767263351008296\n",
      "Epoch 9, Batch 24100, Loss: 0.010382169857621193\n",
      "Epoch 9, Batch 24200, Loss: 0.020106809213757515\n",
      "Epoch 9, Batch 24300, Loss: 0.022433273494243622\n",
      "Epoch 9, Batch 24400, Loss: 0.05300267040729523\n",
      "Epoch 9, Batch 24500, Loss: 0.025433629751205444\n",
      "Epoch 9, Batch 24600, Loss: 0.017330635339021683\n",
      "Epoch 9, Batch 24700, Loss: 0.022929709404706955\n",
      "Epoch 9, Batch 24800, Loss: 0.039243925362825394\n",
      "Epoch 9, Batch 24900, Loss: 0.024483544752001762\n",
      "Epoch 9, Batch 25000, Loss: 0.018371451646089554\n",
      "Epoch 9, Batch 25100, Loss: 0.010787085629999638\n",
      "Epoch 9, Batch 25200, Loss: 0.037391722202301025\n",
      "Epoch 9, Batch 25300, Loss: 0.012345590628683567\n",
      "Epoch 9, Batch 25400, Loss: 0.016815101727843285\n",
      "Epoch 9, Batch 25500, Loss: 0.017688246443867683\n",
      "Epoch 9, Batch 25600, Loss: 0.031236372888088226\n",
      "Epoch 9, Batch 25700, Loss: 0.0386856384575367\n",
      "Epoch 9, Batch 25800, Loss: 0.016424668952822685\n",
      "Epoch 9, Batch 25900, Loss: 0.017682000994682312\n",
      "Epoch 9, Batch 26000, Loss: 0.01866203360259533\n",
      "Epoch 9, Batch 26100, Loss: 0.0209162849932909\n",
      "Epoch 9, Batch 26200, Loss: 0.030313901603221893\n",
      "Epoch 9, Batch 26300, Loss: 0.0937475711107254\n",
      "Epoch 9, Batch 26400, Loss: 0.03670034557580948\n",
      "Epoch 9, Batch 26500, Loss: 0.05579809471964836\n",
      "Epoch 9, Batch 26600, Loss: 0.0210146252065897\n",
      "Epoch 9, Batch 26700, Loss: 0.025657951831817627\n",
      "Epoch 9, Batch 26800, Loss: 0.029023943468928337\n",
      "Epoch 9, Batch 26900, Loss: 0.014612166211009026\n",
      "Epoch 9, Batch 27000, Loss: 0.02005757950246334\n",
      "Epoch 9, Batch 27100, Loss: 0.03181128948926926\n",
      "Epoch 9, Batch 27200, Loss: 0.013678769581019878\n",
      "Epoch 9, Batch 27300, Loss: 0.02338586002588272\n",
      "Epoch 9, Batch 27400, Loss: 0.022803427651524544\n",
      "Epoch 9, Batch 27500, Loss: 0.021997764706611633\n",
      "Epoch 9, Batch 27600, Loss: 0.021150875836610794\n",
      "Epoch 9, Batch 27700, Loss: 0.02078067511320114\n",
      "Epoch 9, Batch 27800, Loss: 0.02084590680897236\n",
      "Epoch 9, Batch 27900, Loss: 0.021372759714722633\n",
      "Epoch 9, Batch 28000, Loss: 0.07405687123537064\n",
      "Epoch 9, Batch 28100, Loss: 0.015985671430826187\n",
      "Epoch 9, Batch 28200, Loss: 0.005038451869040728\n",
      "Epoch 9, Batch 28300, Loss: 0.02362341433763504\n",
      "Epoch 9, Batch 28400, Loss: 0.009439418092370033\n",
      "Epoch 9, Batch 28500, Loss: 0.03457179665565491\n",
      "Epoch 9, Batch 28600, Loss: 0.031126948073506355\n",
      "Epoch 9, Batch 28700, Loss: 0.0365142822265625\n",
      "Epoch 9, Batch 28800, Loss: 0.01579275168478489\n",
      "Epoch 9, Batch 28900, Loss: 0.029743874445557594\n",
      "Epoch 9, Batch 29000, Loss: 0.034893788397312164\n",
      "Epoch 9, Batch 29100, Loss: 0.0381295382976532\n",
      "Epoch 9, Batch 29200, Loss: 0.05575404688715935\n",
      "Epoch 9, Batch 29300, Loss: 0.023556698113679886\n",
      "Epoch 9, Batch 29400, Loss: 0.016926735639572144\n",
      "Epoch 9, Batch 29500, Loss: 0.02278839610517025\n",
      "Epoch 9, Batch 29600, Loss: 0.020004676654934883\n",
      "Epoch 9, Batch 29700, Loss: 0.013532417826354504\n",
      "Epoch 9, Batch 29800, Loss: 0.04190390184521675\n",
      "Epoch 9, Batch 29900, Loss: 0.02126177027821541\n",
      "Epoch 9, Batch 30000, Loss: 0.036350928246974945\n",
      "Epoch 9, Batch 30100, Loss: 0.02876446209847927\n",
      "Epoch 9, Batch 30200, Loss: 0.022247139364480972\n",
      "Epoch 9, Batch 30300, Loss: 0.025743363425135612\n",
      "Epoch 9, Batch 30400, Loss: 0.019802968949079514\n",
      "Epoch 9, Batch 30500, Loss: 0.02363532967865467\n",
      "Epoch 9, Batch 30600, Loss: 0.019018135964870453\n",
      "Epoch 9, Batch 30700, Loss: 0.046708572655916214\n",
      "Epoch 9, Batch 30800, Loss: 0.03482791781425476\n",
      "Epoch 9, Batch 30900, Loss: 0.03172960504889488\n",
      "Epoch 9, Batch 31000, Loss: 0.02014540322124958\n",
      "Epoch 9, Batch 31100, Loss: 0.019077476114034653\n",
      "Epoch 9, Batch 31200, Loss: 0.022086141631007195\n",
      "Epoch 9, Batch 31300, Loss: 0.09385129064321518\n",
      "Epoch 9, Batch 31400, Loss: 0.027137450873851776\n",
      "Epoch 9, Batch 31500, Loss: 0.015479577705264091\n",
      "Epoch 9, Batch 31600, Loss: 0.032771456986665726\n",
      "Epoch 9, Batch 31700, Loss: 0.015987006947398186\n",
      "Epoch 9, Batch 31800, Loss: 0.03637905418872833\n",
      "Epoch 9, Batch 31900, Loss: 0.027080537751317024\n",
      "Epoch 9, Batch 32000, Loss: 0.028191285207867622\n",
      "Epoch 9, Batch 32100, Loss: 0.023023175075650215\n",
      "Epoch 9, Batch 32200, Loss: 0.025319362059235573\n",
      "Epoch 9, Batch 32300, Loss: 0.027069702744483948\n",
      "Epoch 9, Batch 32400, Loss: 0.018755866214632988\n",
      "Epoch 9, Batch 32500, Loss: 0.02674398012459278\n",
      "Epoch 9, Batch 32600, Loss: 0.04860487952828407\n",
      "Epoch 9, Batch 32700, Loss: 0.04275168851017952\n",
      "Epoch 9, Batch 32800, Loss: 0.01684243604540825\n",
      "Epoch 9, Batch 32900, Loss: 0.0642271637916565\n",
      "Epoch 9, Batch 33000, Loss: 0.01627391204237938\n",
      "Epoch 9, Batch 33100, Loss: 0.01654670014977455\n",
      "Epoch 9, Batch 33200, Loss: 0.007583556231111288\n",
      "Epoch 9, Batch 33300, Loss: 0.03571684658527374\n",
      "Epoch 9, Batch 33400, Loss: 0.01006114948540926\n",
      "Epoch 9, Batch 33500, Loss: 0.027260608971118927\n",
      "Epoch 9, Batch 33600, Loss: 0.024112146347761154\n",
      "Epoch 9, Batch 33700, Loss: 0.05399652197957039\n",
      "Epoch 9, Batch 33800, Loss: 0.023794131353497505\n",
      "Epoch 9, Batch 33900, Loss: 0.02573542483150959\n",
      "Epoch 9, Batch 34000, Loss: 0.03786741942167282\n",
      "Epoch 9, Batch 34100, Loss: 0.02469610422849655\n",
      "Epoch 9, Batch 34200, Loss: 0.03900361433625221\n",
      "Epoch 9, Batch 34300, Loss: 0.018233904615044594\n",
      "Epoch 9, Batch 34400, Loss: 0.044359758496284485\n",
      "Epoch 9, Batch 34500, Loss: 0.022937223315238953\n",
      "Epoch 9, Batch 34600, Loss: 0.034418150782585144\n",
      "Epoch 9, Batch 34700, Loss: 0.03330769017338753\n",
      "Epoch 9, Batch 34800, Loss: 0.03463754430413246\n",
      "Epoch 9, Batch 34900, Loss: 0.05015765130519867\n",
      "Epoch 9, Batch 35000, Loss: 0.03652438893914223\n",
      "Epoch 9, Batch 35100, Loss: 0.01794249750673771\n",
      "Epoch 9, Batch 35200, Loss: 0.016634514555335045\n",
      "Epoch 9, Batch 35300, Loss: 0.038359951227903366\n",
      "Epoch 9, Batch 35400, Loss: 0.03436402976512909\n",
      "Epoch 9, Batch 35500, Loss: 0.044416580349206924\n",
      "Epoch 9, Batch 35600, Loss: 0.02224193885922432\n",
      "Epoch 9, Batch 35700, Loss: 0.02134764939546585\n",
      "Epoch 9, Batch 35800, Loss: 0.0334136001765728\n",
      "Epoch 9, Batch 35900, Loss: 0.0704164057970047\n",
      "Epoch 9, Batch 36000, Loss: 0.0360819473862648\n",
      "Epoch 9, Batch 36100, Loss: 0.03033454716205597\n",
      "Epoch 9, Batch 36200, Loss: 0.020672868937253952\n",
      "Epoch 9, Batch 36300, Loss: 0.021931858733296394\n",
      "Epoch 9, Batch 36400, Loss: 0.023186855018138885\n",
      "Epoch 9, Batch 36500, Loss: 0.02513868175446987\n",
      "Epoch 9, Batch 36600, Loss: 0.0388406366109848\n",
      "Epoch 9, Batch 36700, Loss: 0.021363671869039536\n",
      "Epoch 9, Batch 36800, Loss: 0.026930171996355057\n",
      "Validation Loss: 2.8566470191705227\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Assuming the model is already defined and moved to the correct device\n",
    "model = model.to(device)  # Ensure model is on the correct device\n",
    "optimizer = Adam(model.parameters(), lr=5e-5)  # Define optimizer\n",
    "\n",
    "# Define DataLoader for both training and validation datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=16)\n",
    "\n",
    "print('Data Loaders Defined')\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10  # Define the number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}  # Move batch data to the correct device\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=batch['input_ids'],\n",
    "                        attention_mask=batch['attention_mask'],\n",
    "                        protein_features=batch['protein_encodings'])\n",
    "\n",
    "        # Compute loss using the criterion with class weights\n",
    "        loss = criterion(outputs, batch['labels'])\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print loss every 100 batches\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Batch {i + 1}, Loss: {loss.item()}\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    for batch in eval_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(input_ids=batch['input_ids'],\n",
    "                        attention_mask=batch['attention_mask'],\n",
    "                        protein_features=batch['protein_encodings'])\n",
    "        loss = criterion(outputs, batch['labels'])\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(eval_loader)\n",
    "    print(f\"Validation Loss: {avg_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dcb32fb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T02:01:35.656687Z",
     "iopub.status.busy": "2024-05-08T02:01:35.656306Z",
     "iopub.status.idle": "2024-05-08T02:01:35.662087Z",
     "shell.execute_reply": "2024-05-08T02:01:35.661177Z"
    },
    "papermill": {
     "duration": 0.319211,
     "end_time": "2024-05-08T02:01:35.663946",
     "exception": false,
     "start_time": "2024-05-08T02:01:35.344735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torch.optim import Adam\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# # Assuming the model, dataset, and device setup\n",
    "# model = model.to(device)  # Ensure model is on the correct device\n",
    "# optimizer = Adam(model.parameters(), lr=5e-5)  # Define optimizer\n",
    "\n",
    "# # Define DataLoader for both training and validation datasets\n",
    "# train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "# eval_loader = DataLoader(eval_dataset, batch_size=16)\n",
    "\n",
    "# # Training loop\n",
    "# num_epochs = 3  # Define the number of epochs\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     for i, batch in enumerate(train_loader):\n",
    "#         # Ensure all data in the batch is moved to the correct device\n",
    "#         batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "#         # Forward pass\n",
    "#         outputs = model(input_ids=batch['input_ids'],\n",
    "#                         attention_mask=batch['attention_mask'],\n",
    "#                         protein_features=batch['protein_encodings'])\n",
    "        \n",
    "#         # Compute loss\n",
    "#         loss = F.cross_entropy(outputs, batch['labels'])  # Assuming your model outputs raw logits\n",
    "\n",
    "#         # Backward pass\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # Print loss every 50 batches\n",
    "#         if (i + 1) % 50 == 0:\n",
    "#             print(f\"Epoch {epoch}, Batch {i + 1}, Loss: {loss.item()}\")  # Output the loss\n",
    "\n",
    "#     # Validation loop (optional, for model evaluation during training)\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         for batch in eval_loader:\n",
    "#             batch = {k: v.to(device) for k, v in batch.items()}\n",
    "#             outputs = model(input_ids=batch['input_ids'],\n",
    "#                             attention_mask=batch['attention_mask'],\n",
    "#                             protein_features=batch['protein_encodings'])\n",
    "#             loss = F.cross_entropy(outputs, batch['labels'])\n",
    "#             # Add additional code to track validation loss, accuracy, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "586fd345",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T02:01:36.289804Z",
     "iopub.status.busy": "2024-05-08T02:01:36.289449Z",
     "iopub.status.idle": "2024-05-08T02:01:36.831483Z",
     "shell.execute_reply": "2024-05-08T02:01:36.830408Z"
    },
    "papermill": {
     "duration": 0.856407,
     "end_time": "2024-05-08T02:01:36.833835",
     "exception": false,
     "start_time": "2024-05-08T02:01:35.977428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save only the state dict\n",
    "torch.save(model.state_dict(), 'model_state_dict.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd9fb53a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T02:01:37.451389Z",
     "iopub.status.busy": "2024-05-08T02:01:37.451001Z",
     "iopub.status.idle": "2024-05-08T02:01:37.998808Z",
     "shell.execute_reply": "2024-05-08T02:01:37.998015Z"
    },
    "papermill": {
     "duration": 0.861251,
     "end_time": "2024-05-08T02:01:38.001347",
     "exception": false,
     "start_time": "2024-05-08T02:01:37.140096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Save the entire model\n",
    "torch.save(model, 'entire_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d7c1fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T18:59:35.122901Z",
     "iopub.status.busy": "2024-05-05T18:59:35.122561Z",
     "iopub.status.idle": "2024-05-05T18:59:35.257471Z",
     "shell.execute_reply": "2024-05-05T18:59:35.256563Z",
     "shell.execute_reply.started": "2024-05-05T18:59:35.122877Z"
    },
    "papermill": {
     "duration": 0.306241,
     "end_time": "2024-05-08T02:01:38.616454",
     "exception": false,
     "start_time": "2024-05-08T02:01:38.310213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2c988d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T19:01:24.693101Z",
     "iopub.status.busy": "2024-05-05T19:01:24.692167Z",
     "iopub.status.idle": "2024-05-05T19:01:24.700407Z",
     "shell.execute_reply": "2024-05-05T19:01:24.699470Z",
     "shell.execute_reply.started": "2024-05-05T19:01:24.693069Z"
    },
    "papermill": {
     "duration": 0.305852,
     "end_time": "2024-05-08T02:01:39.229178",
     "exception": false,
     "start_time": "2024-05-08T02:01:38.923326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6a111d3",
   "metadata": {
    "papermill": {
     "duration": 0.311408,
     "end_time": "2024-05-08T02:01:39.976159",
     "exception": false,
     "start_time": "2024-05-08T02:01:39.664751",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebc635e",
   "metadata": {
    "papermill": {
     "duration": 0.315952,
     "end_time": "2024-05-08T02:01:40.628479",
     "exception": false,
     "start_time": "2024-05-08T02:01:40.312527",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "LOading and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df107bf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T02:01:41.248581Z",
     "iopub.status.busy": "2024-05-08T02:01:41.247809Z",
     "iopub.status.idle": "2024-05-08T02:01:41.251970Z",
     "shell.execute_reply": "2024-05-08T02:01:41.250986Z"
    },
    "papermill": {
     "duration": 0.315999,
     "end_time": "2024-05-08T02:01:41.253944",
     "exception": false,
     "start_time": "2024-05-08T02:01:40.937945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_test = pd.read_csv('/kaggle/input/leash-BELKA/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fcdb17fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T02:01:41.873714Z",
     "iopub.status.busy": "2024-05-08T02:01:41.872872Z",
     "iopub.status.idle": "2024-05-08T02:01:41.877237Z",
     "shell.execute_reply": "2024-05-08T02:01:41.876313Z"
    },
    "papermill": {
     "duration": 0.316849,
     "end_time": "2024-05-08T02:01:41.879395",
     "exception": false,
     "start_time": "2024-05-08T02:01:41.562546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "96e04ed8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T02:01:42.499670Z",
     "iopub.status.busy": "2024-05-08T02:01:42.499297Z",
     "iopub.status.idle": "2024-05-08T02:01:42.503537Z",
     "shell.execute_reply": "2024-05-08T02:01:42.502611Z"
    },
    "papermill": {
     "duration": 0.317376,
     "end_time": "2024-05-08T02:01:42.505349",
     "exception": false,
     "start_time": "2024-05-08T02:01:42.187973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Assuming df_test is your test DataFrame with similar columns as df_train except 'binds'\n",
    "# test_encodings = tokenizer(df_test['molecule_smiles'].tolist(), truncation=True, padding=True, max_length=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4535e702",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T02:01:43.123854Z",
     "iopub.status.busy": "2024-05-08T02:01:43.122867Z",
     "iopub.status.idle": "2024-05-08T02:01:43.127264Z",
     "shell.execute_reply": "2024-05-08T02:01:43.126380Z"
    },
    "papermill": {
     "duration": 0.316681,
     "end_time": "2024-05-08T02:01:43.129175",
     "exception": false,
     "start_time": "2024-05-08T02:01:42.812494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_dataset = SMILESTestDataset(test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4c1c44c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T02:01:43.750151Z",
     "iopub.status.busy": "2024-05-08T02:01:43.749796Z",
     "iopub.status.idle": "2024-05-08T02:01:43.754133Z",
     "shell.execute_reply": "2024-05-08T02:01:43.753206Z"
    },
    "papermill": {
     "duration": 0.316171,
     "end_time": "2024-05-08T02:01:43.756107",
     "exception": false,
     "start_time": "2024-05-08T02:01:43.439936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Predict\n",
    "# predictions = trainer.predict(test_dataset)\n",
    "\n",
    "# # The predictions object includes a predictions array, label_ids array (if available), and metrics (if labels provided during prediction)\n",
    "# pred_labels = predictions.predictions.argmax(-1)  # We use argmax to convert from logits to class labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0555514f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T02:01:44.409809Z",
     "iopub.status.busy": "2024-05-08T02:01:44.409143Z",
     "iopub.status.idle": "2024-05-08T02:01:44.413443Z",
     "shell.execute_reply": "2024-05-08T02:01:44.412472Z"
    },
    "papermill": {
     "duration": 0.339281,
     "end_time": "2024-05-08T02:01:44.415626",
     "exception": false,
     "start_time": "2024-05-08T02:01:44.076345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_test['predicted_binds'] = pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1cc0d89e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T02:01:45.078032Z",
     "iopub.status.busy": "2024-05-08T02:01:45.077423Z",
     "iopub.status.idle": "2024-05-08T02:01:45.082493Z",
     "shell.execute_reply": "2024-05-08T02:01:45.081429Z"
    },
    "papermill": {
     "duration": 0.34609,
     "end_time": "2024-05-08T02:01:45.084615",
     "exception": false,
     "start_time": "2024-05-08T02:01:44.738525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Saving the DataFrame with predictions to a new CSV file\n",
    "# df_test.to_csv('test_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9d6591",
   "metadata": {
    "papermill": {
     "duration": 0.313872,
     "end_time": "2024-05-08T02:01:45.717657",
     "exception": false,
     "start_time": "2024-05-08T02:01:45.403785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8006601,
     "sourceId": 67356,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 33014.530781,
   "end_time": "2024-05-08T02:01:49.623708",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-07T16:51:35.092927",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "07c8f93394664355b3f7941c624d8eda": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6e637df95e644ef4ac4bd16eea09af41",
       "placeholder": "​",
       "style": "IPY_MODEL_68b35c7c31b74bc8b2d458158825ade0",
       "value": " 165k/165k [00:00&lt;00:00, 417kB/s]"
      }
     },
     "0a0fd0558f6d4765bf5a97c52dbe0cac": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0b2b6a8bec8d4f9e835b133c5494b4d3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0c18627bafcc4081bee1893cbba14b01": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0fa81794de8146e2a237f512c2750b0f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "13328f8c95324769a75951d51e4eabdc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2bfac6abe34d4538a1233c5cb1ccbf90",
       "placeholder": "​",
       "style": "IPY_MODEL_2c70eeea4681414a9ed9152cfd8118a4",
       "value": "tokenizer_config.json: 100%"
      }
     },
     "14e753c7336e44c0b12c1b32da66eed3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "17655cef8bf54524a7f500d83ff78e59": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f9ce1d59d90746a898a8267fcfa7b185",
       "placeholder": "​",
       "style": "IPY_MODEL_f8865cc4703d49e1b30f03c312c97cf5",
       "value": "config.json: 100%"
      }
     },
     "1aaa17ba473b447f8e0f9e9c58647401": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1ae3040e08c14595b598e23729fb747c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1ccfd4330ff7418cb18139f4aa189aab": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1df18add0dbd4a8e832aaf4b0b2f2e3a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ebfa58359dfb4796b357655380610e12",
       "max": 772.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e0d4c146f7124ba5b005329e4f49b386",
       "value": 772.0
      }
     },
     "22c43c9adda1415f8eac187ea8c5baa8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "252cf71ec78e450fb96a4b5093107eef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2bfac6abe34d4538a1233c5cb1ccbf90": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2c70eeea4681414a9ed9152cfd8118a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2ce31f8009c34e0ba5a64560346097e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_84511933663746cbbecadb99664f630f",
       "max": 515.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6b4d8ade86d24c27881918ada30c5ef9",
       "value": 515.0
      }
     },
     "32d7c461c2884d0ea808fb443391f1c6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3a34d02e6b05498da4ca962ee79893de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_13328f8c95324769a75951d51e4eabdc",
        "IPY_MODEL_d01788caf33c4b5194dd116ebb837e3e",
        "IPY_MODEL_612dac6541434e1c94d3efa7b6659137"
       ],
       "layout": "IPY_MODEL_252cf71ec78e450fb96a4b5093107eef"
      }
     },
     "3f721594f24b428aaf78472e1c5c9d41": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "409325c1b3344fa48678f7221ba4e45f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9de2b8721acd4373839e50448656e5d9",
        "IPY_MODEL_ce1cdecedeae4a41834555140949a064",
        "IPY_MODEL_7fd576220a95471ea9b0f1dc3bfe38e3"
       ],
       "layout": "IPY_MODEL_6e1b04be101443dca2ef61c1bc8cce0d"
      }
     },
     "49cf8987e7f44ca2ba2f4425d22ef0ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4a475c236a714b1e88101d61fc5c9e40": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_17655cef8bf54524a7f500d83ff78e59",
        "IPY_MODEL_2ce31f8009c34e0ba5a64560346097e7",
        "IPY_MODEL_de23308fd4814358bd104216270ea458"
       ],
       "layout": "IPY_MODEL_e8e8021ce16c452e8536791d9c46e3b8"
      }
     },
     "4ce6af1dc0204f08ba6d8c4627d40455": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_db3c3364ec8b4bfb8a8f2459b345449d",
       "placeholder": "​",
       "style": "IPY_MODEL_5d93d821cefc45fb870ede5b619bc085",
       "value": "special_tokens_map.json: 100%"
      }
     },
     "5d93d821cefc45fb870ede5b619bc085": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "612dac6541434e1c94d3efa7b6659137": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_702e36139b8248029b94081f11662aff",
       "placeholder": "​",
       "style": "IPY_MODEL_dafef2a630234f48b17c1befbade56ca",
       "value": " 62.0/62.0 [00:00&lt;00:00, 2.83kB/s]"
      }
     },
     "68b35c7c31b74bc8b2d458158825ade0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6b4d8ade86d24c27881918ada30c5ef9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6e1b04be101443dca2ef61c1bc8cce0d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6e637df95e644ef4ac4bd16eea09af41": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "702e36139b8248029b94081f11662aff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "72957c4821f942c0995189df67300e30": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e895ea6baf6644dfaf108aa927f8fa2e",
       "placeholder": "​",
       "style": "IPY_MODEL_b4835cec129b4973aefc9d9b5d47a490",
       "value": "vocab.json: 100%"
      }
     },
     "745c039d8389407bba03d86a9b61c26a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "76a466c44f224eed8699e5a251382a4f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7fd576220a95471ea9b0f1dc3bfe38e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0a0fd0558f6d4765bf5a97c52dbe0cac",
       "placeholder": "​",
       "style": "IPY_MODEL_fc91fa4862f344d9a01c301759723e4a",
       "value": " 101k/101k [00:00&lt;00:00, 7.91MB/s]"
      }
     },
     "811628c1449443b1883a570c7e8046b7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1ae3040e08c14595b598e23729fb747c",
       "placeholder": "​",
       "style": "IPY_MODEL_83e939586a384bc98522b89de4a8292f",
       "value": " 336M/336M [00:04&lt;00:00, 76.6MB/s]"
      }
     },
     "83e939586a384bc98522b89de4a8292f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "84511933663746cbbecadb99664f630f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "87684d328adb4a04bbfd0db67c3ee931": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4ce6af1dc0204f08ba6d8c4627d40455",
        "IPY_MODEL_1df18add0dbd4a8e832aaf4b0b2f2e3a",
        "IPY_MODEL_af6afe7924cd442b9e9f8cd9e5deb3be"
       ],
       "layout": "IPY_MODEL_1ccfd4330ff7418cb18139f4aa189aab"
      }
     },
     "887e39e24dc045108fcb92140e220c98": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dfabed2e206e45c6b6e8d8ce919efea1",
       "placeholder": "​",
       "style": "IPY_MODEL_0fa81794de8146e2a237f512c2750b0f",
       "value": "pytorch_model.bin: 100%"
      }
     },
     "8bcca539cdca4d92b5a35c080bc6b91f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "92b582bcf1ff40fdbecb3a08c3966481": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0b2b6a8bec8d4f9e835b133c5494b4d3",
       "max": 336422980.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_745c039d8389407bba03d86a9b61c26a",
       "value": 336422980.0
      }
     },
     "9de2b8721acd4373839e50448656e5d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_32d7c461c2884d0ea808fb443391f1c6",
       "placeholder": "​",
       "style": "IPY_MODEL_dfc51258010f49e98e10ab1e925a5dab",
       "value": "merges.txt: 100%"
      }
     },
     "af6afe7924cd442b9e9f8cd9e5deb3be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1aaa17ba473b447f8e0f9e9c58647401",
       "placeholder": "​",
       "style": "IPY_MODEL_76a466c44f224eed8699e5a251382a4f",
       "value": " 772/772 [00:00&lt;00:00, 69.5kB/s]"
      }
     },
     "b287ce03eaa14696b20dfb9869efe636": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_887e39e24dc045108fcb92140e220c98",
        "IPY_MODEL_92b582bcf1ff40fdbecb3a08c3966481",
        "IPY_MODEL_811628c1449443b1883a570c7e8046b7"
       ],
       "layout": "IPY_MODEL_3f721594f24b428aaf78472e1c5c9d41"
      }
     },
     "b4835cec129b4973aefc9d9b5d47a490": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ba530ec8212f4921876cf335a8f912e8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c313a402618a405facff79f440a3092c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_72957c4821f942c0995189df67300e30",
        "IPY_MODEL_e07ac23acbe34b36a51162c59c40a478",
        "IPY_MODEL_07c8f93394664355b3f7941c624d8eda"
       ],
       "layout": "IPY_MODEL_ba530ec8212f4921876cf335a8f912e8"
      }
     },
     "ce1cdecedeae4a41834555140949a064": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8bcca539cdca4d92b5a35c080bc6b91f",
       "max": 101307.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f463d6c2facf4432abaf2a038133b0ff",
       "value": 101307.0
      }
     },
     "ce43dc84fd4945c197378a75c44a7b9c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d01788caf33c4b5194dd116ebb837e3e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_22c43c9adda1415f8eac187ea8c5baa8",
       "max": 62.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_49cf8987e7f44ca2ba2f4425d22ef0ed",
       "value": 62.0
      }
     },
     "dafef2a630234f48b17c1befbade56ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "db3c3364ec8b4bfb8a8f2459b345449d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "de23308fd4814358bd104216270ea458": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ce43dc84fd4945c197378a75c44a7b9c",
       "placeholder": "​",
       "style": "IPY_MODEL_e2fa5497a7e846a7baeabff3bdc31ef2",
       "value": " 515/515 [00:00&lt;00:00, 41.9kB/s]"
      }
     },
     "dfabed2e206e45c6b6e8d8ce919efea1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dfc51258010f49e98e10ab1e925a5dab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e07ac23acbe34b36a51162c59c40a478": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0c18627bafcc4081bee1893cbba14b01",
       "max": 164540.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_14e753c7336e44c0b12c1b32da66eed3",
       "value": 164540.0
      }
     },
     "e0d4c146f7124ba5b005329e4f49b386": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e2fa5497a7e846a7baeabff3bdc31ef2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e895ea6baf6644dfaf108aa927f8fa2e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e8e8021ce16c452e8536791d9c46e3b8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ebfa58359dfb4796b357655380610e12": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f463d6c2facf4432abaf2a038133b0ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f8865cc4703d49e1b30f03c312c97cf5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f9ce1d59d90746a898a8267fcfa7b185": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fc91fa4862f344d9a01c301759723e4a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
